{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2b29402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working copy: When2Call/data/test/when2call_test_llm_judge.WORKING_COPY.style_concise.jsonl\n",
      "Target: When2Call/data/test/when2call_test_llm_judge.WORKING_COPY.style_concise.jsonl\n",
      "Mode: style_concise\n",
      "Audit file (RESUMABLE): audit/1e8922187545/when2call_test_llm_judge.WORKING_COPY.style_concise.1e8922187545.style_concise.gemini-2.5-flash.K2.audit.jsonl\n",
      "Tool occurrences total: 978\n",
      "Resume position: [1/978] (previously reviewed: 0)\n",
      "LLM: gemini-2.5-flash @ https://generativelanguage.googleapis.com/v1beta/openai/\n",
      "Candidates per tool: 2\n",
      "Candidate snippet chars: 160\n",
      "Policies: risk=risk_policy_v2_structural_logic_primary; logic=logic_tokens_v1; semantic=semantic_signals_v1\n",
      "Perturbation prints: enabled\n",
      "Raw key input (Esc-safe): enabled\n",
      "Embedding signal: disabled\n",
      "Verifier signal: disabled\n",
      "Concise soft target: ratio=0.70, min_base_len=160, min_chars=80\n",
      "Max tokens: 512; retry_on_length=True; retry_max_tokens=1024\n",
      "Commands: ENTER/ok=accept #1, 1..K=accept candidate, r=regenerate K, e=edit candidate, m=manual, s=skip, q/Esc=quit, p<idx>=preview (e.g., p2)\n",
      "\n",
      "================================================================================\n",
      "[1/978] api_token_api.APITokenApi.get_api_tokens\n",
      "instance_key: rec:a7e1784f346e3c8cc2927162d99b44e4:t0:d98b602aebd0833d5b32d0e6f5945bb8 (record_id=a7e1784f346e3c8cc2927162d99b44e4, tool_index=0)\n",
      "Current description RAW (escaped):\n",
      "\"Retrieve a list of API tokens associated with the user's account.\"\n",
      "\n",
      "Current description DECODED:\n",
      "Retrieve a list of API tokens associated with the user's account.\n",
      "\n",
      "Statistics (base):\n",
      "  chars=65; words=11; sentences=1\n",
      "  tokens: flags=0, field_like=0, numbers=0, number_units=0, verbs=1, snake=0, camel=0, logic=0, modals=0, scope=0\n",
      "  previews: flags=[-]; field_like=[-]; numbers=[-]; verbs=[retrieve]; logic=[-]; modals=[-]; scope=[-]\n",
      "Concise soft target (not applied): reason=base_too_short (base_len=65)\n",
      "\n",
      "  [gen] api_token_api.APITokenApi.get_api_tokens | cand 1/2 | round=0 | regen_index=0 | mode=style_concise | seed=None | max_tokens=512\n",
      "      length_guidance: soft_target not applied (reason=base_too_short)\n",
      "\n",
      "  [gen] api_token_api.APITokenApi.get_api_tokens | cand 2/2 | round=0 | regen_index=1 | mode=style_concise | seed=None | max_tokens=512\n",
      "      length_guidance: soft_target not applied (reason=base_too_short)\n",
      "      diversity_instruction: A different paraphrase is required than the previous rewrite. The same sentence skeleton or distinctive phrases must not be reused. Meaning must remain exactly the same; only wording and structure may vary.\n",
      "      previous_rewrite_hint: len=54 sha=aca2485b350d snippet='Retrieves a list of API tokens for the user's account.'\n",
      "\n",
      "Candidates overview:\n",
      "  [1] status=ok; risk=LOW; sim=0.86; emb=-; ent=-; cand(chars=54, words=10, sent=1); len_ratio=0.83; Δchars=-11; -; new(flags=0, fields=0, nums=0, snake=0, camel=0, logic=0, verbs=0); missing_total=1\n",
      "      text: Retrieves a list of API tokens for the user's account.\n",
      "  [2] status=ok; risk=LOW; sim=0.63; emb=-; ent=-; cand(chars=56, words=10, sent=1); len_ratio=0.86; Δchars=-9; -; new(flags=0, fields=0, nums=0, snake=0, camel=0, logic=0, verbs=0); missing_total=1\n",
      "      text: Obtains the API token list linked to the user's account.\n",
      "\n",
      "Changes applied.\n",
      "Mode: style_concise\n",
      "Candidates per tool: 2\n",
      "Candidate snippet chars: 160\n",
      "Perturbation prints: enabled\n",
      "Raw key input (Esc-safe): enabled\n",
      "Descriptions updated (this session): 0\n",
      "Reviewed total (from audit): 0 / 978\n",
      "Completed: False (quit_requested=True)\n",
      "Resume next time from: [1/978]\n",
      "Updated file: When2Call/data/test/when2call_test_llm_judge.WORKING_COPY.style_concise.jsonl\n",
      "Audit file (same on resume): audit/1e8922187545/when2call_test_llm_judge.WORKING_COPY.style_concise.1e8922187545.style_concise.gemini-2.5-flash.K2.audit.jsonl\n",
      "\n",
      "Session summary (heuristic):\n",
      "  accepted=0, edited=0, manual=0, skipped=0\n",
      "  accepted_risk_labels={'LOW': 0, 'MED': 0, 'HIGH': 0, 'NA': 0}\n",
      "  accepted_soft_target: applicable=0, within=0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# 3 Feb 2026\n",
    "#\n",
    "# Interactive, resumable tool-description rewrite workflow with:\n",
    "# - K-candidate generation per tool instance (configurable)\n",
    "# - Deterministic statistical/lexical risk indicators printed alongside base and candidates\n",
    "# - Human-in-the-loop decision (accept candidate, edit, manual, skip), with append-only audit log\n",
    "#\n",
    "# Additions (Jan 21 test):\n",
    "# - Candidate text snippet shown in the overview, so selection can occur without extra commands.\n",
    "# - Explicit preview command documented: p<idx> (e.g., p2) prints the full candidate + stats.\n",
    "#\n",
    "# Additions (Concise soft length target, reviewer-proof):\n",
    "# - Optional soft length target for style_concise: default 30% shorter, applied only if base_len >= threshold.\n",
    "# - The target is guidance only (exceptions allowed to preserve meaning); out-of-target is flagged and logged.\n",
    "# - Length metrics (len_ratio, len_delta) are computed for every candidate and stored in audit for reporting.\n",
    "#\n",
    "# Additions (Semantic drift hardening, v2):\n",
    "# - Logic/negation/quantifier/modal/scope tokens extracted and diffed (beyond purely lexical patterns).\n",
    "# - Risk scoring adjusted: verbs treated as secondary; structural+logic tokens treated as primary.\n",
    "# - Optional semantic signals:\n",
    "#   - Embedding cosine similarity (best-effort; depends on provider support for embeddings endpoint).\n",
    "#   - LLM entailment verifier returning ENTAILS / NOT_ENTAILS (disabled by default).\n",
    "#\n",
    "# Additions (Feb 3 patch):\n",
    "# - \"Perturbations\" visibility: print candidate-generation perturbation context to stdout during generation.\n",
    "# - ESC behavior: raw-key command input on TTY so Esc behaves like quit (q) and never \"accepts\" accidentally.\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "import difflib\n",
    "import re\n",
    "import math\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional, Tuple, List\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# ========= Config =========\n",
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "LLM_MODEL_DEFAULT = \"gemini-2.5-flash\"\n",
    "\n",
    "HASH_HEX_LEN = 32\n",
    "\n",
    "DEFAULT_MAX_TOKENS = 512\n",
    "RETRY_ON_LENGTH = True\n",
    "RETRY_MAX_TOKENS = 1024\n",
    "\n",
    "DEFAULT_ALLOW_RESERIALIZE_FALLBACK = False\n",
    "\n",
    "# How much of the last generated candidate to store in audit and to feed back into prompt.\n",
    "DEFAULT_MAX_PREV_REWRITE_CHARS = 800\n",
    "\n",
    "# Candidate count shown per tool instance.\n",
    "DEFAULT_NUM_CANDIDATES = 2\n",
    "\n",
    "# Printing controls for token previews in statistics.\n",
    "DEFAULT_MAX_TOKEN_PREVIEW = 8\n",
    "DEFAULT_MAX_TOKEN_STRING_LEN = 48\n",
    "\n",
    "# Candidate text snippet in overview (chars).\n",
    "DEFAULT_CANDIDATE_SNIPPET_CHARS = 160\n",
    "\n",
    "# Soft concise length target knobs (reviewer-proof defaults).\n",
    "DEFAULT_CONCISE_TARGET_RATIO = 0.70\n",
    "DEFAULT_CONCISE_TARGET_MIN_BASE_LEN = 160\n",
    "DEFAULT_CONCISE_TARGET_MIN_CHARS = 80\n",
    "\n",
    "# Semantic signals (disabled by default).\n",
    "DEFAULT_ENABLE_EMBEDDINGS = False\n",
    "DEFAULT_EMBEDDING_MODEL = \"\"  # Provider-dependent; empty means \"unset\".\n",
    "DEFAULT_EMBEDDING_LOW_COSINE_THRESHOLD = 0.85\n",
    "\n",
    "DEFAULT_ENABLE_VERIFIER = False\n",
    "DEFAULT_VERIFIER_MODEL = \"\"  # Empty means \"use llm_model\".\n",
    "DEFAULT_VERIFIER_MAX_TOKENS = 16\n",
    "\n",
    "# Visibility knobs (Feb 3 patch).\n",
    "DEFAULT_SHOW_PERTURBATIONS = True   # Prints perturbation context during candidate generation.\n",
    "DEFAULT_RAW_KEY_INPUT = True        # Enables raw-key command input on TTY so Esc can be captured.\n",
    "\n",
    "# Policy versioning for audit identity and reporting.\n",
    "RISK_POLICY_NAME = \"risk_policy_v2_structural_logic_primary\"\n",
    "LOGIC_TOKEN_POLICY_NAME = \"logic_tokens_v1\"\n",
    "SEMANTIC_POLICY_NAME = \"semantic_signals_v1\"\n",
    "\n",
    "\n",
    "# ========= Styles =========\n",
    "STYLE_SPECS: Dict[str, Dict[str, Any]] = {\n",
    "    \"style_verbose\": {\n",
    "        \"system\": (\n",
    "            \"Task: rewrite tool descriptions.\\n\"\n",
    "            \"Hard constraints:\\n\"\n",
    "            \"- Meaning must be preserved exactly; no new capabilities, steps, motivations, benefits, or context.\\n\"\n",
    "            \"- No information present in the original description may be deleted.\\n\"\n",
    "            \"- No new parameter names, IDs, field names, flags, or implementation details may be introduced.\\n\"\n",
    "            \"- If parameter/field names/IDs/flags already appear in the original description, they must be kept.\\n\"\n",
    "            \"- No examples, normative language, or assumptions.\\n\"\n",
    "            \"- The subject (the tool) and scope must remain unchanged.\\n\"\n",
    "            \"- Output must be only the rewritten description text, nothing else.\\n\"\n",
    "            \"- Style: verbose but controlled; concise and complete (1–2 sentences), clear and direct.\\n\"\n",
    "        ),\n",
    "        \"regen_diversity_instruction\": (\n",
    "            \"A meaning-equivalent rewrite is required with lexical and syntactic variation from the previous rewrite; \"\n",
    "            \"the same sentence structure should be avoided.\"\n",
    "        ),\n",
    "        \"max_prev_rewrite_chars\": 800,\n",
    "    },\n",
    "    \"style_concise\": {\n",
    "        \"system\": (\n",
    "            \"Task: rewrite tool descriptions.\\n\"\n",
    "            \"Hard constraints:\\n\"\n",
    "            \"- Meaning must be preserved exactly; no new capabilities, steps, motivations, benefits, or context.\\n\"\n",
    "            \"- No information present in the original description may be deleted.\\n\"\n",
    "            \"- No new parameter names, IDs, field names, flags, or implementation details may be introduced.\\n\"\n",
    "            \"- If parameter/field names/IDs/flags already appear in the original description, they must be kept.\\n\"\n",
    "            \"- No examples, normative language, or assumptions.\\n\"\n",
    "            \"- The subject (the tool) and scope must remain unchanged.\\n\"\n",
    "            \"- Output must be only the rewritten description text, nothing else.\\n\"\n",
    "            \"- Style: concise and controlled; 1 sentence preferred, 2 max.\\n\"\n",
    "            \"- Length constraint: shorter than the base description is preferred; if the base description is already short, the rewrite must not exceed its length.\\n\"\n",
    "            \"- Compression rule: remove redundancy, filler, and hedging while preserving all explicitly stated constraints/details.\\n\"\n",
    "        ),\n",
    "        \"regen_diversity_instruction\": (\n",
    "            \"A different paraphrase is required than the previous rewrite. \"\n",
    "            \"The same sentence skeleton or distinctive phrases must not be reused. \"\n",
    "            \"Meaning must remain exactly the same; only wording and structure may vary.\"\n",
    "        ),\n",
    "        \"max_prev_rewrite_chars\": 600,\n",
    "    },\n",
    "    # Alias to tolerate misspellings.\n",
    "    \"style_coicnoso\": {},   # filled after dict creation\n",
    "    \"style_coinceise\": {},  # filled after dict creation\n",
    "}\n",
    "STYLE_SPECS[\"style_coicnoso\"] = STYLE_SPECS[\"style_concise\"]\n",
    "STYLE_SPECS[\"style_coinceise\"] = STYLE_SPECS[\"style_concise\"]\n",
    "\n",
    "\n",
    "def _resolve_style(mode_key: str) -> Tuple[str, Dict[str, Any]]:\n",
    "    mk = (mode_key or \"\").strip()\n",
    "    if not mk:\n",
    "        mk = \"style_verbose\"\n",
    "    if mk not in STYLE_SPECS:\n",
    "        raise ValueError(f\"Unknown MODE_KEY='{mk}'. Supported: {', '.join(sorted(STYLE_SPECS.keys()))}\")\n",
    "    return mk, STYLE_SPECS[mk]\n",
    "\n",
    "\n",
    "# ========= Client =========\n",
    "def make_gemini_client() -> OpenAI:\n",
    "    token = os.environ.get(\"TOKEN_GEMINI\")\n",
    "    if not token:\n",
    "        raise RuntimeError(\"TOKEN_GEMINI environment variable is not set.\")\n",
    "    return OpenAI(api_key=token, base_url=GEMINI_BASE_URL)\n",
    "\n",
    "\n",
    "# ========= Small utils =========\n",
    "def _json_safe(obj: Any) -> Any:\n",
    "    if obj is None or isinstance(obj, (str, int, float, bool)):\n",
    "        return obj\n",
    "    if isinstance(obj, dict):\n",
    "        return {str(k): _json_safe(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return [_json_safe(x) for x in obj]\n",
    "    if hasattr(obj, \"model_dump\") and callable(getattr(obj, \"model_dump\")):\n",
    "        try:\n",
    "            return _json_safe(obj.model_dump())\n",
    "        except Exception:\n",
    "            pass\n",
    "    if hasattr(obj, \"dict\") and callable(getattr(obj, \"dict\")):\n",
    "        try:\n",
    "            return _json_safe(obj.dict())\n",
    "        except Exception:\n",
    "            pass\n",
    "    if hasattr(obj, \"__dict__\"):\n",
    "        try:\n",
    "            return _json_safe(vars(obj))\n",
    "        except Exception:\n",
    "            pass\n",
    "    try:\n",
    "        return str(obj)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def _sha256_text(s: str) -> str:\n",
    "    return hashlib.sha256((s or \"\").encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "def _canonical_json(obj: Any) -> str:\n",
    "    return json.dumps(obj, ensure_ascii=False, sort_keys=True, separators=(\",\", \":\"))\n",
    "\n",
    "\n",
    "def _sha256_file(path: Path) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with path.open(\"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(1024 * 1024), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "\n",
    "def _safe_int_env(name: str, default: int) -> int:\n",
    "    v = os.environ.get(name)\n",
    "    if v is None or not v.strip():\n",
    "        return int(default)\n",
    "    try:\n",
    "        return int(v.strip())\n",
    "    except Exception:\n",
    "        return int(default)\n",
    "\n",
    "\n",
    "def _safe_float_env(name: str, default: float) -> float:\n",
    "    v = os.environ.get(name)\n",
    "    if v is None or not v.strip():\n",
    "        return float(default)\n",
    "    try:\n",
    "        return float(v.strip())\n",
    "    except Exception:\n",
    "        return float(default)\n",
    "\n",
    "\n",
    "def _safe_bool_env(name: str, default: bool) -> bool:\n",
    "    v = os.environ.get(name)\n",
    "    if v is None or not v.strip():\n",
    "        return bool(default)\n",
    "    s = v.strip().lower()\n",
    "    if s in (\"1\", \"true\", \"t\", \"yes\", \"y\", \"on\"):\n",
    "        return True\n",
    "    if s in (\"0\", \"false\", \"f\", \"no\", \"n\", \"off\"):\n",
    "        return False\n",
    "    return bool(default)\n",
    "\n",
    "\n",
    "# ========= Raw-key command input (Esc-safe) =========\n",
    "def _read_command_raw_tty(prompt: str, *, k: int) -> str:\n",
    "    \"\"\"\n",
    "    Reads a short command using raw keypress input on TTY.\n",
    "    - Enter returns the accumulated buffer (possibly empty).\n",
    "    - Esc returns '\\x1b' immediately (caller maps it to quit).\n",
    "    - Backspace edits the buffer.\n",
    "    - For k<=9, numeric selection is returned immediately when it becomes unambiguous.\n",
    "    \"\"\"\n",
    "    # Defer imports so non-TTY / non-Unix runs remain usable.\n",
    "    try:\n",
    "        import termios\n",
    "        import tty\n",
    "    except Exception:\n",
    "        # Fall back to line input if raw mode is unavailable.\n",
    "        return input(prompt)\n",
    "\n",
    "    fd = sys.stdin.fileno()\n",
    "    old = termios.tcgetattr(fd)\n",
    "    buf = \"\"\n",
    "\n",
    "    immediate_digits = (int(k) <= 9)\n",
    "\n",
    "    def echo(s: str) -> None:\n",
    "        sys.stdout.write(s)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    echo(prompt)\n",
    "\n",
    "    try:\n",
    "        tty.setraw(fd)\n",
    "        while True:\n",
    "            ch = sys.stdin.read(1)\n",
    "\n",
    "            # Enter\n",
    "            if ch in (\"\\r\", \"\\n\"):\n",
    "                echo(\"\\n\")\n",
    "                return buf\n",
    "\n",
    "            # Esc\n",
    "            if ch == \"\\x1b\":\n",
    "                echo(\"\\n\")\n",
    "                return \"\\x1b\"\n",
    "\n",
    "            # Backspace / delete\n",
    "            if ch in (\"\\x7f\", \"\\b\"):\n",
    "                if buf:\n",
    "                    buf = buf[:-1]\n",
    "                    echo(\"\\b \\b\")\n",
    "                continue\n",
    "\n",
    "            # Ignore other control chars.\n",
    "            if not ch.isprintable():\n",
    "                continue\n",
    "\n",
    "            # Append printable char and echo.\n",
    "            buf += ch\n",
    "            echo(ch)\n",
    "\n",
    "            low = buf.strip().lower()\n",
    "\n",
    "            # If user typed a single-letter command, return immediately.\n",
    "            if low in (\"r\", \"e\", \"m\", \"s\", \"q\", \"y\"):\n",
    "                echo(\"\\n\")\n",
    "                return low\n",
    "\n",
    "            # Preview shortcut: p<idx> (only immediate if k<=9 and idx is single-digit).\n",
    "            if immediate_digits and low.startswith(\"p\") and len(low) == 2 and low[1].isdigit():\n",
    "                vi = int(low[1])\n",
    "                if 1 <= vi <= int(k):\n",
    "                    echo(\"\\n\")\n",
    "                    return low\n",
    "\n",
    "            # Numeric selection (only immediate for k<=9 to avoid ambiguity like \"10\").\n",
    "            if immediate_digits and len(low) == 1 and low.isdigit():\n",
    "                vi = int(low)\n",
    "                if 1 <= vi <= int(k):\n",
    "                    echo(\"\\n\")\n",
    "                    return low\n",
    "\n",
    "    finally:\n",
    "        termios.tcsetattr(fd, termios.TCSADRAIN, old)\n",
    "\n",
    "\n",
    "def _read_command(prompt: str, *, k: int, raw_key_input: bool) -> str:\n",
    "    \"\"\"\n",
    "    Reads a command from the user.\n",
    "    - If raw_key_input is enabled and stdin is a TTY, uses raw keypress mode to capture Esc.\n",
    "    - Otherwise, falls back to line-based input().\n",
    "    \"\"\"\n",
    "    if raw_key_input and sys.stdin.isatty():\n",
    "        try:\n",
    "            return _read_command_raw_tty(prompt, k=int(k))\n",
    "        except Exception:\n",
    "            # Safe fallback.\n",
    "            return input(prompt)\n",
    "    return input(prompt)\n",
    "\n",
    "\n",
    "# ========= Concise soft target (policy) =========\n",
    "def _make_length_policy(\n",
    "    *,\n",
    "    base_desc: str,\n",
    "    mode_key: str,\n",
    "    concise_ratio: float,\n",
    "    concise_min_base_len: int,\n",
    "    concise_min_chars: int,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Returns a policy object (always present) used for:\n",
    "    - prompt guidance (soft target)\n",
    "    - stats (len_ratio, within_target)\n",
    "    - audit reporting\n",
    "\n",
    "    Soft target is applied only if:\n",
    "    - mode_key == style_concise\n",
    "    - base_len >= concise_min_base_len\n",
    "    - computed target is strictly shorter than base_len\n",
    "    \"\"\"\n",
    "    base = (base_desc or \"\").strip()\n",
    "    base_len = len(base)\n",
    "\n",
    "    ratio = float(concise_ratio)\n",
    "    min_base_len = int(concise_min_base_len)\n",
    "    min_chars = int(concise_min_chars)\n",
    "\n",
    "    reason = \"not_concise_mode\"\n",
    "    applied = False\n",
    "    target_chars: Optional[int] = None\n",
    "\n",
    "    if mode_key == \"style_concise\":\n",
    "        if base_len < min_base_len or base_len <= 0:\n",
    "            reason = \"base_too_short\"\n",
    "        else:\n",
    "            raw_target = int(base_len * ratio)\n",
    "            candidate_target = max(raw_target, min_chars)\n",
    "            # If env is mis-set (min_chars > base), do not apply a target that would exceed base.\n",
    "            if candidate_target >= base_len:\n",
    "                reason = \"target_not_shorter_than_base\"\n",
    "            else:\n",
    "                applied = True\n",
    "                reason = \"ok\"\n",
    "                target_chars = candidate_target\n",
    "\n",
    "    return {\n",
    "        \"policy_name\": \"concise_soft_target_v1\",\n",
    "        \"mode_key\": mode_key,\n",
    "        \"base_len_chars\": base_len,\n",
    "        \"concise_soft_target\": {\n",
    "            \"applied\": bool(applied),\n",
    "            \"reason\": str(reason),\n",
    "            \"target_ratio\": float(ratio),\n",
    "            \"min_base_len\": int(min_base_len),\n",
    "            \"min_chars\": int(min_chars),\n",
    "            \"target_chars\": int(target_chars) if isinstance(target_chars, int) else None,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "# ========= Statistical / lexical indicators =========\n",
    "_FLAG_RE = re.compile(r\"(?<!\\w)--[A-Za-z0-9][A-Za-z0-9_-]*\")\n",
    "_SNAKE_RE = re.compile(r\"\\b[A-Za-z][A-Za-z0-9]*_[A-Za-z0-9_]+\\b\")\n",
    "_CAMEL_RE = re.compile(r\"\\b[a-z]+[A-Z][A-Za-z0-9]*\\b\")\n",
    "_FIELD_COLON_RE = re.compile(r\"\\b[A-Za-z][A-Za-z0-9_]{2,}\\b(?=\\s*[:=])\")\n",
    "_NUMBER_RE = re.compile(r\"\\b\\d+(?:\\.\\d+)?\\b\")\n",
    "_NUMBER_UNIT_RE = re.compile(\n",
    "    r\"\\b\\d+(?:\\.\\d+)?\\s*(?:kb|mb|gb|tb|ms|s|sec|secs|seconds|mins|minutes|hrs|hours|days)\\b\",\n",
    "    re.IGNORECASE,\n",
    ")\n",
    "\n",
    "_HIGH_RISK_VERBS = [\n",
    "    \"create\", \"delete\", \"remove\", \"destroy\",\n",
    "    \"upload\", \"download\", \"send\", \"email\",\n",
    "    \"execute\", \"run\", \"invoke\", \"call\",\n",
    "    \"write\", \"read\", \"save\", \"store\",\n",
    "    \"update\", \"modify\", \"edit\", \"change\",\n",
    "    \"retrieve\", \"fetch\", \"search\", \"browse\",\n",
    "    \"access\", \"open\", \"close\",\n",
    "    \"return\", \"returns\",\n",
    "]\n",
    "_VERB_RE = re.compile(r\"\\b(\" + \"|\".join(re.escape(v) for v in _HIGH_RISK_VERBS) + r\")\\b\", re.IGNORECASE)\n",
    "\n",
    "_LOGIC_WORDS = {\n",
    "    \"only\", \"must\", \"never\", \"not\", \"no\", \"unless\", \"except\",\n",
    "    \"required\", \"optional\",\n",
    "    \"cannot\", \"can't\",\n",
    "}\n",
    "\n",
    "_LOGIC_PHRASES = [\n",
    "    \"at least\",\n",
    "    \"at most\",\n",
    "    \"up to\",\n",
    "    \"no more than\",\n",
    "    \"no less than\",\n",
    "    \"do not\",\n",
    "    \"does not\",\n",
    "    \"did not\",\n",
    "    \"must not\",\n",
    "    \"should not\",\n",
    "    \"may not\",\n",
    "    \"will not\",\n",
    "    \"cannot\",\n",
    "    \"can't\",\n",
    "    \"if and only if\",\n",
    "]\n",
    "\n",
    "_MODAL_WORDS = {\n",
    "    \"may\", \"must\", \"should\", \"will\", \"can\", \"could\", \"would\", \"might\", \"shall\",\n",
    "}\n",
    "\n",
    "_SCOPE_PHRASES = [\n",
    "    \"returns\",\n",
    "    \"return\",\n",
    "    \"can return\",\n",
    "    \"may return\",\n",
    "    \"will return\",\n",
    "    \"must return\",\n",
    "    \"should return\",\n",
    "    \"cannot return\",\n",
    "    \"can't return\",\n",
    "    \"does not return\",\n",
    "    \"do not return\",\n",
    "]\n",
    "\n",
    "\n",
    "def _compile_phrase_patterns(phrases: List[str]) -> Dict[str, re.Pattern]:\n",
    "    out: Dict[str, re.Pattern] = {}\n",
    "    for p in phrases:\n",
    "        esc = re.escape(p).replace(r\"\\ \", r\"\\s+\")\n",
    "        pat = re.compile(r\"(?<![A-Za-z0-9_])\" + esc + r\"(?![A-Za-z0-9_])\", re.IGNORECASE)\n",
    "        out[p.lower()] = pat\n",
    "    return out\n",
    "\n",
    "\n",
    "_LOGIC_PHRASE_PATTERNS = _compile_phrase_patterns(_LOGIC_PHRASES)\n",
    "_SCOPE_PHRASE_PATTERNS = _compile_phrase_patterns(_SCOPE_PHRASES)\n",
    "\n",
    "_WORD_TOKEN_RE = re.compile(r\"[A-Za-z0-9_]+(?:'[A-Za-z0-9_]+)?\", re.IGNORECASE)\n",
    "\n",
    "\n",
    "def _sentence_count(text: str) -> int:\n",
    "    t = (text or \"\").strip()\n",
    "    if not t:\n",
    "        return 0\n",
    "    parts = [p for p in re.split(r\"[.!?]+\", t) if p.strip()]\n",
    "    return len(parts)\n",
    "\n",
    "\n",
    "def _word_count(text: str) -> int:\n",
    "    t = (text or \"\").strip()\n",
    "    if not t:\n",
    "        return 0\n",
    "    return len([w for w in re.split(r\"\\s+\", t) if w])\n",
    "\n",
    "\n",
    "def _extract_phrase_tokens(lower_text: str, patterns: Dict[str, re.Pattern]) -> List[str]:\n",
    "    found: List[str] = []\n",
    "    for canonical, pat in patterns.items():\n",
    "        if pat.search(lower_text):\n",
    "            found.append(canonical)\n",
    "    return sorted(set(found))\n",
    "\n",
    "\n",
    "def _extract_word_tokens(lower_text: str, vocabulary: set) -> List[str]:\n",
    "    toks = [m.group(0).lower() for m in _WORD_TOKEN_RE.finditer(lower_text)]\n",
    "    return sorted(set(t for t in toks if t in vocabulary))\n",
    "\n",
    "\n",
    "def _extract_indicator_tokens(text: str) -> Dict[str, List[str]]:\n",
    "    t = text or \"\"\n",
    "    lower = t.lower()\n",
    "\n",
    "    logic_phr = _extract_phrase_tokens(lower, _LOGIC_PHRASE_PATTERNS)\n",
    "    logic_w = _extract_word_tokens(lower, _LOGIC_WORDS)\n",
    "    logic = sorted(set(logic_phr + logic_w))\n",
    "\n",
    "    modals = _extract_word_tokens(lower, _MODAL_WORDS)\n",
    "    scope = _extract_phrase_tokens(lower, _SCOPE_PHRASE_PATTERNS)\n",
    "\n",
    "    return {\n",
    "        \"flags\": sorted(set(_FLAG_RE.findall(t))),\n",
    "        \"snake\": sorted(set(_SNAKE_RE.findall(t))),\n",
    "        \"camel\": sorted(set(_CAMEL_RE.findall(t))),\n",
    "        \"field_like\": sorted(set(_FIELD_COLON_RE.findall(t))),\n",
    "        \"numbers\": sorted(set(_NUMBER_RE.findall(t))),\n",
    "        \"number_units\": sorted(set(m.group(0) for m in _NUMBER_UNIT_RE.finditer(t))),\n",
    "        \"verbs\": sorted(set(m.group(0).lower() for m in _VERB_RE.finditer(t))),\n",
    "        \"logic\": logic,\n",
    "        \"modals\": modals,\n",
    "        \"scope\": scope,\n",
    "    }\n",
    "\n",
    "\n",
    "def _format_token_preview(tokens: List[str], *, max_items: int, max_len: int) -> str:\n",
    "    if not tokens:\n",
    "        return \"-\"\n",
    "    out: List[str] = []\n",
    "    for t in tokens[: max(0, int(max_items))]:\n",
    "        s = str(t)\n",
    "        if len(s) > int(max_len):\n",
    "            s = s[: int(max_len) - 1] + \"…\"\n",
    "        out.append(s)\n",
    "    if len(tokens) > int(max_items):\n",
    "        out.append(f\"+{len(tokens) - int(max_items)}\")\n",
    "    return \", \".join(out) if out else \"-\"\n",
    "\n",
    "\n",
    "def _diff_token_sets(base: Dict[str, List[str]], cand: Dict[str, List[str]], key: str) -> Tuple[List[str], List[str]]:\n",
    "    b = set(base.get(key, []) or [])\n",
    "    c = set(cand.get(key, []) or [])\n",
    "    new_items = sorted(c - b)\n",
    "    missing_items = sorted(b - c)\n",
    "    return new_items, missing_items\n",
    "\n",
    "\n",
    "def _similarity_ratio(a: str, b: str) -> float:\n",
    "    aa = (a or \"\").strip()\n",
    "    bb = (b or \"\").strip()\n",
    "    if not aa and not bb:\n",
    "        return 1.0\n",
    "    if not aa or not bb:\n",
    "        return 0.0\n",
    "    return float(difflib.SequenceMatcher(None, aa, bb).ratio())\n",
    "\n",
    "\n",
    "def _cosine_similarity(a: List[float], b: List[float]) -> Optional[float]:\n",
    "    if not a or not b:\n",
    "        return None\n",
    "    if len(a) != len(b):\n",
    "        return None\n",
    "    dot = 0.0\n",
    "    na = 0.0\n",
    "    nb = 0.0\n",
    "    for i in range(len(a)):\n",
    "        ai = float(a[i])\n",
    "        bi = float(b[i])\n",
    "        dot += ai * bi\n",
    "        na += ai * ai\n",
    "        nb += bi * bi\n",
    "    if na <= 0.0 or nb <= 0.0:\n",
    "        return None\n",
    "    return float(dot / (math.sqrt(na) * math.sqrt(nb)))\n",
    "\n",
    "\n",
    "def compute_candidate_stats(\n",
    "    *,\n",
    "    base_text: str,\n",
    "    cand_text: str,\n",
    "    mode_key: str,\n",
    "    length_policy: Optional[Dict[str, Any]] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    base = (base_text or \"\").strip()\n",
    "    cand = (cand_text or \"\").strip()\n",
    "\n",
    "    base_tokens = _extract_indicator_tokens(base)\n",
    "    cand_tokens = _extract_indicator_tokens(cand)\n",
    "\n",
    "    diffs: Dict[str, Any] = {}\n",
    "    for k in (\"flags\", \"snake\", \"camel\", \"field_like\", \"numbers\", \"number_units\", \"verbs\", \"logic\", \"modals\", \"scope\"):\n",
    "        new_items, missing_items = _diff_token_sets(base_tokens, cand_tokens, k)\n",
    "        diffs[k] = {\"new\": new_items, \"missing\": missing_items}\n",
    "\n",
    "    base_len = len(base)\n",
    "    cand_len = len(cand)\n",
    "    base_words = _word_count(base)\n",
    "    cand_words = _word_count(cand)\n",
    "    base_sent = _sentence_count(base)\n",
    "    cand_sent = _sentence_count(cand)\n",
    "\n",
    "    sim = _similarity_ratio(base, cand)\n",
    "\n",
    "    len_ratio = (float(cand_len) / float(base_len)) if base_len > 0 else None\n",
    "    len_delta = int(cand_len) - int(base_len)\n",
    "    len_delta_ratio = (float(len_delta) / float(base_len)) if base_len > 0 else None\n",
    "\n",
    "    structural_keys = (\"flags\", \"field_like\", \"numbers\", \"number_units\", \"snake\", \"camel\")\n",
    "    logic_keys = (\"logic\", \"modals\", \"scope\")\n",
    "\n",
    "    new_structural = sum(len(diffs[k][\"new\"]) for k in structural_keys)\n",
    "    missing_structural = sum(len(diffs[k][\"missing\"]) for k in structural_keys)\n",
    "    new_logic = sum(len(diffs[k][\"new\"]) for k in logic_keys)\n",
    "    missing_logic = sum(len(diffs[k][\"missing\"]) for k in logic_keys)\n",
    "\n",
    "    new_verbs = len(diffs[\"verbs\"][\"new\"])\n",
    "    missing_verbs = len(diffs[\"verbs\"][\"missing\"])\n",
    "\n",
    "    risk_label = \"LOW\"\n",
    "    risk_reasons: List[str] = []\n",
    "\n",
    "    if new_structural > 0:\n",
    "        risk_label = \"HIGH\"\n",
    "        risk_reasons.append(\"new_structural_tokens_detected\")\n",
    "    if risk_label != \"HIGH\" and (new_logic > 0 or missing_logic > 0):\n",
    "        risk_label = \"HIGH\"\n",
    "        risk_reasons.append(\"logic_or_modal_or_scope_tokens_changed\")\n",
    "    if risk_label != \"HIGH\" and missing_structural >= 4:\n",
    "        risk_label = \"HIGH\"\n",
    "        risk_reasons.append(\"many_structural_tokens_missing\")\n",
    "\n",
    "    if risk_label == \"LOW\" and missing_structural > 0:\n",
    "        risk_label = \"MED\"\n",
    "        risk_reasons.append(\"some_structural_tokens_missing\")\n",
    "\n",
    "    if risk_label == \"LOW\" and new_verbs > 0 and sim < 0.55:\n",
    "        risk_label = \"MED\"\n",
    "        risk_reasons.append(\"new_risk_verbs_with_low_similarity\")\n",
    "\n",
    "    if risk_label == \"LOW\" and sim < 0.45:\n",
    "        risk_label = \"MED\"\n",
    "        risk_reasons.append(\"very_low_text_similarity\")\n",
    "\n",
    "    soft_flags: List[Dict[str, Any]] = []\n",
    "    if mode_key == \"style_concise\":\n",
    "        if base_len > 0 and cand_len > base_len:\n",
    "            soft_flags.append({\"type\": \"concise_length_exceeds_base\", \"base_len\": base_len, \"cand_len\": cand_len})\n",
    "        if cand_sent > 2:\n",
    "            soft_flags.append({\"type\": \"concise_sentence_count_exceeds_2\", \"sentence_count\": cand_sent})\n",
    "    if mode_key == \"style_verbose\":\n",
    "        if cand_sent > 2:\n",
    "            soft_flags.append({\"type\": \"verbose_sentence_count_exceeds_2\", \"sentence_count\": cand_sent})\n",
    "\n",
    "    concise_target_chars = None\n",
    "    concise_target_applied = False\n",
    "    concise_target_reason = None\n",
    "    within_soft_target = None\n",
    "\n",
    "    if isinstance(length_policy, dict):\n",
    "        ct = (length_policy.get(\"concise_soft_target\") or {})\n",
    "        if isinstance(ct, dict):\n",
    "            concise_target_applied = bool(ct.get(\"applied\", False))\n",
    "            concise_target_reason = ct.get(\"reason\")\n",
    "            concise_target_chars = ct.get(\"target_chars\") if isinstance(ct.get(\"target_chars\"), int) else None\n",
    "\n",
    "    if mode_key == \"style_concise\" and concise_target_applied and isinstance(concise_target_chars, int) and base_len > 0:\n",
    "        within_soft_target = bool(cand_len <= concise_target_chars)\n",
    "        if not within_soft_target:\n",
    "            soft_flags.append(\n",
    "                {\n",
    "                    \"type\": \"concise_exceeds_soft_target\",\n",
    "                    \"target_chars\": int(concise_target_chars),\n",
    "                    \"cand_len\": int(cand_len),\n",
    "                    \"len_ratio\": float(len_ratio) if isinstance(len_ratio, float) else None,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return {\n",
    "        \"policy\": {\n",
    "            \"risk_policy_name\": RISK_POLICY_NAME,\n",
    "            \"logic_token_policy_name\": LOGIC_TOKEN_POLICY_NAME,\n",
    "        },\n",
    "        \"base_len_chars\": base_len,\n",
    "        \"cand_len_chars\": cand_len,\n",
    "        \"len_ratio\": len_ratio,\n",
    "        \"len_delta_chars\": len_delta,\n",
    "        \"len_delta_ratio\": len_delta_ratio,\n",
    "        \"base_words\": base_words,\n",
    "        \"cand_words\": cand_words,\n",
    "        \"base_sentences\": base_sent,\n",
    "        \"cand_sentences\": cand_sent,\n",
    "        \"similarity_ratio\": sim,\n",
    "        \"diffs\": diffs,\n",
    "        \"risk_label\": risk_label,\n",
    "        \"risk_reasons\": risk_reasons,\n",
    "        \"soft_flags\": soft_flags,\n",
    "        \"base_tokens\": base_tokens,\n",
    "        \"cand_tokens\": cand_tokens,\n",
    "        \"length_policy\": length_policy,\n",
    "        \"concise_soft_target_applied\": concise_target_applied,\n",
    "        \"concise_soft_target_reason\": concise_target_reason,\n",
    "        \"concise_soft_target_chars\": concise_target_chars,\n",
    "        \"within_soft_target\": within_soft_target,\n",
    "        \"new_structural_count\": int(new_structural),\n",
    "        \"missing_structural_count\": int(missing_structural),\n",
    "        \"new_logic_count\": int(new_logic),\n",
    "        \"missing_logic_count\": int(missing_logic),\n",
    "        \"new_risk_verbs_count\": int(new_verbs),\n",
    "        \"missing_risk_verbs_count\": int(missing_verbs),\n",
    "    }\n",
    "\n",
    "\n",
    "# ========= Optional semantic signals (embeddings + verifier) =========\n",
    "def _compute_embedding_cosine(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    embedding_model: str,\n",
    "    base_text: str,\n",
    "    cand_text: str,\n",
    ") -> Tuple[Optional[float], Optional[str], Dict[str, Any]]:\n",
    "    meta: Dict[str, Any] = {\"embedding_model\": embedding_model, \"provider_base_url\": GEMINI_BASE_URL}\n",
    "    try:\n",
    "        rb = client.embeddings.create(model=embedding_model, input=base_text)\n",
    "        rc = client.embeddings.create(model=embedding_model, input=cand_text)\n",
    "        vb = getattr(rb.data[0], \"embedding\", None) if getattr(rb, \"data\", None) else None\n",
    "        vc = getattr(rc.data[0], \"embedding\", None) if getattr(rc, \"data\", None) else None\n",
    "        if not isinstance(vb, list) or not isinstance(vc, list):\n",
    "            return None, \"embedding_vector_missing\", meta\n",
    "        cos = _cosine_similarity(vb, vc)\n",
    "        if cos is None:\n",
    "            return None, \"embedding_cosine_failed\", meta\n",
    "        return float(cos), None, meta\n",
    "    except Exception as e:\n",
    "        return None, str(e), meta\n",
    "\n",
    "\n",
    "def _compute_entailment_verdict(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    verifier_model: str,\n",
    "    base_text: str,\n",
    "    cand_text: str,\n",
    "    max_tokens: int,\n",
    ") -> Tuple[Optional[str], Optional[str], Dict[str, Any]]:\n",
    "    meta: Dict[str, Any] = {\"verifier_model\": verifier_model, \"provider_base_url\": GEMINI_BASE_URL}\n",
    "    system = (\n",
    "        \"Task: semantic equivalence gate.\\n\"\n",
    "        \"Decision must be based only on whether the candidate text entails the base text with identical meaning.\\n\"\n",
    "        \"Output must be exactly one of: ENTAILS, NOT_ENTAILS.\\n\"\n",
    "        \"No explanations, no punctuation, no extra tokens.\\n\"\n",
    "    )\n",
    "    user = (\n",
    "        \"Base text:\\n\"\n",
    "        f\"{base_text.strip()}\\n\\n\"\n",
    "        \"Candidate text:\\n\"\n",
    "        f\"{cand_text.strip()}\\n\"\n",
    "    )\n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=verifier_model,\n",
    "            messages=[{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": user}],\n",
    "            temperature=0.0,\n",
    "            max_tokens=int(max_tokens),\n",
    "        )\n",
    "        out = (resp.choices[0].message.content or \"\").strip().upper()\n",
    "        tok = out.split()[0] if out else \"\"\n",
    "        if tok not in (\"ENTAILS\", \"NOT_ENTAILS\"):\n",
    "            tok = \"UNKNOWN\"\n",
    "        meta[\"finish_reason\"] = getattr(resp.choices[0], \"finish_reason\", None)\n",
    "        meta[\"usage\"] = getattr(resp, \"usage\", None)\n",
    "        return tok, None, meta\n",
    "    except Exception as e:\n",
    "        return None, str(e), meta\n",
    "\n",
    "\n",
    "def augment_stats_with_semantic_signals(\n",
    "    *,\n",
    "    stats: Dict[str, Any],\n",
    "    client: Optional[OpenAI],\n",
    "    semantic_cfg: Optional[Dict[str, Any]],\n",
    "    base_text: str,\n",
    "    cand_text: str,\n",
    ") -> Dict[str, Any]:\n",
    "    if not isinstance(stats, dict):\n",
    "        return stats\n",
    "    if not semantic_cfg or not isinstance(semantic_cfg, dict):\n",
    "        return stats\n",
    "    if client is None:\n",
    "        return stats\n",
    "\n",
    "    enabled_embeddings = bool(semantic_cfg.get(\"enable_embeddings\", False))\n",
    "    embedding_model = str(semantic_cfg.get(\"embedding_model\") or \"\").strip()\n",
    "    emb_low_thr = semantic_cfg.get(\"embedding_low_cosine_threshold\", DEFAULT_EMBEDDING_LOW_COSINE_THRESHOLD)\n",
    "\n",
    "    enabled_verifier = bool(semantic_cfg.get(\"enable_verifier\", False))\n",
    "    verifier_model = str(semantic_cfg.get(\"verifier_model\") or \"\").strip()\n",
    "    verifier_max_tokens = int(semantic_cfg.get(\"verifier_max_tokens\", DEFAULT_VERIFIER_MAX_TOKENS))\n",
    "\n",
    "    if not isinstance(stats.get(\"soft_flags\"), list):\n",
    "        stats[\"soft_flags\"] = []\n",
    "\n",
    "    semantic_block: Dict[str, Any] = {\"semantic_policy_name\": SEMANTIC_POLICY_NAME}\n",
    "\n",
    "    if enabled_embeddings and embedding_model:\n",
    "        cos, err, meta = _compute_embedding_cosine(\n",
    "            client=client,\n",
    "            embedding_model=embedding_model,\n",
    "            base_text=base_text,\n",
    "            cand_text=cand_text,\n",
    "        )\n",
    "        semantic_block[\"embedding\"] = {\"cosine\": cos, \"error\": err, \"meta\": meta}\n",
    "        if isinstance(cos, (int, float)) and isinstance(emb_low_thr, (int, float)):\n",
    "            if float(cos) < float(emb_low_thr):\n",
    "                stats[\"soft_flags\"].append(\n",
    "                    {\"type\": \"embedding_low_cosine\", \"cosine\": float(cos), \"threshold\": float(emb_low_thr)}\n",
    "                )\n",
    "        if err:\n",
    "            stats[\"soft_flags\"].append({\"type\": \"embedding_error\", \"error\": str(err)[:200]})\n",
    "\n",
    "    if enabled_verifier:\n",
    "        if not verifier_model:\n",
    "            verifier_model = str(semantic_cfg.get(\"fallback_llm_model\") or \"\").strip()\n",
    "        if verifier_model:\n",
    "            label, err, meta = _compute_entailment_verdict(\n",
    "                client=client,\n",
    "                verifier_model=verifier_model,\n",
    "                base_text=base_text,\n",
    "                cand_text=cand_text,\n",
    "                max_tokens=verifier_max_tokens,\n",
    "            )\n",
    "            semantic_block[\"verifier\"] = {\"label\": label, \"error\": err, \"meta\": meta}\n",
    "            if label == \"NOT_ENTAILS\":\n",
    "                stats[\"soft_flags\"].append({\"type\": \"verifier_not_entails\"})\n",
    "            elif label == \"UNKNOWN\":\n",
    "                stats[\"soft_flags\"].append({\"type\": \"verifier_unknown\"})\n",
    "            if err:\n",
    "                stats[\"soft_flags\"].append({\"type\": \"verifier_error\", \"error\": str(err)[:200]})\n",
    "        else:\n",
    "            stats[\"soft_flags\"].append({\"type\": \"verifier_unconfigured\"})\n",
    "\n",
    "    if semantic_block:\n",
    "        stats[\"semantic\"] = semantic_block\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "def compute_full_candidate_stats(\n",
    "    *,\n",
    "    base_text: str,\n",
    "    cand_text: str,\n",
    "    mode_key: str,\n",
    "    length_policy: Optional[Dict[str, Any]],\n",
    "    client: Optional[OpenAI],\n",
    "    semantic_cfg: Optional[Dict[str, Any]],\n",
    ") -> Dict[str, Any]:\n",
    "    stats = compute_candidate_stats(base_text=base_text, cand_text=cand_text, mode_key=mode_key, length_policy=length_policy)\n",
    "    return augment_stats_with_semantic_signals(\n",
    "        stats=stats,\n",
    "        client=client,\n",
    "        semantic_cfg=semantic_cfg,\n",
    "        base_text=base_text,\n",
    "        cand_text=cand_text,\n",
    "    )\n",
    "\n",
    "\n",
    "def _print_base_stats(base_desc: str, *, max_preview: int, max_tok_len: int) -> None:\n",
    "    base = (base_desc or \"\").strip()\n",
    "    tokens = _extract_indicator_tokens(base)\n",
    "    print(\"\\nStatistics (base):\")\n",
    "    print(f\"  chars={len(base)}; words={_word_count(base)}; sentences={_sentence_count(base)}\")\n",
    "    print(\n",
    "        \"  tokens:\"\n",
    "        f\" flags={len(tokens['flags'])}, field_like={len(tokens['field_like'])}, \"\n",
    "        f\"numbers={len(tokens['numbers'])}, number_units={len(tokens['number_units'])}, \"\n",
    "        f\"verbs={len(tokens['verbs'])}, snake={len(tokens['snake'])}, camel={len(tokens['camel'])}, \"\n",
    "        f\"logic={len(tokens['logic'])}, modals={len(tokens['modals'])}, scope={len(tokens['scope'])}\"\n",
    "    )\n",
    "    print(\n",
    "        \"  previews:\"\n",
    "        f\" flags=[{_format_token_preview(tokens['flags'], max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "        f\" field_like=[{_format_token_preview(tokens['field_like'], max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "        f\" numbers=[{_format_token_preview(tokens['numbers'], max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "        f\" verbs=[{_format_token_preview(tokens['verbs'], max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "        f\" logic=[{_format_token_preview(tokens['logic'], max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "        f\" modals=[{_format_token_preview(tokens['modals'], max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "        f\" scope=[{_format_token_preview(tokens['scope'], max_items=max_preview, max_len=max_tok_len)}]\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _print_candidate_summary_line(\n",
    "    i: int,\n",
    "    cand: Dict[str, Any],\n",
    "    *,\n",
    "    max_preview: int,\n",
    "    max_tok_len: int,\n",
    "    snippet_chars: int,\n",
    ") -> None:\n",
    "    txt = (cand.get(\"text\") or \"\").strip()\n",
    "    err = cand.get(\"error\")\n",
    "    dup = bool(cand.get(\"duplicate\", False))\n",
    "    stats = cand.get(\"stats\") or {}\n",
    "\n",
    "    status = \"ok\"\n",
    "    if err:\n",
    "        status = f\"error:{str(err)[:60]}\"\n",
    "    elif not txt:\n",
    "        status = \"empty\"\n",
    "    elif dup:\n",
    "        status = \"duplicate\"\n",
    "\n",
    "    risk = stats.get(\"risk_label\") or \"-\"\n",
    "    sim = stats.get(\"similarity_ratio\")\n",
    "    sim_s = f\"{float(sim):.2f}\" if isinstance(sim, (int, float)) else \"-\"\n",
    "\n",
    "    diffs = (stats.get(\"diffs\") or {})\n",
    "    new_flags = len(((diffs.get(\"flags\") or {}).get(\"new\") or []))\n",
    "    new_nums = len(((diffs.get(\"numbers\") or {}).get(\"new\") or [])) + len(((diffs.get(\"number_units\") or {}).get(\"new\") or []))\n",
    "    new_verbs = len(((diffs.get(\"verbs\") or {}).get(\"new\") or []))\n",
    "    new_fields = len(((diffs.get(\"field_like\") or {}).get(\"new\") or []))\n",
    "    new_snake = len(((diffs.get(\"snake\") or {}).get(\"new\") or []))\n",
    "    new_camel = len(((diffs.get(\"camel\") or {}).get(\"new\") or []))\n",
    "    new_logic = (\n",
    "        len(((diffs.get(\"logic\") or {}).get(\"new\") or [])) +\n",
    "        len(((diffs.get(\"modals\") or {}).get(\"new\") or [])) +\n",
    "        len(((diffs.get(\"scope\") or {}).get(\"new\") or []))\n",
    "    )\n",
    "    missing_total = (\n",
    "        len(((diffs.get(\"flags\") or {}).get(\"missing\") or [])) +\n",
    "        len(((diffs.get(\"numbers\") or {}).get(\"missing\") or [])) +\n",
    "        len(((diffs.get(\"number_units\") or {}).get(\"missing\") or [])) +\n",
    "        len(((diffs.get(\"verbs\") or {}).get(\"missing\") or [])) +\n",
    "        len(((diffs.get(\"field_like\") or {}).get(\"missing\") or [])) +\n",
    "        len(((diffs.get(\"snake\") or {}).get(\"missing\") or [])) +\n",
    "        len(((diffs.get(\"camel\") or {}).get(\"missing\") or [])) +\n",
    "        len(((diffs.get(\"logic\") or {}).get(\"missing\") or [])) +\n",
    "        len(((diffs.get(\"modals\") or {}).get(\"missing\") or [])) +\n",
    "        len(((diffs.get(\"scope\") or {}).get(\"missing\") or []))\n",
    "    )\n",
    "\n",
    "    clen = stats.get(\"cand_len_chars\")\n",
    "    cwords = stats.get(\"cand_words\")\n",
    "    csent = stats.get(\"cand_sentences\")\n",
    "\n",
    "    clen_s = str(clen) if isinstance(clen, int) else \"-\"\n",
    "    cwords_s = str(cwords) if isinstance(cwords, int) else \"-\"\n",
    "    csent_s = str(csent) if isinstance(csent, int) else \"-\"\n",
    "\n",
    "    lr = stats.get(\"len_ratio\")\n",
    "    lr_s = f\"{float(lr):.2f}\" if isinstance(lr, (int, float)) else \"-\"\n",
    "    ld = stats.get(\"len_delta_chars\")\n",
    "    ld_s = f\"{int(ld):+d}\" if isinstance(ld, int) else \"-\"\n",
    "\n",
    "    t_applied = bool(stats.get(\"concise_soft_target_applied\", False))\n",
    "    t_chars = stats.get(\"concise_soft_target_chars\")\n",
    "    within = stats.get(\"within_soft_target\")\n",
    "    target_s = \"-\"\n",
    "    if t_applied and isinstance(t_chars, int):\n",
    "        if within is True:\n",
    "            target_s = f\"target<={t_chars} ok\"\n",
    "        elif within is False:\n",
    "            target_s = f\"target<={t_chars} NO\"\n",
    "        else:\n",
    "            target_s = f\"target<={t_chars}\"\n",
    "\n",
    "    emb_s = \"-\"\n",
    "    ent_s = \"-\"\n",
    "    sem = stats.get(\"semantic\") if isinstance(stats.get(\"semantic\"), dict) else None\n",
    "    if isinstance(sem, dict):\n",
    "        emb = sem.get(\"embedding\") if isinstance(sem.get(\"embedding\"), dict) else None\n",
    "        if isinstance(emb, dict) and isinstance(emb.get(\"cosine\"), (int, float)):\n",
    "            emb_s = f\"{float(emb.get('cosine')):.2f}\"\n",
    "        ver = sem.get(\"verifier\") if isinstance(sem.get(\"verifier\"), dict) else None\n",
    "        if isinstance(ver, dict) and isinstance(ver.get(\"label\"), str):\n",
    "            ent_s = ver.get(\"label\")\n",
    "\n",
    "    print(\n",
    "        f\"  [{i}] status={status}; risk={risk}; sim={sim_s}; emb={emb_s}; ent={ent_s}; \"\n",
    "        f\"cand(chars={clen_s}, words={cwords_s}, sent={csent_s}); \"\n",
    "        f\"len_ratio={lr_s}; Δchars={ld_s}; {target_s}; \"\n",
    "        f\"new(flags={new_flags}, fields={new_fields}, nums={new_nums}, snake={new_snake}, camel={new_camel}, logic={new_logic}, verbs={new_verbs}); \"\n",
    "        f\"missing_total={missing_total}\"\n",
    "    )\n",
    "\n",
    "    if isinstance(diffs, dict) and txt and not err:\n",
    "        nf = (diffs.get(\"flags\") or {}).get(\"new\") or []\n",
    "        nfv = (diffs.get(\"field_like\") or {}).get(\"new\") or []\n",
    "        nn = (diffs.get(\"numbers\") or {}).get(\"new\") or []\n",
    "        nnu = (diffs.get(\"number_units\") or {}).get(\"new\") or []\n",
    "        nlogic = (diffs.get(\"logic\") or {}).get(\"new\") or []\n",
    "        nmod = (diffs.get(\"modals\") or {}).get(\"new\") or []\n",
    "        nscope = (diffs.get(\"scope\") or {}).get(\"new\") or []\n",
    "        if nf or nfv or nn or nnu or nlogic or nmod or nscope:\n",
    "            print(\n",
    "                \"      new-previews:\"\n",
    "                f\" flags=[{_format_token_preview(list(nf), max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "                f\" fields=[{_format_token_preview(list(nfv), max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "                f\" numbers=[{_format_token_preview(list(nn), max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "                f\" number_units=[{_format_token_preview(list(nnu), max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "                f\" logic=[{_format_token_preview(list(nlogic), max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "                f\" modals=[{_format_token_preview(list(nmod), max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "                f\" scope=[{_format_token_preview(list(nscope), max_items=max_preview, max_len=max_tok_len)}]\"\n",
    "            )\n",
    "\n",
    "    if txt and not err and int(snippet_chars) > 0:\n",
    "        sn = \" \".join(txt.split())\n",
    "        max_sn = int(snippet_chars)\n",
    "        if len(sn) > max_sn:\n",
    "            sn = sn[: max_sn - 1] + \"…\"\n",
    "        print(f\"      text: {sn}\")\n",
    "\n",
    "\n",
    "def _print_candidate_full(\n",
    "    i: int,\n",
    "    cand: Dict[str, Any],\n",
    "    *,\n",
    "    max_preview: int,\n",
    "    max_tok_len: int,\n",
    ") -> None:\n",
    "    txt = (cand.get(\"text\") or \"\").strip()\n",
    "    err = cand.get(\"error\")\n",
    "    stats = cand.get(\"stats\") or {}\n",
    "    diffs = (stats.get(\"diffs\") or {})\n",
    "\n",
    "    print(f\"\\nCandidate [{i}]:\")\n",
    "    if err:\n",
    "        print(f\"  Generation error: {err}\")\n",
    "        if txt:\n",
    "            print(\"  Partial text:\")\n",
    "            print(txt)\n",
    "        return\n",
    "    if not txt:\n",
    "        print(\"  (empty)\")\n",
    "        return\n",
    "\n",
    "    print(txt)\n",
    "\n",
    "    risk = stats.get(\"risk_label\") or \"-\"\n",
    "    reasons = stats.get(\"risk_reasons\") or []\n",
    "    soft = stats.get(\"soft_flags\") or []\n",
    "\n",
    "    print(\"\\n  Candidate statistics:\")\n",
    "    sim = stats.get(\"similarity_ratio\")\n",
    "    sim_s = f\"{float(sim):.2f}\" if isinstance(sim, (int, float)) else \"-\"\n",
    "    lr = stats.get(\"len_ratio\")\n",
    "    lr_s = f\"{float(lr):.2f}\" if isinstance(lr, (int, float)) else \"-\"\n",
    "    ld = stats.get(\"len_delta_chars\")\n",
    "    ld_s = f\"{int(ld):+d}\" if isinstance(ld, int) else \"-\"\n",
    "\n",
    "    sem = stats.get(\"semantic\") if isinstance(stats.get(\"semantic\"), dict) else None\n",
    "    sem_s = \"\"\n",
    "    if isinstance(sem, dict):\n",
    "        emb = sem.get(\"embedding\") if isinstance(sem.get(\"embedding\"), dict) else None\n",
    "        ver = sem.get(\"verifier\") if isinstance(sem.get(\"verifier\"), dict) else None\n",
    "        if isinstance(emb, dict):\n",
    "            sem_s += f\"; emb_cos={emb.get('cosine')}\"\n",
    "            if emb.get(\"error\"):\n",
    "                sem_s += f\"; emb_err={str(emb.get('error'))[:80]}\"\n",
    "        if isinstance(ver, dict):\n",
    "            sem_s += f\"; entail={ver.get('label')}\"\n",
    "            if ver.get(\"error\"):\n",
    "                sem_s += f\"; ent_err={str(ver.get('error'))[:80]}\"\n",
    "\n",
    "    print(f\"    risk={risk}; reasons={reasons if reasons else '[]'}; similarity={sim_s}; len_ratio={lr_s}; Δchars={ld_s}{sem_s}\")\n",
    "\n",
    "    if soft:\n",
    "        print(f\"    soft_flags={soft}\")\n",
    "\n",
    "    for key in (\"flags\", \"field_like\", \"numbers\", \"number_units\", \"snake\", \"camel\", \"logic\", \"modals\", \"scope\", \"verbs\"):\n",
    "        d = diffs.get(key) or {}\n",
    "        new_items = d.get(\"new\") or []\n",
    "        missing_items = d.get(\"missing\") or []\n",
    "        if not new_items and not missing_items:\n",
    "            continue\n",
    "        print(\n",
    "            f\"    {key}:\"\n",
    "            f\" new({len(new_items)})=[{_format_token_preview(list(new_items), max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "            f\" missing({len(missing_items)})=[{_format_token_preview(list(missing_items), max_items=max_preview, max_len=max_tok_len)}]\"\n",
    "        )\n",
    "\n",
    "\n",
    "# ========= Raw JSON-string patcher (for tools stored as JSON strings) =========\n",
    "def _extract_json_string_value(raw_json: str, key: str) -> Optional[str]:\n",
    "    token = f'\"{key}\"'\n",
    "    i = raw_json.find(token)\n",
    "    if i < 0:\n",
    "        return None\n",
    "    i = raw_json.find(\":\", i + len(token))\n",
    "    if i < 0:\n",
    "        return None\n",
    "    i += 1\n",
    "    n = len(raw_json)\n",
    "    while i < n and raw_json[i] in \" \\t\\r\\n\":\n",
    "        i += 1\n",
    "    if i >= n or raw_json[i] != '\"':\n",
    "        return None\n",
    "    start = i\n",
    "    i += 1\n",
    "    esc = False\n",
    "    while i < n:\n",
    "        c = raw_json[i]\n",
    "        if esc:\n",
    "            esc = False\n",
    "        else:\n",
    "            if c == \"\\\\\":\n",
    "                esc = True\n",
    "            elif c == '\"':\n",
    "                return raw_json[start : i + 1]\n",
    "        i += 1\n",
    "    return None\n",
    "\n",
    "\n",
    "def _decode_raw_json_string(raw_json_string_with_quotes: str) -> str:\n",
    "    try:\n",
    "        obj = json.loads('{\"description\":' + raw_json_string_with_quotes + \"}\")\n",
    "        return obj.get(\"description\") or \"\"\n",
    "    except json.JSONDecodeError:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def _get_description_for_print(entry: Any) -> Tuple[str, str]:\n",
    "    if isinstance(entry, str):\n",
    "        raw = _extract_json_string_value(entry, \"description\")\n",
    "        if raw is not None:\n",
    "            return raw, \"raw_json\"\n",
    "        try:\n",
    "            obj = json.loads(entry)\n",
    "            return obj.get(\"description\") or \"\", \"rendered\"\n",
    "        except json.JSONDecodeError:\n",
    "            return \"\", \"rendered\"\n",
    "    if isinstance(entry, dict):\n",
    "        return entry.get(\"description\") or \"\", \"rendered\"\n",
    "    return \"\", \"rendered\"\n",
    "\n",
    "\n",
    "def _load_tool(entry: Any) -> Tuple[Optional[Dict[str, Any]], str]:\n",
    "    if isinstance(entry, str):\n",
    "        try:\n",
    "            return json.loads(entry), \"json_str\"\n",
    "        except json.JSONDecodeError:\n",
    "            return None, \"other\"\n",
    "    if isinstance(entry, dict):\n",
    "        return entry, \"dict\"\n",
    "    return None, \"other\"\n",
    "\n",
    "\n",
    "def _skip_ws(s: str, i: int) -> int:\n",
    "    n = len(s)\n",
    "    while i < n and s[i] in \" \\t\\r\\n\":\n",
    "        i += 1\n",
    "    return i\n",
    "\n",
    "\n",
    "def _scan_string_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    n = len(s)\n",
    "    if i >= n or s[i] != '\"':\n",
    "        return None\n",
    "    j = i + 1\n",
    "    esc = False\n",
    "    while j < n:\n",
    "        c = s[j]\n",
    "        if esc:\n",
    "            esc = False\n",
    "        else:\n",
    "            if c == \"\\\\\":\n",
    "                esc = True\n",
    "            elif c == '\"':\n",
    "                return (i, j + 1)\n",
    "        j += 1\n",
    "    return None\n",
    "\n",
    "\n",
    "def _scan_number_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    n = len(s)\n",
    "    j = i\n",
    "    if j < n and s[j] == \"-\":\n",
    "        j += 1\n",
    "    if j >= n:\n",
    "        return None\n",
    "    if s[j] == \"0\":\n",
    "        j += 1\n",
    "    elif s[j].isdigit():\n",
    "        while j < n and s[j].isdigit():\n",
    "            j += 1\n",
    "    else:\n",
    "        return None\n",
    "    if j < n and s[j] == \".\":\n",
    "        j += 1\n",
    "        if j >= n or not s[j].isdigit():\n",
    "            return None\n",
    "        while j < n and s[j].isdigit():\n",
    "            j += 1\n",
    "    if j < n and s[j] in \"eE\":\n",
    "        j += 1\n",
    "        if j < n and s[j] in \"+-\":\n",
    "            j += 1\n",
    "        if j >= n or not s[j].isdigit():\n",
    "            return None\n",
    "        while j < n and s[j].isdigit():\n",
    "            j += 1\n",
    "    return (i, j)\n",
    "\n",
    "\n",
    "def _scan_literal_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    for lit in (\"true\", \"false\", \"null\"):\n",
    "        if s.startswith(lit, i):\n",
    "            return (i, i + len(lit))\n",
    "    return None\n",
    "\n",
    "\n",
    "def _scan_container_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    n = len(s)\n",
    "    if i >= n:\n",
    "        return None\n",
    "\n",
    "    opener = s[i]\n",
    "    if opener not in \"{[\":\n",
    "        return None\n",
    "\n",
    "    stack: List[str] = [\"}\" if opener == \"{\" else \"]\"]\n",
    "    j = i + 1\n",
    "    in_str = False\n",
    "    esc = False\n",
    "\n",
    "    while j < n:\n",
    "        c = s[j]\n",
    "\n",
    "        if in_str:\n",
    "            if esc:\n",
    "                esc = False\n",
    "            else:\n",
    "                if c == \"\\\\\":\n",
    "                    esc = True\n",
    "                elif c == '\"':\n",
    "                    in_str = False\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        if c == '\"':\n",
    "            in_str = True\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        if c == \"{\":\n",
    "            stack.append(\"}\")\n",
    "            j += 1\n",
    "            continue\n",
    "        if c == \"[\":\n",
    "            stack.append(\"]\")\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        if c in \"}]\":\n",
    "            if not stack:\n",
    "                return None\n",
    "            expected = stack[-1]\n",
    "            if c != expected:\n",
    "                return None\n",
    "            stack.pop()\n",
    "            j += 1\n",
    "            if not stack:\n",
    "                return (i, j)\n",
    "            continue\n",
    "\n",
    "        j += 1\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def _is_value_delim(c: str) -> bool:\n",
    "    return c in \",}]\"\n",
    "\n",
    "\n",
    "def _scan_value_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    n = len(s)\n",
    "    i = _skip_ws(s, i)\n",
    "    if i >= n:\n",
    "        return None\n",
    "\n",
    "    c = s[i]\n",
    "    if c == '\"':\n",
    "        return _scan_string_span(s, i)\n",
    "    if c in \"{[\":\n",
    "        return _scan_container_span(s, i)\n",
    "\n",
    "    span: Optional[Tuple[int, int]]\n",
    "    if c == \"-\" or c.isdigit():\n",
    "        span = _scan_number_span(s, i)\n",
    "    else:\n",
    "        span = _scan_literal_span(s, i)\n",
    "\n",
    "    if not span:\n",
    "        return None\n",
    "\n",
    "    _, end = span\n",
    "    k = _skip_ws(s, end)\n",
    "    if k >= n:\n",
    "        return span\n",
    "    if _is_value_delim(s[k]):\n",
    "        return span\n",
    "    return None\n",
    "\n",
    "\n",
    "def _replace_top_level_string_field_in_raw_object(raw_json_obj: str, key: str, new_value: str) -> Tuple[str, bool, str]:\n",
    "    s = raw_json_obj\n",
    "    n = len(s)\n",
    "\n",
    "    i = _skip_ws(s, 0)\n",
    "    if i >= n or s[i] != \"{\":\n",
    "        return raw_json_obj, False, \"not_object\"\n",
    "\n",
    "    i += 1\n",
    "    found_any_key = False\n",
    "    expect_key = True\n",
    "\n",
    "    while True:\n",
    "        i = _skip_ws(s, i)\n",
    "        if i >= n:\n",
    "            return raw_json_obj, False, \"cannot_scan_value\"\n",
    "\n",
    "        if expect_key:\n",
    "            if s[i] == \"}\":\n",
    "                return raw_json_obj, False, \"key_not_found\"\n",
    "            if s[i] != '\"':\n",
    "                return raw_json_obj, False, \"invalid_key_string\"\n",
    "\n",
    "            key_span = _scan_string_span(s, i)\n",
    "            if not key_span:\n",
    "                return raw_json_obj, False, \"invalid_key_string\"\n",
    "\n",
    "            found_any_key = True\n",
    "            k_start, k_end = key_span\n",
    "            try:\n",
    "                key_decoded = json.loads(s[k_start:k_end])\n",
    "            except Exception:\n",
    "                return raw_json_obj, False, \"invalid_key_string\"\n",
    "\n",
    "            i = _skip_ws(s, k_end)\n",
    "            if i >= n or s[i] != \":\":\n",
    "                return raw_json_obj, False, \"missing_colon\"\n",
    "\n",
    "            v_span = _scan_value_span(s, i + 1)\n",
    "            if not v_span:\n",
    "                return raw_json_obj, False, \"cannot_scan_value\"\n",
    "\n",
    "            v_start, v_end = v_span\n",
    "\n",
    "            if key_decoded == key:\n",
    "                if v_start >= n or s[v_start] != '\"':\n",
    "                    return raw_json_obj, False, \"value_not_string\"\n",
    "\n",
    "                replacement_literal = json.dumps(new_value, ensure_ascii=False)\n",
    "                patched = s[:v_start] + replacement_literal + s[v_end:]\n",
    "\n",
    "                try:\n",
    "                    obj = json.loads(patched)\n",
    "                except Exception:\n",
    "                    return raw_json_obj, False, \"json_load_failed_after_patch\"\n",
    "\n",
    "                if isinstance(obj, dict) and obj.get(key) == new_value:\n",
    "                    return patched, True, \"ok\"\n",
    "                return raw_json_obj, False, \"validation_failed_after_patch\"\n",
    "\n",
    "            i = v_end\n",
    "            expect_key = False\n",
    "            continue\n",
    "\n",
    "        i = _skip_ws(s, i)\n",
    "        if i >= n:\n",
    "            return raw_json_obj, False, \"cannot_scan_value\"\n",
    "\n",
    "        if s[i] == \",\":\n",
    "            i += 1\n",
    "            expect_key = True\n",
    "            continue\n",
    "        if s[i] == \"}\":\n",
    "            return raw_json_obj, False, (\"key_not_found\" if found_any_key else \"key_not_found\")\n",
    "        return raw_json_obj, False, \"cannot_scan_value\"\n",
    "\n",
    "\n",
    "# ========= IDs =========\n",
    "def _tool_fingerprint_excluding_description(tool_obj: Dict[str, Any]) -> str:\n",
    "    filtered = {k: v for k, v in tool_obj.items() if k != \"description\"}\n",
    "    payload = _canonical_json(filtered)\n",
    "    return hashlib.sha256(payload.encode(\"utf-8\")).hexdigest()[:HASH_HEX_LEN]\n",
    "\n",
    "\n",
    "def _record_id(record_obj: Dict[str, Any], tool_field: str) -> str:\n",
    "    rec = dict(record_obj)\n",
    "    tools = rec.get(tool_field)\n",
    "    if isinstance(tools, list):\n",
    "        canon_tools: List[Any] = []\n",
    "        for entry in tools:\n",
    "            tool_obj, kind = _load_tool(entry)\n",
    "            if tool_obj is None:\n",
    "                canon_tools.append({\"_unparsed\": entry, \"_kind\": kind})\n",
    "            else:\n",
    "                canon_tools.append({k: v for k, v in tool_obj.items() if k != \"description\"})\n",
    "        rec[tool_field] = canon_tools\n",
    "    payload = _canonical_json(rec)\n",
    "    return hashlib.sha256(payload.encode(\"utf-8\")).hexdigest()[:HASH_HEX_LEN]\n",
    "\n",
    "\n",
    "def _tool_instance_key(record_id: str, tool_index: int, tool_obj: Dict[str, Any]) -> str:\n",
    "    fp = _tool_fingerprint_excluding_description(tool_obj)\n",
    "    return f\"rec:{record_id}:t{tool_index}:{fp}\"\n",
    "\n",
    "\n",
    "# ========= Audit (single file, resumable) =========\n",
    "def _audit_identity(\n",
    "    dataset_path: Path,\n",
    "    *,\n",
    "    mode_key: str,\n",
    "    model: str,\n",
    "    tool_field: str,\n",
    "    num_candidates: int,\n",
    "    semantic_cfg: Optional[Dict[str, Any]],\n",
    ") -> str:\n",
    "    sc = semantic_cfg or {}\n",
    "    stable = (\n",
    "        f\"{dataset_path.resolve()}|{mode_key}|{model}|{tool_field}|K={int(num_candidates)}|\"\n",
    "        f\"{RISK_POLICY_NAME}|{LOGIC_TOKEN_POLICY_NAME}|{SEMANTIC_POLICY_NAME}|\"\n",
    "        f\"emb={bool(sc.get('enable_embeddings', False))}:{str(sc.get('embedding_model') or '')}|\"\n",
    "        f\"ver={bool(sc.get('enable_verifier', False))}:{str(sc.get('verifier_model') or '')}\"\n",
    "    )\n",
    "    return hashlib.sha256(stable.encode(\"utf-8\")).hexdigest()[:12]\n",
    "\n",
    "\n",
    "def _audit_file_path(\n",
    "    dataset_path: Path,\n",
    "    *,\n",
    "    audit_dir: Path,\n",
    "    mode_key: str,\n",
    "    model: str,\n",
    "    tool_field: str,\n",
    "    num_candidates: int,\n",
    "    semantic_cfg: Optional[Dict[str, Any]],\n",
    ") -> Path:\n",
    "    audit_key = _audit_identity(\n",
    "        dataset_path,\n",
    "        mode_key=mode_key,\n",
    "        model=model,\n",
    "        tool_field=tool_field,\n",
    "        num_candidates=int(num_candidates),\n",
    "        semantic_cfg=semantic_cfg,\n",
    "    )\n",
    "    safe_model = \"\".join(ch if ch.isalnum() or ch in (\"-\", \"_\", \".\") else \"_\" for ch in model)\n",
    "    out_dir = audit_dir / audit_key\n",
    "    filename = f\"{dataset_path.stem}.{audit_key}.{mode_key}.{safe_model}.K{int(num_candidates)}.audit.jsonl\"\n",
    "    return out_dir / filename\n",
    "\n",
    "\n",
    "def _append_audit_event(audit_file: Path, event: Dict[str, Any]) -> None:\n",
    "    audit_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    safe_event = _json_safe(event)\n",
    "    with audit_file.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(safe_event, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "def _load_resume_state(\n",
    "    audit_file: Path,\n",
    ") -> Tuple[\n",
    "    Dict[str, Tuple[str, Optional[str], Optional[Dict[str, Any]]]],\n",
    "    Dict[str, int],\n",
    "    Dict[str, Optional[str]],\n",
    "    Optional[Dict[str, Any]],\n",
    "]:\n",
    "    decisions: Dict[str, Tuple[str, Optional[str], Optional[Dict[str, Any]]]] = {}\n",
    "    regen_counts: Dict[str, int] = {}\n",
    "    last_rejected_text: Dict[str, Optional[str]] = {}\n",
    "    prior_run_start: Optional[Dict[str, Any]] = None\n",
    "\n",
    "    if not audit_file.exists():\n",
    "        return decisions, regen_counts, last_rejected_text, None\n",
    "\n",
    "    best_round: Dict[str, int] = {}\n",
    "\n",
    "    with audit_file.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                ev = json.loads(line)\n",
    "            except Exception:\n",
    "                continue\n",
    "            if not isinstance(ev, dict):\n",
    "                continue\n",
    "\n",
    "            et = ev.get(\"event_type\")\n",
    "            if et == \"run_start\" and prior_run_start is None:\n",
    "                prior_run_start = ev\n",
    "\n",
    "            if et == \"regenerate\":\n",
    "                ik = ev.get(\"instance_key\")\n",
    "                rr = ev.get(\"generation_round\")\n",
    "                txt = ev.get(\"last_generated_text\")\n",
    "                if isinstance(ik, str) and isinstance(rr, int) and rr >= 0:\n",
    "                    prev = regen_counts.get(ik, 0)\n",
    "                    if rr > prev:\n",
    "                        regen_counts[ik] = rr\n",
    "                    prev_best = best_round.get(ik, -1)\n",
    "                    if rr >= prev_best:\n",
    "                        best_round[ik] = rr\n",
    "                        last_rejected_text[ik] = txt if isinstance(txt, str) else None\n",
    "\n",
    "            if et == \"decision\":\n",
    "                ik = ev.get(\"instance_key\")\n",
    "                status = ev.get(\"status\")\n",
    "                final_desc = ev.get(\"final_description\")\n",
    "                llm_bundle = ev.get(\"llm_bundle\")\n",
    "                if isinstance(ik, str) and isinstance(status, str):\n",
    "                    decisions[ik] = (\n",
    "                        status,\n",
    "                        final_desc if isinstance(final_desc, str) else None,\n",
    "                        llm_bundle if isinstance(llm_bundle, dict) else None,\n",
    "                    )\n",
    "\n",
    "    return decisions, regen_counts, last_rejected_text, prior_run_start\n",
    "\n",
    "\n",
    "# ========= LLM helpers =========\n",
    "def _sanitize_llm_output(text: str) -> str:\n",
    "    t = (text or \"\").strip()\n",
    "    if t.startswith(\"{\") and \"description\" in t:\n",
    "        try:\n",
    "            obj = json.loads(t)\n",
    "            if isinstance(obj, dict) and isinstance(obj.get(\"description\"), str):\n",
    "                t = obj[\"description\"].strip()\n",
    "        except Exception:\n",
    "            pass\n",
    "    if (t.startswith('\"') and t.endswith('\"')) or (t.startswith(\"'\") and t.endswith(\"'\")):\n",
    "        t = t[1:-1].strip()\n",
    "    return t\n",
    "\n",
    "\n",
    "def _llm_chat_completion(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    model: str,\n",
    "    messages: List[Dict[str, str]],\n",
    "    temperature: float,\n",
    "    max_tokens: int,\n",
    "    seed: Optional[int],\n",
    ") -> Tuple[str, Dict[str, Any]]:\n",
    "    meta: Dict[str, Any] = {\n",
    "        \"seed_requested\": seed,\n",
    "        \"seed_applied\": False,\n",
    "        \"seed_error\": None,\n",
    "        \"finish_reason\": None,\n",
    "        \"usage\": None,\n",
    "        \"max_tokens_requested\": int(max_tokens),\n",
    "        \"max_param_used\": None,\n",
    "    }\n",
    "\n",
    "    base_kwargs: Dict[str, Any] = dict(model=model, messages=messages, temperature=temperature)\n",
    "\n",
    "    def attempt(max_param_used: str, include_seed: bool) -> Tuple[str, Dict[str, Any]]:\n",
    "        req = dict(base_kwargs)\n",
    "        if max_param_used == \"max_completion_tokens\":\n",
    "            req[\"max_completion_tokens\"] = int(max_tokens)\n",
    "        else:\n",
    "            req[\"max_tokens\"] = int(max_tokens)\n",
    "        if include_seed and seed is not None:\n",
    "            req[\"seed\"] = int(seed)\n",
    "\n",
    "        resp = client.chat.completions.create(**req)\n",
    "        text = (resp.choices[0].message.content or \"\").strip()\n",
    "\n",
    "        meta_local = dict(meta)\n",
    "        meta_local[\"max_param_used\"] = max_param_used\n",
    "        meta_local[\"finish_reason\"] = getattr(resp.choices[0], \"finish_reason\", None)\n",
    "        meta_local[\"usage\"] = getattr(resp, \"usage\", None)\n",
    "        meta_local[\"seed_applied\"] = bool(include_seed and seed is not None)\n",
    "        return text, meta_local\n",
    "\n",
    "    def is_seed_error(e: Exception) -> bool:\n",
    "        s = str(e).lower()\n",
    "        return (\"seed\" in s) and (\"unknown\" in s or \"unsupported\" in s or \"invalid\" in s)\n",
    "\n",
    "    try:\n",
    "        return attempt(\"max_completion_tokens\", include_seed=True)\n",
    "    except Exception as e1:\n",
    "        if seed is not None and is_seed_error(e1):\n",
    "            meta[\"seed_error\"] = str(e1)\n",
    "            try:\n",
    "                return attempt(\"max_completion_tokens\", include_seed=False)\n",
    "            except Exception:\n",
    "                pass\n",
    "        try:\n",
    "            return attempt(\"max_tokens\", include_seed=True)\n",
    "        except Exception as e2:\n",
    "            if seed is not None and is_seed_error(e2):\n",
    "                meta[\"seed_error\"] = str(e2)\n",
    "                return attempt(\"max_tokens\", include_seed=False)\n",
    "            raise\n",
    "\n",
    "\n",
    "def generate_description_via_llm(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    tool_name: str,\n",
    "    base_description: str,\n",
    "    model: str,\n",
    "    seed: Optional[int],\n",
    "    max_tokens: int,\n",
    "    retry_on_length: bool,\n",
    "    retry_max_tokens: int,\n",
    "    mode_key: str,\n",
    "    style_spec: Dict[str, Any],\n",
    "    regen_index: int = 0,\n",
    "    previous_rewrite: Optional[str] = None,\n",
    "    length_policy: Optional[Dict[str, Any]] = None,\n",
    ") -> Tuple[str, Dict[str, Any]]:\n",
    "    system = str(style_spec[\"system\"])\n",
    "    regen_instr = str(style_spec.get(\"regen_diversity_instruction\") or \"\")\n",
    "    max_prev = int(style_spec.get(\"max_prev_rewrite_chars\") or DEFAULT_MAX_PREV_REWRITE_CHARS)\n",
    "\n",
    "    user_parts: List[str] = []\n",
    "    user_parts.append(f\"Tool name: {tool_name}\")\n",
    "    user_parts.append(\"Base description:\")\n",
    "    user_parts.append(base_description.strip() or \"(empty)\")\n",
    "    user_parts.append(\"\")\n",
    "    user_parts.append(f\"Rewrite in '{mode_key}' under the constraints.\")\n",
    "\n",
    "    if mode_key == \"style_concise\" and isinstance(length_policy, dict):\n",
    "        ct = length_policy.get(\"concise_soft_target\") if isinstance(length_policy.get(\"concise_soft_target\"), dict) else {}\n",
    "        applied = bool(ct.get(\"applied\", False))\n",
    "        target_chars = ct.get(\"target_chars\") if isinstance(ct.get(\"target_chars\"), int) else None\n",
    "        ratio = ct.get(\"target_ratio\")\n",
    "        if applied and isinstance(target_chars, int):\n",
    "            pct = int(float(ratio) * 100) if isinstance(ratio, (int, float)) else 70\n",
    "            user_parts.append(\"\")\n",
    "            user_parts.append(f\"Length guidance (soft target): <= {target_chars} characters (~{pct}% of base).\")\n",
    "            user_parts.append(\n",
    "                \"Exceeding the target is permitted only if strictly necessary to preserve meaning; \"\n",
    "                \"no explicitly stated details may be omitted.\"\n",
    "            )\n",
    "        else:\n",
    "            user_parts.append(\"\")\n",
    "            user_parts.append(\n",
    "                \"Length guidance: the base description is short or cannot be shortened safely; \"\n",
    "                \"the rewrite must not exceed the base length and must remain as brief as possible.\"\n",
    "            )\n",
    "\n",
    "    if regen_index > 0:\n",
    "        user_parts.append(\"\")\n",
    "        user_parts.append(f\"Regeneration request: {regen_index}\")\n",
    "        if regen_instr:\n",
    "            user_parts.append(regen_instr)\n",
    "        if previous_rewrite and previous_rewrite.strip():\n",
    "            prev = previous_rewrite.strip()\n",
    "            if len(prev) > max_prev:\n",
    "                prev = prev[:max_prev].rstrip()\n",
    "            user_parts.append(\"\")\n",
    "            user_parts.append(\"Previous rewrite (wording must not be reused):\")\n",
    "            user_parts.append(prev)\n",
    "\n",
    "    user = \"\\n\".join(user_parts)\n",
    "\n",
    "    raw1, meta1 = _llm_chat_completion(\n",
    "        client=client,\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": user}],\n",
    "        temperature=0.0,\n",
    "        max_tokens=max_tokens,\n",
    "        seed=seed,\n",
    "    )\n",
    "    san1 = _sanitize_llm_output(raw1)\n",
    "    finish1 = (meta1.get(\"finish_reason\") or \"\").lower()\n",
    "    looks_truncated_1 = (finish1 == \"length\")\n",
    "\n",
    "    if not looks_truncated_1:\n",
    "        return san1, {\n",
    "            \"proposal_origin\": \"primary\",\n",
    "            \"proposal_sanitized_final\": san1,\n",
    "            \"llm_text_raw_primary\": raw1,\n",
    "            \"llm_text_raw_retry\": None,\n",
    "            \"primary\": meta1,\n",
    "            \"retry\": None,\n",
    "            \"mode_key\": mode_key,\n",
    "            \"length_policy\": length_policy,\n",
    "        }\n",
    "\n",
    "    raw2 = None\n",
    "    meta2 = None\n",
    "    san2 = None\n",
    "    best_san = san1\n",
    "    origin = \"primary\"\n",
    "\n",
    "    if retry_on_length and retry_max_tokens > max_tokens:\n",
    "        raw2, meta2 = _llm_chat_completion(\n",
    "            client=client,\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": user}],\n",
    "            temperature=0.0,\n",
    "            max_tokens=int(retry_max_tokens),\n",
    "            seed=seed,\n",
    "        )\n",
    "        san2 = _sanitize_llm_output(raw2)\n",
    "        if san2 and len(san2) >= len(best_san):\n",
    "            best_san = san2\n",
    "            origin = \"retry\"\n",
    "\n",
    "    return best_san, {\n",
    "        \"proposal_origin\": origin,\n",
    "        \"proposal_sanitized_final\": best_san,\n",
    "        \"llm_text_raw_primary\": raw1,\n",
    "        \"llm_text_raw_retry\": raw2,\n",
    "        \"primary\": meta1,\n",
    "        \"retry\": meta2,\n",
    "        \"mode_key\": mode_key,\n",
    "        \"length_policy\": length_policy,\n",
    "    }\n",
    "\n",
    "\n",
    "def _print_perturbation_context(\n",
    "    *,\n",
    "    show: bool,\n",
    "    tool_name: str,\n",
    "    candidate_i_1based: int,\n",
    "    k: int,\n",
    "    generation_round: int,\n",
    "    regen_index: int,\n",
    "    seed: Optional[int],\n",
    "    max_tokens: int,\n",
    "    mode_key: str,\n",
    "    style_spec: Dict[str, Any],\n",
    "    length_policy: Optional[Dict[str, Any]],\n",
    "    prev_hint: Optional[str],\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Prints (to stdout) the \"perturbation context\" used for this candidate generation.\n",
    "    This is intentionally concise: it shows *what* changes across candidates/rounds without dumping full prompts.\n",
    "    \"\"\"\n",
    "    if not show:\n",
    "        return\n",
    "\n",
    "    regen_instr = str(style_spec.get(\"regen_diversity_instruction\") or \"\").strip()\n",
    "\n",
    "    ct = None\n",
    "    if isinstance(length_policy, dict):\n",
    "        ct0 = length_policy.get(\"concise_soft_target\")\n",
    "        if isinstance(ct0, dict):\n",
    "            ct = ct0\n",
    "\n",
    "    ct_applied = bool(ct.get(\"applied\", False)) if isinstance(ct, dict) else False\n",
    "    ct_target = ct.get(\"target_chars\") if (isinstance(ct, dict) and isinstance(ct.get(\"target_chars\"), int)) else None\n",
    "    ct_reason = ct.get(\"reason\") if isinstance(ct, dict) else None\n",
    "\n",
    "    print(\n",
    "        f\"\\n  [gen] {tool_name} | cand {candidate_i_1based}/{int(k)} | round={int(generation_round)} | \"\n",
    "        f\"regen_index={int(regen_index)} | mode={mode_key} | seed={seed} | max_tokens={int(max_tokens)}\"\n",
    "    )\n",
    "\n",
    "    if mode_key == \"style_concise\":\n",
    "        if ct_applied and isinstance(ct_target, int):\n",
    "            print(f\"      length_guidance: soft_target<= {int(ct_target)} chars (applied)\")\n",
    "        else:\n",
    "            print(f\"      length_guidance: soft_target not applied (reason={ct_reason})\")\n",
    "\n",
    "    if int(generation_round) > 0 or int(regen_index) > 0:\n",
    "        if regen_instr:\n",
    "            sn = \" \".join(regen_instr.split())\n",
    "            if len(sn) > 220:\n",
    "                sn = sn[:219] + \"…\"\n",
    "            print(f\"      diversity_instruction: {sn}\")\n",
    "\n",
    "    if prev_hint and prev_hint.strip():\n",
    "        ph = prev_hint.strip()\n",
    "        ph_sn = \" \".join(ph.split())\n",
    "        if len(ph_sn) > 220:\n",
    "            ph_sn = ph_sn[:219] + \"…\"\n",
    "        print(\n",
    "            f\"      previous_rewrite_hint: len={len(ph)} sha={_sha256_text(ph)[:12]} snippet='{ph_sn}'\"\n",
    "        )\n",
    "\n",
    "\n",
    "def generate_k_candidates_with_stats(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    tool_name: str,\n",
    "    base_description: str,\n",
    "    model: str,\n",
    "    seed: Optional[int],\n",
    "    max_tokens: int,\n",
    "    retry_on_length: bool,\n",
    "    retry_max_tokens: int,\n",
    "    mode_key: str,\n",
    "    style_spec: Dict[str, Any],\n",
    "    generation_round: int,\n",
    "    k: int,\n",
    "    previous_rewrite_hint: Optional[str],\n",
    "    min_sleep_sec_between_calls: float,\n",
    "    length_policy: Optional[Dict[str, Any]],\n",
    "    semantic_cfg: Optional[Dict[str, Any]],\n",
    "    show_perturbations: bool,\n",
    ") -> Tuple[List[Dict[str, Any]], Optional[str]]:\n",
    "    base_desc = (base_description or \"\").strip()\n",
    "    k_eff = max(1, int(k))\n",
    "\n",
    "    candidates: List[Dict[str, Any]] = []\n",
    "    seen: set = set()\n",
    "\n",
    "    prev = previous_rewrite_hint.strip() if isinstance(previous_rewrite_hint, str) and previous_rewrite_hint.strip() else None\n",
    "    last_generated_text: Optional[str] = None\n",
    "\n",
    "    for i in range(0, k_eff):\n",
    "        regen_index = int(generation_round) * 1000 + i\n",
    "        text = \"\"\n",
    "        bundle: Optional[Dict[str, Any]] = None\n",
    "        err: Optional[str] = None\n",
    "\n",
    "        # Feb 3 patch: print perturbation context *before* the LLM call.\n",
    "        _print_perturbation_context(\n",
    "            show=bool(show_perturbations),\n",
    "            tool_name=tool_name,\n",
    "            candidate_i_1based=i + 1,\n",
    "            k=k_eff,\n",
    "            generation_round=int(generation_round),\n",
    "            regen_index=int(regen_index),\n",
    "            seed=seed,\n",
    "            max_tokens=int(max_tokens),\n",
    "            mode_key=mode_key,\n",
    "            style_spec=style_spec,\n",
    "            length_policy=length_policy,\n",
    "            prev_hint=prev,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            text, bundle = generate_description_via_llm(\n",
    "                client=client,\n",
    "                tool_name=tool_name,\n",
    "                base_description=base_desc,\n",
    "                model=model,\n",
    "                seed=seed,\n",
    "                max_tokens=max_tokens,\n",
    "                retry_on_length=retry_on_length,\n",
    "                retry_max_tokens=retry_max_tokens,\n",
    "                mode_key=mode_key,\n",
    "                style_spec=style_spec,\n",
    "                regen_index=regen_index,\n",
    "                previous_rewrite=prev,\n",
    "                length_policy=length_policy,\n",
    "            )\n",
    "            text = (text or \"\").strip()\n",
    "            last_generated_text = text if text else last_generated_text\n",
    "        except Exception as e:\n",
    "            err = str(e)\n",
    "            text = \"\"\n",
    "\n",
    "        duplicate = False\n",
    "        if text:\n",
    "            if text in seen:\n",
    "                duplicate = True\n",
    "            else:\n",
    "                seen.add(text)\n",
    "\n",
    "        stats = compute_full_candidate_stats(\n",
    "            base_text=base_desc,\n",
    "            cand_text=text,\n",
    "            mode_key=mode_key,\n",
    "            length_policy=length_policy,\n",
    "            client=client,\n",
    "            semantic_cfg=semantic_cfg,\n",
    "        ) if text else None\n",
    "\n",
    "        candidates.append(\n",
    "            {\n",
    "                \"candidate_index\": i + 1,\n",
    "                \"text\": text,\n",
    "                \"error\": err,\n",
    "                \"bundle\": bundle,\n",
    "                \"duplicate\": duplicate,\n",
    "                \"stats\": stats,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        prev = text if text else prev\n",
    "\n",
    "        if min_sleep_sec_between_calls > 0:\n",
    "            time.sleep(float(min_sleep_sec_between_calls))\n",
    "\n",
    "    return candidates, last_generated_text\n",
    "\n",
    "\n",
    "# ========= IO =========\n",
    "def make_working_copy(input_jsonl: str, output_jsonl: str, *, overwrite: bool = False) -> str:\n",
    "    src = Path(input_jsonl)\n",
    "    dst = Path(output_jsonl)\n",
    "\n",
    "    if not src.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {src}\")\n",
    "\n",
    "    if dst.exists() and not overwrite:\n",
    "        return str(dst)\n",
    "\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(src, dst)\n",
    "    return str(dst)\n",
    "\n",
    "\n",
    "def _normalize_cmd(raw: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalizes user command strings.\n",
    "    Important: maps Esc (raw '\\x1b' or common textual forms) to quit.\n",
    "    \"\"\"\n",
    "    r = raw if raw is not None else \"\"\n",
    "    # If raw-key mode is enabled, Esc is returned as '\\x1b'.\n",
    "    if (\"\\x1b\" in r) or (r.strip().lower() in (\"esc\", \"<esc>\", \"^[\", \"escape\")):\n",
    "        return \"q\"\n",
    "\n",
    "    c = (r or \"\").strip().lower()\n",
    "    if c in (\"\", \"y\", \"yes\", \"ok\", \"okay\", \"si\", \"sì\"):\n",
    "        return \"y\"\n",
    "    if c in (\"r\", \"retry\", \"again\", \"prova\", \"prova ancora\", \"rigenera\"):\n",
    "        return \"r\"\n",
    "    if c in (\"e\", \"edit\", \"modifica\"):\n",
    "        return \"e\"\n",
    "    if c in (\"m\", \"manual\", \"mine\", \"mio\", \"mia\", \"custom\"):\n",
    "        return \"m\"\n",
    "    if c in (\"s\", \"skip\", \"salta\", \"pass\"):\n",
    "        return \"s\"\n",
    "    if c in (\"q\", \"quit\", \"exit\", \"esci\"):\n",
    "        return \"q\"\n",
    "    return c\n",
    "\n",
    "\n",
    "def _parse_candidate_choice(cmd: str, *, k: int) -> Optional[int]:\n",
    "    c = (cmd or \"\").strip()\n",
    "    if not c:\n",
    "        return None\n",
    "    if c.isdigit():\n",
    "        v = int(c)\n",
    "        if 1 <= v <= int(k):\n",
    "            return v\n",
    "    return None\n",
    "\n",
    "\n",
    "# ========= Main interactive =========\n",
    "def interactive_llm_tools_in_jsonl(\n",
    "    jsonl_path: str,\n",
    "    *,\n",
    "    tool_field: str,\n",
    "    create_backup_of_target: bool,\n",
    "    llm_model: str,\n",
    "    seed: Optional[int],\n",
    "    max_tokens: int,\n",
    "    retry_on_length: bool,\n",
    "    retry_max_tokens: int,\n",
    "    allow_reserialize_fallback: bool,\n",
    "    min_sleep_sec_between_calls: float,\n",
    "    audit_dir: str,\n",
    "    mode_key: str,\n",
    "    num_candidates: int,\n",
    "    max_token_preview: int,\n",
    "    max_token_string_len: int,\n",
    "    candidate_snippet_chars: int,\n",
    "    concise_target_ratio: float,\n",
    "    concise_target_min_base_len: int,\n",
    "    concise_target_min_chars: int,\n",
    "    semantic_cfg: Optional[Dict[str, Any]],\n",
    "    show_perturbations: bool,\n",
    "    raw_key_input: bool,\n",
    ") -> None:\n",
    "    mode_key, style_spec = _resolve_style(mode_key)\n",
    "\n",
    "    path = Path(jsonl_path)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {jsonl_path}\")\n",
    "\n",
    "    client = make_gemini_client()\n",
    "    audit_file = _audit_file_path(\n",
    "        path,\n",
    "        audit_dir=Path(audit_dir),\n",
    "        mode_key=mode_key,\n",
    "        model=llm_model,\n",
    "        tool_field=tool_field,\n",
    "        num_candidates=int(num_candidates),\n",
    "        semantic_cfg=semantic_cfg,\n",
    "    )\n",
    "\n",
    "    decisions_by_instance, regen_counts, last_rejected_text_by_instance, prior_run_start = _load_resume_state(audit_file)\n",
    "\n",
    "    tool_order: List[Dict[str, Any]] = []\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for raw_line in f:\n",
    "            line = raw_line.rstrip(\"\\n\")\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            try:\n",
    "                record = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "            if not isinstance(record, dict):\n",
    "                continue\n",
    "\n",
    "            rid = _record_id(record, tool_field=tool_field)\n",
    "            tools = record.get(tool_field)\n",
    "            if not isinstance(tools, list):\n",
    "                continue\n",
    "\n",
    "            for tool_index, entry in enumerate(tools):\n",
    "                tool_obj, kind = _load_tool(entry)\n",
    "                if not tool_obj:\n",
    "                    continue\n",
    "                name = (tool_obj.get(\"name\") or \"\").strip()\n",
    "                if not name:\n",
    "                    continue\n",
    "\n",
    "                desc_print, desc_mode = _get_description_for_print(entry)\n",
    "                instance_key = _tool_instance_key(rid, tool_index, tool_obj)\n",
    "\n",
    "                tool_order.append(\n",
    "                    {\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_index,\n",
    "                        \"tool_name\": name,\n",
    "                        \"desc_print\": desc_print,\n",
    "                        \"desc_mode\": desc_mode,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"entry_kind\": kind,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    n_total = len(tool_order)\n",
    "    n_prev_reviewed = len(decisions_by_instance)\n",
    "\n",
    "    start_pos = 0\n",
    "    while start_pos < n_total and tool_order[start_pos][\"instance_key\"] in decisions_by_instance:\n",
    "        start_pos += 1\n",
    "\n",
    "    session_id = hashlib.sha256(f\"{time.time_ns()}\".encode(\"utf-8\")).hexdigest()[:12]\n",
    "    before_sha = _sha256_file(path)\n",
    "\n",
    "    length_policy_config = {\n",
    "        \"concise_soft_target\": {\n",
    "            \"ratio\": float(concise_target_ratio),\n",
    "            \"min_base_len\": int(concise_target_min_base_len),\n",
    "            \"min_chars\": int(concise_target_min_chars),\n",
    "            \"policy_name\": \"concise_soft_target_v1\",\n",
    "        }\n",
    "    }\n",
    "\n",
    "    semantic_cfg_norm = dict(semantic_cfg or {})\n",
    "    semantic_cfg_norm[\"fallback_llm_model\"] = llm_model\n",
    "\n",
    "    if prior_run_start is None:\n",
    "        _append_audit_event(\n",
    "            audit_file,\n",
    "            {\n",
    "                \"event_type\": \"run_start\",\n",
    "                \"ts\": int(time.time()),\n",
    "                \"session_id\": session_id,\n",
    "                \"mode\": mode_key,\n",
    "                \"model\": llm_model,\n",
    "                \"seed\": seed,\n",
    "                \"dataset_path\": str(path),\n",
    "                \"dataset_sha256_at_session_start\": before_sha,\n",
    "                \"tool_field\": tool_field,\n",
    "                \"n_total_occurrences\": n_total,\n",
    "                \"max_tokens_requested\": int(max_tokens),\n",
    "                \"retry_on_length\": bool(retry_on_length),\n",
    "                \"retry_max_tokens\": int(retry_max_tokens),\n",
    "                \"allow_reserialize_fallback\": bool(allow_reserialize_fallback),\n",
    "                \"num_candidates\": int(num_candidates),\n",
    "                \"min_sleep_sec_between_calls\": float(min_sleep_sec_between_calls),\n",
    "                \"stats_max_token_preview\": int(max_token_preview),\n",
    "                \"stats_max_token_string_len\": int(max_token_string_len),\n",
    "                \"candidate_snippet_chars\": int(candidate_snippet_chars),\n",
    "                \"length_policy_config\": length_policy_config,\n",
    "                \"policy_versions\": {\n",
    "                    \"risk_policy_name\": RISK_POLICY_NAME,\n",
    "                    \"logic_token_policy_name\": LOGIC_TOKEN_POLICY_NAME,\n",
    "                    \"semantic_policy_name\": SEMANTIC_POLICY_NAME,\n",
    "                },\n",
    "                \"semantic_cfg\": semantic_cfg_norm,\n",
    "                \"show_perturbations\": bool(show_perturbations),\n",
    "                \"raw_key_input\": bool(raw_key_input),\n",
    "            },\n",
    "        )\n",
    "    else:\n",
    "        _append_audit_event(\n",
    "            audit_file,\n",
    "            {\n",
    "                \"event_type\": \"run_resume\",\n",
    "                \"ts\": int(time.time()),\n",
    "                \"session_id\": session_id,\n",
    "                \"mode\": mode_key,\n",
    "                \"model\": llm_model,\n",
    "                \"seed\": seed,\n",
    "                \"dataset_path\": str(path),\n",
    "                \"dataset_sha256_at_session_start\": before_sha,\n",
    "                \"tool_field\": tool_field,\n",
    "                \"n_total_occurrences\": n_total,\n",
    "                \"n_previously_reviewed\": n_prev_reviewed,\n",
    "                \"resume_from_index_1based\": (start_pos + 1) if start_pos < n_total else (n_total + 1),\n",
    "                \"num_candidates\": int(num_candidates),\n",
    "                \"candidate_snippet_chars\": int(candidate_snippet_chars),\n",
    "                \"length_policy_config\": length_policy_config,\n",
    "                \"policy_versions\": {\n",
    "                    \"risk_policy_name\": RISK_POLICY_NAME,\n",
    "                    \"logic_token_policy_name\": LOGIC_TOKEN_POLICY_NAME,\n",
    "                    \"semantic_policy_name\": SEMANTIC_POLICY_NAME,\n",
    "                },\n",
    "                \"semantic_cfg\": semantic_cfg_norm,\n",
    "                \"show_perturbations\": bool(show_perturbations),\n",
    "                \"raw_key_input\": bool(raw_key_input),\n",
    "            },\n",
    "        )\n",
    "\n",
    "    print(f\"Target: {path}\")\n",
    "    print(f\"Mode: {mode_key}\")\n",
    "    print(f\"Audit file (RESUMABLE): {audit_file}\")\n",
    "    print(f\"Tool occurrences total: {n_total}\")\n",
    "    if start_pos < n_total:\n",
    "        print(f\"Resume position: [{start_pos + 1}/{n_total}] (previously reviewed: {n_prev_reviewed})\")\n",
    "    else:\n",
    "        print(f\"Resume position: completed (previously reviewed: {n_prev_reviewed})\")\n",
    "    print(f\"LLM: {llm_model} @ {GEMINI_BASE_URL}\")\n",
    "    print(f\"Candidates per tool: {int(num_candidates)}\")\n",
    "    print(f\"Candidate snippet chars: {int(candidate_snippet_chars)}\")\n",
    "    print(f\"Policies: risk={RISK_POLICY_NAME}; logic={LOGIC_TOKEN_POLICY_NAME}; semantic={SEMANTIC_POLICY_NAME}\")\n",
    "    print(f\"Perturbation prints: {'enabled' if show_perturbations else 'disabled'}\")\n",
    "    print(f\"Raw key input (Esc-safe): {'enabled' if raw_key_input else 'disabled'}\")\n",
    "\n",
    "    if semantic_cfg_norm.get(\"enable_embeddings\"):\n",
    "        print(\n",
    "            \"Embedding signal: enabled; \"\n",
    "            f\"model='{semantic_cfg_norm.get('embedding_model')}', \"\n",
    "            f\"low_cos_thr={semantic_cfg_norm.get('embedding_low_cosine_threshold')}\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"Embedding signal: disabled\")\n",
    "    if semantic_cfg_norm.get(\"enable_verifier\"):\n",
    "        print(\n",
    "            \"Verifier signal: enabled; \"\n",
    "            f\"model='{semantic_cfg_norm.get('verifier_model') or llm_model}', \"\n",
    "            f\"max_tokens={int(semantic_cfg_norm.get('verifier_max_tokens', DEFAULT_VERIFIER_MAX_TOKENS))}\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"Verifier signal: disabled\")\n",
    "\n",
    "    if mode_key == \"style_concise\":\n",
    "        print(\n",
    "            \"Concise soft target: \"\n",
    "            f\"ratio={float(concise_target_ratio):.2f}, \"\n",
    "            f\"min_base_len={int(concise_target_min_base_len)}, \"\n",
    "            f\"min_chars={int(concise_target_min_chars)}\"\n",
    "        )\n",
    "    print(f\"Max tokens: {int(max_tokens)}; retry_on_length={bool(retry_on_length)}; retry_max_tokens={int(retry_max_tokens)}\")\n",
    "    print(\n",
    "        \"Commands: ENTER/ok=accept #1, 1..K=accept candidate, r=regenerate K, \"\n",
    "        \"e=edit candidate, m=manual, s=skip, q/Esc=quit, p<idx>=preview (e.g., p2)\\n\"\n",
    "    )\n",
    "\n",
    "    quit_requested = False\n",
    "    resume_next_index_1based: Optional[int] = None\n",
    "\n",
    "    max_prev = int(style_spec.get(\"max_prev_rewrite_chars\") or DEFAULT_MAX_PREV_REWRITE_CHARS)\n",
    "\n",
    "    session_summary: Dict[str, Any] = {\n",
    "        \"accepted\": 0,\n",
    "        \"edited\": 0,\n",
    "        \"manual\": 0,\n",
    "        \"skipped\": 0,\n",
    "        \"accepted_risk_labels\": {\"LOW\": 0, \"MED\": 0, \"HIGH\": 0, \"NA\": 0},\n",
    "        \"accepted_similarity_sum\": 0.0,\n",
    "        \"accepted_similarity_n\": 0,\n",
    "        \"accepted_base_chars_sum\": 0,\n",
    "        \"accepted_cand_chars_sum\": 0,\n",
    "        \"accepted_len_ratio_sum\": 0.0,\n",
    "        \"accepted_len_ratio_n\": 0,\n",
    "        \"accepted_len_delta_sum\": 0,\n",
    "        \"accepted_soft_target_applicable_n\": 0,\n",
    "        \"accepted_within_soft_target_n\": 0,\n",
    "        \"accepted_embedding_cos_sum\": 0.0,\n",
    "        \"accepted_embedding_cos_n\": 0,\n",
    "        \"accepted_entails\": 0,\n",
    "        \"accepted_not_entails\": 0,\n",
    "        \"accepted_entails_unknown\": 0,\n",
    "    }\n",
    "\n",
    "    for pos in range(start_pos, n_total):\n",
    "        item = tool_order[pos]\n",
    "        idx = pos + 1\n",
    "\n",
    "        name = item[\"tool_name\"]\n",
    "        desc_mode = item[\"desc_mode\"]\n",
    "        old_desc_print = item[\"desc_print\"]\n",
    "        instance_key = item[\"instance_key\"]\n",
    "        rid = item[\"record_id\"]\n",
    "        tool_i = item[\"tool_index\"]\n",
    "\n",
    "        generation_round = int(regen_counts.get(instance_key, 0))\n",
    "        previous_rewrite_hint: Optional[str] = last_rejected_text_by_instance.get(instance_key)\n",
    "\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"[{idx}/{n_total}] {name}\")\n",
    "        print(f\"instance_key: {instance_key} (record_id={rid}, tool_index={tool_i})\")\n",
    "\n",
    "        if desc_mode == \"raw_json\":\n",
    "            print(\"Current description RAW (escaped):\")\n",
    "            print(old_desc_print if old_desc_print else \"(empty)\")\n",
    "            base_desc = _decode_raw_json_string(old_desc_print) if old_desc_print else \"\"\n",
    "            print(\"\\nCurrent description DECODED:\")\n",
    "            print(base_desc if base_desc else \"(empty)\")\n",
    "        else:\n",
    "            base_desc = old_desc_print or \"\"\n",
    "            print(\"Current description:\")\n",
    "            print(base_desc if base_desc else \"(empty)\")\n",
    "\n",
    "        base_desc = (base_desc or \"\").strip()\n",
    "        base_len_chars = len(base_desc)\n",
    "\n",
    "        length_policy = _make_length_policy(\n",
    "            base_desc=base_desc,\n",
    "            mode_key=mode_key,\n",
    "            concise_ratio=float(concise_target_ratio),\n",
    "            concise_min_base_len=int(concise_target_min_base_len),\n",
    "            concise_min_chars=int(concise_target_min_chars),\n",
    "        )\n",
    "\n",
    "        _print_base_stats(base_desc, max_preview=int(max_token_preview), max_tok_len=int(max_token_string_len))\n",
    "        if mode_key == \"style_concise\":\n",
    "            ct = length_policy.get(\"concise_soft_target\", {}) if isinstance(length_policy.get(\"concise_soft_target\"), dict) else {}\n",
    "            if ct.get(\"applied\") and isinstance(ct.get(\"target_chars\"), int):\n",
    "                print(f\"Concise soft target (applied): target_chars={ct.get('target_chars')} (base_len={base_len_chars})\")\n",
    "            else:\n",
    "                print(f\"Concise soft target (not applied): reason={ct.get('reason')} (base_len={base_len_chars})\")\n",
    "\n",
    "        candidates: List[Dict[str, Any]] = []\n",
    "        last_generated_text: Optional[str] = None\n",
    "\n",
    "        while True:\n",
    "            if not candidates:\n",
    "                try:\n",
    "                    candidates, last_generated_text = generate_k_candidates_with_stats(\n",
    "                        client=client,\n",
    "                        tool_name=name,\n",
    "                        base_description=base_desc,\n",
    "                        model=llm_model,\n",
    "                        seed=seed,\n",
    "                        max_tokens=max_tokens,\n",
    "                        retry_on_length=retry_on_length,\n",
    "                        retry_max_tokens=retry_max_tokens,\n",
    "                        mode_key=mode_key,\n",
    "                        style_spec=style_spec,\n",
    "                        generation_round=generation_round,\n",
    "                        k=int(num_candidates),\n",
    "                        previous_rewrite_hint=previous_rewrite_hint,\n",
    "                        min_sleep_sec_between_calls=float(min_sleep_sec_between_calls),\n",
    "                        length_policy=length_policy,\n",
    "                        semantic_cfg=semantic_cfg_norm,\n",
    "                        show_perturbations=bool(show_perturbations),\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nLLM ERROR (candidate set generation): {e}\")\n",
    "                    raw = _read_command(\"Choice [m=manual, s=skip, q/Esc=quit] > \", k=int(num_candidates), raw_key_input=bool(raw_key_input))\n",
    "                    cmd = _normalize_cmd(raw)\n",
    "                    now = int(time.time())\n",
    "\n",
    "                    if cmd == \"q\":\n",
    "                        quit_requested = True\n",
    "                        resume_next_index_1based = idx\n",
    "                        break\n",
    "\n",
    "                    if cmd == \"s\":\n",
    "                        decisions_by_instance[instance_key] = (\"skipped\", None, None)\n",
    "                        _append_audit_event(\n",
    "                            audit_file,\n",
    "                            {\n",
    "                                \"event_type\": \"decision\",\n",
    "                                \"ts\": now,\n",
    "                                \"session_id\": session_id,\n",
    "                                \"status\": \"skipped\",\n",
    "                                \"tool_name\": name,\n",
    "                                \"instance_key\": instance_key,\n",
    "                                \"record_id\": rid,\n",
    "                                \"tool_index\": tool_i,\n",
    "                                \"model\": llm_model,\n",
    "                                \"seed\": seed,\n",
    "                                \"mode\": mode_key,\n",
    "                                \"base_description\": base_desc,\n",
    "                                \"final_description\": None,\n",
    "                                \"source\": \"user\",\n",
    "                                \"note\": \"skip_after_llm_error\",\n",
    "                                \"length_policy\": length_policy,\n",
    "                                \"semantic_cfg\": semantic_cfg_norm,\n",
    "                            },\n",
    "                        )\n",
    "                        session_summary[\"skipped\"] += 1\n",
    "                        break\n",
    "\n",
    "                    if cmd == \"m\":\n",
    "                        manual_final = input(\"Manual final description (empty cancels) > \").rstrip(\"\\n\").strip()\n",
    "                        status = \"manual\" if manual_final else \"skipped\"\n",
    "                        decisions_by_instance[instance_key] = (status, manual_final or None, None)\n",
    "                        diff_stats = compute_full_candidate_stats(\n",
    "                            base_text=base_desc,\n",
    "                            cand_text=manual_final,\n",
    "                            mode_key=mode_key,\n",
    "                            length_policy=length_policy,\n",
    "                            client=client,\n",
    "                            semantic_cfg=semantic_cfg_norm,\n",
    "                        ) if manual_final else None\n",
    "\n",
    "                        _append_audit_event(\n",
    "                            audit_file,\n",
    "                            {\n",
    "                                \"event_type\": \"decision\",\n",
    "                                \"ts\": now,\n",
    "                                \"session_id\": session_id,\n",
    "                                \"status\": status,\n",
    "                                \"tool_name\": name,\n",
    "                                \"instance_key\": instance_key,\n",
    "                                \"record_id\": rid,\n",
    "                                \"tool_index\": tool_i,\n",
    "                                \"model\": llm_model,\n",
    "                                \"seed\": seed,\n",
    "                                \"mode\": mode_key,\n",
    "                                \"base_description\": base_desc,\n",
    "                                \"final_description\": manual_final or None,\n",
    "                                \"source\": \"user\",\n",
    "                                \"note\": \"manual_after_llm_error\",\n",
    "                                \"diff_stats\": diff_stats,\n",
    "                                \"length_policy\": length_policy,\n",
    "                                \"semantic_cfg\": semantic_cfg_norm,\n",
    "                            },\n",
    "                        )\n",
    "                        if status == \"manual\":\n",
    "                            session_summary[\"manual\"] += 1\n",
    "                        else:\n",
    "                            session_summary[\"skipped\"] += 1\n",
    "                        break\n",
    "\n",
    "                    candidates = []\n",
    "                    continue\n",
    "\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"candidates_generated\",\n",
    "                        \"ts\": int(time.time()),\n",
    "                        \"session_id\": session_id,\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"mode\": mode_key,\n",
    "                        \"model\": llm_model,\n",
    "                        \"seed\": seed,\n",
    "                        \"generation_round\": int(generation_round),\n",
    "                        \"num_candidates_requested\": int(num_candidates),\n",
    "                        \"base_len_chars\": int(base_len_chars),\n",
    "                        \"length_policy\": length_policy,\n",
    "                        \"semantic_cfg\": semantic_cfg_norm,\n",
    "                        \"candidates_summary\": [\n",
    "                            {\n",
    "                                \"candidate_index\": c.get(\"candidate_index\"),\n",
    "                                \"text_sha256\": _sha256_text((c.get(\"text\") or \"\").strip()),\n",
    "                                \"text_len\": len((c.get(\"text\") or \"\").strip()),\n",
    "                                \"error\": c.get(\"error\"),\n",
    "                                \"duplicate\": bool(c.get(\"duplicate\", False)),\n",
    "                                \"risk_label\": ((c.get(\"stats\") or {}).get(\"risk_label\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"similarity_ratio\": ((c.get(\"stats\") or {}).get(\"similarity_ratio\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"len_ratio\": ((c.get(\"stats\") or {}).get(\"len_ratio\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"len_delta_chars\": ((c.get(\"stats\") or {}).get(\"len_delta_chars\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"new_structural_count\": ((c.get(\"stats\") or {}).get(\"new_structural_count\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"missing_structural_count\": ((c.get(\"stats\") or {}).get(\"missing_structural_count\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"new_logic_count\": ((c.get(\"stats\") or {}).get(\"new_logic_count\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"missing_logic_count\": ((c.get(\"stats\") or {}).get(\"missing_logic_count\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"concise_soft_target_applied\": ((c.get(\"stats\") or {}).get(\"concise_soft_target_applied\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"concise_soft_target_chars\": ((c.get(\"stats\") or {}).get(\"concise_soft_target_chars\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"within_soft_target\": ((c.get(\"stats\") or {}).get(\"within_soft_target\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"embedding_cosine\": (\n",
    "                                    (((c.get(\"stats\") or {}).get(\"semantic\") or {}).get(\"embedding\") or {}).get(\"cosine\")\n",
    "                                    if isinstance(c.get(\"stats\"), dict) else None\n",
    "                                ),\n",
    "                                \"verifier_label\": (\n",
    "                                    (((c.get(\"stats\") or {}).get(\"semantic\") or {}).get(\"verifier\") or {}).get(\"label\")\n",
    "                                    if isinstance(c.get(\"stats\"), dict) else None\n",
    "                                ),\n",
    "                            }\n",
    "                            for c in candidates\n",
    "                        ],\n",
    "                    },\n",
    "                )\n",
    "\n",
    "            print(\"\\nCandidates overview:\")\n",
    "            for c in candidates:\n",
    "                _print_candidate_summary_line(\n",
    "                    int(c.get(\"candidate_index\") or 0),\n",
    "                    c,\n",
    "                    max_preview=int(max_token_preview),\n",
    "                    max_tok_len=int(max_token_string_len),\n",
    "                    snippet_chars=int(candidate_snippet_chars),\n",
    "                )\n",
    "\n",
    "            raw = _read_command(\n",
    "                f\"\\nChoice [ENTER=accept #1, 1..{int(num_candidates)}=accept, r=regen, e=edit, m=manual, s=skip, q/Esc=quit, p<idx>=preview] > \",\n",
    "                k=int(num_candidates),\n",
    "                raw_key_input=bool(raw_key_input),\n",
    "            )\n",
    "            cmd = _normalize_cmd(raw)\n",
    "            now = int(time.time())\n",
    "\n",
    "            if cmd == \"q\":\n",
    "                quit_requested = True\n",
    "                resume_next_index_1based = idx\n",
    "                break\n",
    "\n",
    "            if cmd == \"s\":\n",
    "                decisions_by_instance[instance_key] = (\"skipped\", None, None)\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"decision\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"status\": \"skipped\",\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"model\": llm_model,\n",
    "                        \"seed\": seed,\n",
    "                        \"mode\": mode_key,\n",
    "                        \"base_description\": base_desc,\n",
    "                        \"final_description\": None,\n",
    "                        \"source\": \"user\",\n",
    "                        \"note\": \"skip\",\n",
    "                        \"length_policy\": length_policy,\n",
    "                        \"semantic_cfg\": semantic_cfg_norm,\n",
    "                    },\n",
    "                )\n",
    "                session_summary[\"skipped\"] += 1\n",
    "                break\n",
    "\n",
    "            if cmd == \"r\":\n",
    "                generation_round += 1\n",
    "                regen_counts[instance_key] = int(generation_round)\n",
    "\n",
    "                if last_generated_text and isinstance(last_generated_text, str) and last_generated_text.strip():\n",
    "                    hint = last_generated_text.strip()\n",
    "                    if len(hint) > max_prev:\n",
    "                        hint = hint[:max_prev].rstrip()\n",
    "                    previous_rewrite_hint = hint\n",
    "                    last_rejected_text_by_instance[instance_key] = hint\n",
    "\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"regenerate\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"mode\": mode_key,\n",
    "                        \"generation_round\": int(generation_round),\n",
    "                        \"last_generated_text\": previous_rewrite_hint,\n",
    "                        \"last_generated_text_sha256\": _sha256_text(previous_rewrite_hint or \"\"),\n",
    "                        \"length_policy\": length_policy,\n",
    "                        \"semantic_cfg\": semantic_cfg_norm,\n",
    "                    },\n",
    "                )\n",
    "\n",
    "                candidates = []\n",
    "                last_generated_text = None\n",
    "                if min_sleep_sec_between_calls > 0:\n",
    "                    time.sleep(float(min_sleep_sec_between_calls))\n",
    "                continue\n",
    "\n",
    "            if cmd == \"m\":\n",
    "                manual_final = input(\"Manual final description (empty cancels) > \").rstrip(\"\\n\").strip()\n",
    "                status = \"manual\" if manual_final else \"skipped\"\n",
    "                decisions_by_instance[instance_key] = (status, manual_final or None, None)\n",
    "\n",
    "                diff_stats = compute_full_candidate_stats(\n",
    "                    base_text=base_desc,\n",
    "                    cand_text=manual_final,\n",
    "                    mode_key=mode_key,\n",
    "                    length_policy=length_policy,\n",
    "                    client=client,\n",
    "                    semantic_cfg=semantic_cfg_norm,\n",
    "                ) if manual_final else None\n",
    "\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"decision\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"status\": status,\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"model\": llm_model,\n",
    "                        \"seed\": seed,\n",
    "                        \"mode\": mode_key,\n",
    "                        \"base_description\": base_desc,\n",
    "                        \"final_description\": manual_final or None,\n",
    "                        \"source\": \"user\",\n",
    "                        \"note\": \"manual_replace\",\n",
    "                        \"diff_stats\": diff_stats,\n",
    "                        \"length_policy\": length_policy,\n",
    "                        \"semantic_cfg\": semantic_cfg_norm,\n",
    "                    },\n",
    "                )\n",
    "                if status == \"manual\":\n",
    "                    session_summary[\"manual\"] += 1\n",
    "                else:\n",
    "                    session_summary[\"skipped\"] += 1\n",
    "                break\n",
    "\n",
    "            if cmd == \"e\":\n",
    "                raw_idx = input(f\"Candidate index to edit [1..{int(num_candidates)}] (empty=1) > \").strip()\n",
    "                chosen_i = 1\n",
    "                if raw_idx and raw_idx.isdigit():\n",
    "                    chosen_i = int(raw_idx)\n",
    "                if not (1 <= chosen_i <= int(num_candidates)):\n",
    "                    print(\"Invalid candidate index.\")\n",
    "                    continue\n",
    "\n",
    "                cand = candidates[chosen_i - 1] if (chosen_i - 1) < len(candidates) else None\n",
    "                base_text = (cand.get(\"text\") or \"\").strip() if isinstance(cand, dict) else \"\"\n",
    "                if base_text:\n",
    "                    print(\"\\nSelected candidate text:\")\n",
    "                    print(base_text)\n",
    "                else:\n",
    "                    print(\"\\nSelected candidate is empty; editing starts from empty string.\")\n",
    "                    base_text = \"\"\n",
    "\n",
    "                edited = input(\"Edit final description (empty cancels) > \").rstrip(\"\\n\").strip()\n",
    "                status = \"edited\" if edited else \"skipped\"\n",
    "                bundle = cand.get(\"bundle\") if isinstance(cand, dict) else None\n",
    "                stats = compute_full_candidate_stats(\n",
    "                    base_text=base_desc,\n",
    "                    cand_text=edited,\n",
    "                    mode_key=mode_key,\n",
    "                    length_policy=length_policy,\n",
    "                    client=client,\n",
    "                    semantic_cfg=semantic_cfg_norm,\n",
    "                ) if edited else None\n",
    "\n",
    "                decisions_by_instance[instance_key] = (status, edited or None, bundle if isinstance(bundle, dict) else None)\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"decision\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"status\": status,\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"model\": llm_model,\n",
    "                        \"seed\": seed,\n",
    "                        \"mode\": mode_key,\n",
    "                        \"base_description\": base_desc,\n",
    "                        \"final_description\": edited or None,\n",
    "                        \"source\": \"user\",\n",
    "                        \"note\": \"edit_candidate\",\n",
    "                        \"chosen_candidate_index\": int(chosen_i),\n",
    "                        \"llm_bundle\": bundle if isinstance(bundle, dict) else None,\n",
    "                        \"diff_stats\": stats,\n",
    "                        \"generation_round\": int(generation_round),\n",
    "                        \"length_policy\": length_policy,\n",
    "                        \"semantic_cfg\": semantic_cfg_norm,\n",
    "                    },\n",
    "                )\n",
    "                if status == \"edited\":\n",
    "                    session_summary[\"edited\"] += 1\n",
    "                else:\n",
    "                    session_summary[\"skipped\"] += 1\n",
    "                break\n",
    "\n",
    "            choice_i = 1 if cmd == \"y\" else _parse_candidate_choice(cmd, k=int(num_candidates))\n",
    "            if choice_i is not None:\n",
    "                if not (1 <= int(choice_i) <= int(num_candidates)):\n",
    "                    print(\"Invalid candidate index.\")\n",
    "                    continue\n",
    "                cand = candidates[int(choice_i) - 1] if (int(choice_i) - 1) < len(candidates) else None\n",
    "                if not isinstance(cand, dict):\n",
    "                    print(\"Candidate not available.\")\n",
    "                    continue\n",
    "                if cand.get(\"error\") or not (cand.get(\"text\") or \"\").strip():\n",
    "                    print(\"Selected candidate is not acceptable (empty or error).\")\n",
    "                    _print_candidate_full(int(choice_i), cand, max_preview=int(max_token_preview), max_tok_len=int(max_token_string_len))\n",
    "                    continue\n",
    "\n",
    "                final_desc = (cand.get(\"text\") or \"\").strip()\n",
    "                bundle = cand.get(\"bundle\") if isinstance(cand.get(\"bundle\"), dict) else None\n",
    "                stats = cand.get(\"stats\") if isinstance(cand.get(\"stats\"), dict) else compute_full_candidate_stats(\n",
    "                    base_text=base_desc,\n",
    "                    cand_text=final_desc,\n",
    "                    mode_key=mode_key,\n",
    "                    length_policy=length_policy,\n",
    "                    client=client,\n",
    "                    semantic_cfg=semantic_cfg_norm,\n",
    "                )\n",
    "\n",
    "                decisions_by_instance[instance_key] = (\"accepted\", final_desc, bundle)\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"decision\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"status\": \"accepted\",\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"model\": llm_model,\n",
    "                        \"seed\": seed,\n",
    "                        \"mode\": mode_key,\n",
    "                        \"base_description\": base_desc,\n",
    "                        \"final_description\": final_desc,\n",
    "                        \"source\": \"llm\",\n",
    "                        \"chosen_candidate_index\": int(choice_i),\n",
    "                        \"generation_round\": int(generation_round),\n",
    "                        \"llm_bundle\": bundle,\n",
    "                        \"diff_stats\": stats,\n",
    "                        \"length_policy\": length_policy,\n",
    "                        \"semantic_cfg\": semantic_cfg_norm,\n",
    "                    },\n",
    "                )\n",
    "\n",
    "                session_summary[\"accepted\"] += 1\n",
    "                rl = (stats.get(\"risk_label\") if isinstance(stats, dict) else None) or \"NA\"\n",
    "                if rl not in session_summary[\"accepted_risk_labels\"]:\n",
    "                    rl = \"NA\"\n",
    "                session_summary[\"accepted_risk_labels\"][rl] += 1\n",
    "\n",
    "                sim = stats.get(\"similarity_ratio\") if isinstance(stats, dict) else None\n",
    "                if isinstance(sim, (int, float)):\n",
    "                    session_summary[\"accepted_similarity_sum\"] += float(sim)\n",
    "                    session_summary[\"accepted_similarity_n\"] += 1\n",
    "\n",
    "                bl = stats.get(\"base_len_chars\") if isinstance(stats, dict) else None\n",
    "                cl = stats.get(\"cand_len_chars\") if isinstance(stats, dict) else None\n",
    "                lr = stats.get(\"len_ratio\") if isinstance(stats, dict) else None\n",
    "                ld = stats.get(\"len_delta_chars\") if isinstance(stats, dict) else None\n",
    "                if isinstance(bl, int) and isinstance(cl, int):\n",
    "                    session_summary[\"accepted_base_chars_sum\"] += int(bl)\n",
    "                    session_summary[\"accepted_cand_chars_sum\"] += int(cl)\n",
    "                if isinstance(lr, (int, float)):\n",
    "                    session_summary[\"accepted_len_ratio_sum\"] += float(lr)\n",
    "                    session_summary[\"accepted_len_ratio_n\"] += 1\n",
    "                if isinstance(ld, int):\n",
    "                    session_summary[\"accepted_len_delta_sum\"] += int(ld)\n",
    "\n",
    "                wst = stats.get(\"within_soft_target\") if isinstance(stats, dict) else None\n",
    "                st_applied = bool(stats.get(\"concise_soft_target_applied\", False)) if isinstance(stats, dict) else False\n",
    "                if st_applied:\n",
    "                    session_summary[\"accepted_soft_target_applicable_n\"] += 1\n",
    "                    if wst is True:\n",
    "                        session_summary[\"accepted_within_soft_target_n\"] += 1\n",
    "\n",
    "                sem = stats.get(\"semantic\") if isinstance(stats.get(\"semantic\"), dict) else None\n",
    "                if isinstance(sem, dict):\n",
    "                    emb = sem.get(\"embedding\") if isinstance(sem.get(\"embedding\"), dict) else None\n",
    "                    if isinstance(emb, dict) and isinstance(emb.get(\"cosine\"), (int, float)):\n",
    "                        session_summary[\"accepted_embedding_cos_sum\"] += float(emb.get(\"cosine\"))\n",
    "                        session_summary[\"accepted_embedding_cos_n\"] += 1\n",
    "                    ver = sem.get(\"verifier\") if isinstance(sem.get(\"verifier\"), dict) else None\n",
    "                    if isinstance(ver, dict) and isinstance(ver.get(\"label\"), str):\n",
    "                        lab = ver.get(\"label\")\n",
    "                        if lab == \"ENTAILS\":\n",
    "                            session_summary[\"accepted_entails\"] += 1\n",
    "                        elif lab == \"NOT_ENTAILS\":\n",
    "                            session_summary[\"accepted_not_entails\"] += 1\n",
    "                        else:\n",
    "                            session_summary[\"accepted_entails_unknown\"] += 1\n",
    "\n",
    "                break\n",
    "\n",
    "            if cmd.startswith(\"p\"):\n",
    "                raw_idx = cmd[1:].strip()\n",
    "                if raw_idx.isdigit():\n",
    "                    vi = int(raw_idx)\n",
    "                    if 1 <= vi <= int(num_candidates):\n",
    "                        _print_candidate_full(vi, candidates[vi - 1], max_preview=int(max_token_preview), max_tok_len=int(max_token_string_len))\n",
    "                        continue\n",
    "                print(\"Preview command format: p<index>, for example: p2\")\n",
    "                continue\n",
    "\n",
    "            print(\"Invalid command. Preview: p<index> (example: p2).\")\n",
    "\n",
    "        if quit_requested:\n",
    "            break\n",
    "\n",
    "    # ========= Apply decisions to file =========\n",
    "    tmp_path = path.with_suffix(path.suffix + \".tmp\")\n",
    "    updated_count = 0\n",
    "    patch_failures = 0\n",
    "\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as fin, tmp_path.open(\"w\", encoding=\"utf-8\") as fout:\n",
    "        for raw_line in fin:\n",
    "            line = raw_line.rstrip(\"\\n\")\n",
    "            if not line.strip():\n",
    "                fout.write(line + \"\\n\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                record = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                fout.write(line + \"\\n\")\n",
    "                continue\n",
    "\n",
    "            if not isinstance(record, dict):\n",
    "                fout.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "                continue\n",
    "\n",
    "            rid = _record_id(record, tool_field=tool_field)\n",
    "            tools = record.get(tool_field)\n",
    "\n",
    "            if isinstance(tools, list):\n",
    "                new_tools: List[Any] = []\n",
    "                for tool_index, entry in enumerate(tools):\n",
    "                    tool_obj, kind = _load_tool(entry)\n",
    "                    if not tool_obj:\n",
    "                        new_tools.append(entry)\n",
    "                        continue\n",
    "\n",
    "                    instance_key = _tool_instance_key(rid, tool_index, tool_obj)\n",
    "                    decision = decisions_by_instance.get(instance_key)\n",
    "\n",
    "                    if decision is None:\n",
    "                        new_tools.append(entry)\n",
    "                        continue\n",
    "\n",
    "                    status, new_desc, llm_bundle = decision\n",
    "                    if status in (\"accepted\", \"edited\", \"manual\") and new_desc:\n",
    "                        if kind == \"json_str\" and isinstance(entry, str):\n",
    "                            already_ok = False\n",
    "                            try:\n",
    "                                obj0 = json.loads(entry)\n",
    "                                if isinstance(obj0, dict) and obj0.get(\"description\") == new_desc:\n",
    "                                    already_ok = True\n",
    "                            except Exception:\n",
    "                                already_ok = False\n",
    "\n",
    "                            if already_ok:\n",
    "                                new_tools.append(entry)\n",
    "                                continue\n",
    "\n",
    "                            patched, ok, reason = _replace_top_level_string_field_in_raw_object(entry, \"description\", new_desc)\n",
    "                            if ok:\n",
    "                                new_tools.append(patched)\n",
    "                                updated_count += 1\n",
    "                            else:\n",
    "                                fallback_ok = False\n",
    "                                fallback_patched = entry\n",
    "                                if allow_reserialize_fallback:\n",
    "                                    try:\n",
    "                                        obj = json.loads(entry)\n",
    "                                        if isinstance(obj, dict):\n",
    "                                            obj[\"description\"] = new_desc\n",
    "                                            fallback_patched = json.dumps(obj, ensure_ascii=False)\n",
    "                                            fallback_ok = True\n",
    "                                    except Exception:\n",
    "                                        fallback_ok = False\n",
    "\n",
    "                                if fallback_ok:\n",
    "                                    new_tools.append(fallback_patched)\n",
    "                                    updated_count += 1\n",
    "                                    _append_audit_event(\n",
    "                                        audit_file,\n",
    "                                        {\n",
    "                                            \"event_type\": \"patch_fallback_reserialize\",\n",
    "                                            \"ts\": int(time.time()),\n",
    "                                            \"session_id\": session_id,\n",
    "                                            \"instance_key\": instance_key,\n",
    "                                            \"record_id\": rid,\n",
    "                                            \"tool_index\": tool_index,\n",
    "                                            \"tool_name\": tool_obj.get(\"name\"),\n",
    "                                            \"mode\": mode_key,\n",
    "                                            \"entry_sha256_before\": _sha256_text(entry),\n",
    "                                            \"entry_sha256_after\": _sha256_text(fallback_patched),\n",
    "                                            \"patch_reason\": reason,\n",
    "                                        },\n",
    "                                    )\n",
    "                                else:\n",
    "                                    new_tools.append(entry)\n",
    "                                    patch_failures += 1\n",
    "                        else:\n",
    "                            if tool_obj.get(\"description\") == new_desc:\n",
    "                                new_tools.append(tool_obj)\n",
    "                                continue\n",
    "                            tool_obj[\"description\"] = new_desc\n",
    "                            new_tools.append(tool_obj)\n",
    "                            updated_count += 1\n",
    "                    else:\n",
    "                        new_tools.append(entry)\n",
    "\n",
    "                record[tool_field] = new_tools\n",
    "\n",
    "            fout.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    if create_backup_of_target:\n",
    "        bak_path = path.with_suffix(path.suffix + \".bak\")\n",
    "        if not bak_path.exists():\n",
    "            shutil.copy2(path, bak_path)\n",
    "\n",
    "    tmp_path.replace(path)\n",
    "    after_sha = _sha256_file(path)\n",
    "\n",
    "    n_reviewed = len(decisions_by_instance)\n",
    "    n_skipped = sum(1 for st, _, _ in decisions_by_instance.values() if st == \"skipped\")\n",
    "    completed = (n_reviewed >= n_total) and (not quit_requested)\n",
    "\n",
    "    avg_sim = None\n",
    "    if int(session_summary[\"accepted_similarity_n\"]) > 0:\n",
    "        avg_sim = float(session_summary[\"accepted_similarity_sum\"]) / float(session_summary[\"accepted_similarity_n\"])\n",
    "\n",
    "    avg_len_ratio = None\n",
    "    if int(session_summary[\"accepted_len_ratio_n\"]) > 0:\n",
    "        avg_len_ratio = float(session_summary[\"accepted_len_ratio_sum\"]) / float(session_summary[\"accepted_len_ratio_n\"])\n",
    "\n",
    "    avg_len_delta = None\n",
    "    if int(session_summary[\"accepted\"]) > 0:\n",
    "        avg_len_delta = float(session_summary[\"accepted_len_delta_sum\"]) / float(session_summary[\"accepted\"])\n",
    "\n",
    "    avg_base_len = None\n",
    "    avg_cand_len = None\n",
    "    if int(session_summary[\"accepted\"]) > 0:\n",
    "        avg_base_len = float(session_summary[\"accepted_base_chars_sum\"]) / float(session_summary[\"accepted\"])\n",
    "        avg_cand_len = float(session_summary[\"accepted_cand_chars_sum\"]) / float(session_summary[\"accepted\"])\n",
    "\n",
    "    avg_emb_cos = None\n",
    "    if int(session_summary[\"accepted_embedding_cos_n\"]) > 0:\n",
    "        avg_emb_cos = float(session_summary[\"accepted_embedding_cos_sum\"]) / float(session_summary[\"accepted_embedding_cos_n\"])\n",
    "\n",
    "    _append_audit_event(\n",
    "        audit_file,\n",
    "        {\n",
    "            \"event_type\": \"run_end\",\n",
    "            \"ts\": int(time.time()),\n",
    "            \"session_id\": session_id,\n",
    "            \"mode\": mode_key,\n",
    "            \"model\": llm_model,\n",
    "            \"seed\": seed,\n",
    "            \"dataset_path\": str(path),\n",
    "            \"dataset_sha256_at_session_start\": before_sha,\n",
    "            \"dataset_sha256_at_session_end\": after_sha,\n",
    "            \"n_total_occurrences\": n_total,\n",
    "            \"n_reviewed_total\": n_reviewed,\n",
    "            \"n_updated_this_session\": updated_count,\n",
    "            \"n_skipped_total\": n_skipped,\n",
    "            \"completed\": bool(completed),\n",
    "            \"quit_requested\": bool(quit_requested),\n",
    "            \"raw_patch_failures_this_session\": patch_failures,\n",
    "            \"resume_next_index_1based\": resume_next_index_1based if quit_requested else (n_total + 1 if completed else None),\n",
    "            \"session_summary\": {\n",
    "                \"accepted\": int(session_summary[\"accepted\"]),\n",
    "                \"edited\": int(session_summary[\"edited\"]),\n",
    "                \"manual\": int(session_summary[\"manual\"]),\n",
    "                \"skipped\": int(session_summary[\"skipped\"]),\n",
    "                \"accepted_risk_labels\": session_summary[\"accepted_risk_labels\"],\n",
    "                \"accepted_avg_similarity\": avg_sim,\n",
    "                \"accepted_similarity_n\": int(session_summary[\"accepted_similarity_n\"]),\n",
    "                \"accepted_avg_len_ratio\": avg_len_ratio,\n",
    "                \"accepted_len_ratio_n\": int(session_summary[\"accepted_len_ratio_n\"]),\n",
    "                \"accepted_avg_len_delta_chars\": avg_len_delta,\n",
    "                \"accepted_avg_base_len_chars\": avg_base_len,\n",
    "                \"accepted_avg_cand_len_chars\": avg_cand_len,\n",
    "                \"accepted_soft_target_applicable_n\": int(session_summary[\"accepted_soft_target_applicable_n\"]),\n",
    "                \"accepted_within_soft_target_n\": int(session_summary[\"accepted_within_soft_target_n\"]),\n",
    "                \"accepted_avg_embedding_cosine\": avg_emb_cos,\n",
    "                \"accepted_embedding_cosine_n\": int(session_summary[\"accepted_embedding_cos_n\"]),\n",
    "                \"accepted_entails\": int(session_summary[\"accepted_entails\"]),\n",
    "                \"accepted_not_entails\": int(session_summary[\"accepted_not_entails\"]),\n",
    "                \"accepted_entails_unknown\": int(session_summary[\"accepted_entails_unknown\"]),\n",
    "            },\n",
    "            \"length_policy_config\": length_policy_config,\n",
    "            \"policy_versions\": {\n",
    "                \"risk_policy_name\": RISK_POLICY_NAME,\n",
    "                \"logic_token_policy_name\": LOGIC_TOKEN_POLICY_NAME,\n",
    "                \"semantic_policy_name\": SEMANTIC_POLICY_NAME,\n",
    "            },\n",
    "            \"semantic_cfg\": semantic_cfg_norm,\n",
    "            \"show_perturbations\": bool(show_perturbations),\n",
    "            \"raw_key_input\": bool(raw_key_input),\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(\"\\nChanges applied.\")\n",
    "    print(f\"Mode: {mode_key}\")\n",
    "    print(f\"Candidates per tool: {int(num_candidates)}\")\n",
    "    print(f\"Candidate snippet chars: {int(candidate_snippet_chars)}\")\n",
    "    print(f\"Perturbation prints: {'enabled' if show_perturbations else 'disabled'}\")\n",
    "    print(f\"Raw key input (Esc-safe): {'enabled' if raw_key_input else 'disabled'}\")\n",
    "    print(f\"Descriptions updated (this session): {updated_count}\")\n",
    "    if patch_failures:\n",
    "        print(f\"Raw JSON-string patch failures (left unchanged): {patch_failures}\")\n",
    "    print(f\"Reviewed total (from audit): {n_reviewed} / {n_total}\")\n",
    "    print(f\"Completed: {completed} (quit_requested={quit_requested})\")\n",
    "    if quit_requested and resume_next_index_1based is not None:\n",
    "        print(f\"Resume next time from: [{resume_next_index_1based}/{n_total}]\")\n",
    "    print(f\"Updated file: {path}\")\n",
    "    print(f\"Audit file (same on resume): {audit_file}\")\n",
    "\n",
    "    print(\"\\nSession summary (heuristic):\")\n",
    "    print(\n",
    "        f\"  accepted={int(session_summary['accepted'])}, edited={int(session_summary['edited'])}, \"\n",
    "        f\"manual={int(session_summary['manual'])}, skipped={int(session_summary['skipped'])}\"\n",
    "    )\n",
    "    print(f\"  accepted_risk_labels={session_summary['accepted_risk_labels']}\")\n",
    "    if avg_sim is not None:\n",
    "        print(f\"  accepted_avg_similarity={avg_sim:.2f} (n={int(session_summary['accepted_similarity_n'])})\")\n",
    "    if avg_len_ratio is not None:\n",
    "        print(f\"  accepted_avg_len_ratio={avg_len_ratio:.2f} (n={int(session_summary['accepted_len_ratio_n'])})\")\n",
    "    if avg_len_delta is not None:\n",
    "        print(f\"  accepted_avg_len_delta_chars={avg_len_delta:+.1f}\")\n",
    "    if avg_base_len is not None and avg_cand_len is not None:\n",
    "        print(f\"  accepted_avg_base_len_chars={avg_base_len:.1f}; accepted_avg_cand_len_chars={avg_cand_len:.1f}\")\n",
    "    if avg_emb_cos is not None:\n",
    "        print(f\"  accepted_avg_embedding_cosine={avg_emb_cos:.2f} (n={int(session_summary['accepted_embedding_cosine_n'])})\")\n",
    "    if semantic_cfg_norm.get(\"enable_verifier\"):\n",
    "        print(\n",
    "            \"  accepted_verifier_counts: \"\n",
    "            f\"ENTAILS={int(session_summary['accepted_entails'])}, \"\n",
    "            f\"NOT_ENTAILS={int(session_summary['accepted_not_entails'])}, \"\n",
    "            f\"UNKNOWN={int(session_summary['accepted_entails_unknown'])}\"\n",
    "        )\n",
    "    if mode_key == \"style_concise\":\n",
    "        print(\n",
    "            \"  accepted_soft_target: \"\n",
    "            f\"applicable={int(session_summary['accepted_soft_target_applicable_n'])}, \"\n",
    "            f\"within={int(session_summary['accepted_within_soft_target_n'])}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def _derive_working_copy_path(input_path: str, mode_key: str) -> str:\n",
    "    p = Path(input_path)\n",
    "    return str(p.with_name(f\"{p.stem}.WORKING_COPY.{mode_key}{p.suffix}\"))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    from pathlib import Path\n",
    "    from config_loader import load_config\n",
    "\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--config\", default=os.environ.get(\"CONFIG_PATH\", \"config.toml\"))\n",
    "    args, _unknown = ap.parse_known_args()\n",
    "\n",
    "\n",
    "    cfg = load_config(args.config)\n",
    "\n",
    "    # 1) Base URL viene dal config (non più costante hardcoded)\n",
    "    GEMINI_BASE_URL = cfg.base_url\n",
    "\n",
    "    # 2) Token SEMPRE da env (sicurezza)\n",
    "    if not os.environ.get(cfg.token_env):\n",
    "        raise RuntimeError(f\"{cfg.token_env} environment variable is not set.\")\n",
    "\n",
    "    # 3) Risoluzione alias style (se presenti nel config)\n",
    "    mk = (cfg.mode_key or \"\").strip() or \"style_verbose\"\n",
    "    mk = (cfg.style_aliases or {}).get(mk, mk)\n",
    "    mode_key_resolved, _ = _resolve_style(mk)\n",
    "\n",
    "    # 4) Input/Output\n",
    "    INPUT_JSONL = cfg.input_jsonl\n",
    "    OUTPUT_JSONL = cfg.output_jsonl.strip() or _derive_working_copy_path(INPUT_JSONL, mode_key_resolved)\n",
    "\n",
    "    working = make_working_copy(INPUT_JSONL, OUTPUT_JSONL, overwrite=False)\n",
    "    print(f\"Working copy: {working}\")\n",
    "\n",
    "    # 5) Semantic cfg\n",
    "    semantic_cfg_val: Dict[str, Any] = {\n",
    "        \"enable_embeddings\": bool(cfg.enable_embeddings and bool(cfg.embedding_model.strip())),\n",
    "        \"embedding_model\": str(cfg.embedding_model).strip(),\n",
    "        \"embedding_low_cosine_threshold\": float(cfg.embedding_low_cosine_threshold),\n",
    "        \"enable_verifier\": bool(cfg.enable_verifier),\n",
    "        \"verifier_model\": str(cfg.verifier_model).strip(),\n",
    "        \"verifier_max_tokens\": int(cfg.verifier_max_tokens),\n",
    "    }\n",
    "\n",
    "    interactive_llm_tools_in_jsonl(\n",
    "        working,\n",
    "        tool_field=cfg.tool_field,\n",
    "        create_backup_of_target=cfg.create_backup_of_target,\n",
    "        llm_model=cfg.model,\n",
    "        seed=cfg.seed,\n",
    "        max_tokens=int(cfg.max_tokens),\n",
    "        retry_on_length=bool(cfg.retry_on_length),\n",
    "        retry_max_tokens=int(cfg.retry_max_tokens),\n",
    "        allow_reserialize_fallback=bool(cfg.allow_reserialize_fallback),\n",
    "        min_sleep_sec_between_calls=float(cfg.min_sleep_sec_between_calls),\n",
    "        audit_dir=cfg.audit_dir,\n",
    "        mode_key=mode_key_resolved,\n",
    "        num_candidates=int(cfg.num_candidates),\n",
    "        max_token_preview=int(cfg.stats_max_token_preview),\n",
    "        max_token_string_len=int(cfg.stats_max_token_string_len),\n",
    "        candidate_snippet_chars=int(cfg.candidate_snippet_chars),\n",
    "        concise_target_ratio=float(cfg.concise_target_ratio),\n",
    "        concise_target_min_base_len=int(cfg.concise_target_min_base_len),\n",
    "        concise_target_min_chars=int(cfg.concise_target_min_chars),\n",
    "        semantic_cfg=semantic_cfg_val,\n",
    "        show_perturbations=bool(cfg.show_perturbations),\n",
    "        raw_key_input=bool(cfg.raw_key_input),\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
