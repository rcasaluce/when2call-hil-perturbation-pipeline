{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b29402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working copy: When2Call/data/test/when2call_test_llm_judge.WORKING_COPY.style_concise.jsonl\n",
      "Target: When2Call/data/test/when2call_test_llm_judge.WORKING_COPY.style_concise.jsonl\n",
      "Mode: style_concise\n",
      "Audit file (RESUMABLE): audit/06f0b2ed2c69/when2call_test_llm_judge.WORKING_COPY.style_concise.06f0b2ed2c69.style_concise.gemini-2.5-flash.K2.audit.jsonl\n",
      "Tool occurrences total: 978\n",
      "Resume position: [2/978] (previously reviewed: 1)\n",
      "LLM: gemini-2.5-flash @ https://generativelanguage.googleapis.com/v1beta/openai/\n",
      "Candidates per tool: 2\n",
      "Candidate snippet chars: 160\n",
      "Policies: risk=risk_policy_v2_structural_logic_primary; logic=logic_tokens_v1; semantic=semantic_signals_v1\n",
      "Perturbation prints: enabled\n",
      "Raw key input (Esc-safe): enabled\n",
      "Embedding signal: disabled\n",
      "Verifier signal: disabled\n",
      "Concise soft target: ratio=0.70, min_base_len=160, min_chars=80\n",
      "Max tokens: 512; retry_on_length=True; retry_max_tokens=1024\n",
      "Commands: ENTER/ok=accept #1, 1..K=accept candidate, r=regenerate K, e=edit candidate, m=manual, s=skip, q/Esc=quit, p<idx>=preview (e.g., p2)\n",
      "\n",
      "================================================================================\n",
      "[2/978] api_token_api.APITokenApi.post_api_token\n",
      "instance_key: rec:a7e1784f346e3c8cc2927162d99b44e4:t1:d946021bf0a1e7148706c0e020753872 (record_id=a7e1784f346e3c8cc2927162d99b44e4, tool_index=1)\n",
      "Current description RAW (escaped):\n",
      "\"Creates an API token to authenticate and authorize API calls.\"\n",
      "\n",
      "Current description DECODED:\n",
      "Creates an API token to authenticate and authorize API calls.\n",
      "\n",
      "Statistics (base):\n",
      "  chars=61; words=10; sentences=1\n",
      "  tokens: flags=0, field_like=0, numbers=0, number_units=0, verbs=0, snake=0, camel=0, logic=0, modals=0, scope=0\n",
      "  previews: flags=[-]; field_like=[-]; numbers=[-]; verbs=[-]; logic=[-]; modals=[-]; scope=[-]\n",
      "Concise soft target (not applied): reason=base_too_short (base_len=61)\n",
      "\n",
      "  [gen] api_token_api.APITokenApi.post_api_token | cand 1/2 | round=0 | regen_index=0 | mode=style_concise | seed=None | max_tokens=512\n",
      "      length_guidance: soft_target not applied (reason=base_too_short)\n",
      "\n",
      "  [gen] api_token_api.APITokenApi.post_api_token | cand 2/2 | round=0 | regen_index=1 | mode=style_concise | seed=None | max_tokens=512\n",
      "      length_guidance: soft_target not applied (reason=base_too_short)\n",
      "      diversity_instruction: A different paraphrase is required than the previous rewrite. The same sentence skeleton or distinctive phrases must not be reused. Meaning must remain exactly the same; only wording and structure may vary.\n",
      "      previous_rewrite_hint: len=61 sha=f67fd095b46d snippet='Creates an API token to authenticate and authorize API calls.'\n",
      "\n",
      "Candidates overview:\n",
      "  [1] status=ok; risk=LOW; sim=1.00; emb=-; ent=-; cand(chars=61, words=10, sent=1); len_ratio=1.00; Δchars=+0; -; new(flags=0, fields=0, nums=0, snake=0, camel=0, logic=0, verbs=0); missing_total=0\n",
      "      text: Creates an API token to authenticate and authorize API calls.\n",
      "  [2] status=ok; risk=LOW; sim=0.87; emb=-; ent=-; cand(chars=68, words=10, sent=1); len_ratio=1.11; Δchars=+7; -; new(flags=0, fields=0, nums=0, snake=0, camel=0, logic=0, verbs=0); missing_total=0\n",
      "      text: Generates an API token for authenticating and authorizing API calls.\n",
      "================================================================================\n",
      "[3/978] Buses_3_FindBus\n",
      "instance_key: rec:64cbc7e8819e45258b49e186164c9fad:t0:9eb0bebb83fe4602fcb0390818dc2b64 (record_id=64cbc7e8819e45258b49e186164c9fad, tool_index=0)\n",
      "Current description RAW (escaped):\n",
      "\"Find a bus itinerary connecting two cities on a given date.\"\n",
      "\n",
      "Current description DECODED:\n",
      "Find a bus itinerary connecting two cities on a given date.\n",
      "\n",
      "Statistics (base):\n",
      "  chars=59; words=11; sentences=1\n",
      "  tokens: flags=0, field_like=0, numbers=0, number_units=0, verbs=0, snake=0, camel=0, logic=0, modals=0, scope=0\n",
      "  previews: flags=[-]; field_like=[-]; numbers=[-]; verbs=[-]; logic=[-]; modals=[-]; scope=[-]\n",
      "Concise soft target (not applied): reason=base_too_short (base_len=59)\n",
      "\n",
      "  [gen] Buses_3_FindBus | cand 1/2 | round=0 | regen_index=0 | mode=style_concise | seed=None | max_tokens=512\n",
      "      length_guidance: soft_target not applied (reason=base_too_short)\n",
      "\n",
      "  [gen] Buses_3_FindBus | cand 2/2 | round=0 | regen_index=1 | mode=style_concise | seed=None | max_tokens=512\n",
      "      length_guidance: soft_target not applied (reason=base_too_short)\n",
      "      diversity_instruction: A different paraphrase is required than the previous rewrite. The same sentence skeleton or distinctive phrases must not be reused. Meaning must remain exactly the same; only wording and structure may vary.\n",
      "      previous_rewrite_hint: len=60 sha=da8bcd44c31f snippet='Finds a bus itinerary connecting two cities on a given date.'\n",
      "\n",
      "Candidates overview:\n",
      "  [1] status=ok; risk=LOW; sim=0.99; emb=-; ent=-; cand(chars=60, words=11, sent=1); len_ratio=1.02; Δchars=+1; -; new(flags=0, fields=0, nums=0, snake=0, camel=0, logic=0, verbs=0); missing_total=0\n",
      "      text: Finds a bus itinerary connecting two cities on a given date.\n",
      "  [2] status=ok; risk=LOW; sim=0.83; emb=-; ent=-; cand(chars=68, words=11, sent=1); len_ratio=1.15; Δchars=+9; -; new(flags=0, fields=0, nums=0, snake=0, camel=0, logic=0, verbs=0); missing_total=0\n",
      "      text: Retrieves a bus itinerary connecting two cities on a specified date.\n",
      "\n",
      "Changes applied.\n",
      "Mode: style_concise\n",
      "Candidates per tool: 2\n",
      "Candidate snippet chars: 160\n",
      "Perturbation prints: enabled\n",
      "Raw key input (Esc-safe): enabled\n",
      "Descriptions updated (this session): 0\n",
      "Reviewed total (from audit): 2 / 978\n",
      "Completed: False (quit_requested=True)\n",
      "Resume next time from: [3/978]\n",
      "Updated file: When2Call/data/test/when2call_test_llm_judge.WORKING_COPY.style_concise.jsonl\n",
      "Audit file (same on resume): audit/06f0b2ed2c69/when2call_test_llm_judge.WORKING_COPY.style_concise.06f0b2ed2c69.style_concise.gemini-2.5-flash.K2.audit.jsonl\n",
      "\n",
      "Session summary (heuristic):\n",
      "  accepted=1, edited=0, manual=0, skipped=0\n",
      "  accepted_risk_labels={'LOW': 1, 'MED': 0, 'HIGH': 0, 'NA': 0}\n",
      "  accepted_avg_similarity=1.00 (n=1)\n",
      "  accepted_avg_len_ratio=1.00 (n=1)\n",
      "  accepted_avg_len_delta_chars=+0.0\n",
      "  accepted_avg_base_len_chars=61.0; accepted_avg_cand_len_chars=61.0\n",
      "  accepted_soft_target: applicable=0, within=0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# 3 Feb 2026\n",
    "#\n",
    "# Interactive, resumable tool-description rewrite workflow with:\n",
    "# - K-candidate generation per tool instance (configurable)\n",
    "# - Deterministic statistical/lexical risk indicators printed alongside base and candidates\n",
    "# - Human-in-the-loop decision (accept candidate, edit, manual, skip), with append-only audit log\n",
    "#\n",
    "# Additions (Jan 21 test):\n",
    "# - Candidate text snippet shown in the overview, so selection can occur without extra commands.\n",
    "# - Explicit preview command documented: p<idx> (e.g., p2) prints the full candidate + stats.\n",
    "#\n",
    "# Additions (Concise soft length target, reviewer-proof):\n",
    "# - Optional soft length target for style_concise: default 30% shorter, applied only if base_len >= threshold.\n",
    "# - The target is guidance only (exceptions allowed to preserve meaning); out-of-target is flagged and logged.\n",
    "# - Length metrics (len_ratio, len_delta) are computed for every candidate and stored in audit for reporting.\n",
    "#\n",
    "# Additions (Semantic drift hardening, v2):\n",
    "# - Logic/negation/quantifier/modal/scope tokens extracted and diffed (beyond purely lexical patterns).\n",
    "# - Risk scoring adjusted: verbs treated as secondary; structural+logic tokens treated as primary.\n",
    "# - Optional semantic signals:\n",
    "#   - Embedding cosine similarity (best-effort; depends on provider support for embeddings endpoint).\n",
    "#   - LLM entailment verifier returning ENTAILS / NOT_ENTAILS (disabled by default).\n",
    "#\n",
    "# Additions (Feb 3 patch):\n",
    "# - \"Perturbations\" visibility: print candidate-generation perturbation context to stdout during generation.\n",
    "# - ESC behavior: raw-key command input on TTY so Esc behaves like quit (q) and never \"accepts\" accidentally.\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "import difflib\n",
    "import re\n",
    "import math\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional, Tuple, List\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# ========= Config =========\n",
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "LLM_MODEL_DEFAULT = \"gemini-2.5-flash\"\n",
    "\n",
    "HASH_HEX_LEN = 32\n",
    "\n",
    "DEFAULT_MAX_TOKENS = 512\n",
    "RETRY_ON_LENGTH = True\n",
    "RETRY_MAX_TOKENS = 1024\n",
    "\n",
    "DEFAULT_ALLOW_RESERIALIZE_FALLBACK = False\n",
    "\n",
    "# How much of the last generated candidate to store in audit and to feed back into prompt.\n",
    "DEFAULT_MAX_PREV_REWRITE_CHARS = 800\n",
    "\n",
    "# Candidate count shown per tool instance.\n",
    "DEFAULT_NUM_CANDIDATES = 2\n",
    "\n",
    "# Printing controls for token previews in statistics.\n",
    "DEFAULT_MAX_TOKEN_PREVIEW = 8\n",
    "DEFAULT_MAX_TOKEN_STRING_LEN = 48\n",
    "\n",
    "# Candidate text snippet in overview (chars).\n",
    "DEFAULT_CANDIDATE_SNIPPET_CHARS = 160\n",
    "\n",
    "# Soft concise length target knobs (reviewer-proof defaults).\n",
    "DEFAULT_CONCISE_TARGET_RATIO = 0.70\n",
    "DEFAULT_CONCISE_TARGET_MIN_BASE_LEN = 160\n",
    "DEFAULT_CONCISE_TARGET_MIN_CHARS = 80\n",
    "\n",
    "# Semantic signals (disabled by default).\n",
    "DEFAULT_ENABLE_EMBEDDINGS = False\n",
    "DEFAULT_EMBEDDING_MODEL = \"\"  # Provider-dependent; empty means \"unset\".\n",
    "DEFAULT_EMBEDDING_LOW_COSINE_THRESHOLD = 0.85\n",
    "\n",
    "DEFAULT_ENABLE_VERIFIER = False\n",
    "DEFAULT_VERIFIER_MODEL = \"\"  # Empty means \"use llm_model\".\n",
    "DEFAULT_VERIFIER_MAX_TOKENS = 16\n",
    "\n",
    "# Visibility knobs (Feb 3 patch).\n",
    "DEFAULT_SHOW_PERTURBATIONS = True   # Prints perturbation context during candidate generation.\n",
    "DEFAULT_RAW_KEY_INPUT = True        # Enables raw-key command input on TTY so Esc can be captured.\n",
    "\n",
    "# Policy versioning for audit identity and reporting.\n",
    "RISK_POLICY_NAME = \"risk_policy_v2_structural_logic_primary\"\n",
    "LOGIC_TOKEN_POLICY_NAME = \"logic_tokens_v1\"\n",
    "SEMANTIC_POLICY_NAME = \"semantic_signals_v1\"\n",
    "\n",
    "\n",
    "# ========= Styles =========\n",
    "STYLE_SPECS: Dict[str, Dict[str, Any]] = {\n",
    "    \"style_verbose\": {\n",
    "        \"system\": (\n",
    "            \"Task: rewrite tool descriptions.\\n\"\n",
    "            \"Hard constraints:\\n\"\n",
    "            \"- Meaning must be preserved exactly; no new capabilities, steps, motivations, benefits, or context.\\n\"\n",
    "            \"- No information present in the original description may be deleted.\\n\"\n",
    "            \"- No new parameter names, IDs, field names, flags, or implementation details may be introduced.\\n\"\n",
    "            \"- If parameter/field names/IDs/flags already appear in the original description, they must be kept.\\n\"\n",
    "            \"- No examples, normative language, or assumptions.\\n\"\n",
    "            \"- The subject (the tool) and scope must remain unchanged.\\n\"\n",
    "            \"- Output must be only the rewritten description text, nothing else.\\n\"\n",
    "            \"- Style: verbose but controlled; concise and complete (1–2 sentences), clear and direct.\\n\"\n",
    "        ),\n",
    "        \"regen_diversity_instruction\": (\n",
    "            \"A meaning-equivalent rewrite is required with lexical and syntactic variation from the previous rewrite; \"\n",
    "            \"the same sentence structure should be avoided.\"\n",
    "        ),\n",
    "        \"max_prev_rewrite_chars\": 800,\n",
    "    },\n",
    "    \"style_concise\": {\n",
    "        \"system\": (\n",
    "            \"Task: rewrite tool descriptions.\\n\"\n",
    "            \"Hard constraints:\\n\"\n",
    "            \"- Meaning must be preserved exactly; no new capabilities, steps, motivations, benefits, or context.\\n\"\n",
    "            \"- No information present in the original description may be deleted.\\n\"\n",
    "            \"- No new parameter names, IDs, field names, flags, or implementation details may be introduced.\\n\"\n",
    "            \"- If parameter/field names/IDs/flags already appear in the original description, they must be kept.\\n\"\n",
    "            \"- No examples, normative language, or assumptions.\\n\"\n",
    "            \"- The subject (the tool) and scope must remain unchanged.\\n\"\n",
    "            \"- Output must be only the rewritten description text, nothing else.\\n\"\n",
    "            \"- Style: concise and controlled; 1 sentence preferred, 2 max.\\n\"\n",
    "            \"- Length constraint: shorter than the base description is preferred; if the base description is already short, the rewrite must not exceed its length.\\n\"\n",
    "            \"- Compression rule: remove redundancy, filler, and hedging while preserving all explicitly stated constraints/details.\\n\"\n",
    "        ),\n",
    "        \"regen_diversity_instruction\": (\n",
    "            \"A different paraphrase is required than the previous rewrite. \"\n",
    "            \"The same sentence skeleton or distinctive phrases must not be reused. \"\n",
    "            \"Meaning must remain exactly the same; only wording and structure may vary.\"\n",
    "        ),\n",
    "        \"max_prev_rewrite_chars\": 600,\n",
    "    },\n",
    "    # Alias to tolerate misspellings.\n",
    "    \"style_coicnoso\": {},   # filled after dict creation\n",
    "    \"style_coinceise\": {},  # filled after dict creation\n",
    "}\n",
    "STYLE_SPECS[\"style_coicnoso\"] = STYLE_SPECS[\"style_concise\"]\n",
    "STYLE_SPECS[\"style_coinceise\"] = STYLE_SPECS[\"style_concise\"]\n",
    "\n",
    "\n",
    "def _resolve_style(mode_key: str) -> Tuple[str, Dict[str, Any]]:\n",
    "    mk = (mode_key or \"\").strip()\n",
    "    if not mk:\n",
    "        mk = \"style_verbose\"\n",
    "    if mk not in STYLE_SPECS:\n",
    "        raise ValueError(f\"Unknown MODE_KEY='{mk}'. Supported: {', '.join(sorted(STYLE_SPECS.keys()))}\")\n",
    "    return mk, STYLE_SPECS[mk]\n",
    "\n",
    "\n",
    "# ========= Client =========\n",
    "def make_gemini_client() -> OpenAI:\n",
    "    token = os.environ.get(\"TOKEN_GEMINI\")\n",
    "    if not token:\n",
    "        raise RuntimeError(\"TOKEN_GEMINI environment variable is not set.\")\n",
    "    return OpenAI(api_key=token, base_url=GEMINI_BASE_URL)\n",
    "\n",
    "\n",
    "# ========= Small utils =========\n",
    "def _json_safe(obj: Any) -> Any:\n",
    "    if obj is None or isinstance(obj, (str, int, float, bool)):\n",
    "        return obj\n",
    "    if isinstance(obj, dict):\n",
    "        return {str(k): _json_safe(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return [_json_safe(x) for x in obj]\n",
    "    if hasattr(obj, \"model_dump\") and callable(getattr(obj, \"model_dump\")):\n",
    "        try:\n",
    "            return _json_safe(obj.model_dump())\n",
    "        except Exception:\n",
    "            pass\n",
    "    if hasattr(obj, \"dict\") and callable(getattr(obj, \"dict\")):\n",
    "        try:\n",
    "            return _json_safe(obj.dict())\n",
    "        except Exception:\n",
    "            pass\n",
    "    if hasattr(obj, \"__dict__\"):\n",
    "        try:\n",
    "            return _json_safe(vars(obj))\n",
    "        except Exception:\n",
    "            pass\n",
    "    try:\n",
    "        return str(obj)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def _sha256_text(s: str) -> str:\n",
    "    return hashlib.sha256((s or \"\").encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "def _canonical_json(obj: Any) -> str:\n",
    "    return json.dumps(obj, ensure_ascii=False, sort_keys=True, separators=(\",\", \":\"))\n",
    "\n",
    "\n",
    "def _sha256_file(path: Path) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with path.open(\"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(1024 * 1024), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "\n",
    "def _safe_int_env(name: str, default: int) -> int:\n",
    "    v = os.environ.get(name)\n",
    "    if v is None or not v.strip():\n",
    "        return int(default)\n",
    "    try:\n",
    "        return int(v.strip())\n",
    "    except Exception:\n",
    "        return int(default)\n",
    "\n",
    "\n",
    "def _safe_float_env(name: str, default: float) -> float:\n",
    "    v = os.environ.get(name)\n",
    "    if v is None or not v.strip():\n",
    "        return float(default)\n",
    "    try:\n",
    "        return float(v.strip())\n",
    "    except Exception:\n",
    "        return float(default)\n",
    "\n",
    "\n",
    "def _safe_bool_env(name: str, default: bool) -> bool:\n",
    "    v = os.environ.get(name)\n",
    "    if v is None or not v.strip():\n",
    "        return bool(default)\n",
    "    s = v.strip().lower()\n",
    "    if s in (\"1\", \"true\", \"t\", \"yes\", \"y\", \"on\"):\n",
    "        return True\n",
    "    if s in (\"0\", \"false\", \"f\", \"no\", \"n\", \"off\"):\n",
    "        return False\n",
    "    return bool(default)\n",
    "\n",
    "\n",
    "# ========= Raw-key command input (Esc-safe) =========\n",
    "def _read_command_raw_tty(prompt: str, *, k: int) -> str:\n",
    "    \"\"\"\n",
    "    Reads a short command using raw keypress input on TTY.\n",
    "    - Enter returns the accumulated buffer (possibly empty).\n",
    "    - Esc returns '\\x1b' immediately (caller maps it to quit).\n",
    "    - Backspace edits the buffer.\n",
    "    - For k<=9, numeric selection is returned immediately when it becomes unambiguous.\n",
    "    \"\"\"\n",
    "    # Defer imports so non-TTY / non-Unix runs remain usable.\n",
    "    try:\n",
    "        import termios\n",
    "        import tty\n",
    "    except Exception:\n",
    "        # Fall back to line input if raw mode is unavailable.\n",
    "        return input(prompt)\n",
    "\n",
    "    fd = sys.stdin.fileno()\n",
    "    old = termios.tcgetattr(fd)\n",
    "    buf = \"\"\n",
    "\n",
    "    immediate_digits = (int(k) <= 9)\n",
    "\n",
    "    def echo(s: str) -> None:\n",
    "        sys.stdout.write(s)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    echo(prompt)\n",
    "\n",
    "    try:\n",
    "        tty.setraw(fd)\n",
    "        while True:\n",
    "            ch = sys.stdin.read(1)\n",
    "\n",
    "            # Enter\n",
    "            if ch in (\"\\r\", \"\\n\"):\n",
    "                echo(\"\\n\")\n",
    "                return buf\n",
    "\n",
    "            # Esc\n",
    "            if ch == \"\\x1b\":\n",
    "                echo(\"\\n\")\n",
    "                return \"\\x1b\"\n",
    "\n",
    "            # Backspace / delete\n",
    "            if ch in (\"\\x7f\", \"\\b\"):\n",
    "                if buf:\n",
    "                    buf = buf[:-1]\n",
    "                    echo(\"\\b \\b\")\n",
    "                continue\n",
    "\n",
    "            # Ignore other control chars.\n",
    "            if not ch.isprintable():\n",
    "                continue\n",
    "\n",
    "            # Append printable char and echo.\n",
    "            buf += ch\n",
    "            echo(ch)\n",
    "\n",
    "            low = buf.strip().lower()\n",
    "\n",
    "            # If user typed a single-letter command, return immediately.\n",
    "            if low in (\"r\", \"e\", \"m\", \"s\", \"q\", \"y\"):\n",
    "                echo(\"\\n\")\n",
    "                return low\n",
    "\n",
    "            # Preview shortcut: p<idx> (only immediate if k<=9 and idx is single-digit).\n",
    "            if immediate_digits and low.startswith(\"p\") and len(low) == 2 and low[1].isdigit():\n",
    "                vi = int(low[1])\n",
    "                if 1 <= vi <= int(k):\n",
    "                    echo(\"\\n\")\n",
    "                    return low\n",
    "\n",
    "            # Numeric selection (only immediate for k<=9 to avoid ambiguity like \"10\").\n",
    "            if immediate_digits and len(low) == 1 and low.isdigit():\n",
    "                vi = int(low)\n",
    "                if 1 <= vi <= int(k):\n",
    "                    echo(\"\\n\")\n",
    "                    return low\n",
    "\n",
    "    finally:\n",
    "        termios.tcsetattr(fd, termios.TCSADRAIN, old)\n",
    "\n",
    "\n",
    "def _read_command(prompt: str, *, k: int, raw_key_input: bool) -> str:\n",
    "    \"\"\"\n",
    "    Reads a command from the user.\n",
    "    - If raw_key_input is enabled and stdin is a TTY, uses raw keypress mode to capture Esc.\n",
    "    - Otherwise, falls back to line-based input().\n",
    "    \"\"\"\n",
    "    if raw_key_input and sys.stdin.isatty():\n",
    "        try:\n",
    "            return _read_command_raw_tty(prompt, k=int(k))\n",
    "        except Exception:\n",
    "            # Safe fallback.\n",
    "            return input(prompt)\n",
    "    return input(prompt)\n",
    "\n",
    "\n",
    "# ========= Concise soft target (policy) =========\n",
    "def _make_length_policy(\n",
    "    *,\n",
    "    base_desc: str,\n",
    "    mode_key: str,\n",
    "    concise_ratio: float,\n",
    "    concise_min_base_len: int,\n",
    "    concise_min_chars: int,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Returns a policy object (always present) used for:\n",
    "    - prompt guidance (soft target)\n",
    "    - stats (len_ratio, within_target)\n",
    "    - audit reporting\n",
    "\n",
    "    Soft target is applied only if:\n",
    "    - mode_key == style_concise\n",
    "    - base_len >= concise_min_base_len\n",
    "    - computed target is strictly shorter than base_len\n",
    "    \"\"\"\n",
    "    base = (base_desc or \"\").strip()\n",
    "    base_len = len(base)\n",
    "\n",
    "    ratio = float(concise_ratio)\n",
    "    min_base_len = int(concise_min_base_len)\n",
    "    min_chars = int(concise_min_chars)\n",
    "\n",
    "    reason = \"not_concise_mode\"\n",
    "    applied = False\n",
    "    target_chars: Optional[int] = None\n",
    "\n",
    "    if mode_key == \"style_concise\":\n",
    "        if base_len < min_base_len or base_len <= 0:\n",
    "            reason = \"base_too_short\"\n",
    "        else:\n",
    "            raw_target = int(base_len * ratio)\n",
    "            candidate_target = max(raw_target, min_chars)\n",
    "            # If env is mis-set (min_chars > base), do not apply a target that would exceed base.\n",
    "            if candidate_target >= base_len:\n",
    "                reason = \"target_not_shorter_than_base\"\n",
    "            else:\n",
    "                applied = True\n",
    "                reason = \"ok\"\n",
    "                target_chars = candidate_target\n",
    "\n",
    "    return {\n",
    "        \"policy_name\": \"concise_soft_target_v1\",\n",
    "        \"mode_key\": mode_key,\n",
    "        \"base_len_chars\": base_len,\n",
    "        \"concise_soft_target\": {\n",
    "            \"applied\": bool(applied),\n",
    "            \"reason\": str(reason),\n",
    "            \"target_ratio\": float(ratio),\n",
    "            \"min_base_len\": int(min_base_len),\n",
    "            \"min_chars\": int(min_chars),\n",
    "            \"target_chars\": int(target_chars) if isinstance(target_chars, int) else None,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "# ========= Statistical / lexical indicators =========\n",
    "_FLAG_RE = re.compile(r\"(?<!\\w)--[A-Za-z0-9][A-Za-z0-9_-]*\")\n",
    "_SNAKE_RE = re.compile(r\"\\b[A-Za-z][A-Za-z0-9]*_[A-Za-z0-9_]+\\b\")\n",
    "_CAMEL_RE = re.compile(r\"\\b[a-z]+[A-Z][A-Za-z0-9]*\\b\")\n",
    "_FIELD_COLON_RE = re.compile(r\"\\b[A-Za-z][A-Za-z0-9_]{2,}\\b(?=\\s*[:=])\")\n",
    "_NUMBER_RE = re.compile(r\"\\b\\d+(?:\\.\\d+)?\\b\")\n",
    "_NUMBER_UNIT_RE = re.compile(\n",
    "    r\"\\b\\d+(?:\\.\\d+)?\\s*(?:kb|mb|gb|tb|ms|s|sec|secs|seconds|mins|minutes|hrs|hours|days)\\b\",\n",
    "    re.IGNORECASE,\n",
    ")\n",
    "\n",
    "_HIGH_RISK_VERBS = [\n",
    "    \"create\", \"delete\", \"remove\", \"destroy\",\n",
    "    \"upload\", \"download\", \"send\", \"email\",\n",
    "    \"execute\", \"run\", \"invoke\", \"call\",\n",
    "    \"write\", \"read\", \"save\", \"store\",\n",
    "    \"update\", \"modify\", \"edit\", \"change\",\n",
    "    \"retrieve\", \"fetch\", \"search\", \"browse\",\n",
    "    \"access\", \"open\", \"close\",\n",
    "    \"return\", \"returns\",\n",
    "]\n",
    "_VERB_RE = re.compile(r\"\\b(\" + \"|\".join(re.escape(v) for v in _HIGH_RISK_VERBS) + r\")\\b\", re.IGNORECASE)\n",
    "\n",
    "_LOGIC_WORDS = {\n",
    "    \"only\", \"must\", \"never\", \"not\", \"no\", \"unless\", \"except\",\n",
    "    \"required\", \"optional\",\n",
    "    \"cannot\", \"can't\",\n",
    "}\n",
    "\n",
    "_LOGIC_PHRASES = [\n",
    "    \"at least\",\n",
    "    \"at most\",\n",
    "    \"up to\",\n",
    "    \"no more than\",\n",
    "    \"no less than\",\n",
    "    \"do not\",\n",
    "    \"does not\",\n",
    "    \"did not\",\n",
    "    \"must not\",\n",
    "    \"should not\",\n",
    "    \"may not\",\n",
    "    \"will not\",\n",
    "    \"cannot\",\n",
    "    \"can't\",\n",
    "    \"if and only if\",\n",
    "]\n",
    "\n",
    "_MODAL_WORDS = {\n",
    "    \"may\", \"must\", \"should\", \"will\", \"can\", \"could\", \"would\", \"might\", \"shall\",\n",
    "}\n",
    "\n",
    "_SCOPE_PHRASES = [\n",
    "    \"returns\",\n",
    "    \"return\",\n",
    "    \"can return\",\n",
    "    \"may return\",\n",
    "    \"will return\",\n",
    "    \"must return\",\n",
    "    \"should return\",\n",
    "    \"cannot return\",\n",
    "    \"can't return\",\n",
    "    \"does not return\",\n",
    "    \"do not return\",\n",
    "]\n",
    "\n",
    "\n",
    "def _compile_phrase_patterns(phrases: List[str]) -> Dict[str, re.Pattern]:\n",
    "    out: Dict[str, re.Pattern] = {}\n",
    "    for p in phrases:\n",
    "        esc = re.escape(p).replace(r\"\\ \", r\"\\s+\")\n",
    "        pat = re.compile(r\"(?<![A-Za-z0-9_])\" + esc + r\"(?![A-Za-z0-9_])\", re.IGNORECASE)\n",
    "        out[p.lower()] = pat\n",
    "    return out\n",
    "\n",
    "\n",
    "_LOGIC_PHRASE_PATTERNS = _compile_phrase_patterns(_LOGIC_PHRASES)\n",
    "_SCOPE_PHRASE_PATTERNS = _compile_phrase_patterns(_SCOPE_PHRASES)\n",
    "\n",
    "_WORD_TOKEN_RE = re.compile(r\"[A-Za-z0-9_]+(?:'[A-Za-z0-9_]+)?\", re.IGNORECASE)\n",
    "\n",
    "\n",
    "def _sentence_count(text: str) -> int:\n",
    "    t = (text or \"\").strip()\n",
    "    if not t:\n",
    "        return 0\n",
    "    parts = [p for p in re.split(r\"[.!?]+\", t) if p.strip()]\n",
    "    return len(parts)\n",
    "\n",
    "\n",
    "def _word_count(text: str) -> int:\n",
    "    t = (text or \"\").strip()\n",
    "    if not t:\n",
    "        return 0\n",
    "    return len([w for w in re.split(r\"\\s+\", t) if w])\n",
    "\n",
    "\n",
    "def _extract_phrase_tokens(lower_text: str, patterns: Dict[str, re.Pattern]) -> List[str]:\n",
    "    found: List[str] = []\n",
    "    for canonical, pat in patterns.items():\n",
    "        if pat.search(lower_text):\n",
    "            found.append(canonical)\n",
    "    return sorted(set(found))\n",
    "\n",
    "\n",
    "def _extract_word_tokens(lower_text: str, vocabulary: set) -> List[str]:\n",
    "    toks = [m.group(0).lower() for m in _WORD_TOKEN_RE.finditer(lower_text)]\n",
    "    return sorted(set(t for t in toks if t in vocabulary))\n",
    "\n",
    "\n",
    "def _extract_indicator_tokens(text: str) -> Dict[str, List[str]]:\n",
    "    t = text or \"\"\n",
    "    lower = t.lower()\n",
    "\n",
    "    logic_phr = _extract_phrase_tokens(lower, _LOGIC_PHRASE_PATTERNS)\n",
    "    logic_w = _extract_word_tokens(lower, _LOGIC_WORDS)\n",
    "    logic = sorted(set(logic_phr + logic_w))\n",
    "\n",
    "    modals = _extract_word_tokens(lower, _MODAL_WORDS)\n",
    "    scope = _extract_phrase_tokens(lower, _SCOPE_PHRASE_PATTERNS)\n",
    "\n",
    "    return {\n",
    "        \"flags\": sorted(set(_FLAG_RE.findall(t))),\n",
    "        \"snake\": sorted(set(_SNAKE_RE.findall(t))),\n",
    "        \"camel\": sorted(set(_CAMEL_RE.findall(t))),\n",
    "        \"field_like\": sorted(set(_FIELD_COLON_RE.findall(t))),\n",
    "        \"numbers\": sorted(set(_NUMBER_RE.findall(t))),\n",
    "        \"number_units\": sorted(set(m.group(0) for m in _NUMBER_UNIT_RE.finditer(t))),\n",
    "        \"verbs\": sorted(set(m.group(0).lower() for m in _VERB_RE.finditer(t))),\n",
    "        \"logic\": logic,\n",
    "        \"modals\": modals,\n",
    "        \"scope\": scope,\n",
    "    }\n",
    "\n",
    "\n",
    "def _format_token_preview(tokens: List[str], *, max_items: int, max_len: int) -> str:\n",
    "    if not tokens:\n",
    "        return \"-\"\n",
    "    out: List[str] = []\n",
    "    for t in tokens[: max(0, int(max_items))]:\n",
    "        s = str(t)\n",
    "        if len(s) > int(max_len):\n",
    "            s = s[: int(max_len) - 1] + \"…\"\n",
    "        out.append(s)\n",
    "    if len(tokens) > int(max_items):\n",
    "        out.append(f\"+{len(tokens) - int(max_items)}\")\n",
    "    return \", \".join(out) if out else \"-\"\n",
    "\n",
    "\n",
    "def _diff_token_sets(base: Dict[str, List[str]], cand: Dict[str, List[str]], key: str) -> Tuple[List[str], List[str]]:\n",
    "    b = set(base.get(key, []) or [])\n",
    "    c = set(cand.get(key, []) or [])\n",
    "    new_items = sorted(c - b)\n",
    "    missing_items = sorted(b - c)\n",
    "    return new_items, missing_items\n",
    "\n",
    "\n",
    "def _similarity_ratio(a: str, b: str) -> float:\n",
    "    aa = (a or \"\").strip()\n",
    "    bb = (b or \"\").strip()\n",
    "    if not aa and not bb:\n",
    "        return 1.0\n",
    "    if not aa or not bb:\n",
    "        return 0.0\n",
    "    return float(difflib.SequenceMatcher(None, aa, bb).ratio())\n",
    "\n",
    "\n",
    "def _cosine_similarity(a: List[float], b: List[float]) -> Optional[float]:\n",
    "    if not a or not b:\n",
    "        return None\n",
    "    if len(a) != len(b):\n",
    "        return None\n",
    "    dot = 0.0\n",
    "    na = 0.0\n",
    "    nb = 0.0\n",
    "    for i in range(len(a)):\n",
    "        ai = float(a[i])\n",
    "        bi = float(b[i])\n",
    "        dot += ai * bi\n",
    "        na += ai * ai\n",
    "        nb += bi * bi\n",
    "    if na <= 0.0 or nb <= 0.0:\n",
    "        return None\n",
    "    return float(dot / (math.sqrt(na) * math.sqrt(nb)))\n",
    "\n",
    "\n",
    "def compute_candidate_stats(\n",
    "    *,\n",
    "    base_text: str,\n",
    "    cand_text: str,\n",
    "    mode_key: str,\n",
    "    length_policy: Optional[Dict[str, Any]] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    base = (base_text or \"\").strip()\n",
    "    cand = (cand_text or \"\").strip()\n",
    "\n",
    "    base_tokens = _extract_indicator_tokens(base)\n",
    "    cand_tokens = _extract_indicator_tokens(cand)\n",
    "\n",
    "    diffs: Dict[str, Any] = {}\n",
    "    for k in (\"flags\", \"snake\", \"camel\", \"field_like\", \"numbers\", \"number_units\", \"verbs\", \"logic\", \"modals\", \"scope\"):\n",
    "        new_items, missing_items = _diff_token_sets(base_tokens, cand_tokens, k)\n",
    "        diffs[k] = {\"new\": new_items, \"missing\": missing_items}\n",
    "\n",
    "    base_len = len(base)\n",
    "    cand_len = len(cand)\n",
    "    base_words = _word_count(base)\n",
    "    cand_words = _word_count(cand)\n",
    "    base_sent = _sentence_count(base)\n",
    "    cand_sent = _sentence_count(cand)\n",
    "\n",
    "    sim = _similarity_ratio(base, cand)\n",
    "\n",
    "    len_ratio = (float(cand_len) / float(base_len)) if base_len > 0 else None\n",
    "    len_delta = int(cand_len) - int(base_len)\n",
    "    len_delta_ratio = (float(len_delta) / float(base_len)) if base_len > 0 else None\n",
    "\n",
    "    structural_keys = (\"flags\", \"field_like\", \"numbers\", \"number_units\", \"snake\", \"camel\")\n",
    "    logic_keys = (\"logic\", \"modals\", \"scope\")\n",
    "\n",
    "    new_structural = sum(len(diffs[k][\"new\"]) for k in structural_keys)\n",
    "    missing_structural = sum(len(diffs[k][\"missing\"]) for k in structural_keys)\n",
    "    new_logic = sum(len(diffs[k][\"new\"]) for k in logic_keys)\n",
    "    missing_logic = sum(len(diffs[k][\"missing\"]) for k in logic_keys)\n",
    "\n",
    "    new_verbs = len(diffs[\"verbs\"][\"new\"])\n",
    "    missing_verbs = len(diffs[\"verbs\"][\"missing\"])\n",
    "\n",
    "    risk_label = \"LOW\"\n",
    "    risk_reasons: List[str] = []\n",
    "\n",
    "    if new_structural > 0:\n",
    "        risk_label = \"HIGH\"\n",
    "        risk_reasons.append(\"new_structural_tokens_detected\")\n",
    "    if risk_label != \"HIGH\" and (new_logic > 0 or missing_logic > 0):\n",
    "        risk_label = \"HIGH\"\n",
    "        risk_reasons.append(\"logic_or_modal_or_scope_tokens_changed\")\n",
    "    if risk_label != \"HIGH\" and missing_structural >= 4:\n",
    "        risk_label = \"HIGH\"\n",
    "        risk_reasons.append(\"many_structural_tokens_missing\")\n",
    "\n",
    "    if risk_label == \"LOW\" and missing_structural > 0:\n",
    "        risk_label = \"MED\"\n",
    "        risk_reasons.append(\"some_structural_tokens_missing\")\n",
    "\n",
    "    if risk_label == \"LOW\" and new_verbs > 0 and sim < 0.55:\n",
    "        risk_label = \"MED\"\n",
    "        risk_reasons.append(\"new_risk_verbs_with_low_similarity\")\n",
    "\n",
    "    if risk_label == \"LOW\" and sim < 0.45:\n",
    "        risk_label = \"MED\"\n",
    "        risk_reasons.append(\"very_low_text_similarity\")\n",
    "\n",
    "    soft_flags: List[Dict[str, Any]] = []\n",
    "    if mode_key == \"style_concise\":\n",
    "        if base_len > 0 and cand_len > base_len:\n",
    "            soft_flags.append({\"type\": \"concise_length_exceeds_base\", \"base_len\": base_len, \"cand_len\": cand_len})\n",
    "        if cand_sent > 2:\n",
    "            soft_flags.append({\"type\": \"concise_sentence_count_exceeds_2\", \"sentence_count\": cand_sent})\n",
    "    if mode_key == \"style_verbose\":\n",
    "        if cand_sent > 2:\n",
    "            soft_flags.append({\"type\": \"verbose_sentence_count_exceeds_2\", \"sentence_count\": cand_sent})\n",
    "\n",
    "    concise_target_chars = None\n",
    "    concise_target_applied = False\n",
    "    concise_target_reason = None\n",
    "    within_soft_target = None\n",
    "\n",
    "    if isinstance(length_policy, dict):\n",
    "        ct = (length_policy.get(\"concise_soft_target\") or {})\n",
    "        if isinstance(ct, dict):\n",
    "            concise_target_applied = bool(ct.get(\"applied\", False))\n",
    "            concise_target_reason = ct.get(\"reason\")\n",
    "            concise_target_chars = ct.get(\"target_chars\") if isinstance(ct.get(\"target_chars\"), int) else None\n",
    "\n",
    "    if mode_key == \"style_concise\" and concise_target_applied and isinstance(concise_target_chars, int) and base_len > 0:\n",
    "        within_soft_target = bool(cand_len <= concise_target_chars)\n",
    "        if not within_soft_target:\n",
    "            soft_flags.append(\n",
    "                {\n",
    "                    \"type\": \"concise_exceeds_soft_target\",\n",
    "                    \"target_chars\": int(concise_target_chars),\n",
    "                    \"cand_len\": int(cand_len),\n",
    "                    \"len_ratio\": float(len_ratio) if isinstance(len_ratio, float) else None,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return {\n",
    "        \"policy\": {\n",
    "            \"risk_policy_name\": RISK_POLICY_NAME,\n",
    "            \"logic_token_policy_name\": LOGIC_TOKEN_POLICY_NAME,\n",
    "        },\n",
    "        \"base_len_chars\": base_len,\n",
    "        \"cand_len_chars\": cand_len,\n",
    "        \"len_ratio\": len_ratio,\n",
    "        \"len_delta_chars\": len_delta,\n",
    "        \"len_delta_ratio\": len_delta_ratio,\n",
    "        \"base_words\": base_words,\n",
    "        \"cand_words\": cand_words,\n",
    "        \"base_sentences\": base_sent,\n",
    "        \"cand_sentences\": cand_sent,\n",
    "        \"similarity_ratio\": sim,\n",
    "        \"diffs\": diffs,\n",
    "        \"risk_label\": risk_label,\n",
    "        \"risk_reasons\": risk_reasons,\n",
    "        \"soft_flags\": soft_flags,\n",
    "        \"base_tokens\": base_tokens,\n",
    "        \"cand_tokens\": cand_tokens,\n",
    "        \"length_policy\": length_policy,\n",
    "        \"concise_soft_target_applied\": concise_target_applied,\n",
    "        \"concise_soft_target_reason\": concise_target_reason,\n",
    "        \"concise_soft_target_chars\": concise_target_chars,\n",
    "        \"within_soft_target\": within_soft_target,\n",
    "        \"new_structural_count\": int(new_structural),\n",
    "        \"missing_structural_count\": int(missing_structural),\n",
    "        \"new_logic_count\": int(new_logic),\n",
    "        \"missing_logic_count\": int(missing_logic),\n",
    "        \"new_risk_verbs_count\": int(new_verbs),\n",
    "        \"missing_risk_verbs_count\": int(missing_verbs),\n",
    "    }\n",
    "\n",
    "\n",
    "# ========= Optional semantic signals (embeddings + verifier) =========\n",
    "def _compute_embedding_cosine(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    embedding_model: str,\n",
    "    base_text: str,\n",
    "    cand_text: str,\n",
    ") -> Tuple[Optional[float], Optional[str], Dict[str, Any]]:\n",
    "    meta: Dict[str, Any] = {\"embedding_model\": embedding_model, \"provider_base_url\": GEMINI_BASE_URL}\n",
    "    try:\n",
    "        rb = client.embeddings.create(model=embedding_model, input=base_text)\n",
    "        rc = client.embeddings.create(model=embedding_model, input=cand_text)\n",
    "        vb = getattr(rb.data[0], \"embedding\", None) if getattr(rb, \"data\", None) else None\n",
    "        vc = getattr(rc.data[0], \"embedding\", None) if getattr(rc, \"data\", None) else None\n",
    "        if not isinstance(vb, list) or not isinstance(vc, list):\n",
    "            return None, \"embedding_vector_missing\", meta\n",
    "        cos = _cosine_similarity(vb, vc)\n",
    "        if cos is None:\n",
    "            return None, \"embedding_cosine_failed\", meta\n",
    "        return float(cos), None, meta\n",
    "    except Exception as e:\n",
    "        return None, str(e), meta\n",
    "\n",
    "\n",
    "def _compute_entailment_verdict(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    verifier_model: str,\n",
    "    base_text: str,\n",
    "    cand_text: str,\n",
    "    max_tokens: int,\n",
    ") -> Tuple[Optional[str], Optional[str], Dict[str, Any]]:\n",
    "    meta: Dict[str, Any] = {\"verifier_model\": verifier_model, \"provider_base_url\": GEMINI_BASE_URL}\n",
    "    system = (\n",
    "        \"Task: semantic equivalence gate.\\n\"\n",
    "        \"Decision must be based only on whether the candidate text entails the base text with identical meaning.\\n\"\n",
    "        \"Output must be exactly one of: ENTAILS, NOT_ENTAILS.\\n\"\n",
    "        \"No explanations, no punctuation, no extra tokens.\\n\"\n",
    "    )\n",
    "    user = (\n",
    "        \"Base text:\\n\"\n",
    "        f\"{base_text.strip()}\\n\\n\"\n",
    "        \"Candidate text:\\n\"\n",
    "        f\"{cand_text.strip()}\\n\"\n",
    "    )\n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=verifier_model,\n",
    "            messages=[{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": user}],\n",
    "            temperature=0.0,\n",
    "            max_tokens=int(max_tokens),\n",
    "        )\n",
    "        out = (resp.choices[0].message.content or \"\").strip().upper()\n",
    "        tok = out.split()[0] if out else \"\"\n",
    "        if tok not in (\"ENTAILS\", \"NOT_ENTAILS\"):\n",
    "            tok = \"UNKNOWN\"\n",
    "        meta[\"finish_reason\"] = getattr(resp.choices[0], \"finish_reason\", None)\n",
    "        meta[\"usage\"] = getattr(resp, \"usage\", None)\n",
    "        return tok, None, meta\n",
    "    except Exception as e:\n",
    "        return None, str(e), meta\n",
    "\n",
    "\n",
    "def augment_stats_with_semantic_signals(\n",
    "    *,\n",
    "    stats: Dict[str, Any],\n",
    "    client: Optional[OpenAI],\n",
    "    semantic_cfg: Optional[Dict[str, Any]],\n",
    "    base_text: str,\n",
    "    cand_text: str,\n",
    ") -> Dict[str, Any]:\n",
    "    if not isinstance(stats, dict):\n",
    "        return stats\n",
    "    if not semantic_cfg or not isinstance(semantic_cfg, dict):\n",
    "        return stats\n",
    "    if client is None:\n",
    "        return stats\n",
    "\n",
    "    enabled_embeddings = bool(semantic_cfg.get(\"enable_embeddings\", False))\n",
    "    embedding_model = str(semantic_cfg.get(\"embedding_model\") or \"\").strip()\n",
    "    emb_low_thr = semantic_cfg.get(\"embedding_low_cosine_threshold\", DEFAULT_EMBEDDING_LOW_COSINE_THRESHOLD)\n",
    "\n",
    "    enabled_verifier = bool(semantic_cfg.get(\"enable_verifier\", False))\n",
    "    verifier_model = str(semantic_cfg.get(\"verifier_model\") or \"\").strip()\n",
    "    verifier_max_tokens = int(semantic_cfg.get(\"verifier_max_tokens\", DEFAULT_VERIFIER_MAX_TOKENS))\n",
    "\n",
    "    if not isinstance(stats.get(\"soft_flags\"), list):\n",
    "        stats[\"soft_flags\"] = []\n",
    "\n",
    "    semantic_block: Dict[str, Any] = {\"semantic_policy_name\": SEMANTIC_POLICY_NAME}\n",
    "\n",
    "    if enabled_embeddings and embedding_model:\n",
    "        cos, err, meta = _compute_embedding_cosine(\n",
    "            client=client,\n",
    "            embedding_model=embedding_model,\n",
    "            base_text=base_text,\n",
    "            cand_text=cand_text,\n",
    "        )\n",
    "        semantic_block[\"embedding\"] = {\"cosine\": cos, \"error\": err, \"meta\": meta}\n",
    "        if isinstance(cos, (int, float)) and isinstance(emb_low_thr, (int, float)):\n",
    "            if float(cos) < float(emb_low_thr):\n",
    "                stats[\"soft_flags\"].append(\n",
    "                    {\"type\": \"embedding_low_cosine\", \"cosine\": float(cos), \"threshold\": float(emb_low_thr)}\n",
    "                )\n",
    "        if err:\n",
    "            stats[\"soft_flags\"].append({\"type\": \"embedding_error\", \"error\": str(err)[:200]})\n",
    "\n",
    "    if enabled_verifier:\n",
    "        if not verifier_model:\n",
    "            verifier_model = str(semantic_cfg.get(\"fallback_llm_model\") or \"\").strip()\n",
    "        if verifier_model:\n",
    "            label, err, meta = _compute_entailment_verdict(\n",
    "                client=client,\n",
    "                verifier_model=verifier_model,\n",
    "                base_text=base_text,\n",
    "                cand_text=cand_text,\n",
    "                max_tokens=verifier_max_tokens,\n",
    "            )\n",
    "            semantic_block[\"verifier\"] = {\"label\": label, \"error\": err, \"meta\": meta}\n",
    "            if label == \"NOT_ENTAILS\":\n",
    "                stats[\"soft_flags\"].append({\"type\": \"verifier_not_entails\"})\n",
    "            elif label == \"UNKNOWN\":\n",
    "                stats[\"soft_flags\"].append({\"type\": \"verifier_unknown\"})\n",
    "            if err:\n",
    "                stats[\"soft_flags\"].append({\"type\": \"verifier_error\", \"error\": str(err)[:200]})\n",
    "        else:\n",
    "            stats[\"soft_flags\"].append({\"type\": \"verifier_unconfigured\"})\n",
    "\n",
    "    if semantic_block:\n",
    "        stats[\"semantic\"] = semantic_block\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "def compute_full_candidate_stats(\n",
    "    *,\n",
    "    base_text: str,\n",
    "    cand_text: str,\n",
    "    mode_key: str,\n",
    "    length_policy: Optional[Dict[str, Any]],\n",
    "    client: Optional[OpenAI],\n",
    "    semantic_cfg: Optional[Dict[str, Any]],\n",
    ") -> Dict[str, Any]:\n",
    "    stats = compute_candidate_stats(base_text=base_text, cand_text=cand_text, mode_key=mode_key, length_policy=length_policy)\n",
    "    return augment_stats_with_semantic_signals(\n",
    "        stats=stats,\n",
    "        client=client,\n",
    "        semantic_cfg=semantic_cfg,\n",
    "        base_text=base_text,\n",
    "        cand_text=cand_text,\n",
    "    )\n",
    "\n",
    "\n",
    "def _print_base_stats(base_desc: str, *, max_preview: int, max_tok_len: int) -> None:\n",
    "    base = (base_desc or \"\").strip()\n",
    "    tokens = _extract_indicator_tokens(base)\n",
    "    print(\"\\nStatistics (base):\")\n",
    "    print(f\"  chars={len(base)}; words={_word_count(base)}; sentences={_sentence_count(base)}\")\n",
    "    print(\n",
    "        \"  tokens:\"\n",
    "        f\" flags={len(tokens['flags'])}, field_like={len(tokens['field_like'])}, \"\n",
    "        f\"numbers={len(tokens['numbers'])}, number_units={len(tokens['number_units'])}, \"\n",
    "        f\"verbs={len(tokens['verbs'])}, snake={len(tokens['snake'])}, camel={len(tokens['camel'])}, \"\n",
    "        f\"logic={len(tokens['logic'])}, modals={len(tokens['modals'])}, scope={len(tokens['scope'])}\"\n",
    "    )\n",
    "    print(\n",
    "        \"  previews:\"\n",
    "        f\" flags=[{_format_token_preview(tokens['flags'], max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "        f\" field_like=[{_format_token_preview(tokens['field_like'], max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "        f\" numbers=[{_format_token_preview(tokens['numbers'], max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "        f\" verbs=[{_format_token_preview(tokens['verbs'], max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "        f\" logic=[{_format_token_preview(tokens['logic'], max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "        f\" modals=[{_format_token_preview(tokens['modals'], max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "        f\" scope=[{_format_token_preview(tokens['scope'], max_items=max_preview, max_len=max_tok_len)}]\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _print_candidate_summary_line(\n",
    "    i: int,\n",
    "    cand: Dict[str, Any],\n",
    "    *,\n",
    "    max_preview: int,\n",
    "    max_tok_len: int,\n",
    "    snippet_chars: int,\n",
    ") -> None:\n",
    "    txt = (cand.get(\"text\") or \"\").strip()\n",
    "    err = cand.get(\"error\")\n",
    "    dup = bool(cand.get(\"duplicate\", False))\n",
    "    stats = cand.get(\"stats\") or {}\n",
    "\n",
    "    status = \"ok\"\n",
    "    if err:\n",
    "        status = f\"error:{str(err)[:60]}\"\n",
    "    elif not txt:\n",
    "        status = \"empty\"\n",
    "    elif dup:\n",
    "        status = \"duplicate\"\n",
    "\n",
    "    risk = stats.get(\"risk_label\") or \"-\"\n",
    "    sim = stats.get(\"similarity_ratio\")\n",
    "    sim_s = f\"{float(sim):.2f}\" if isinstance(sim, (int, float)) else \"-\"\n",
    "\n",
    "    diffs = (stats.get(\"diffs\") or {})\n",
    "    new_flags = len(((diffs.get(\"flags\") or {}).get(\"new\") or []))\n",
    "    new_nums = len(((diffs.get(\"numbers\") or {}).get(\"new\") or [])) + len(((diffs.get(\"number_units\") or {}).get(\"new\") or []))\n",
    "    new_verbs = len(((diffs.get(\"verbs\") or {}).get(\"new\") or []))\n",
    "    new_fields = len(((diffs.get(\"field_like\") or {}).get(\"new\") or []))\n",
    "    new_snake = len(((diffs.get(\"snake\") or {}).get(\"new\") or []))\n",
    "    new_camel = len(((diffs.get(\"camel\") or {}).get(\"new\") or []))\n",
    "    new_logic = (\n",
    "        len(((diffs.get(\"logic\") or {}).get(\"new\") or [])) +\n",
    "        len(((diffs.get(\"modals\") or {}).get(\"new\") or [])) +\n",
    "        len(((diffs.get(\"scope\") or {}).get(\"new\") or []))\n",
    "    )\n",
    "    missing_total = (\n",
    "        len(((diffs.get(\"flags\") or {}).get(\"missing\") or [])) +\n",
    "        len(((diffs.get(\"numbers\") or {}).get(\"missing\") or [])) +\n",
    "        len(((diffs.get(\"number_units\") or {}).get(\"missing\") or [])) +\n",
    "        len(((diffs.get(\"verbs\") or {}).get(\"missing\") or [])) +\n",
    "        len(((diffs.get(\"field_like\") or {}).get(\"missing\") or [])) +\n",
    "        len(((diffs.get(\"snake\") or {}).get(\"missing\") or [])) +\n",
    "        len(((diffs.get(\"camel\") or {}).get(\"missing\") or [])) +\n",
    "        len(((diffs.get(\"logic\") or {}).get(\"missing\") or [])) +\n",
    "        len(((diffs.get(\"modals\") or {}).get(\"missing\") or [])) +\n",
    "        len(((diffs.get(\"scope\") or {}).get(\"missing\") or []))\n",
    "    )\n",
    "\n",
    "    clen = stats.get(\"cand_len_chars\")\n",
    "    cwords = stats.get(\"cand_words\")\n",
    "    csent = stats.get(\"cand_sentences\")\n",
    "\n",
    "    clen_s = str(clen) if isinstance(clen, int) else \"-\"\n",
    "    cwords_s = str(cwords) if isinstance(cwords, int) else \"-\"\n",
    "    csent_s = str(csent) if isinstance(csent, int) else \"-\"\n",
    "\n",
    "    lr = stats.get(\"len_ratio\")\n",
    "    lr_s = f\"{float(lr):.2f}\" if isinstance(lr, (int, float)) else \"-\"\n",
    "    ld = stats.get(\"len_delta_chars\")\n",
    "    ld_s = f\"{int(ld):+d}\" if isinstance(ld, int) else \"-\"\n",
    "\n",
    "    t_applied = bool(stats.get(\"concise_soft_target_applied\", False))\n",
    "    t_chars = stats.get(\"concise_soft_target_chars\")\n",
    "    within = stats.get(\"within_soft_target\")\n",
    "    target_s = \"-\"\n",
    "    if t_applied and isinstance(t_chars, int):\n",
    "        if within is True:\n",
    "            target_s = f\"target<={t_chars} ok\"\n",
    "        elif within is False:\n",
    "            target_s = f\"target<={t_chars} NO\"\n",
    "        else:\n",
    "            target_s = f\"target<={t_chars}\"\n",
    "\n",
    "    emb_s = \"-\"\n",
    "    ent_s = \"-\"\n",
    "    sem = stats.get(\"semantic\") if isinstance(stats.get(\"semantic\"), dict) else None\n",
    "    if isinstance(sem, dict):\n",
    "        emb = sem.get(\"embedding\") if isinstance(sem.get(\"embedding\"), dict) else None\n",
    "        if isinstance(emb, dict) and isinstance(emb.get(\"cosine\"), (int, float)):\n",
    "            emb_s = f\"{float(emb.get('cosine')):.2f}\"\n",
    "        ver = sem.get(\"verifier\") if isinstance(sem.get(\"verifier\"), dict) else None\n",
    "        if isinstance(ver, dict) and isinstance(ver.get(\"label\"), str):\n",
    "            ent_s = ver.get(\"label\")\n",
    "\n",
    "    print(\n",
    "        f\"  [{i}] status={status}; risk={risk}; sim={sim_s}; emb={emb_s}; ent={ent_s}; \"\n",
    "        f\"cand(chars={clen_s}, words={cwords_s}, sent={csent_s}); \"\n",
    "        f\"len_ratio={lr_s}; Δchars={ld_s}; {target_s}; \"\n",
    "        f\"new(flags={new_flags}, fields={new_fields}, nums={new_nums}, snake={new_snake}, camel={new_camel}, logic={new_logic}, verbs={new_verbs}); \"\n",
    "        f\"missing_total={missing_total}\"\n",
    "    )\n",
    "\n",
    "    if isinstance(diffs, dict) and txt and not err:\n",
    "        nf = (diffs.get(\"flags\") or {}).get(\"new\") or []\n",
    "        nfv = (diffs.get(\"field_like\") or {}).get(\"new\") or []\n",
    "        nn = (diffs.get(\"numbers\") or {}).get(\"new\") or []\n",
    "        nnu = (diffs.get(\"number_units\") or {}).get(\"new\") or []\n",
    "        nlogic = (diffs.get(\"logic\") or {}).get(\"new\") or []\n",
    "        nmod = (diffs.get(\"modals\") or {}).get(\"new\") or []\n",
    "        nscope = (diffs.get(\"scope\") or {}).get(\"new\") or []\n",
    "        if nf or nfv or nn or nnu or nlogic or nmod or nscope:\n",
    "            print(\n",
    "                \"      new-previews:\"\n",
    "                f\" flags=[{_format_token_preview(list(nf), max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "                f\" fields=[{_format_token_preview(list(nfv), max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "                f\" numbers=[{_format_token_preview(list(nn), max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "                f\" number_units=[{_format_token_preview(list(nnu), max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "                f\" logic=[{_format_token_preview(list(nlogic), max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "                f\" modals=[{_format_token_preview(list(nmod), max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "                f\" scope=[{_format_token_preview(list(nscope), max_items=max_preview, max_len=max_tok_len)}]\"\n",
    "            )\n",
    "\n",
    "    if txt and not err and int(snippet_chars) > 0:\n",
    "        sn = \" \".join(txt.split())\n",
    "        max_sn = int(snippet_chars)\n",
    "        if len(sn) > max_sn:\n",
    "            sn = sn[: max_sn - 1] + \"…\"\n",
    "        print(f\"      text: {sn}\")\n",
    "\n",
    "\n",
    "def _print_candidate_full(\n",
    "    i: int,\n",
    "    cand: Dict[str, Any],\n",
    "    *,\n",
    "    max_preview: int,\n",
    "    max_tok_len: int,\n",
    ") -> None:\n",
    "    txt = (cand.get(\"text\") or \"\").strip()\n",
    "    err = cand.get(\"error\")\n",
    "    stats = cand.get(\"stats\") or {}\n",
    "    diffs = (stats.get(\"diffs\") or {})\n",
    "\n",
    "    print(f\"\\nCandidate [{i}]:\")\n",
    "    if err:\n",
    "        print(f\"  Generation error: {err}\")\n",
    "        if txt:\n",
    "            print(\"  Partial text:\")\n",
    "            print(txt)\n",
    "        return\n",
    "    if not txt:\n",
    "        print(\"  (empty)\")\n",
    "        return\n",
    "\n",
    "    print(txt)\n",
    "\n",
    "    risk = stats.get(\"risk_label\") or \"-\"\n",
    "    reasons = stats.get(\"risk_reasons\") or []\n",
    "    soft = stats.get(\"soft_flags\") or []\n",
    "\n",
    "    print(\"\\n  Candidate statistics:\")\n",
    "    sim = stats.get(\"similarity_ratio\")\n",
    "    sim_s = f\"{float(sim):.2f}\" if isinstance(sim, (int, float)) else \"-\"\n",
    "    lr = stats.get(\"len_ratio\")\n",
    "    lr_s = f\"{float(lr):.2f}\" if isinstance(lr, (int, float)) else \"-\"\n",
    "    ld = stats.get(\"len_delta_chars\")\n",
    "    ld_s = f\"{int(ld):+d}\" if isinstance(ld, int) else \"-\"\n",
    "\n",
    "    sem = stats.get(\"semantic\") if isinstance(stats.get(\"semantic\"), dict) else None\n",
    "    sem_s = \"\"\n",
    "    if isinstance(sem, dict):\n",
    "        emb = sem.get(\"embedding\") if isinstance(sem.get(\"embedding\"), dict) else None\n",
    "        ver = sem.get(\"verifier\") if isinstance(sem.get(\"verifier\"), dict) else None\n",
    "        if isinstance(emb, dict):\n",
    "            sem_s += f\"; emb_cos={emb.get('cosine')}\"\n",
    "            if emb.get(\"error\"):\n",
    "                sem_s += f\"; emb_err={str(emb.get('error'))[:80]}\"\n",
    "        if isinstance(ver, dict):\n",
    "            sem_s += f\"; entail={ver.get('label')}\"\n",
    "            if ver.get(\"error\"):\n",
    "                sem_s += f\"; ent_err={str(ver.get('error'))[:80]}\"\n",
    "\n",
    "    print(f\"    risk={risk}; reasons={reasons if reasons else '[]'}; similarity={sim_s}; len_ratio={lr_s}; Δchars={ld_s}{sem_s}\")\n",
    "\n",
    "    if soft:\n",
    "        print(f\"    soft_flags={soft}\")\n",
    "\n",
    "    for key in (\"flags\", \"field_like\", \"numbers\", \"number_units\", \"snake\", \"camel\", \"logic\", \"modals\", \"scope\", \"verbs\"):\n",
    "        d = diffs.get(key) or {}\n",
    "        new_items = d.get(\"new\") or []\n",
    "        missing_items = d.get(\"missing\") or []\n",
    "        if not new_items and not missing_items:\n",
    "            continue\n",
    "        print(\n",
    "            f\"    {key}:\"\n",
    "            f\" new({len(new_items)})=[{_format_token_preview(list(new_items), max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "            f\" missing({len(missing_items)})=[{_format_token_preview(list(missing_items), max_items=max_preview, max_len=max_tok_len)}]\"\n",
    "        )\n",
    "\n",
    "\n",
    "# ========= Raw JSON-string patcher (for tools stored as JSON strings) =========\n",
    "def _extract_json_string_value(raw_json: str, key: str) -> Optional[str]:\n",
    "    token = f'\"{key}\"'\n",
    "    i = raw_json.find(token)\n",
    "    if i < 0:\n",
    "        return None\n",
    "    i = raw_json.find(\":\", i + len(token))\n",
    "    if i < 0:\n",
    "        return None\n",
    "    i += 1\n",
    "    n = len(raw_json)\n",
    "    while i < n and raw_json[i] in \" \\t\\r\\n\":\n",
    "        i += 1\n",
    "    if i >= n or raw_json[i] != '\"':\n",
    "        return None\n",
    "    start = i\n",
    "    i += 1\n",
    "    esc = False\n",
    "    while i < n:\n",
    "        c = raw_json[i]\n",
    "        if esc:\n",
    "            esc = False\n",
    "        else:\n",
    "            if c == \"\\\\\":\n",
    "                esc = True\n",
    "            elif c == '\"':\n",
    "                return raw_json[start : i + 1]\n",
    "        i += 1\n",
    "    return None\n",
    "\n",
    "\n",
    "def _decode_raw_json_string(raw_json_string_with_quotes: str) -> str:\n",
    "    try:\n",
    "        obj = json.loads('{\"description\":' + raw_json_string_with_quotes + \"}\")\n",
    "        return obj.get(\"description\") or \"\"\n",
    "    except json.JSONDecodeError:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def _get_description_for_print(entry: Any) -> Tuple[str, str]:\n",
    "    if isinstance(entry, str):\n",
    "        raw = _extract_json_string_value(entry, \"description\")\n",
    "        if raw is not None:\n",
    "            return raw, \"raw_json\"\n",
    "        try:\n",
    "            obj = json.loads(entry)\n",
    "            return obj.get(\"description\") or \"\", \"rendered\"\n",
    "        except json.JSONDecodeError:\n",
    "            return \"\", \"rendered\"\n",
    "    if isinstance(entry, dict):\n",
    "        return entry.get(\"description\") or \"\", \"rendered\"\n",
    "    return \"\", \"rendered\"\n",
    "\n",
    "\n",
    "def _load_tool(entry: Any) -> Tuple[Optional[Dict[str, Any]], str]:\n",
    "    if isinstance(entry, str):\n",
    "        try:\n",
    "            return json.loads(entry), \"json_str\"\n",
    "        except json.JSONDecodeError:\n",
    "            return None, \"other\"\n",
    "    if isinstance(entry, dict):\n",
    "        return entry, \"dict\"\n",
    "    return None, \"other\"\n",
    "\n",
    "\n",
    "def _skip_ws(s: str, i: int) -> int:\n",
    "    n = len(s)\n",
    "    while i < n and s[i] in \" \\t\\r\\n\":\n",
    "        i += 1\n",
    "    return i\n",
    "\n",
    "\n",
    "def _scan_string_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    n = len(s)\n",
    "    if i >= n or s[i] != '\"':\n",
    "        return None\n",
    "    j = i + 1\n",
    "    esc = False\n",
    "    while j < n:\n",
    "        c = s[j]\n",
    "        if esc:\n",
    "            esc = False\n",
    "        else:\n",
    "            if c == \"\\\\\":\n",
    "                esc = True\n",
    "            elif c == '\"':\n",
    "                return (i, j + 1)\n",
    "        j += 1\n",
    "    return None\n",
    "\n",
    "\n",
    "def _scan_number_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    n = len(s)\n",
    "    j = i\n",
    "    if j < n and s[j] == \"-\":\n",
    "        j += 1\n",
    "    if j >= n:\n",
    "        return None\n",
    "    if s[j] == \"0\":\n",
    "        j += 1\n",
    "    elif s[j].isdigit():\n",
    "        while j < n and s[j].isdigit():\n",
    "            j += 1\n",
    "    else:\n",
    "        return None\n",
    "    if j < n and s[j] == \".\":\n",
    "        j += 1\n",
    "        if j >= n or not s[j].isdigit():\n",
    "            return None\n",
    "        while j < n and s[j].isdigit():\n",
    "            j += 1\n",
    "    if j < n and s[j] in \"eE\":\n",
    "        j += 1\n",
    "        if j < n and s[j] in \"+-\":\n",
    "            j += 1\n",
    "        if j >= n or not s[j].isdigit():\n",
    "            return None\n",
    "        while j < n and s[j].isdigit():\n",
    "            j += 1\n",
    "    return (i, j)\n",
    "\n",
    "\n",
    "def _scan_literal_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    for lit in (\"true\", \"false\", \"null\"):\n",
    "        if s.startswith(lit, i):\n",
    "            return (i, i + len(lit))\n",
    "    return None\n",
    "\n",
    "\n",
    "def _scan_container_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    n = len(s)\n",
    "    if i >= n:\n",
    "        return None\n",
    "\n",
    "    opener = s[i]\n",
    "    if opener not in \"{[\":\n",
    "        return None\n",
    "\n",
    "    stack: List[str] = [\"}\" if opener == \"{\" else \"]\"]\n",
    "    j = i + 1\n",
    "    in_str = False\n",
    "    esc = False\n",
    "\n",
    "    while j < n:\n",
    "        c = s[j]\n",
    "\n",
    "        if in_str:\n",
    "            if esc:\n",
    "                esc = False\n",
    "            else:\n",
    "                if c == \"\\\\\":\n",
    "                    esc = True\n",
    "                elif c == '\"':\n",
    "                    in_str = False\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        if c == '\"':\n",
    "            in_str = True\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        if c == \"{\":\n",
    "            stack.append(\"}\")\n",
    "            j += 1\n",
    "            continue\n",
    "        if c == \"[\":\n",
    "            stack.append(\"]\")\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        if c in \"}]\":\n",
    "            if not stack:\n",
    "                return None\n",
    "            expected = stack[-1]\n",
    "            if c != expected:\n",
    "                return None\n",
    "            stack.pop()\n",
    "            j += 1\n",
    "            if not stack:\n",
    "                return (i, j)\n",
    "            continue\n",
    "\n",
    "        j += 1\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def _is_value_delim(c: str) -> bool:\n",
    "    return c in \",}]\"\n",
    "\n",
    "\n",
    "def _scan_value_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    n = len(s)\n",
    "    i = _skip_ws(s, i)\n",
    "    if i >= n:\n",
    "        return None\n",
    "\n",
    "    c = s[i]\n",
    "    if c == '\"':\n",
    "        return _scan_string_span(s, i)\n",
    "    if c in \"{[\":\n",
    "        return _scan_container_span(s, i)\n",
    "\n",
    "    span: Optional[Tuple[int, int]]\n",
    "    if c == \"-\" or c.isdigit():\n",
    "        span = _scan_number_span(s, i)\n",
    "    else:\n",
    "        span = _scan_literal_span(s, i)\n",
    "\n",
    "    if not span:\n",
    "        return None\n",
    "\n",
    "    _, end = span\n",
    "    k = _skip_ws(s, end)\n",
    "    if k >= n:\n",
    "        return span\n",
    "    if _is_value_delim(s[k]):\n",
    "        return span\n",
    "    return None\n",
    "\n",
    "\n",
    "def _replace_top_level_string_field_in_raw_object(raw_json_obj: str, key: str, new_value: str) -> Tuple[str, bool, str]:\n",
    "    s = raw_json_obj\n",
    "    n = len(s)\n",
    "\n",
    "    i = _skip_ws(s, 0)\n",
    "    if i >= n or s[i] != \"{\":\n",
    "        return raw_json_obj, False, \"not_object\"\n",
    "\n",
    "    i += 1\n",
    "    found_any_key = False\n",
    "    expect_key = True\n",
    "\n",
    "    while True:\n",
    "        i = _skip_ws(s, i)\n",
    "        if i >= n:\n",
    "            return raw_json_obj, False, \"cannot_scan_value\"\n",
    "\n",
    "        if expect_key:\n",
    "            if s[i] == \"}\":\n",
    "                return raw_json_obj, False, \"key_not_found\"\n",
    "            if s[i] != '\"':\n",
    "                return raw_json_obj, False, \"invalid_key_string\"\n",
    "\n",
    "            key_span = _scan_string_span(s, i)\n",
    "            if not key_span:\n",
    "                return raw_json_obj, False, \"invalid_key_string\"\n",
    "\n",
    "            found_any_key = True\n",
    "            k_start, k_end = key_span\n",
    "            try:\n",
    "                key_decoded = json.loads(s[k_start:k_end])\n",
    "            except Exception:\n",
    "                return raw_json_obj, False, \"invalid_key_string\"\n",
    "\n",
    "            i = _skip_ws(s, k_end)\n",
    "            if i >= n or s[i] != \":\":\n",
    "                return raw_json_obj, False, \"missing_colon\"\n",
    "\n",
    "            v_span = _scan_value_span(s, i + 1)\n",
    "            if not v_span:\n",
    "                return raw_json_obj, False, \"cannot_scan_value\"\n",
    "\n",
    "            v_start, v_end = v_span\n",
    "\n",
    "            if key_decoded == key:\n",
    "                if v_start >= n or s[v_start] != '\"':\n",
    "                    return raw_json_obj, False, \"value_not_string\"\n",
    "\n",
    "                replacement_literal = json.dumps(new_value, ensure_ascii=False)\n",
    "                patched = s[:v_start] + replacement_literal + s[v_end:]\n",
    "\n",
    "                try:\n",
    "                    obj = json.loads(patched)\n",
    "                except Exception:\n",
    "                    return raw_json_obj, False, \"json_load_failed_after_patch\"\n",
    "\n",
    "                if isinstance(obj, dict) and obj.get(key) == new_value:\n",
    "                    return patched, True, \"ok\"\n",
    "                return raw_json_obj, False, \"validation_failed_after_patch\"\n",
    "\n",
    "            i = v_end\n",
    "            expect_key = False\n",
    "            continue\n",
    "\n",
    "        i = _skip_ws(s, i)\n",
    "        if i >= n:\n",
    "            return raw_json_obj, False, \"cannot_scan_value\"\n",
    "\n",
    "        if s[i] == \",\":\n",
    "            i += 1\n",
    "            expect_key = True\n",
    "            continue\n",
    "        if s[i] == \"}\":\n",
    "            return raw_json_obj, False, (\"key_not_found\" if found_any_key else \"key_not_found\")\n",
    "        return raw_json_obj, False, \"cannot_scan_value\"\n",
    "\n",
    "\n",
    "# ========= IDs =========\n",
    "def _tool_fingerprint_excluding_description(tool_obj: Dict[str, Any]) -> str:\n",
    "    filtered = {k: v for k, v in tool_obj.items() if k != \"description\"}\n",
    "    payload = _canonical_json(filtered)\n",
    "    return hashlib.sha256(payload.encode(\"utf-8\")).hexdigest()[:HASH_HEX_LEN]\n",
    "\n",
    "\n",
    "def _record_id(record_obj: Dict[str, Any], tool_field: str) -> str:\n",
    "    rec = dict(record_obj)\n",
    "    tools = rec.get(tool_field)\n",
    "    if isinstance(tools, list):\n",
    "        canon_tools: List[Any] = []\n",
    "        for entry in tools:\n",
    "            tool_obj, kind = _load_tool(entry)\n",
    "            if tool_obj is None:\n",
    "                canon_tools.append({\"_unparsed\": entry, \"_kind\": kind})\n",
    "            else:\n",
    "                canon_tools.append({k: v for k, v in tool_obj.items() if k != \"description\"})\n",
    "        rec[tool_field] = canon_tools\n",
    "    payload = _canonical_json(rec)\n",
    "    return hashlib.sha256(payload.encode(\"utf-8\")).hexdigest()[:HASH_HEX_LEN]\n",
    "\n",
    "\n",
    "def _tool_instance_key(record_id: str, tool_index: int, tool_obj: Dict[str, Any]) -> str:\n",
    "    fp = _tool_fingerprint_excluding_description(tool_obj)\n",
    "    return f\"rec:{record_id}:t{tool_index}:{fp}\"\n",
    "\n",
    "\n",
    "# ========= Audit (single file, resumable) =========\n",
    "def _audit_identity(\n",
    "    dataset_path: Path,\n",
    "    *,\n",
    "    mode_key: str,\n",
    "    model: str,\n",
    "    tool_field: str,\n",
    "    num_candidates: int,\n",
    "    semantic_cfg: Optional[Dict[str, Any]],\n",
    ") -> str:\n",
    "    sc = semantic_cfg or {}\n",
    "    stable = (\n",
    "        f\"{dataset_path.resolve()}|{mode_key}|{model}|{tool_field}|K={int(num_candidates)}|\"\n",
    "        f\"{RISK_POLICY_NAME}|{LOGIC_TOKEN_POLICY_NAME}|{SEMANTIC_POLICY_NAME}|\"\n",
    "        f\"emb={bool(sc.get('enable_embeddings', False))}:{str(sc.get('embedding_model') or '')}|\"\n",
    "        f\"ver={bool(sc.get('enable_verifier', False))}:{str(sc.get('verifier_model') or '')}\"\n",
    "    )\n",
    "    return hashlib.sha256(stable.encode(\"utf-8\")).hexdigest()[:12]\n",
    "\n",
    "\n",
    "def _audit_file_path(\n",
    "    dataset_path: Path,\n",
    "    *,\n",
    "    audit_dir: Path,\n",
    "    mode_key: str,\n",
    "    model: str,\n",
    "    tool_field: str,\n",
    "    num_candidates: int,\n",
    "    semantic_cfg: Optional[Dict[str, Any]],\n",
    ") -> Path:\n",
    "    audit_key = _audit_identity(\n",
    "        dataset_path,\n",
    "        mode_key=mode_key,\n",
    "        model=model,\n",
    "        tool_field=tool_field,\n",
    "        num_candidates=int(num_candidates),\n",
    "        semantic_cfg=semantic_cfg,\n",
    "    )\n",
    "    safe_model = \"\".join(ch if ch.isalnum() or ch in (\"-\", \"_\", \".\") else \"_\" for ch in model)\n",
    "    out_dir = audit_dir / audit_key\n",
    "    filename = f\"{dataset_path.stem}.{audit_key}.{mode_key}.{safe_model}.K{int(num_candidates)}.audit.jsonl\"\n",
    "    return out_dir / filename\n",
    "\n",
    "\n",
    "def _append_audit_event(audit_file: Path, event: Dict[str, Any]) -> None:\n",
    "    audit_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    safe_event = _json_safe(event)\n",
    "    with audit_file.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(safe_event, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "def _load_resume_state(\n",
    "    audit_file: Path,\n",
    ") -> Tuple[\n",
    "    Dict[str, Tuple[str, Optional[str], Optional[Dict[str, Any]]]],\n",
    "    Dict[str, int],\n",
    "    Dict[str, Optional[str]],\n",
    "    Optional[Dict[str, Any]],\n",
    "]:\n",
    "    decisions: Dict[str, Tuple[str, Optional[str], Optional[Dict[str, Any]]]] = {}\n",
    "    regen_counts: Dict[str, int] = {}\n",
    "    last_rejected_text: Dict[str, Optional[str]] = {}\n",
    "    prior_run_start: Optional[Dict[str, Any]] = None\n",
    "\n",
    "    if not audit_file.exists():\n",
    "        return decisions, regen_counts, last_rejected_text, None\n",
    "\n",
    "    best_round: Dict[str, int] = {}\n",
    "\n",
    "    with audit_file.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                ev = json.loads(line)\n",
    "            except Exception:\n",
    "                continue\n",
    "            if not isinstance(ev, dict):\n",
    "                continue\n",
    "\n",
    "            et = ev.get(\"event_type\")\n",
    "            if et == \"run_start\" and prior_run_start is None:\n",
    "                prior_run_start = ev\n",
    "\n",
    "            if et == \"regenerate\":\n",
    "                ik = ev.get(\"instance_key\")\n",
    "                rr = ev.get(\"generation_round\")\n",
    "                txt = ev.get(\"last_generated_text\")\n",
    "                if isinstance(ik, str) and isinstance(rr, int) and rr >= 0:\n",
    "                    prev = regen_counts.get(ik, 0)\n",
    "                    if rr > prev:\n",
    "                        regen_counts[ik] = rr\n",
    "                    prev_best = best_round.get(ik, -1)\n",
    "                    if rr >= prev_best:\n",
    "                        best_round[ik] = rr\n",
    "                        last_rejected_text[ik] = txt if isinstance(txt, str) else None\n",
    "\n",
    "            if et == \"decision\":\n",
    "                ik = ev.get(\"instance_key\")\n",
    "                status = ev.get(\"status\")\n",
    "                final_desc = ev.get(\"final_description\")\n",
    "                llm_bundle = ev.get(\"llm_bundle\")\n",
    "                if isinstance(ik, str) and isinstance(status, str):\n",
    "                    decisions[ik] = (\n",
    "                        status,\n",
    "                        final_desc if isinstance(final_desc, str) else None,\n",
    "                        llm_bundle if isinstance(llm_bundle, dict) else None,\n",
    "                    )\n",
    "\n",
    "    return decisions, regen_counts, last_rejected_text, prior_run_start\n",
    "\n",
    "\n",
    "# ========= LLM helpers =========\n",
    "def _sanitize_llm_output(text: str) -> str:\n",
    "    t = (text or \"\").strip()\n",
    "    if t.startswith(\"{\") and \"description\" in t:\n",
    "        try:\n",
    "            obj = json.loads(t)\n",
    "            if isinstance(obj, dict) and isinstance(obj.get(\"description\"), str):\n",
    "                t = obj[\"description\"].strip()\n",
    "        except Exception:\n",
    "            pass\n",
    "    if (t.startswith('\"') and t.endswith('\"')) or (t.startswith(\"'\") and t.endswith(\"'\")):\n",
    "        t = t[1:-1].strip()\n",
    "    return t\n",
    "\n",
    "\n",
    "def _llm_chat_completion(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    model: str,\n",
    "    messages: List[Dict[str, str]],\n",
    "    temperature: float,\n",
    "    max_tokens: int,\n",
    "    seed: Optional[int],\n",
    ") -> Tuple[str, Dict[str, Any]]:\n",
    "    meta: Dict[str, Any] = {\n",
    "        \"seed_requested\": seed,\n",
    "        \"seed_applied\": False,\n",
    "        \"seed_error\": None,\n",
    "        \"finish_reason\": None,\n",
    "        \"usage\": None,\n",
    "        \"max_tokens_requested\": int(max_tokens),\n",
    "        \"max_param_used\": None,\n",
    "    }\n",
    "\n",
    "    base_kwargs: Dict[str, Any] = dict(model=model, messages=messages, temperature=temperature)\n",
    "\n",
    "    def attempt(max_param_used: str, include_seed: bool) -> Tuple[str, Dict[str, Any]]:\n",
    "        req = dict(base_kwargs)\n",
    "        if max_param_used == \"max_completion_tokens\":\n",
    "            req[\"max_completion_tokens\"] = int(max_tokens)\n",
    "        else:\n",
    "            req[\"max_tokens\"] = int(max_tokens)\n",
    "        if include_seed and seed is not None:\n",
    "            req[\"seed\"] = int(seed)\n",
    "\n",
    "        resp = client.chat.completions.create(**req)\n",
    "        text = (resp.choices[0].message.content or \"\").strip()\n",
    "\n",
    "        meta_local = dict(meta)\n",
    "        meta_local[\"max_param_used\"] = max_param_used\n",
    "        meta_local[\"finish_reason\"] = getattr(resp.choices[0], \"finish_reason\", None)\n",
    "        meta_local[\"usage\"] = getattr(resp, \"usage\", None)\n",
    "        meta_local[\"seed_applied\"] = bool(include_seed and seed is not None)\n",
    "        return text, meta_local\n",
    "\n",
    "    def is_seed_error(e: Exception) -> bool:\n",
    "        s = str(e).lower()\n",
    "        return (\"seed\" in s) and (\"unknown\" in s or \"unsupported\" in s or \"invalid\" in s)\n",
    "\n",
    "    try:\n",
    "        return attempt(\"max_completion_tokens\", include_seed=True)\n",
    "    except Exception as e1:\n",
    "        if seed is not None and is_seed_error(e1):\n",
    "            meta[\"seed_error\"] = str(e1)\n",
    "            try:\n",
    "                return attempt(\"max_completion_tokens\", include_seed=False)\n",
    "            except Exception:\n",
    "                pass\n",
    "        try:\n",
    "            return attempt(\"max_tokens\", include_seed=True)\n",
    "        except Exception as e2:\n",
    "            if seed is not None and is_seed_error(e2):\n",
    "                meta[\"seed_error\"] = str(e2)\n",
    "                return attempt(\"max_tokens\", include_seed=False)\n",
    "            raise\n",
    "\n",
    "\n",
    "def generate_description_via_llm(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    tool_name: str,\n",
    "    base_description: str,\n",
    "    model: str,\n",
    "    seed: Optional[int],\n",
    "    max_tokens: int,\n",
    "    retry_on_length: bool,\n",
    "    retry_max_tokens: int,\n",
    "    mode_key: str,\n",
    "    style_spec: Dict[str, Any],\n",
    "    regen_index: int = 0,\n",
    "    previous_rewrite: Optional[str] = None,\n",
    "    length_policy: Optional[Dict[str, Any]] = None,\n",
    ") -> Tuple[str, Dict[str, Any]]:\n",
    "    system = str(style_spec[\"system\"])\n",
    "    regen_instr = str(style_spec.get(\"regen_diversity_instruction\") or \"\")\n",
    "    max_prev = int(style_spec.get(\"max_prev_rewrite_chars\") or DEFAULT_MAX_PREV_REWRITE_CHARS)\n",
    "\n",
    "    user_parts: List[str] = []\n",
    "    user_parts.append(f\"Tool name: {tool_name}\")\n",
    "    user_parts.append(\"Base description:\")\n",
    "    user_parts.append(base_description.strip() or \"(empty)\")\n",
    "    user_parts.append(\"\")\n",
    "    user_parts.append(f\"Rewrite in '{mode_key}' under the constraints.\")\n",
    "\n",
    "    if mode_key == \"style_concise\" and isinstance(length_policy, dict):\n",
    "        ct = length_policy.get(\"concise_soft_target\") if isinstance(length_policy.get(\"concise_soft_target\"), dict) else {}\n",
    "        applied = bool(ct.get(\"applied\", False))\n",
    "        target_chars = ct.get(\"target_chars\") if isinstance(ct.get(\"target_chars\"), int) else None\n",
    "        ratio = ct.get(\"target_ratio\")\n",
    "        if applied and isinstance(target_chars, int):\n",
    "            pct = int(float(ratio) * 100) if isinstance(ratio, (int, float)) else 70\n",
    "            user_parts.append(\"\")\n",
    "            user_parts.append(f\"Length guidance (soft target): <= {target_chars} characters (~{pct}% of base).\")\n",
    "            user_parts.append(\n",
    "                \"Exceeding the target is permitted only if strictly necessary to preserve meaning; \"\n",
    "                \"no explicitly stated details may be omitted.\"\n",
    "            )\n",
    "        else:\n",
    "            user_parts.append(\"\")\n",
    "            user_parts.append(\n",
    "                \"Length guidance: the base description is short or cannot be shortened safely; \"\n",
    "                \"the rewrite must not exceed the base length and must remain as brief as possible.\"\n",
    "            )\n",
    "\n",
    "    if regen_index > 0:\n",
    "        user_parts.append(\"\")\n",
    "        user_parts.append(f\"Regeneration request: {regen_index}\")\n",
    "        if regen_instr:\n",
    "            user_parts.append(regen_instr)\n",
    "        if previous_rewrite and previous_rewrite.strip():\n",
    "            prev = previous_rewrite.strip()\n",
    "            if len(prev) > max_prev:\n",
    "                prev = prev[:max_prev].rstrip()\n",
    "            user_parts.append(\"\")\n",
    "            user_parts.append(\"Previous rewrite (wording must not be reused):\")\n",
    "            user_parts.append(prev)\n",
    "\n",
    "    user = \"\\n\".join(user_parts)\n",
    "\n",
    "    raw1, meta1 = _llm_chat_completion(\n",
    "        client=client,\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": user}],\n",
    "        temperature=0.0,\n",
    "        max_tokens=max_tokens,\n",
    "        seed=seed,\n",
    "    )\n",
    "    san1 = _sanitize_llm_output(raw1)\n",
    "    finish1 = (meta1.get(\"finish_reason\") or \"\").lower()\n",
    "    looks_truncated_1 = (finish1 == \"length\")\n",
    "\n",
    "    if not looks_truncated_1:\n",
    "        return san1, {\n",
    "            \"proposal_origin\": \"primary\",\n",
    "            \"proposal_sanitized_final\": san1,\n",
    "            \"llm_text_raw_primary\": raw1,\n",
    "            \"llm_text_raw_retry\": None,\n",
    "            \"primary\": meta1,\n",
    "            \"retry\": None,\n",
    "            \"mode_key\": mode_key,\n",
    "            \"length_policy\": length_policy,\n",
    "        }\n",
    "\n",
    "    raw2 = None\n",
    "    meta2 = None\n",
    "    san2 = None\n",
    "    best_san = san1\n",
    "    origin = \"primary\"\n",
    "\n",
    "    if retry_on_length and retry_max_tokens > max_tokens:\n",
    "        raw2, meta2 = _llm_chat_completion(\n",
    "            client=client,\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": user}],\n",
    "            temperature=0.0,\n",
    "            max_tokens=int(retry_max_tokens),\n",
    "            seed=seed,\n",
    "        )\n",
    "        san2 = _sanitize_llm_output(raw2)\n",
    "        if san2 and len(san2) >= len(best_san):\n",
    "            best_san = san2\n",
    "            origin = \"retry\"\n",
    "\n",
    "    return best_san, {\n",
    "        \"proposal_origin\": origin,\n",
    "        \"proposal_sanitized_final\": best_san,\n",
    "        \"llm_text_raw_primary\": raw1,\n",
    "        \"llm_text_raw_retry\": raw2,\n",
    "        \"primary\": meta1,\n",
    "        \"retry\": meta2,\n",
    "        \"mode_key\": mode_key,\n",
    "        \"length_policy\": length_policy,\n",
    "    }\n",
    "\n",
    "\n",
    "def _print_perturbation_context(\n",
    "    *,\n",
    "    show: bool,\n",
    "    tool_name: str,\n",
    "    candidate_i_1based: int,\n",
    "    k: int,\n",
    "    generation_round: int,\n",
    "    regen_index: int,\n",
    "    seed: Optional[int],\n",
    "    max_tokens: int,\n",
    "    mode_key: str,\n",
    "    style_spec: Dict[str, Any],\n",
    "    length_policy: Optional[Dict[str, Any]],\n",
    "    prev_hint: Optional[str],\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Prints (to stdout) the \"perturbation context\" used for this candidate generation.\n",
    "    This is intentionally concise: it shows *what* changes across candidates/rounds without dumping full prompts.\n",
    "    \"\"\"\n",
    "    if not show:\n",
    "        return\n",
    "\n",
    "    regen_instr = str(style_spec.get(\"regen_diversity_instruction\") or \"\").strip()\n",
    "\n",
    "    ct = None\n",
    "    if isinstance(length_policy, dict):\n",
    "        ct0 = length_policy.get(\"concise_soft_target\")\n",
    "        if isinstance(ct0, dict):\n",
    "            ct = ct0\n",
    "\n",
    "    ct_applied = bool(ct.get(\"applied\", False)) if isinstance(ct, dict) else False\n",
    "    ct_target = ct.get(\"target_chars\") if (isinstance(ct, dict) and isinstance(ct.get(\"target_chars\"), int)) else None\n",
    "    ct_reason = ct.get(\"reason\") if isinstance(ct, dict) else None\n",
    "\n",
    "    print(\n",
    "        f\"\\n  [gen] {tool_name} | cand {candidate_i_1based}/{int(k)} | round={int(generation_round)} | \"\n",
    "        f\"regen_index={int(regen_index)} | mode={mode_key} | seed={seed} | max_tokens={int(max_tokens)}\"\n",
    "    )\n",
    "\n",
    "    if mode_key == \"style_concise\":\n",
    "        if ct_applied and isinstance(ct_target, int):\n",
    "            print(f\"      length_guidance: soft_target<= {int(ct_target)} chars (applied)\")\n",
    "        else:\n",
    "            print(f\"      length_guidance: soft_target not applied (reason={ct_reason})\")\n",
    "\n",
    "    if int(generation_round) > 0 or int(regen_index) > 0:\n",
    "        if regen_instr:\n",
    "            sn = \" \".join(regen_instr.split())\n",
    "            if len(sn) > 220:\n",
    "                sn = sn[:219] + \"…\"\n",
    "            print(f\"      diversity_instruction: {sn}\")\n",
    "\n",
    "    if prev_hint and prev_hint.strip():\n",
    "        ph = prev_hint.strip()\n",
    "        ph_sn = \" \".join(ph.split())\n",
    "        if len(ph_sn) > 220:\n",
    "            ph_sn = ph_sn[:219] + \"…\"\n",
    "        print(\n",
    "            f\"      previous_rewrite_hint: len={len(ph)} sha={_sha256_text(ph)[:12]} snippet='{ph_sn}'\"\n",
    "        )\n",
    "\n",
    "\n",
    "def generate_k_candidates_with_stats(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    tool_name: str,\n",
    "    base_description: str,\n",
    "    model: str,\n",
    "    seed: Optional[int],\n",
    "    max_tokens: int,\n",
    "    retry_on_length: bool,\n",
    "    retry_max_tokens: int,\n",
    "    mode_key: str,\n",
    "    style_spec: Dict[str, Any],\n",
    "    generation_round: int,\n",
    "    k: int,\n",
    "    previous_rewrite_hint: Optional[str],\n",
    "    min_sleep_sec_between_calls: float,\n",
    "    length_policy: Optional[Dict[str, Any]],\n",
    "    semantic_cfg: Optional[Dict[str, Any]],\n",
    "    show_perturbations: bool,\n",
    ") -> Tuple[List[Dict[str, Any]], Optional[str]]:\n",
    "    base_desc = (base_description or \"\").strip()\n",
    "    k_eff = max(1, int(k))\n",
    "\n",
    "    candidates: List[Dict[str, Any]] = []\n",
    "    seen: set = set()\n",
    "\n",
    "    prev = previous_rewrite_hint.strip() if isinstance(previous_rewrite_hint, str) and previous_rewrite_hint.strip() else None\n",
    "    last_generated_text: Optional[str] = None\n",
    "\n",
    "    for i in range(0, k_eff):\n",
    "        regen_index = int(generation_round) * 1000 + i\n",
    "        text = \"\"\n",
    "        bundle: Optional[Dict[str, Any]] = None\n",
    "        err: Optional[str] = None\n",
    "\n",
    "        # Feb 3 patch: print perturbation context *before* the LLM call.\n",
    "        _print_perturbation_context(\n",
    "            show=bool(show_perturbations),\n",
    "            tool_name=tool_name,\n",
    "            candidate_i_1based=i + 1,\n",
    "            k=k_eff,\n",
    "            generation_round=int(generation_round),\n",
    "            regen_index=int(regen_index),\n",
    "            seed=seed,\n",
    "            max_tokens=int(max_tokens),\n",
    "            mode_key=mode_key,\n",
    "            style_spec=style_spec,\n",
    "            length_policy=length_policy,\n",
    "            prev_hint=prev,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            text, bundle = generate_description_via_llm(\n",
    "                client=client,\n",
    "                tool_name=tool_name,\n",
    "                base_description=base_desc,\n",
    "                model=model,\n",
    "                seed=seed,\n",
    "                max_tokens=max_tokens,\n",
    "                retry_on_length=retry_on_length,\n",
    "                retry_max_tokens=retry_max_tokens,\n",
    "                mode_key=mode_key,\n",
    "                style_spec=style_spec,\n",
    "                regen_index=regen_index,\n",
    "                previous_rewrite=prev,\n",
    "                length_policy=length_policy,\n",
    "            )\n",
    "            text = (text or \"\").strip()\n",
    "            last_generated_text = text if text else last_generated_text\n",
    "        except Exception as e:\n",
    "            err = str(e)\n",
    "            text = \"\"\n",
    "\n",
    "        duplicate = False\n",
    "        if text:\n",
    "            if text in seen:\n",
    "                duplicate = True\n",
    "            else:\n",
    "                seen.add(text)\n",
    "\n",
    "        stats = compute_full_candidate_stats(\n",
    "            base_text=base_desc,\n",
    "            cand_text=text,\n",
    "            mode_key=mode_key,\n",
    "            length_policy=length_policy,\n",
    "            client=client,\n",
    "            semantic_cfg=semantic_cfg,\n",
    "        ) if text else None\n",
    "\n",
    "        candidates.append(\n",
    "            {\n",
    "                \"candidate_index\": i + 1,\n",
    "                \"text\": text,\n",
    "                \"error\": err,\n",
    "                \"bundle\": bundle,\n",
    "                \"duplicate\": duplicate,\n",
    "                \"stats\": stats,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        prev = text if text else prev\n",
    "\n",
    "        if min_sleep_sec_between_calls > 0:\n",
    "            time.sleep(float(min_sleep_sec_between_calls))\n",
    "\n",
    "    return candidates, last_generated_text\n",
    "\n",
    "\n",
    "# ========= IO =========\n",
    "def make_working_copy(input_jsonl: str, output_jsonl: str, *, overwrite: bool = False) -> str:\n",
    "    src = Path(input_jsonl)\n",
    "    dst = Path(output_jsonl)\n",
    "\n",
    "    if not src.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {src}\")\n",
    "\n",
    "    if dst.exists() and not overwrite:\n",
    "        return str(dst)\n",
    "\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(src, dst)\n",
    "    return str(dst)\n",
    "\n",
    "\n",
    "def _normalize_cmd(raw: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalizes user command strings.\n",
    "    Important: maps Esc (raw '\\x1b' or common textual forms) to quit.\n",
    "    \"\"\"\n",
    "    r = raw if raw is not None else \"\"\n",
    "    # If raw-key mode is enabled, Esc is returned as '\\x1b'.\n",
    "    if (\"\\x1b\" in r) or (r.strip().lower() in (\"esc\", \"<esc>\", \"^[\", \"escape\")):\n",
    "        return \"q\"\n",
    "\n",
    "    c = (r or \"\").strip().lower()\n",
    "    if c in (\"\", \"y\", \"yes\", \"ok\", \"okay\", \"si\", \"sì\"):\n",
    "        return \"y\"\n",
    "    if c in (\"r\", \"retry\", \"again\", \"prova\", \"prova ancora\", \"rigenera\"):\n",
    "        return \"r\"\n",
    "    if c in (\"e\", \"edit\", \"modifica\"):\n",
    "        return \"e\"\n",
    "    if c in (\"m\", \"manual\", \"mine\", \"mio\", \"mia\", \"custom\"):\n",
    "        return \"m\"\n",
    "    if c in (\"s\", \"skip\", \"salta\", \"pass\"):\n",
    "        return \"s\"\n",
    "    if c in (\"q\", \"quit\", \"exit\", \"esci\"):\n",
    "        return \"q\"\n",
    "    return c\n",
    "\n",
    "\n",
    "def _parse_candidate_choice(cmd: str, *, k: int) -> Optional[int]:\n",
    "    c = (cmd or \"\").strip()\n",
    "    if not c:\n",
    "        return None\n",
    "    if c.isdigit():\n",
    "        v = int(c)\n",
    "        if 1 <= v <= int(k):\n",
    "            return v\n",
    "    return None\n",
    "\n",
    "\n",
    "# ========= Main interactive =========\n",
    "def interactive_llm_tools_in_jsonl(\n",
    "    jsonl_path: str,\n",
    "    *,\n",
    "    tool_field: str,\n",
    "    create_backup_of_target: bool,\n",
    "    llm_model: str,\n",
    "    seed: Optional[int],\n",
    "    max_tokens: int,\n",
    "    retry_on_length: bool,\n",
    "    retry_max_tokens: int,\n",
    "    allow_reserialize_fallback: bool,\n",
    "    min_sleep_sec_between_calls: float,\n",
    "    audit_dir: str,\n",
    "    mode_key: str,\n",
    "    num_candidates: int,\n",
    "    max_token_preview: int,\n",
    "    max_token_string_len: int,\n",
    "    candidate_snippet_chars: int,\n",
    "    concise_target_ratio: float,\n",
    "    concise_target_min_base_len: int,\n",
    "    concise_target_min_chars: int,\n",
    "    semantic_cfg: Optional[Dict[str, Any]],\n",
    "    show_perturbations: bool,\n",
    "    raw_key_input: bool,\n",
    ") -> None:\n",
    "    mode_key, style_spec = _resolve_style(mode_key)\n",
    "\n",
    "    path = Path(jsonl_path)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {jsonl_path}\")\n",
    "\n",
    "    client = make_gemini_client()\n",
    "    audit_file = _audit_file_path(\n",
    "        path,\n",
    "        audit_dir=Path(audit_dir),\n",
    "        mode_key=mode_key,\n",
    "        model=llm_model,\n",
    "        tool_field=tool_field,\n",
    "        num_candidates=int(num_candidates),\n",
    "        semantic_cfg=semantic_cfg,\n",
    "    )\n",
    "\n",
    "    decisions_by_instance, regen_counts, last_rejected_text_by_instance, prior_run_start = _load_resume_state(audit_file)\n",
    "\n",
    "    tool_order: List[Dict[str, Any]] = []\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for raw_line in f:\n",
    "            line = raw_line.rstrip(\"\\n\")\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            try:\n",
    "                record = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "            if not isinstance(record, dict):\n",
    "                continue\n",
    "\n",
    "            rid = _record_id(record, tool_field=tool_field)\n",
    "            tools = record.get(tool_field)\n",
    "            if not isinstance(tools, list):\n",
    "                continue\n",
    "\n",
    "            for tool_index, entry in enumerate(tools):\n",
    "                tool_obj, kind = _load_tool(entry)\n",
    "                if not tool_obj:\n",
    "                    continue\n",
    "                name = (tool_obj.get(\"name\") or \"\").strip()\n",
    "                if not name:\n",
    "                    continue\n",
    "\n",
    "                desc_print, desc_mode = _get_description_for_print(entry)\n",
    "                instance_key = _tool_instance_key(rid, tool_index, tool_obj)\n",
    "\n",
    "                tool_order.append(\n",
    "                    {\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_index,\n",
    "                        \"tool_name\": name,\n",
    "                        \"desc_print\": desc_print,\n",
    "                        \"desc_mode\": desc_mode,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"entry_kind\": kind,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    n_total = len(tool_order)\n",
    "    n_prev_reviewed = len(decisions_by_instance)\n",
    "\n",
    "    start_pos = 0\n",
    "    while start_pos < n_total and tool_order[start_pos][\"instance_key\"] in decisions_by_instance:\n",
    "        start_pos += 1\n",
    "\n",
    "    session_id = hashlib.sha256(f\"{time.time_ns()}\".encode(\"utf-8\")).hexdigest()[:12]\n",
    "    before_sha = _sha256_file(path)\n",
    "\n",
    "    length_policy_config = {\n",
    "        \"concise_soft_target\": {\n",
    "            \"ratio\": float(concise_target_ratio),\n",
    "            \"min_base_len\": int(concise_target_min_base_len),\n",
    "            \"min_chars\": int(concise_target_min_chars),\n",
    "            \"policy_name\": \"concise_soft_target_v1\",\n",
    "        }\n",
    "    }\n",
    "\n",
    "    semantic_cfg_norm = dict(semantic_cfg or {})\n",
    "    semantic_cfg_norm[\"fallback_llm_model\"] = llm_model\n",
    "\n",
    "    if prior_run_start is None:\n",
    "        _append_audit_event(\n",
    "            audit_file,\n",
    "            {\n",
    "                \"event_type\": \"run_start\",\n",
    "                \"ts\": int(time.time()),\n",
    "                \"session_id\": session_id,\n",
    "                \"mode\": mode_key,\n",
    "                \"model\": llm_model,\n",
    "                \"seed\": seed,\n",
    "                \"dataset_path\": str(path),\n",
    "                \"dataset_sha256_at_session_start\": before_sha,\n",
    "                \"tool_field\": tool_field,\n",
    "                \"n_total_occurrences\": n_total,\n",
    "                \"max_tokens_requested\": int(max_tokens),\n",
    "                \"retry_on_length\": bool(retry_on_length),\n",
    "                \"retry_max_tokens\": int(retry_max_tokens),\n",
    "                \"allow_reserialize_fallback\": bool(allow_reserialize_fallback),\n",
    "                \"num_candidates\": int(num_candidates),\n",
    "                \"min_sleep_sec_between_calls\": float(min_sleep_sec_between_calls),\n",
    "                \"stats_max_token_preview\": int(max_token_preview),\n",
    "                \"stats_max_token_string_len\": int(max_token_string_len),\n",
    "                \"candidate_snippet_chars\": int(candidate_snippet_chars),\n",
    "                \"length_policy_config\": length_policy_config,\n",
    "                \"policy_versions\": {\n",
    "                    \"risk_policy_name\": RISK_POLICY_NAME,\n",
    "                    \"logic_token_policy_name\": LOGIC_TOKEN_POLICY_NAME,\n",
    "                    \"semantic_policy_name\": SEMANTIC_POLICY_NAME,\n",
    "                },\n",
    "                \"semantic_cfg\": semantic_cfg_norm,\n",
    "                \"show_perturbations\": bool(show_perturbations),\n",
    "                \"raw_key_input\": bool(raw_key_input),\n",
    "            },\n",
    "        )\n",
    "    else:\n",
    "        _append_audit_event(\n",
    "            audit_file,\n",
    "            {\n",
    "                \"event_type\": \"run_resume\",\n",
    "                \"ts\": int(time.time()),\n",
    "                \"session_id\": session_id,\n",
    "                \"mode\": mode_key,\n",
    "                \"model\": llm_model,\n",
    "                \"seed\": seed,\n",
    "                \"dataset_path\": str(path),\n",
    "                \"dataset_sha256_at_session_start\": before_sha,\n",
    "                \"tool_field\": tool_field,\n",
    "                \"n_total_occurrences\": n_total,\n",
    "                \"n_previously_reviewed\": n_prev_reviewed,\n",
    "                \"resume_from_index_1based\": (start_pos + 1) if start_pos < n_total else (n_total + 1),\n",
    "                \"num_candidates\": int(num_candidates),\n",
    "                \"candidate_snippet_chars\": int(candidate_snippet_chars),\n",
    "                \"length_policy_config\": length_policy_config,\n",
    "                \"policy_versions\": {\n",
    "                    \"risk_policy_name\": RISK_POLICY_NAME,\n",
    "                    \"logic_token_policy_name\": LOGIC_TOKEN_POLICY_NAME,\n",
    "                    \"semantic_policy_name\": SEMANTIC_POLICY_NAME,\n",
    "                },\n",
    "                \"semantic_cfg\": semantic_cfg_norm,\n",
    "                \"show_perturbations\": bool(show_perturbations),\n",
    "                \"raw_key_input\": bool(raw_key_input),\n",
    "            },\n",
    "        )\n",
    "\n",
    "    print(f\"Target: {path}\")\n",
    "    print(f\"Mode: {mode_key}\")\n",
    "    print(f\"Audit file (RESUMABLE): {audit_file}\")\n",
    "    print(f\"Tool occurrences total: {n_total}\")\n",
    "    if start_pos < n_total:\n",
    "        print(f\"Resume position: [{start_pos + 1}/{n_total}] (previously reviewed: {n_prev_reviewed})\")\n",
    "    else:\n",
    "        print(f\"Resume position: completed (previously reviewed: {n_prev_reviewed})\")\n",
    "    print(f\"LLM: {llm_model} @ {GEMINI_BASE_URL}\")\n",
    "    print(f\"Candidates per tool: {int(num_candidates)}\")\n",
    "    print(f\"Candidate snippet chars: {int(candidate_snippet_chars)}\")\n",
    "    print(f\"Policies: risk={RISK_POLICY_NAME}; logic={LOGIC_TOKEN_POLICY_NAME}; semantic={SEMANTIC_POLICY_NAME}\")\n",
    "    print(f\"Perturbation prints: {'enabled' if show_perturbations else 'disabled'}\")\n",
    "    print(f\"Raw key input (Esc-safe): {'enabled' if raw_key_input else 'disabled'}\")\n",
    "\n",
    "    if semantic_cfg_norm.get(\"enable_embeddings\"):\n",
    "        print(\n",
    "            \"Embedding signal: enabled; \"\n",
    "            f\"model='{semantic_cfg_norm.get('embedding_model')}', \"\n",
    "            f\"low_cos_thr={semantic_cfg_norm.get('embedding_low_cosine_threshold')}\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"Embedding signal: disabled\")\n",
    "    if semantic_cfg_norm.get(\"enable_verifier\"):\n",
    "        print(\n",
    "            \"Verifier signal: enabled; \"\n",
    "            f\"model='{semantic_cfg_norm.get('verifier_model') or llm_model}', \"\n",
    "            f\"max_tokens={int(semantic_cfg_norm.get('verifier_max_tokens', DEFAULT_VERIFIER_MAX_TOKENS))}\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"Verifier signal: disabled\")\n",
    "\n",
    "    if mode_key == \"style_concise\":\n",
    "        print(\n",
    "            \"Concise soft target: \"\n",
    "            f\"ratio={float(concise_target_ratio):.2f}, \"\n",
    "            f\"min_base_len={int(concise_target_min_base_len)}, \"\n",
    "            f\"min_chars={int(concise_target_min_chars)}\"\n",
    "        )\n",
    "    print(f\"Max tokens: {int(max_tokens)}; retry_on_length={bool(retry_on_length)}; retry_max_tokens={int(retry_max_tokens)}\")\n",
    "    print(\n",
    "        \"Commands: ENTER/ok=accept #1, 1..K=accept candidate, r=regenerate K, \"\n",
    "        \"e=edit candidate, m=manual, s=skip, q/Esc=quit, p<idx>=preview (e.g., p2)\\n\"\n",
    "    )\n",
    "\n",
    "    quit_requested = False\n",
    "    resume_next_index_1based: Optional[int] = None\n",
    "\n",
    "    max_prev = int(style_spec.get(\"max_prev_rewrite_chars\") or DEFAULT_MAX_PREV_REWRITE_CHARS)\n",
    "\n",
    "    session_summary: Dict[str, Any] = {\n",
    "        \"accepted\": 0,\n",
    "        \"edited\": 0,\n",
    "        \"manual\": 0,\n",
    "        \"skipped\": 0,\n",
    "        \"accepted_risk_labels\": {\"LOW\": 0, \"MED\": 0, \"HIGH\": 0, \"NA\": 0},\n",
    "        \"accepted_similarity_sum\": 0.0,\n",
    "        \"accepted_similarity_n\": 0,\n",
    "        \"accepted_base_chars_sum\": 0,\n",
    "        \"accepted_cand_chars_sum\": 0,\n",
    "        \"accepted_len_ratio_sum\": 0.0,\n",
    "        \"accepted_len_ratio_n\": 0,\n",
    "        \"accepted_len_delta_sum\": 0,\n",
    "        \"accepted_soft_target_applicable_n\": 0,\n",
    "        \"accepted_within_soft_target_n\": 0,\n",
    "        \"accepted_embedding_cos_sum\": 0.0,\n",
    "        \"accepted_embedding_cos_n\": 0,\n",
    "        \"accepted_entails\": 0,\n",
    "        \"accepted_not_entails\": 0,\n",
    "        \"accepted_entails_unknown\": 0,\n",
    "    }\n",
    "\n",
    "    for pos in range(start_pos, n_total):\n",
    "        item = tool_order[pos]\n",
    "        idx = pos + 1\n",
    "\n",
    "        name = item[\"tool_name\"]\n",
    "        desc_mode = item[\"desc_mode\"]\n",
    "        old_desc_print = item[\"desc_print\"]\n",
    "        instance_key = item[\"instance_key\"]\n",
    "        rid = item[\"record_id\"]\n",
    "        tool_i = item[\"tool_index\"]\n",
    "\n",
    "        generation_round = int(regen_counts.get(instance_key, 0))\n",
    "        previous_rewrite_hint: Optional[str] = last_rejected_text_by_instance.get(instance_key)\n",
    "\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"[{idx}/{n_total}] {name}\")\n",
    "        print(f\"instance_key: {instance_key} (record_id={rid}, tool_index={tool_i})\")\n",
    "\n",
    "        if desc_mode == \"raw_json\":\n",
    "            print(\"Current description RAW (escaped):\")\n",
    "            print(old_desc_print if old_desc_print else \"(empty)\")\n",
    "            base_desc = _decode_raw_json_string(old_desc_print) if old_desc_print else \"\"\n",
    "            print(\"\\nCurrent description DECODED:\")\n",
    "            print(base_desc if base_desc else \"(empty)\")\n",
    "        else:\n",
    "            base_desc = old_desc_print or \"\"\n",
    "            print(\"Current description:\")\n",
    "            print(base_desc if base_desc else \"(empty)\")\n",
    "\n",
    "        base_desc = (base_desc or \"\").strip()\n",
    "        base_len_chars = len(base_desc)\n",
    "\n",
    "        length_policy = _make_length_policy(\n",
    "            base_desc=base_desc,\n",
    "            mode_key=mode_key,\n",
    "            concise_ratio=float(concise_target_ratio),\n",
    "            concise_min_base_len=int(concise_target_min_base_len),\n",
    "            concise_min_chars=int(concise_target_min_chars),\n",
    "        )\n",
    "\n",
    "        _print_base_stats(base_desc, max_preview=int(max_token_preview), max_tok_len=int(max_token_string_len))\n",
    "        if mode_key == \"style_concise\":\n",
    "            ct = length_policy.get(\"concise_soft_target\", {}) if isinstance(length_policy.get(\"concise_soft_target\"), dict) else {}\n",
    "            if ct.get(\"applied\") and isinstance(ct.get(\"target_chars\"), int):\n",
    "                print(f\"Concise soft target (applied): target_chars={ct.get('target_chars')} (base_len={base_len_chars})\")\n",
    "            else:\n",
    "                print(f\"Concise soft target (not applied): reason={ct.get('reason')} (base_len={base_len_chars})\")\n",
    "\n",
    "        candidates: List[Dict[str, Any]] = []\n",
    "        last_generated_text: Optional[str] = None\n",
    "\n",
    "        while True:\n",
    "            if not candidates:\n",
    "                try:\n",
    "                    candidates, last_generated_text = generate_k_candidates_with_stats(\n",
    "                        client=client,\n",
    "                        tool_name=name,\n",
    "                        base_description=base_desc,\n",
    "                        model=llm_model,\n",
    "                        seed=seed,\n",
    "                        max_tokens=max_tokens,\n",
    "                        retry_on_length=retry_on_length,\n",
    "                        retry_max_tokens=retry_max_tokens,\n",
    "                        mode_key=mode_key,\n",
    "                        style_spec=style_spec,\n",
    "                        generation_round=generation_round,\n",
    "                        k=int(num_candidates),\n",
    "                        previous_rewrite_hint=previous_rewrite_hint,\n",
    "                        min_sleep_sec_between_calls=float(min_sleep_sec_between_calls),\n",
    "                        length_policy=length_policy,\n",
    "                        semantic_cfg=semantic_cfg_norm,\n",
    "                        show_perturbations=bool(show_perturbations),\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nLLM ERROR (candidate set generation): {e}\")\n",
    "                    raw = _read_command(\"Choice [m=manual, s=skip, q/Esc=quit] > \", k=int(num_candidates), raw_key_input=bool(raw_key_input))\n",
    "                    cmd = _normalize_cmd(raw)\n",
    "                    now = int(time.time())\n",
    "\n",
    "                    if cmd == \"q\":\n",
    "                        quit_requested = True\n",
    "                        resume_next_index_1based = idx\n",
    "                        break\n",
    "\n",
    "                    if cmd == \"s\":\n",
    "                        decisions_by_instance[instance_key] = (\"skipped\", None, None)\n",
    "                        _append_audit_event(\n",
    "                            audit_file,\n",
    "                            {\n",
    "                                \"event_type\": \"decision\",\n",
    "                                \"ts\": now,\n",
    "                                \"session_id\": session_id,\n",
    "                                \"status\": \"skipped\",\n",
    "                                \"tool_name\": name,\n",
    "                                \"instance_key\": instance_key,\n",
    "                                \"record_id\": rid,\n",
    "                                \"tool_index\": tool_i,\n",
    "                                \"model\": llm_model,\n",
    "                                \"seed\": seed,\n",
    "                                \"mode\": mode_key,\n",
    "                                \"base_description\": base_desc,\n",
    "                                \"final_description\": None,\n",
    "                                \"source\": \"user\",\n",
    "                                \"note\": \"skip_after_llm_error\",\n",
    "                                \"length_policy\": length_policy,\n",
    "                                \"semantic_cfg\": semantic_cfg_norm,\n",
    "                            },\n",
    "                        )\n",
    "                        session_summary[\"skipped\"] += 1\n",
    "                        break\n",
    "\n",
    "                    if cmd == \"m\":\n",
    "                        manual_final = input(\"Manual final description (empty cancels) > \").rstrip(\"\\n\").strip()\n",
    "                        status = \"manual\" if manual_final else \"skipped\"\n",
    "                        decisions_by_instance[instance_key] = (status, manual_final or None, None)\n",
    "                        diff_stats = compute_full_candidate_stats(\n",
    "                            base_text=base_desc,\n",
    "                            cand_text=manual_final,\n",
    "                            mode_key=mode_key,\n",
    "                            length_policy=length_policy,\n",
    "                            client=client,\n",
    "                            semantic_cfg=semantic_cfg_norm,\n",
    "                        ) if manual_final else None\n",
    "\n",
    "                        _append_audit_event(\n",
    "                            audit_file,\n",
    "                            {\n",
    "                                \"event_type\": \"decision\",\n",
    "                                \"ts\": now,\n",
    "                                \"session_id\": session_id,\n",
    "                                \"status\": status,\n",
    "                                \"tool_name\": name,\n",
    "                                \"instance_key\": instance_key,\n",
    "                                \"record_id\": rid,\n",
    "                                \"tool_index\": tool_i,\n",
    "                                \"model\": llm_model,\n",
    "                                \"seed\": seed,\n",
    "                                \"mode\": mode_key,\n",
    "                                \"base_description\": base_desc,\n",
    "                                \"final_description\": manual_final or None,\n",
    "                                \"source\": \"user\",\n",
    "                                \"note\": \"manual_after_llm_error\",\n",
    "                                \"diff_stats\": diff_stats,\n",
    "                                \"length_policy\": length_policy,\n",
    "                                \"semantic_cfg\": semantic_cfg_norm,\n",
    "                            },\n",
    "                        )\n",
    "                        if status == \"manual\":\n",
    "                            session_summary[\"manual\"] += 1\n",
    "                        else:\n",
    "                            session_summary[\"skipped\"] += 1\n",
    "                        break\n",
    "\n",
    "                    candidates = []\n",
    "                    continue\n",
    "\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"candidates_generated\",\n",
    "                        \"ts\": int(time.time()),\n",
    "                        \"session_id\": session_id,\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"mode\": mode_key,\n",
    "                        \"model\": llm_model,\n",
    "                        \"seed\": seed,\n",
    "                        \"generation_round\": int(generation_round),\n",
    "                        \"num_candidates_requested\": int(num_candidates),\n",
    "                        \"base_len_chars\": int(base_len_chars),\n",
    "                        \"length_policy\": length_policy,\n",
    "                        \"semantic_cfg\": semantic_cfg_norm,\n",
    "                        \"candidates_summary\": [\n",
    "                            {\n",
    "                                \"candidate_index\": c.get(\"candidate_index\"),\n",
    "                                \"text_sha256\": _sha256_text((c.get(\"text\") or \"\").strip()),\n",
    "                                \"text_len\": len((c.get(\"text\") or \"\").strip()),\n",
    "                                \"error\": c.get(\"error\"),\n",
    "                                \"duplicate\": bool(c.get(\"duplicate\", False)),\n",
    "                                \"risk_label\": ((c.get(\"stats\") or {}).get(\"risk_label\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"similarity_ratio\": ((c.get(\"stats\") or {}).get(\"similarity_ratio\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"len_ratio\": ((c.get(\"stats\") or {}).get(\"len_ratio\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"len_delta_chars\": ((c.get(\"stats\") or {}).get(\"len_delta_chars\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"new_structural_count\": ((c.get(\"stats\") or {}).get(\"new_structural_count\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"missing_structural_count\": ((c.get(\"stats\") or {}).get(\"missing_structural_count\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"new_logic_count\": ((c.get(\"stats\") or {}).get(\"new_logic_count\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"missing_logic_count\": ((c.get(\"stats\") or {}).get(\"missing_logic_count\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"concise_soft_target_applied\": ((c.get(\"stats\") or {}).get(\"concise_soft_target_applied\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"concise_soft_target_chars\": ((c.get(\"stats\") or {}).get(\"concise_soft_target_chars\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"within_soft_target\": ((c.get(\"stats\") or {}).get(\"within_soft_target\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"embedding_cosine\": (\n",
    "                                    (((c.get(\"stats\") or {}).get(\"semantic\") or {}).get(\"embedding\") or {}).get(\"cosine\")\n",
    "                                    if isinstance(c.get(\"stats\"), dict) else None\n",
    "                                ),\n",
    "                                \"verifier_label\": (\n",
    "                                    (((c.get(\"stats\") or {}).get(\"semantic\") or {}).get(\"verifier\") or {}).get(\"label\")\n",
    "                                    if isinstance(c.get(\"stats\"), dict) else None\n",
    "                                ),\n",
    "                            }\n",
    "                            for c in candidates\n",
    "                        ],\n",
    "                    },\n",
    "                )\n",
    "\n",
    "            print(\"\\nCandidates overview:\")\n",
    "            for c in candidates:\n",
    "                _print_candidate_summary_line(\n",
    "                    int(c.get(\"candidate_index\") or 0),\n",
    "                    c,\n",
    "                    max_preview=int(max_token_preview),\n",
    "                    max_tok_len=int(max_token_string_len),\n",
    "                    snippet_chars=int(candidate_snippet_chars),\n",
    "                )\n",
    "\n",
    "            raw = _read_command(\n",
    "                f\"\\nChoice [ENTER=accept #1, 1..{int(num_candidates)}=accept, r=regen, e=edit, m=manual, s=skip, q/Esc=quit, p<idx>=preview] > \",\n",
    "                k=int(num_candidates),\n",
    "                raw_key_input=bool(raw_key_input),\n",
    "            )\n",
    "            cmd = _normalize_cmd(raw)\n",
    "            now = int(time.time())\n",
    "\n",
    "            if cmd == \"q\":\n",
    "                quit_requested = True\n",
    "                resume_next_index_1based = idx\n",
    "                break\n",
    "\n",
    "            if cmd == \"s\":\n",
    "                decisions_by_instance[instance_key] = (\"skipped\", None, None)\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"decision\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"status\": \"skipped\",\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"model\": llm_model,\n",
    "                        \"seed\": seed,\n",
    "                        \"mode\": mode_key,\n",
    "                        \"base_description\": base_desc,\n",
    "                        \"final_description\": None,\n",
    "                        \"source\": \"user\",\n",
    "                        \"note\": \"skip\",\n",
    "                        \"length_policy\": length_policy,\n",
    "                        \"semantic_cfg\": semantic_cfg_norm,\n",
    "                    },\n",
    "                )\n",
    "                session_summary[\"skipped\"] += 1\n",
    "                break\n",
    "\n",
    "            if cmd == \"r\":\n",
    "                generation_round += 1\n",
    "                regen_counts[instance_key] = int(generation_round)\n",
    "\n",
    "                if last_generated_text and isinstance(last_generated_text, str) and last_generated_text.strip():\n",
    "                    hint = last_generated_text.strip()\n",
    "                    if len(hint) > max_prev:\n",
    "                        hint = hint[:max_prev].rstrip()\n",
    "                    previous_rewrite_hint = hint\n",
    "                    last_rejected_text_by_instance[instance_key] = hint\n",
    "\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"regenerate\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"mode\": mode_key,\n",
    "                        \"generation_round\": int(generation_round),\n",
    "                        \"last_generated_text\": previous_rewrite_hint,\n",
    "                        \"last_generated_text_sha256\": _sha256_text(previous_rewrite_hint or \"\"),\n",
    "                        \"length_policy\": length_policy,\n",
    "                        \"semantic_cfg\": semantic_cfg_norm,\n",
    "                    },\n",
    "                )\n",
    "\n",
    "                candidates = []\n",
    "                last_generated_text = None\n",
    "                if min_sleep_sec_between_calls > 0:\n",
    "                    time.sleep(float(min_sleep_sec_between_calls))\n",
    "                continue\n",
    "\n",
    "            if cmd == \"m\":\n",
    "                manual_final = input(\"Manual final description (empty cancels) > \").rstrip(\"\\n\").strip()\n",
    "                status = \"manual\" if manual_final else \"skipped\"\n",
    "                decisions_by_instance[instance_key] = (status, manual_final or None, None)\n",
    "\n",
    "                diff_stats = compute_full_candidate_stats(\n",
    "                    base_text=base_desc,\n",
    "                    cand_text=manual_final,\n",
    "                    mode_key=mode_key,\n",
    "                    length_policy=length_policy,\n",
    "                    client=client,\n",
    "                    semantic_cfg=semantic_cfg_norm,\n",
    "                ) if manual_final else None\n",
    "\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"decision\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"status\": status,\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"model\": llm_model,\n",
    "                        \"seed\": seed,\n",
    "                        \"mode\": mode_key,\n",
    "                        \"base_description\": base_desc,\n",
    "                        \"final_description\": manual_final or None,\n",
    "                        \"source\": \"user\",\n",
    "                        \"note\": \"manual_replace\",\n",
    "                        \"diff_stats\": diff_stats,\n",
    "                        \"length_policy\": length_policy,\n",
    "                        \"semantic_cfg\": semantic_cfg_norm,\n",
    "                    },\n",
    "                )\n",
    "                if status == \"manual\":\n",
    "                    session_summary[\"manual\"] += 1\n",
    "                else:\n",
    "                    session_summary[\"skipped\"] += 1\n",
    "                break\n",
    "\n",
    "            if cmd == \"e\":\n",
    "                raw_idx = input(f\"Candidate index to edit [1..{int(num_candidates)}] (empty=1) > \").strip()\n",
    "                chosen_i = 1\n",
    "                if raw_idx and raw_idx.isdigit():\n",
    "                    chosen_i = int(raw_idx)\n",
    "                if not (1 <= chosen_i <= int(num_candidates)):\n",
    "                    print(\"Invalid candidate index.\")\n",
    "                    continue\n",
    "\n",
    "                cand = candidates[chosen_i - 1] if (chosen_i - 1) < len(candidates) else None\n",
    "                base_text = (cand.get(\"text\") or \"\").strip() if isinstance(cand, dict) else \"\"\n",
    "                if base_text:\n",
    "                    print(\"\\nSelected candidate text:\")\n",
    "                    print(base_text)\n",
    "                else:\n",
    "                    print(\"\\nSelected candidate is empty; editing starts from empty string.\")\n",
    "                    base_text = \"\"\n",
    "\n",
    "                edited = input(\"Edit final description (empty cancels) > \").rstrip(\"\\n\").strip()\n",
    "                status = \"edited\" if edited else \"skipped\"\n",
    "                bundle = cand.get(\"bundle\") if isinstance(cand, dict) else None\n",
    "                stats = compute_full_candidate_stats(\n",
    "                    base_text=base_desc,\n",
    "                    cand_text=edited,\n",
    "                    mode_key=mode_key,\n",
    "                    length_policy=length_policy,\n",
    "                    client=client,\n",
    "                    semantic_cfg=semantic_cfg_norm,\n",
    "                ) if edited else None\n",
    "\n",
    "                decisions_by_instance[instance_key] = (status, edited or None, bundle if isinstance(bundle, dict) else None)\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"decision\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"status\": status,\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"model\": llm_model,\n",
    "                        \"seed\": seed,\n",
    "                        \"mode\": mode_key,\n",
    "                        \"base_description\": base_desc,\n",
    "                        \"final_description\": edited or None,\n",
    "                        \"source\": \"user\",\n",
    "                        \"note\": \"edit_candidate\",\n",
    "                        \"chosen_candidate_index\": int(chosen_i),\n",
    "                        \"llm_bundle\": bundle if isinstance(bundle, dict) else None,\n",
    "                        \"diff_stats\": stats,\n",
    "                        \"generation_round\": int(generation_round),\n",
    "                        \"length_policy\": length_policy,\n",
    "                        \"semantic_cfg\": semantic_cfg_norm,\n",
    "                    },\n",
    "                )\n",
    "                if status == \"edited\":\n",
    "                    session_summary[\"edited\"] += 1\n",
    "                else:\n",
    "                    session_summary[\"skipped\"] += 1\n",
    "                break\n",
    "\n",
    "            choice_i = 1 if cmd == \"y\" else _parse_candidate_choice(cmd, k=int(num_candidates))\n",
    "            if choice_i is not None:\n",
    "                if not (1 <= int(choice_i) <= int(num_candidates)):\n",
    "                    print(\"Invalid candidate index.\")\n",
    "                    continue\n",
    "                cand = candidates[int(choice_i) - 1] if (int(choice_i) - 1) < len(candidates) else None\n",
    "                if not isinstance(cand, dict):\n",
    "                    print(\"Candidate not available.\")\n",
    "                    continue\n",
    "                if cand.get(\"error\") or not (cand.get(\"text\") or \"\").strip():\n",
    "                    print(\"Selected candidate is not acceptable (empty or error).\")\n",
    "                    _print_candidate_full(int(choice_i), cand, max_preview=int(max_token_preview), max_tok_len=int(max_token_string_len))\n",
    "                    continue\n",
    "\n",
    "                final_desc = (cand.get(\"text\") or \"\").strip()\n",
    "                bundle = cand.get(\"bundle\") if isinstance(cand.get(\"bundle\"), dict) else None\n",
    "                stats = cand.get(\"stats\") if isinstance(cand.get(\"stats\"), dict) else compute_full_candidate_stats(\n",
    "                    base_text=base_desc,\n",
    "                    cand_text=final_desc,\n",
    "                    mode_key=mode_key,\n",
    "                    length_policy=length_policy,\n",
    "                    client=client,\n",
    "                    semantic_cfg=semantic_cfg_norm,\n",
    "                )\n",
    "\n",
    "                decisions_by_instance[instance_key] = (\"accepted\", final_desc, bundle)\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"decision\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"status\": \"accepted\",\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"model\": llm_model,\n",
    "                        \"seed\": seed,\n",
    "                        \"mode\": mode_key,\n",
    "                        \"base_description\": base_desc,\n",
    "                        \"final_description\": final_desc,\n",
    "                        \"source\": \"llm\",\n",
    "                        \"chosen_candidate_index\": int(choice_i),\n",
    "                        \"generation_round\": int(generation_round),\n",
    "                        \"llm_bundle\": bundle,\n",
    "                        \"diff_stats\": stats,\n",
    "                        \"length_policy\": length_policy,\n",
    "                        \"semantic_cfg\": semantic_cfg_norm,\n",
    "                    },\n",
    "                )\n",
    "\n",
    "                session_summary[\"accepted\"] += 1\n",
    "                rl = (stats.get(\"risk_label\") if isinstance(stats, dict) else None) or \"NA\"\n",
    "                if rl not in session_summary[\"accepted_risk_labels\"]:\n",
    "                    rl = \"NA\"\n",
    "                session_summary[\"accepted_risk_labels\"][rl] += 1\n",
    "\n",
    "                sim = stats.get(\"similarity_ratio\") if isinstance(stats, dict) else None\n",
    "                if isinstance(sim, (int, float)):\n",
    "                    session_summary[\"accepted_similarity_sum\"] += float(sim)\n",
    "                    session_summary[\"accepted_similarity_n\"] += 1\n",
    "\n",
    "                bl = stats.get(\"base_len_chars\") if isinstance(stats, dict) else None\n",
    "                cl = stats.get(\"cand_len_chars\") if isinstance(stats, dict) else None\n",
    "                lr = stats.get(\"len_ratio\") if isinstance(stats, dict) else None\n",
    "                ld = stats.get(\"len_delta_chars\") if isinstance(stats, dict) else None\n",
    "                if isinstance(bl, int) and isinstance(cl, int):\n",
    "                    session_summary[\"accepted_base_chars_sum\"] += int(bl)\n",
    "                    session_summary[\"accepted_cand_chars_sum\"] += int(cl)\n",
    "                if isinstance(lr, (int, float)):\n",
    "                    session_summary[\"accepted_len_ratio_sum\"] += float(lr)\n",
    "                    session_summary[\"accepted_len_ratio_n\"] += 1\n",
    "                if isinstance(ld, int):\n",
    "                    session_summary[\"accepted_len_delta_sum\"] += int(ld)\n",
    "\n",
    "                wst = stats.get(\"within_soft_target\") if isinstance(stats, dict) else None\n",
    "                st_applied = bool(stats.get(\"concise_soft_target_applied\", False)) if isinstance(stats, dict) else False\n",
    "                if st_applied:\n",
    "                    session_summary[\"accepted_soft_target_applicable_n\"] += 1\n",
    "                    if wst is True:\n",
    "                        session_summary[\"accepted_within_soft_target_n\"] += 1\n",
    "\n",
    "                sem = stats.get(\"semantic\") if isinstance(stats.get(\"semantic\"), dict) else None\n",
    "                if isinstance(sem, dict):\n",
    "                    emb = sem.get(\"embedding\") if isinstance(sem.get(\"embedding\"), dict) else None\n",
    "                    if isinstance(emb, dict) and isinstance(emb.get(\"cosine\"), (int, float)):\n",
    "                        session_summary[\"accepted_embedding_cos_sum\"] += float(emb.get(\"cosine\"))\n",
    "                        session_summary[\"accepted_embedding_cos_n\"] += 1\n",
    "                    ver = sem.get(\"verifier\") if isinstance(sem.get(\"verifier\"), dict) else None\n",
    "                    if isinstance(ver, dict) and isinstance(ver.get(\"label\"), str):\n",
    "                        lab = ver.get(\"label\")\n",
    "                        if lab == \"ENTAILS\":\n",
    "                            session_summary[\"accepted_entails\"] += 1\n",
    "                        elif lab == \"NOT_ENTAILS\":\n",
    "                            session_summary[\"accepted_not_entails\"] += 1\n",
    "                        else:\n",
    "                            session_summary[\"accepted_entails_unknown\"] += 1\n",
    "\n",
    "                break\n",
    "\n",
    "            if cmd.startswith(\"p\"):\n",
    "                raw_idx = cmd[1:].strip()\n",
    "                if raw_idx.isdigit():\n",
    "                    vi = int(raw_idx)\n",
    "                    if 1 <= vi <= int(num_candidates):\n",
    "                        _print_candidate_full(vi, candidates[vi - 1], max_preview=int(max_token_preview), max_tok_len=int(max_token_string_len))\n",
    "                        continue\n",
    "                print(\"Preview command format: p<index>, for example: p2\")\n",
    "                continue\n",
    "\n",
    "            print(\"Invalid command. Preview: p<index> (example: p2).\")\n",
    "\n",
    "        if quit_requested:\n",
    "            break\n",
    "\n",
    "    # ========= Apply decisions to file =========\n",
    "    tmp_path = path.with_suffix(path.suffix + \".tmp\")\n",
    "    updated_count = 0\n",
    "    patch_failures = 0\n",
    "\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as fin, tmp_path.open(\"w\", encoding=\"utf-8\") as fout:\n",
    "        for raw_line in fin:\n",
    "            line = raw_line.rstrip(\"\\n\")\n",
    "            if not line.strip():\n",
    "                fout.write(line + \"\\n\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                record = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                fout.write(line + \"\\n\")\n",
    "                continue\n",
    "\n",
    "            if not isinstance(record, dict):\n",
    "                fout.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "                continue\n",
    "\n",
    "            rid = _record_id(record, tool_field=tool_field)\n",
    "            tools = record.get(tool_field)\n",
    "\n",
    "            if isinstance(tools, list):\n",
    "                new_tools: List[Any] = []\n",
    "                for tool_index, entry in enumerate(tools):\n",
    "                    tool_obj, kind = _load_tool(entry)\n",
    "                    if not tool_obj:\n",
    "                        new_tools.append(entry)\n",
    "                        continue\n",
    "\n",
    "                    instance_key = _tool_instance_key(rid, tool_index, tool_obj)\n",
    "                    decision = decisions_by_instance.get(instance_key)\n",
    "\n",
    "                    if decision is None:\n",
    "                        new_tools.append(entry)\n",
    "                        continue\n",
    "\n",
    "                    status, new_desc, llm_bundle = decision\n",
    "                    if status in (\"accepted\", \"edited\", \"manual\") and new_desc:\n",
    "                        if kind == \"json_str\" and isinstance(entry, str):\n",
    "                            already_ok = False\n",
    "                            try:\n",
    "                                obj0 = json.loads(entry)\n",
    "                                if isinstance(obj0, dict) and obj0.get(\"description\") == new_desc:\n",
    "                                    already_ok = True\n",
    "                            except Exception:\n",
    "                                already_ok = False\n",
    "\n",
    "                            if already_ok:\n",
    "                                new_tools.append(entry)\n",
    "                                continue\n",
    "\n",
    "                            patched, ok, reason = _replace_top_level_string_field_in_raw_object(entry, \"description\", new_desc)\n",
    "                            if ok:\n",
    "                                new_tools.append(patched)\n",
    "                                updated_count += 1\n",
    "                            else:\n",
    "                                fallback_ok = False\n",
    "                                fallback_patched = entry\n",
    "                                if allow_reserialize_fallback:\n",
    "                                    try:\n",
    "                                        obj = json.loads(entry)\n",
    "                                        if isinstance(obj, dict):\n",
    "                                            obj[\"description\"] = new_desc\n",
    "                                            fallback_patched = json.dumps(obj, ensure_ascii=False)\n",
    "                                            fallback_ok = True\n",
    "                                    except Exception:\n",
    "                                        fallback_ok = False\n",
    "\n",
    "                                if fallback_ok:\n",
    "                                    new_tools.append(fallback_patched)\n",
    "                                    updated_count += 1\n",
    "                                    _append_audit_event(\n",
    "                                        audit_file,\n",
    "                                        {\n",
    "                                            \"event_type\": \"patch_fallback_reserialize\",\n",
    "                                            \"ts\": int(time.time()),\n",
    "                                            \"session_id\": session_id,\n",
    "                                            \"instance_key\": instance_key,\n",
    "                                            \"record_id\": rid,\n",
    "                                            \"tool_index\": tool_index,\n",
    "                                            \"tool_name\": tool_obj.get(\"name\"),\n",
    "                                            \"mode\": mode_key,\n",
    "                                            \"entry_sha256_before\": _sha256_text(entry),\n",
    "                                            \"entry_sha256_after\": _sha256_text(fallback_patched),\n",
    "                                            \"patch_reason\": reason,\n",
    "                                        },\n",
    "                                    )\n",
    "                                else:\n",
    "                                    new_tools.append(entry)\n",
    "                                    patch_failures += 1\n",
    "                        else:\n",
    "                            if tool_obj.get(\"description\") == new_desc:\n",
    "                                new_tools.append(tool_obj)\n",
    "                                continue\n",
    "                            tool_obj[\"description\"] = new_desc\n",
    "                            new_tools.append(tool_obj)\n",
    "                            updated_count += 1\n",
    "                    else:\n",
    "                        new_tools.append(entry)\n",
    "\n",
    "                record[tool_field] = new_tools\n",
    "\n",
    "            fout.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    if create_backup_of_target:\n",
    "        bak_path = path.with_suffix(path.suffix + \".bak\")\n",
    "        if not bak_path.exists():\n",
    "            shutil.copy2(path, bak_path)\n",
    "\n",
    "    tmp_path.replace(path)\n",
    "    after_sha = _sha256_file(path)\n",
    "\n",
    "    n_reviewed = len(decisions_by_instance)\n",
    "    n_skipped = sum(1 for st, _, _ in decisions_by_instance.values() if st == \"skipped\")\n",
    "    completed = (n_reviewed >= n_total) and (not quit_requested)\n",
    "\n",
    "    avg_sim = None\n",
    "    if int(session_summary[\"accepted_similarity_n\"]) > 0:\n",
    "        avg_sim = float(session_summary[\"accepted_similarity_sum\"]) / float(session_summary[\"accepted_similarity_n\"])\n",
    "\n",
    "    avg_len_ratio = None\n",
    "    if int(session_summary[\"accepted_len_ratio_n\"]) > 0:\n",
    "        avg_len_ratio = float(session_summary[\"accepted_len_ratio_sum\"]) / float(session_summary[\"accepted_len_ratio_n\"])\n",
    "\n",
    "    avg_len_delta = None\n",
    "    if int(session_summary[\"accepted\"]) > 0:\n",
    "        avg_len_delta = float(session_summary[\"accepted_len_delta_sum\"]) / float(session_summary[\"accepted\"])\n",
    "\n",
    "    avg_base_len = None\n",
    "    avg_cand_len = None\n",
    "    if int(session_summary[\"accepted\"]) > 0:\n",
    "        avg_base_len = float(session_summary[\"accepted_base_chars_sum\"]) / float(session_summary[\"accepted\"])\n",
    "        avg_cand_len = float(session_summary[\"accepted_cand_chars_sum\"]) / float(session_summary[\"accepted\"])\n",
    "\n",
    "    avg_emb_cos = None\n",
    "    if int(session_summary[\"accepted_embedding_cos_n\"]) > 0:\n",
    "        avg_emb_cos = float(session_summary[\"accepted_embedding_cos_sum\"]) / float(session_summary[\"accepted_embedding_cos_n\"])\n",
    "\n",
    "    _append_audit_event(\n",
    "        audit_file,\n",
    "        {\n",
    "            \"event_type\": \"run_end\",\n",
    "            \"ts\": int(time.time()),\n",
    "            \"session_id\": session_id,\n",
    "            \"mode\": mode_key,\n",
    "            \"model\": llm_model,\n",
    "            \"seed\": seed,\n",
    "            \"dataset_path\": str(path),\n",
    "            \"dataset_sha256_at_session_start\": before_sha,\n",
    "            \"dataset_sha256_at_session_end\": after_sha,\n",
    "            \"n_total_occurrences\": n_total,\n",
    "            \"n_reviewed_total\": n_reviewed,\n",
    "            \"n_updated_this_session\": updated_count,\n",
    "            \"n_skipped_total\": n_skipped,\n",
    "            \"completed\": bool(completed),\n",
    "            \"quit_requested\": bool(quit_requested),\n",
    "            \"raw_patch_failures_this_session\": patch_failures,\n",
    "            \"resume_next_index_1based\": resume_next_index_1based if quit_requested else (n_total + 1 if completed else None),\n",
    "            \"session_summary\": {\n",
    "                \"accepted\": int(session_summary[\"accepted\"]),\n",
    "                \"edited\": int(session_summary[\"edited\"]),\n",
    "                \"manual\": int(session_summary[\"manual\"]),\n",
    "                \"skipped\": int(session_summary[\"skipped\"]),\n",
    "                \"accepted_risk_labels\": session_summary[\"accepted_risk_labels\"],\n",
    "                \"accepted_avg_similarity\": avg_sim,\n",
    "                \"accepted_similarity_n\": int(session_summary[\"accepted_similarity_n\"]),\n",
    "                \"accepted_avg_len_ratio\": avg_len_ratio,\n",
    "                \"accepted_len_ratio_n\": int(session_summary[\"accepted_len_ratio_n\"]),\n",
    "                \"accepted_avg_len_delta_chars\": avg_len_delta,\n",
    "                \"accepted_avg_base_len_chars\": avg_base_len,\n",
    "                \"accepted_avg_cand_len_chars\": avg_cand_len,\n",
    "                \"accepted_soft_target_applicable_n\": int(session_summary[\"accepted_soft_target_applicable_n\"]),\n",
    "                \"accepted_within_soft_target_n\": int(session_summary[\"accepted_within_soft_target_n\"]),\n",
    "                \"accepted_avg_embedding_cosine\": avg_emb_cos,\n",
    "                \"accepted_embedding_cosine_n\": int(session_summary[\"accepted_embedding_cos_n\"]),\n",
    "                \"accepted_entails\": int(session_summary[\"accepted_entails\"]),\n",
    "                \"accepted_not_entails\": int(session_summary[\"accepted_not_entails\"]),\n",
    "                \"accepted_entails_unknown\": int(session_summary[\"accepted_entails_unknown\"]),\n",
    "            },\n",
    "            \"length_policy_config\": length_policy_config,\n",
    "            \"policy_versions\": {\n",
    "                \"risk_policy_name\": RISK_POLICY_NAME,\n",
    "                \"logic_token_policy_name\": LOGIC_TOKEN_POLICY_NAME,\n",
    "                \"semantic_policy_name\": SEMANTIC_POLICY_NAME,\n",
    "            },\n",
    "            \"semantic_cfg\": semantic_cfg_norm,\n",
    "            \"show_perturbations\": bool(show_perturbations),\n",
    "            \"raw_key_input\": bool(raw_key_input),\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(\"\\nChanges applied.\")\n",
    "    print(f\"Mode: {mode_key}\")\n",
    "    print(f\"Candidates per tool: {int(num_candidates)}\")\n",
    "    print(f\"Candidate snippet chars: {int(candidate_snippet_chars)}\")\n",
    "    print(f\"Perturbation prints: {'enabled' if show_perturbations else 'disabled'}\")\n",
    "    print(f\"Raw key input (Esc-safe): {'enabled' if raw_key_input else 'disabled'}\")\n",
    "    print(f\"Descriptions updated (this session): {updated_count}\")\n",
    "    if patch_failures:\n",
    "        print(f\"Raw JSON-string patch failures (left unchanged): {patch_failures}\")\n",
    "    print(f\"Reviewed total (from audit): {n_reviewed} / {n_total}\")\n",
    "    print(f\"Completed: {completed} (quit_requested={quit_requested})\")\n",
    "    if quit_requested and resume_next_index_1based is not None:\n",
    "        print(f\"Resume next time from: [{resume_next_index_1based}/{n_total}]\")\n",
    "    print(f\"Updated file: {path}\")\n",
    "    print(f\"Audit file (same on resume): {audit_file}\")\n",
    "\n",
    "    print(\"\\nSession summary (heuristic):\")\n",
    "    print(\n",
    "        f\"  accepted={int(session_summary['accepted'])}, edited={int(session_summary['edited'])}, \"\n",
    "        f\"manual={int(session_summary['manual'])}, skipped={int(session_summary['skipped'])}\"\n",
    "    )\n",
    "    print(f\"  accepted_risk_labels={session_summary['accepted_risk_labels']}\")\n",
    "    if avg_sim is not None:\n",
    "        print(f\"  accepted_avg_similarity={avg_sim:.2f} (n={int(session_summary['accepted_similarity_n'])})\")\n",
    "    if avg_len_ratio is not None:\n",
    "        print(f\"  accepted_avg_len_ratio={avg_len_ratio:.2f} (n={int(session_summary['accepted_len_ratio_n'])})\")\n",
    "    if avg_len_delta is not None:\n",
    "        print(f\"  accepted_avg_len_delta_chars={avg_len_delta:+.1f}\")\n",
    "    if avg_base_len is not None and avg_cand_len is not None:\n",
    "        print(f\"  accepted_avg_base_len_chars={avg_base_len:.1f}; accepted_avg_cand_len_chars={avg_cand_len:.1f}\")\n",
    "    if avg_emb_cos is not None:\n",
    "        print(f\"  accepted_avg_embedding_cosine={avg_emb_cos:.2f} (n={int(session_summary['accepted_embedding_cosine_n'])})\")\n",
    "    if semantic_cfg_norm.get(\"enable_verifier\"):\n",
    "        print(\n",
    "            \"  accepted_verifier_counts: \"\n",
    "            f\"ENTAILS={int(session_summary['accepted_entails'])}, \"\n",
    "            f\"NOT_ENTAILS={int(session_summary['accepted_not_entails'])}, \"\n",
    "            f\"UNKNOWN={int(session_summary['accepted_entails_unknown'])}\"\n",
    "        )\n",
    "    if mode_key == \"style_concise\":\n",
    "        print(\n",
    "            \"  accepted_soft_target: \"\n",
    "            f\"applicable={int(session_summary['accepted_soft_target_applicable_n'])}, \"\n",
    "            f\"within={int(session_summary['accepted_within_soft_target_n'])}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def _derive_working_copy_path(input_path: str, mode_key: str) -> str:\n",
    "    p = Path(input_path)\n",
    "    return str(p.with_name(f\"{p.stem}.WORKING_COPY.{mode_key}{p.suffix}\"))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ----- Inputs -----\n",
    "    INPUT_JSONL = os.environ.get(\"INPUT_JSONL\") or \"When2Call/data/test/when2call_test_llm_judge.jsonl\"\n",
    "    MODE_KEY = os.environ.get(\"MODE_KEY\") or \"style_concise\"\n",
    "    LLM_MODEL = os.environ.get(\"LLM_MODEL\") or LLM_MODEL_DEFAULT\n",
    "\n",
    "    mode_key_resolved, _ = _resolve_style(MODE_KEY)\n",
    "\n",
    "    OUTPUT_JSONL = os.environ.get(\"OUTPUT_JSONL\") or _derive_working_copy_path(INPUT_JSONL, mode_key_resolved)\n",
    "\n",
    "    working = make_working_copy(INPUT_JSONL, OUTPUT_JSONL, overwrite=False)\n",
    "    print(f\"Working copy: {working}\")\n",
    "\n",
    "    # ----- Runtime knobs -----\n",
    "    seed_env = os.environ.get(\"GEMINI_SEED\")\n",
    "    seed_val: Optional[int] = int(seed_env.strip()) if (seed_env and seed_env.strip()) else None\n",
    "\n",
    "    max_tokens_env = os.environ.get(\"GEMINI_MAX_TOKENS\")\n",
    "    max_tokens_val = int(max_tokens_env.strip()) if (max_tokens_env and max_tokens_env.strip()) else DEFAULT_MAX_TOKENS\n",
    "\n",
    "    retry_max_tokens_env = os.environ.get(\"GEMINI_RETRY_MAX_TOKENS\")\n",
    "    retry_max_tokens_val = int(retry_max_tokens_env.strip()) if (retry_max_tokens_env and retry_max_tokens_env.strip()) else RETRY_MAX_TOKENS\n",
    "\n",
    "    allow_reserialize_env = os.environ.get(\"ALLOW_RESERIALIZE_FALLBACK\")\n",
    "    allow_reserialize_val = (\n",
    "        bool(int(allow_reserialize_env.strip()))\n",
    "        if (allow_reserialize_env and allow_reserialize_env.strip())\n",
    "        else DEFAULT_ALLOW_RESERIALIZE_FALLBACK\n",
    "    )\n",
    "\n",
    "    num_candidates_val = _safe_int_env(\"NUM_CANDIDATES\", DEFAULT_NUM_CANDIDATES)\n",
    "    min_sleep_val = _safe_float_env(\"MIN_SLEEP_SEC_BETWEEN_CALLS\", 0.0)\n",
    "\n",
    "    max_preview_val = _safe_int_env(\"STATS_MAX_TOKEN_PREVIEW\", DEFAULT_MAX_TOKEN_PREVIEW)\n",
    "    max_tok_len_val = _safe_int_env(\"STATS_MAX_TOKEN_STRING_LEN\", DEFAULT_MAX_TOKEN_STRING_LEN)\n",
    "\n",
    "    cand_snippet_val = _safe_int_env(\"CANDIDATE_SNIPPET_CHARS\", DEFAULT_CANDIDATE_SNIPPET_CHARS)\n",
    "\n",
    "    concise_ratio_val = _safe_float_env(\"CONCISE_TARGET_RATIO\", DEFAULT_CONCISE_TARGET_RATIO)\n",
    "    concise_min_base_len_val = _safe_int_env(\"CONCISE_TARGET_MIN_BASE_LEN\", DEFAULT_CONCISE_TARGET_MIN_BASE_LEN)\n",
    "    concise_min_chars_val = _safe_int_env(\"CONCISE_TARGET_MIN_CHARS\", DEFAULT_CONCISE_TARGET_MIN_CHARS)\n",
    "\n",
    "    enable_embeddings_val = _safe_bool_env(\"ENABLE_EMBEDDINGS\", DEFAULT_ENABLE_EMBEDDINGS)\n",
    "    embedding_model_val = os.environ.get(\"EMBEDDING_MODEL\") or DEFAULT_EMBEDDING_MODEL\n",
    "    emb_low_thr_val = _safe_float_env(\"EMBEDDING_LOW_COSINE_THRESHOLD\", DEFAULT_EMBEDDING_LOW_COSINE_THRESHOLD)\n",
    "\n",
    "    enable_verifier_val = _safe_bool_env(\"ENABLE_VERIFIER\", DEFAULT_ENABLE_VERIFIER)\n",
    "    verifier_model_val = os.environ.get(\"VERIFIER_MODEL\") or DEFAULT_VERIFIER_MODEL\n",
    "    verifier_max_tokens_val = _safe_int_env(\"VERIFIER_MAX_TOKENS\", DEFAULT_VERIFIER_MAX_TOKENS)\n",
    "\n",
    "    semantic_cfg_val: Dict[str, Any] = {\n",
    "        \"enable_embeddings\": bool(enable_embeddings_val and bool(str(embedding_model_val).strip())),\n",
    "        \"embedding_model\": str(embedding_model_val).strip(),\n",
    "        \"embedding_low_cosine_threshold\": float(emb_low_thr_val),\n",
    "        \"enable_verifier\": bool(enable_verifier_val),\n",
    "        \"verifier_model\": str(verifier_model_val).strip(),\n",
    "        \"verifier_max_tokens\": int(verifier_max_tokens_val),\n",
    "    }\n",
    "\n",
    "    # Feb 3 knobs\n",
    "    show_perturbations_val = _safe_bool_env(\"SHOW_PERTURBATIONS\", DEFAULT_SHOW_PERTURBATIONS)\n",
    "    raw_key_input_val = _safe_bool_env(\"RAW_KEY_INPUT\", DEFAULT_RAW_KEY_INPUT)\n",
    "\n",
    "    interactive_llm_tools_in_jsonl(\n",
    "        working,\n",
    "        tool_field=\"tools\",\n",
    "        create_backup_of_target=False,\n",
    "        llm_model=LLM_MODEL,\n",
    "        seed=seed_val,\n",
    "        max_tokens=max_tokens_val,\n",
    "        retry_on_length=RETRY_ON_LENGTH,\n",
    "        retry_max_tokens=retry_max_tokens_val,\n",
    "        allow_reserialize_fallback=allow_reserialize_val,\n",
    "        min_sleep_sec_between_calls=float(min_sleep_val),\n",
    "        audit_dir=os.environ.get(\"AUDIT_DIR\") or \"audit\",\n",
    "        mode_key=mode_key_resolved,\n",
    "        num_candidates=int(num_candidates_val),\n",
    "        max_token_preview=int(max_preview_val),\n",
    "        max_token_string_len=int(max_tok_len_val),\n",
    "        candidate_snippet_chars=int(cand_snippet_val),\n",
    "        concise_target_ratio=float(concise_ratio_val),\n",
    "        concise_target_min_base_len=int(concise_min_base_len_val),\n",
    "        concise_target_min_chars=int(concise_min_chars_val),\n",
    "        semantic_cfg=semantic_cfg_val,\n",
    "        show_perturbations=bool(show_perturbations_val),\n",
    "        raw_key_input=bool(raw_key_input_val),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b48619ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working copy: When2Call/data/test/when2call_test_llm_judge.WORKING_COPY.style_concise.jsonl\n",
      "Target: When2Call/data/test/when2call_test_llm_judge.WORKING_COPY.style_concise.jsonl\n",
      "Mode: style_concise\n",
      "Audit file (RESUMABLE): audit/55b59d7780f3/when2call_test_llm_judge.WORKING_COPY.style_concise.55b59d7780f3.style_concise.gemini-2.5-flash.K2.audit.jsonl\n",
      "Tool occurrences total: 978\n",
      "Resume position: [4/978] (previously reviewed: 3)\n",
      "LLM: gemini-2.5-flash @ https://generativelanguage.googleapis.com/v1beta/openai/\n",
      "Candidates per tool: 2\n",
      "Candidate snippet chars: 160\n",
      "Concise soft target: ratio=0.70, min_base_len=160, min_chars=80\n",
      "Max tokens: 512; retry_on_length=True; retry_max_tokens=1024\n",
      "Commands: ENTER/ok=accept #1, 1..K=accept candidate, r=regenerate K, e=edit candidate, m=manual, s=skip, q=quit, p<idx>=preview (e.g., p2)\n",
      "\n",
      "================================================================================\n",
      "[4/978] Buses_3_BuyBusTicket\n",
      "instance_key: rec:64cbc7e8819e45258b49e186164c9fad:t1:9a77a4750b12a8be645d3b59a745bc6f (record_id=64cbc7e8819e45258b49e186164c9fad, tool_index=1)\n",
      "Current description RAW (escaped):\n",
      "\"Purchase bus tickets by specifying the route, date, and time, with configurable options for passenger count and luggage\"\n",
      "\n",
      "Current description DECODED:\n",
      "Purchase bus tickets by specifying the route, date, and time, with configurable options for passenger count and luggage\n",
      "\n",
      "Statistics (base):\n",
      "  chars=119; words=18; sentences=1\n",
      "  tokens: flags=0, field_like=0, numbers=0, number_units=0, verbs=0, snake=0, camel=0\n",
      "  previews: flags=[-]; field_like=[-]; numbers=[-]; verbs=[-]\n",
      "Concise soft target (not applied): reason=base_too_short (base_len=119)\n",
      "\n",
      "Candidates overview:\n",
      "  [1] status=ok; risk=LOW; sim=0.82; cand(chars=107, words=18, sent=1); len_ratio=0.90; Δchars=-12; -; new(flags=0, fields=0, nums=0, verbs=0); missing_total=0\n",
      "      text: Buy bus tickets by providing the route, date, and time, and setting options for passenger count and luggage\n",
      "  [2] status=ok; risk=LOW; sim=0.81; cand(chars=106, words=16, sent=1); len_ratio=0.89; Δchars=-13; -; new(flags=0, fields=0, nums=0, verbs=0); missing_total=0\n",
      "      text: Purchase bus tickets using the route, date, and time, with adjustable passenger count and luggage options.\n",
      "================================================================================\n",
      "[5/978] Events_3_BuyEventTickets\n",
      "instance_key: rec:64cbc7e8819e45258b49e186164c9fad:t2:f7ea47f45d40a99ab97120828159bb35 (record_id=64cbc7e8819e45258b49e186164c9fad, tool_index=2)\n",
      "Current description RAW (escaped):\n",
      "\"Facilitates the purchase of tickets for a cultural event on a specific date in a designated city.\"\n",
      "\n",
      "Current description DECODED:\n",
      "Facilitates the purchase of tickets for a cultural event on a specific date in a designated city.\n",
      "\n",
      "Statistics (base):\n",
      "  chars=97; words=17; sentences=1\n",
      "  tokens: flags=0, field_like=0, numbers=0, number_units=0, verbs=0, snake=0, camel=0\n",
      "  previews: flags=[-]; field_like=[-]; numbers=[-]; verbs=[-]\n",
      "Concise soft target (not applied): reason=base_too_short (base_len=97)\n",
      "\n",
      "Candidates overview:\n",
      "  [1] status=ok; risk=LOW; sim=0.88; cand(chars=79, words=14, sent=1); len_ratio=0.81; Δchars=-18; -; new(flags=0, fields=0, nums=0, verbs=0); missing_total=0\n",
      "      text: Purchases tickets for a cultural event on a specific date in a designated city.\n",
      "  [2] status=ok; risk=LOW; sim=0.84; cand(chars=84, words=15, sent=1); len_ratio=0.87; Δchars=-13; -; new(flags=0, fields=0, nums=0, verbs=0); missing_total=0\n",
      "      text: Enables buying tickets for a cultural event on a specific date in a designated city.\n",
      "================================================================================\n",
      "[6/978] detail_adriel_project\n",
      "instance_key: rec:b1fc67ad28853bc7cf426157105c4f7a:t0:15bf463dbfec2440ef5beedaedb315ae (record_id=b1fc67ad28853bc7cf426157105c4f7a, tool_index=0)\n",
      "Current description RAW (escaped):\n",
      "\"Retrieve the detailed information of the project that Adriel was working on, including the project's current status and expected completion date.\"\n",
      "\n",
      "Current description DECODED:\n",
      "Retrieve the detailed information of the project that Adriel was working on, including the project's current status and expected completion date.\n",
      "\n",
      "Statistics (base):\n",
      "  chars=145; words=21; sentences=1\n",
      "  tokens: flags=0, field_like=0, numbers=0, number_units=0, verbs=1, snake=0, camel=0\n",
      "  previews: flags=[-]; field_like=[-]; numbers=[-]; verbs=[retrieve]\n",
      "Concise soft target (not applied): reason=base_too_short (base_len=145)\n",
      "\n",
      "Candidates overview:\n",
      "  [1] status=ok; risk=LOW; sim=0.78; cand(chars=110, words=14, sent=1); len_ratio=0.76; Δchars=-35; -; new(flags=0, fields=0, nums=0, verbs=0); missing_total=0\n",
      "      text: Retrieve detailed information for Adriel's project, including its current status and expected completion date.\n",
      "  [2] status=ok; risk=LOW; sim=0.68; cand(chars=114, words=14, sent=1); len_ratio=0.79; Δchars=-31; -; new(flags=0, fields=0, nums=0, verbs=0); missing_total=0\n",
      "      text: Retrieve comprehensive details for Adriel's project, encompassing its current status and expected completion date.\n",
      "================================================================================\n",
      "[7/978] adriel_detail_experience_and_education\n",
      "instance_key: rec:b1fc67ad28853bc7cf426157105c4f7a:t1:552e6914f4d8602e073623549ab163e5 (record_id=b1fc67ad28853bc7cf426157105c4f7a, tool_index=1)\n",
      "Current description RAW (escaped):\n",
      "\"Retrieve the detailed information regarding Adriel's professional experiences and educational background.\"\n",
      "\n",
      "Current description DECODED:\n",
      "Retrieve the detailed information regarding Adriel's professional experiences and educational background.\n",
      "\n",
      "Statistics (base):\n",
      "  chars=105; words=11; sentences=1\n",
      "  tokens: flags=0, field_like=0, numbers=0, number_units=0, verbs=1, snake=0, camel=0\n",
      "  previews: flags=[-]; field_like=[-]; numbers=[-]; verbs=[retrieve]\n",
      "Concise soft target (not applied): reason=base_too_short (base_len=105)\n",
      "\n",
      "Candidates overview:\n",
      "  [1] status=ok; risk=LOW; sim=0.78; cand(chars=79, words=8, sent=1); len_ratio=0.75; Δchars=-26; -; new(flags=0, fields=0, nums=0, verbs=0); missing_total=0\n",
      "      text: Retrieve Adriel's detailed professional experiences and educational background.\n",
      "  [2] status=ok; risk=HIGH; sim=0.73; cand(chars=77, words=8, sent=1); len_ratio=0.73; Δchars=-28; -; new(flags=0, fields=0, nums=0, verbs=1); missing_total=1\n",
      "      new-previews: flags=[-]; fields=[-]; numbers=[-]; verbs=[access]\n",
      "      text: Access Adriel's detailed professional experiences and educational background.\n",
      "================================================================================\n",
      "[8/978] adriel_experiences_and_education\n",
      "instance_key: rec:b1fc67ad28853bc7cf426157105c4f7a:t2:0dd47bcb8139b03279c071251c44b942 (record_id=b1fc67ad28853bc7cf426157105c4f7a, tool_index=2)\n",
      "Current description RAW (escaped):\n",
      "\"Retrieve a comprehensive list detailing Adriel's professional experiences and educational background.\"\n",
      "\n",
      "Current description DECODED:\n",
      "Retrieve a comprehensive list detailing Adriel's professional experiences and educational background.\n",
      "\n",
      "Statistics (base):\n",
      "  chars=101; words=11; sentences=1\n",
      "  tokens: flags=0, field_like=0, numbers=0, number_units=0, verbs=1, snake=0, camel=0\n",
      "  previews: flags=[-]; field_like=[-]; numbers=[-]; verbs=[retrieve]\n",
      "Concise soft target (not applied): reason=base_too_short (base_len=101)\n",
      "\n",
      "Candidates overview:\n",
      "  [1] status=ok; risk=LOW; sim=0.82; cand(chars=70, words=7, sent=1); len_ratio=0.69; Δchars=-31; -; new(flags=0, fields=0, nums=0, verbs=0); missing_total=0\n",
      "      text: Retrieve Adriel's professional experiences and educational background.\n",
      "  [2] status=ok; risk=HIGH; sim=0.77; cand(chars=68, words=7, sent=1); len_ratio=0.67; Δchars=-33; -; new(flags=0, fields=0, nums=0, verbs=1); missing_total=1\n",
      "      new-previews: flags=[-]; fields=[-]; numbers=[-]; verbs=[access]\n",
      "      text: Access Adriel's professional experiences and educational background.\n",
      "================================================================================\n",
      "[9/978] adriel_contact\n",
      "instance_key: rec:b1fc67ad28853bc7cf426157105c4f7a:t3:f1ff10bdd965a36c7f60d8772eb62927 (record_id=b1fc67ad28853bc7cf426157105c4f7a, tool_index=3)\n",
      "Current description RAW (escaped):\n",
      "\"Retrieve the contact information for Adriel, including name, email, and phone number. If no contact_id is provided, the function returns the default contact information.\"\n",
      "\n",
      "Current description DECODED:\n",
      "Retrieve the contact information for Adriel, including name, email, and phone number. If no contact_id is provided, the function returns the default contact information.\n",
      "\n",
      "Statistics (base):\n",
      "  chars=169; words=24; sentences=2\n",
      "  tokens: flags=0, field_like=0, numbers=0, number_units=0, verbs=2, snake=1, camel=0\n",
      "  previews: flags=[-]; field_like=[-]; numbers=[-]; verbs=[email, retrieve]\n",
      "Concise soft target (applied): target_chars=118 (base_len=169)\n",
      "\n",
      "Candidates overview:\n",
      "  [1] status=ok; risk=MED; sim=0.60; cand(chars=115, words=15, sent=1); len_ratio=0.68; Δchars=-54; target<=118 ok; new(flags=0, fields=0, nums=0, verbs=0); missing_total=1\n",
      "      text: Retrieves Adriel's contact information (name, email, phone number); returns default if no `contact_id` is provided.\n",
      "  [2] status=ok; risk=MED; sim=0.62; cand(chars=142, words=19, sent=1); len_ratio=0.84; Δchars=-27; target<=118 NO; new(flags=0, fields=0, nums=0, verbs=0); missing_total=1\n",
      "      text: Retrieves Adriel's contact information, including name, email, and phone number; default details are provided if no `contact_id` is specified.\n",
      "================================================================================\n",
      "[10/978] adriel_tech_stack\n",
      "instance_key: rec:b1fc67ad28853bc7cf426157105c4f7a:t4:74420c3c80d9e0b7f9f29a9b64d09bcb (record_id=b1fc67ad28853bc7cf426157105c4f7a, tool_index=4)\n",
      "Current description RAW (escaped):\n",
      "\"Retrieves the list of technologies that Adriel is currently working with, including programming languages, frameworks, and tools.\"\n",
      "\n",
      "Current description DECODED:\n",
      "Retrieves the list of technologies that Adriel is currently working with, including programming languages, frameworks, and tools.\n",
      "\n",
      "Statistics (base):\n",
      "  chars=129; words=17; sentences=1\n",
      "  tokens: flags=0, field_like=0, numbers=0, number_units=0, verbs=0, snake=0, camel=0\n",
      "  previews: flags=[-]; field_like=[-]; numbers=[-]; verbs=[-]\n",
      "Concise soft target (not applied): reason=base_too_short (base_len=129)\n",
      "\n",
      "Candidates overview:\n",
      "  [1] status=ok; risk=LOW; sim=0.72; cand(chars=96, words=10, sent=1); len_ratio=0.74; Δchars=-33; -; new(flags=0, fields=0, nums=0, verbs=0); missing_total=0\n",
      "      text: Retrieves Adriel's current technologies, including programming languages, frameworks, and tools.\n",
      "  [2] status=ok; risk=LOW; sim=0.78; cand(chars=99, words=12, sent=1); len_ratio=0.77; Δchars=-30; -; new(flags=0, fields=0, nums=0, verbs=0); missing_total=0\n",
      "      text: Retrieves technologies Adriel currently uses, such as programming languages, frameworks, and tools.\n",
      "================================================================================\n",
      "[11/978] help\n",
      "instance_key: rec:b1fc67ad28853bc7cf426157105c4f7a:t5:f88f85e0f514695fbe7d0bffeaa85c99 (record_id=b1fc67ad28853bc7cf426157105c4f7a, tool_index=5)\n",
      "Current description RAW (escaped):\n",
      "\"Provides a list of available commands and their descriptions for a given context within the application.\"\n",
      "\n",
      "Current description DECODED:\n",
      "Provides a list of available commands and their descriptions for a given context within the application.\n",
      "\n",
      "Statistics (base):\n",
      "  chars=104; words=16; sentences=1\n",
      "  tokens: flags=0, field_like=0, numbers=0, number_units=0, verbs=0, snake=0, camel=0\n",
      "  previews: flags=[-]; field_like=[-]; numbers=[-]; verbs=[-]\n",
      "Concise soft target (not applied): reason=base_too_short (base_len=104)\n",
      "\n",
      "Candidates overview:\n",
      "  [1] status=ok; risk=LOW; sim=0.76; cand(chars=80, words=11, sent=1); len_ratio=0.77; Δchars=-24; -; new(flags=0, fields=0, nums=0, verbs=0); missing_total=0\n",
      "      text: Lists available commands and their descriptions for a given application context.\n",
      "  [2] status=ok; risk=LOW; sim=0.92; cand(chars=94, words=13, sent=1); len_ratio=0.90; Δchars=-10; -; new(flags=0, fields=0, nums=0, verbs=0); missing_total=0\n",
      "      text: Presents available commands and their descriptions for a given context within the application.\n",
      "\n",
      "Changes applied.\n",
      "Mode: style_concise\n",
      "Candidates per tool: 2\n",
      "Candidate snippet chars: 160\n",
      "Descriptions updated (this session): 7\n",
      "Reviewed total (from audit): 10 / 978\n",
      "Completed: False (quit_requested=True)\n",
      "Resume next time from: [11/978]\n",
      "Updated file: When2Call/data/test/when2call_test_llm_judge.WORKING_COPY.style_concise.jsonl\n",
      "Audit file (same on resume): audit/55b59d7780f3/when2call_test_llm_judge.WORKING_COPY.style_concise.55b59d7780f3.style_concise.gemini-2.5-flash.K2.audit.jsonl\n",
      "\n",
      "Session summary (heuristic):\n",
      "  accepted=7, edited=0, manual=0, skipped=0\n",
      "  accepted_risk_labels={'LOW': 5, 'MED': 1, 'HIGH': 1, 'NA': 0}\n",
      "  accepted_avg_similarity=0.75 (n=7)\n",
      "  accepted_avg_len_ratio=0.76 (n=7)\n",
      "  accepted_avg_len_delta_chars=-29.6\n",
      "  accepted_avg_base_len_chars=123.6; accepted_avg_cand_len_chars=94.0\n",
      "  accepted_soft_target: applicable=1, within=1\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# December 28\n",
    "#\n",
    "# Interactive, resumable tool-description rewrite workflow with:\n",
    "# - K-candidate generation per tool instance (configurable)\n",
    "# - Deterministic statistical/lexical risk indicators printed alongside base and candidates\n",
    "# - Human-in-the-loop decision (accept candidate, edit, manual, skip), with append-only audit log\n",
    "#\n",
    "# Additions (Jan 21 test):\n",
    "# - Candidate text snippet shown in the overview, so the reviewer can choose without extra commands.\n",
    "# - Explicit preview command documented: p<idx> (e.g., p2) prints the full candidate + stats.\n",
    "#\n",
    "# Additions (Concise soft length target, reviewer-proof):\n",
    "# - Optional soft length target for style_concise: default 30% shorter, applied only if base_len >= threshold.\n",
    "# - The target is guidance only (exceptions allowed to preserve meaning); out-of-target is flagged and logged.\n",
    "# - Length metrics (len_ratio, len_delta) are computed for every candidate and stored in audit for reporting.\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "import difflib\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional, Tuple, List\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# ========= Config =========\n",
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "LLM_MODEL_DEFAULT = \"gemini-2.5-flash\"\n",
    "\n",
    "HASH_HEX_LEN = 32\n",
    "\n",
    "DEFAULT_MAX_TOKENS = 512\n",
    "RETRY_ON_LENGTH = True\n",
    "RETRY_MAX_TOKENS = 1024\n",
    "\n",
    "DEFAULT_ALLOW_RESERIALIZE_FALLBACK = False\n",
    "\n",
    "# How much of the last generated candidate to store in audit and to feed back into prompt.\n",
    "DEFAULT_MAX_PREV_REWRITE_CHARS = 800\n",
    "\n",
    "# Candidate count shown per tool instance.\n",
    "DEFAULT_NUM_CANDIDATES = 2\n",
    "\n",
    "# Printing controls for token previews in statistics.\n",
    "DEFAULT_MAX_TOKEN_PREVIEW = 8\n",
    "DEFAULT_MAX_TOKEN_STRING_LEN = 48\n",
    "\n",
    "# Candidate text snippet in overview (chars).\n",
    "DEFAULT_CANDIDATE_SNIPPET_CHARS = 160\n",
    "\n",
    "# Soft concise length target knobs (reviewer-proof defaults).\n",
    "DEFAULT_CONCISE_TARGET_RATIO = 0.70\n",
    "DEFAULT_CONCISE_TARGET_MIN_BASE_LEN = 160\n",
    "DEFAULT_CONCISE_TARGET_MIN_CHARS = 80\n",
    "\n",
    "\n",
    "# ========= Styles =========\n",
    "STYLE_SPECS: Dict[str, Dict[str, Any]] = {\n",
    "    \"style_verbose\": {\n",
    "        \"system\": (\n",
    "            \"Rewrite tool descriptions.\\n\"\n",
    "            \"Hard constraints:\\n\"\n",
    "            \"- Preserve meaning exactly; do not add new capabilities, steps, motivations, benefits, or context.\\n\"\n",
    "            \"- Do not delete information present in the original description.\\n\"\n",
    "            \"- Do not introduce new parameter names, IDs, field names, flags, or implementation details.\\n\"\n",
    "            \"- If parameter/field names/IDs/flags already appear in the original description, keep them (do not remove them).\\n\"\n",
    "            \"- Do not add examples, normative language, or assumptions.\\n\"\n",
    "            \"- Keep the same subject (the tool) and the same scope.\\n\"\n",
    "            \"- Output only the rewritten description text, nothing else.\\n\"\n",
    "            \"- Style: verbose but controlled; keep it concise and complete (1–2 sentences), clear and direct.\\n\"\n",
    "        ),\n",
    "        \"regen_diversity_instruction\": (\n",
    "            \"Return a meaning-equivalent rewrite that is lexically different from your previous rewrite; \"\n",
    "            \"avoid repeating the same sentence structure.\"\n",
    "        ),\n",
    "        \"max_prev_rewrite_chars\": 800,\n",
    "    },\n",
    "    \"style_concise\": {\n",
    "        \"system\": (\n",
    "            \"Rewrite tool descriptions.\\n\"\n",
    "            \"Hard constraints:\\n\"\n",
    "            \"- Preserve meaning exactly; do not add new capabilities, steps, motivations, benefits, or context.\\n\"\n",
    "            \"- Do not delete information present in the original description.\\n\"\n",
    "            \"- Do not introduce new parameter names, IDs, field names, flags, or implementation details.\\n\"\n",
    "            \"- If parameter/field names/IDs/flags already appear in the original description, keep them (do not remove them).\\n\"\n",
    "            \"- Do not add examples, normative language, or assumptions.\\n\"\n",
    "            \"- Keep the same subject (the tool) and the same scope.\\n\"\n",
    "            \"- Output only the rewritten description text, nothing else.\\n\"\n",
    "            \" - Style: concise and controlled; 1 sentence preferred, 2 max.\\n\"\n",
    "            \" - Length constraint: aim to be shorter than the base description; if the base description is already short, do not exceed its length.\\n\"\n",
    "            \" - Compression rule: remove redundancy, filler, and hedging; keep all explicitly stated constraints/details.\\n\"\n",
    "        ),\n",
    "        \"regen_diversity_instruction\": (\n",
    "            \"You must produce a different paraphrase than the previous rewrite. \"\n",
    "            \"Do not reuse the same sentence skeleton or distinctive phrases. \"\n",
    "            \"Keep meaning exactly the same; only vary wording and structure.\"\n",
    "        ),\n",
    "        \"max_prev_rewrite_chars\": 600,\n",
    "    },\n",
    "    # Alias to tolerate misspellings.\n",
    "    \"style_coicnoso\": {},   # filled after dict creation\n",
    "    \"style_coinceise\": {},  # filled after dict creation\n",
    "}\n",
    "STYLE_SPECS[\"style_coicnoso\"] = STYLE_SPECS[\"style_concise\"]\n",
    "STYLE_SPECS[\"style_coinceise\"] = STYLE_SPECS[\"style_concise\"]\n",
    "\n",
    "\n",
    "def _resolve_style(mode_key: str) -> Tuple[str, Dict[str, Any]]:\n",
    "    mk = (mode_key or \"\").strip()\n",
    "    if not mk:\n",
    "        mk = \"style_verbose\"\n",
    "    if mk not in STYLE_SPECS:\n",
    "        raise ValueError(f\"Unknown MODE_KEY='{mk}'. Supported: {', '.join(sorted(STYLE_SPECS.keys()))}\")\n",
    "    return mk, STYLE_SPECS[mk]\n",
    "\n",
    "\n",
    "# ========= Client =========\n",
    "def make_gemini_client() -> OpenAI:\n",
    "    token = os.environ.get(\"TOKEN_GEMINI\")\n",
    "    if not token:\n",
    "        raise RuntimeError(\"TOKEN_GEMINI environment variable is not set.\")\n",
    "    return OpenAI(api_key=token, base_url=GEMINI_BASE_URL)\n",
    "\n",
    "\n",
    "# ========= Small utils =========\n",
    "def _json_safe(obj: Any) -> Any:\n",
    "    if obj is None or isinstance(obj, (str, int, float, bool)):\n",
    "        return obj\n",
    "    if isinstance(obj, dict):\n",
    "        return {str(k): _json_safe(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return [_json_safe(x) for x in obj]\n",
    "    if hasattr(obj, \"model_dump\") and callable(getattr(obj, \"model_dump\")):\n",
    "        try:\n",
    "            return _json_safe(obj.model_dump())\n",
    "        except Exception:\n",
    "            pass\n",
    "    if hasattr(obj, \"dict\") and callable(getattr(obj, \"dict\")):\n",
    "        try:\n",
    "            return _json_safe(obj.dict())\n",
    "        except Exception:\n",
    "            pass\n",
    "    if hasattr(obj, \"__dict__\"):\n",
    "        try:\n",
    "            return _json_safe(vars(obj))\n",
    "        except Exception:\n",
    "            pass\n",
    "    try:\n",
    "        return str(obj)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def _sha256_text(s: str) -> str:\n",
    "    return hashlib.sha256((s or \"\").encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "def _canonical_json(obj: Any) -> str:\n",
    "    return json.dumps(obj, ensure_ascii=False, sort_keys=True, separators=(\",\", \":\"))\n",
    "\n",
    "\n",
    "def _sha256_file(path: Path) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with path.open(\"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(1024 * 1024), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "\n",
    "def _safe_int_env(name: str, default: int) -> int:\n",
    "    v = os.environ.get(name)\n",
    "    if v is None or not v.strip():\n",
    "        return int(default)\n",
    "    try:\n",
    "        return int(v.strip())\n",
    "    except Exception:\n",
    "        return int(default)\n",
    "\n",
    "\n",
    "def _safe_float_env(name: str, default: float) -> float:\n",
    "    v = os.environ.get(name)\n",
    "    if v is None or not v.strip():\n",
    "        return float(default)\n",
    "    try:\n",
    "        return float(v.strip())\n",
    "    except Exception:\n",
    "        return float(default)\n",
    "\n",
    "\n",
    "# ========= Concise soft target (policy) =========\n",
    "def _make_length_policy(\n",
    "    *,\n",
    "    base_desc: str,\n",
    "    mode_key: str,\n",
    "    concise_ratio: float,\n",
    "    concise_min_base_len: int,\n",
    "    concise_min_chars: int,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Returns a policy object (always present) used for:\n",
    "    - prompt guidance (soft target)\n",
    "    - stats (len_ratio, within_target)\n",
    "    - audit reporting\n",
    "\n",
    "    Soft target is applied only if:\n",
    "    - mode_key == style_concise\n",
    "    - base_len >= concise_min_base_len\n",
    "    - computed target is strictly shorter than base_len\n",
    "    \"\"\"\n",
    "    base = (base_desc or \"\").strip()\n",
    "    base_len = len(base)\n",
    "\n",
    "    ratio = float(concise_ratio)\n",
    "    min_base_len = int(concise_min_base_len)\n",
    "    min_chars = int(concise_min_chars)\n",
    "\n",
    "    reason = \"not_concise_mode\"\n",
    "    applied = False\n",
    "    target_chars: Optional[int] = None\n",
    "\n",
    "    if mode_key == \"style_concise\":\n",
    "        if base_len < min_base_len or base_len <= 0:\n",
    "            reason = \"base_too_short\"\n",
    "        else:\n",
    "            raw_target = int(base_len * ratio)\n",
    "            candidate_target = max(raw_target, min_chars)\n",
    "            # If env is mis-set (min_chars > base), do not apply a target that would exceed base.\n",
    "            if candidate_target >= base_len:\n",
    "                reason = \"target_not_shorter_than_base\"\n",
    "            else:\n",
    "                applied = True\n",
    "                reason = \"ok\"\n",
    "                target_chars = candidate_target\n",
    "\n",
    "    return {\n",
    "        \"policy_name\": \"concise_soft_target_v1\",\n",
    "        \"mode_key\": mode_key,\n",
    "        \"base_len_chars\": base_len,\n",
    "        \"concise_soft_target\": {\n",
    "            \"applied\": bool(applied),\n",
    "            \"reason\": str(reason),\n",
    "            \"target_ratio\": float(ratio),\n",
    "            \"min_base_len\": int(min_base_len),\n",
    "            \"min_chars\": int(min_chars),\n",
    "            \"target_chars\": int(target_chars) if isinstance(target_chars, int) else None,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "# ========= Statistical / lexical indicators =========\n",
    "_FLAG_RE = re.compile(r\"(?<!\\w)--[A-Za-z0-9][A-Za-z0-9_-]*\")\n",
    "_SNAKE_RE = re.compile(r\"\\b[A-Za-z][A-Za-z0-9]*_[A-Za-z0-9_]+\\b\")\n",
    "_CAMEL_RE = re.compile(r\"\\b[a-z]+[A-Z][A-Za-z0-9]*\\b\")\n",
    "_FIELD_COLON_RE = re.compile(r\"\\b[A-Za-z][A-Za-z0-9_]{2,}\\b(?=\\s*[:=])\")\n",
    "_NUMBER_RE = re.compile(r\"\\b\\d+(?:\\.\\d+)?\\b\")\n",
    "_NUMBER_UNIT_RE = re.compile(r\"\\b\\d+(?:\\.\\d+)?\\s*(?:kb|mb|gb|tb|ms|s|sec|secs|seconds|mins|minutes|hrs|hours|days)\\b\", re.IGNORECASE)\n",
    "\n",
    "# Conservative action verbs indicating possible semantic drift if newly introduced.\n",
    "_HIGH_RISK_VERBS = [\n",
    "    \"create\", \"delete\", \"remove\", \"destroy\",\n",
    "    \"upload\", \"download\", \"send\", \"email\",\n",
    "    \"execute\", \"run\", \"invoke\", \"call\",\n",
    "    \"write\", \"read\", \"save\", \"store\",\n",
    "    \"update\", \"modify\", \"edit\", \"change\",\n",
    "    \"retrieve\", \"fetch\", \"search\", \"browse\",\n",
    "    \"access\", \"open\", \"close\",\n",
    "]\n",
    "_VERB_RE = re.compile(r\"\\b(\" + \"|\".join(re.escape(v) for v in _HIGH_RISK_VERBS) + r\")\\b\", re.IGNORECASE)\n",
    "\n",
    "\n",
    "def _sentence_count(text: str) -> int:\n",
    "    t = (text or \"\").strip()\n",
    "    if not t:\n",
    "        return 0\n",
    "    parts = [p for p in re.split(r\"[.!?]+\", t) if p.strip()]\n",
    "    return len(parts)\n",
    "\n",
    "\n",
    "def _word_count(text: str) -> int:\n",
    "    t = (text or \"\").strip()\n",
    "    if not t:\n",
    "        return 0\n",
    "    return len([w for w in re.split(r\"\\s+\", t) if w])\n",
    "\n",
    "\n",
    "def _extract_indicator_tokens(text: str) -> Dict[str, List[str]]:\n",
    "    t = text or \"\"\n",
    "    return {\n",
    "        \"flags\": sorted(set(_FLAG_RE.findall(t))),\n",
    "        \"snake\": sorted(set(_SNAKE_RE.findall(t))),\n",
    "        \"camel\": sorted(set(_CAMEL_RE.findall(t))),\n",
    "        \"field_like\": sorted(set(_FIELD_COLON_RE.findall(t))),\n",
    "        \"numbers\": sorted(set(_NUMBER_RE.findall(t))),\n",
    "        \"number_units\": sorted(set(m.group(0) for m in _NUMBER_UNIT_RE.finditer(t))),\n",
    "        \"verbs\": sorted(set(m.group(0).lower() for m in _VERB_RE.finditer(t))),\n",
    "    }\n",
    "\n",
    "\n",
    "def _format_token_preview(tokens: List[str], *, max_items: int, max_len: int) -> str:\n",
    "    if not tokens:\n",
    "        return \"-\"\n",
    "    out: List[str] = []\n",
    "    for t in tokens[: max(0, int(max_items))]:\n",
    "        s = str(t)\n",
    "        if len(s) > int(max_len):\n",
    "            s = s[: int(max_len) - 1] + \"…\"\n",
    "        out.append(s)\n",
    "    if len(tokens) > int(max_items):\n",
    "        out.append(f\"+{len(tokens) - int(max_items)}\")\n",
    "    return \", \".join(out) if out else \"-\"\n",
    "\n",
    "\n",
    "def _diff_token_sets(base: Dict[str, List[str]], cand: Dict[str, List[str]], key: str) -> Tuple[List[str], List[str]]:\n",
    "    b = set(base.get(key, []) or [])\n",
    "    c = set(cand.get(key, []) or [])\n",
    "    new_items = sorted(c - b)\n",
    "    missing_items = sorted(b - c)\n",
    "    return new_items, missing_items\n",
    "\n",
    "\n",
    "def _similarity_ratio(a: str, b: str) -> float:\n",
    "    aa = (a or \"\").strip()\n",
    "    bb = (b or \"\").strip()\n",
    "    if not aa and not bb:\n",
    "        return 1.0\n",
    "    if not aa or not bb:\n",
    "        return 0.0\n",
    "    return float(difflib.SequenceMatcher(None, aa, bb).ratio())\n",
    "\n",
    "\n",
    "def compute_candidate_stats(\n",
    "    *,\n",
    "    base_text: str,\n",
    "    cand_text: str,\n",
    "    mode_key: str,\n",
    "    length_policy: Optional[Dict[str, Any]] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    base = (base_text or \"\").strip()\n",
    "    cand = (cand_text or \"\").strip()\n",
    "\n",
    "    base_tokens = _extract_indicator_tokens(base)\n",
    "    cand_tokens = _extract_indicator_tokens(cand)\n",
    "\n",
    "    diffs: Dict[str, Any] = {}\n",
    "    for k in (\"flags\", \"snake\", \"camel\", \"field_like\", \"numbers\", \"number_units\", \"verbs\"):\n",
    "        new_items, missing_items = _diff_token_sets(base_tokens, cand_tokens, k)\n",
    "        diffs[k] = {\"new\": new_items, \"missing\": missing_items}\n",
    "\n",
    "    base_len = len(base)\n",
    "    cand_len = len(cand)\n",
    "    base_words = _word_count(base)\n",
    "    cand_words = _word_count(cand)\n",
    "    base_sent = _sentence_count(base)\n",
    "    cand_sent = _sentence_count(cand)\n",
    "\n",
    "    sim = _similarity_ratio(base, cand)\n",
    "\n",
    "    len_ratio = (float(cand_len) / float(base_len)) if base_len > 0 else None\n",
    "    len_delta = int(cand_len) - int(base_len)\n",
    "    len_delta_ratio = (float(len_delta) / float(base_len)) if base_len > 0 else None\n",
    "\n",
    "    new_critical = (\n",
    "        len(diffs[\"flags\"][\"new\"]) +\n",
    "        len(diffs[\"field_like\"][\"new\"]) +\n",
    "        len(diffs[\"numbers\"][\"new\"]) +\n",
    "        len(diffs[\"number_units\"][\"new\"]) +\n",
    "        len(diffs[\"verbs\"][\"new\"]) +\n",
    "        len(diffs[\"snake\"][\"new\"]) +\n",
    "        len(diffs[\"camel\"][\"new\"])\n",
    "    )\n",
    "    missing_signal = (\n",
    "        len(diffs[\"flags\"][\"missing\"]) +\n",
    "        len(diffs[\"field_like\"][\"missing\"]) +\n",
    "        len(diffs[\"numbers\"][\"missing\"]) +\n",
    "        len(diffs[\"number_units\"][\"missing\"]) +\n",
    "        len(diffs[\"verbs\"][\"missing\"]) +\n",
    "        len(diffs[\"snake\"][\"missing\"]) +\n",
    "        len(diffs[\"camel\"][\"missing\"])\n",
    "    )\n",
    "\n",
    "    risk_label = \"LOW\"\n",
    "    risk_reasons: List[str] = []\n",
    "\n",
    "    if new_critical > 0:\n",
    "        risk_label = \"HIGH\"\n",
    "        risk_reasons.append(\"new_indicator_tokens_detected\")\n",
    "    if risk_label != \"HIGH\" and missing_signal >= 4:\n",
    "        risk_label = \"HIGH\"\n",
    "        risk_reasons.append(\"many_indicator_tokens_missing\")\n",
    "    if risk_label == \"LOW\" and missing_signal > 0:\n",
    "        risk_label = \"MED\"\n",
    "        risk_reasons.append(\"some_indicator_tokens_missing\")\n",
    "    if risk_label == \"LOW\" and sim < 0.55:\n",
    "        risk_label = \"MED\"\n",
    "        risk_reasons.append(\"low_text_similarity\")\n",
    "\n",
    "    soft_flags: List[Dict[str, Any]] = []\n",
    "    if mode_key == \"style_concise\":\n",
    "        if base_len > 0 and cand_len > base_len:\n",
    "            soft_flags.append({\"type\": \"concise_length_exceeds_base\", \"base_len\": base_len, \"cand_len\": cand_len})\n",
    "        if cand_sent > 2:\n",
    "            soft_flags.append({\"type\": \"concise_sentence_count_exceeds_2\", \"sentence_count\": cand_sent})\n",
    "    if mode_key == \"style_verbose\":\n",
    "        if cand_sent > 2:\n",
    "            soft_flags.append({\"type\": \"verbose_sentence_count_exceeds_2\", \"sentence_count\": cand_sent})\n",
    "\n",
    "    # Concise soft target evaluation (flag only; never a hard reject).\n",
    "    concise_target_chars = None\n",
    "    concise_target_applied = False\n",
    "    concise_target_reason = None\n",
    "    within_soft_target = None\n",
    "\n",
    "    if isinstance(length_policy, dict):\n",
    "        ct = (length_policy.get(\"concise_soft_target\") or {})\n",
    "        if isinstance(ct, dict):\n",
    "            concise_target_applied = bool(ct.get(\"applied\", False))\n",
    "            concise_target_reason = ct.get(\"reason\")\n",
    "            concise_target_chars = ct.get(\"target_chars\") if isinstance(ct.get(\"target_chars\"), int) else None\n",
    "\n",
    "    if mode_key == \"style_concise\" and concise_target_applied and isinstance(concise_target_chars, int) and base_len > 0:\n",
    "        within_soft_target = bool(cand_len <= concise_target_chars)\n",
    "        if not within_soft_target:\n",
    "            soft_flags.append(\n",
    "                {\n",
    "                    \"type\": \"concise_exceeds_soft_target\",\n",
    "                    \"target_chars\": int(concise_target_chars),\n",
    "                    \"cand_len\": int(cand_len),\n",
    "                    \"len_ratio\": float(len_ratio) if isinstance(len_ratio, float) else None,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return {\n",
    "        \"base_len_chars\": base_len,\n",
    "        \"cand_len_chars\": cand_len,\n",
    "        \"len_ratio\": len_ratio,\n",
    "        \"len_delta_chars\": len_delta,\n",
    "        \"len_delta_ratio\": len_delta_ratio,\n",
    "        \"base_words\": base_words,\n",
    "        \"cand_words\": cand_words,\n",
    "        \"base_sentences\": base_sent,\n",
    "        \"cand_sentences\": cand_sent,\n",
    "        \"similarity_ratio\": sim,\n",
    "        \"diffs\": diffs,\n",
    "        \"risk_label\": risk_label,\n",
    "        \"risk_reasons\": risk_reasons,\n",
    "        \"soft_flags\": soft_flags,\n",
    "        \"base_tokens\": base_tokens,\n",
    "        \"cand_tokens\": cand_tokens,\n",
    "        \"length_policy\": length_policy,\n",
    "        \"concise_soft_target_applied\": concise_target_applied,\n",
    "        \"concise_soft_target_reason\": concise_target_reason,\n",
    "        \"concise_soft_target_chars\": concise_target_chars,\n",
    "        \"within_soft_target\": within_soft_target,\n",
    "    }\n",
    "\n",
    "\n",
    "def _print_base_stats(base_desc: str, *, max_preview: int, max_tok_len: int) -> None:\n",
    "    base = (base_desc or \"\").strip()\n",
    "    tokens = _extract_indicator_tokens(base)\n",
    "    print(\"\\nStatistics (base):\")\n",
    "    print(f\"  chars={len(base)}; words={_word_count(base)}; sentences={_sentence_count(base)}\")\n",
    "    print(\n",
    "        \"  tokens:\"\n",
    "        f\" flags={len(tokens['flags'])}, field_like={len(tokens['field_like'])}, \"\n",
    "        f\"numbers={len(tokens['numbers'])}, number_units={len(tokens['number_units'])}, \"\n",
    "        f\"verbs={len(tokens['verbs'])}, snake={len(tokens['snake'])}, camel={len(tokens['camel'])}\"\n",
    "    )\n",
    "    print(\n",
    "        \"  previews:\"\n",
    "        f\" flags=[{_format_token_preview(tokens['flags'], max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "        f\" field_like=[{_format_token_preview(tokens['field_like'], max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "        f\" numbers=[{_format_token_preview(tokens['numbers'], max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "        f\" verbs=[{_format_token_preview(tokens['verbs'], max_items=max_preview, max_len=max_tok_len)}]\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _print_candidate_summary_line(\n",
    "    i: int,\n",
    "    cand: Dict[str, Any],\n",
    "    *,\n",
    "    max_preview: int,\n",
    "    max_tok_len: int,\n",
    "    snippet_chars: int,\n",
    ") -> None:\n",
    "    txt = (cand.get(\"text\") or \"\").strip()\n",
    "    err = cand.get(\"error\")\n",
    "    dup = bool(cand.get(\"duplicate\", False))\n",
    "    stats = cand.get(\"stats\") or {}\n",
    "\n",
    "    status = \"ok\"\n",
    "    if err:\n",
    "        status = f\"error:{str(err)[:60]}\"\n",
    "    elif not txt:\n",
    "        status = \"empty\"\n",
    "    elif dup:\n",
    "        status = \"duplicate\"\n",
    "\n",
    "    risk = stats.get(\"risk_label\") or \"-\"\n",
    "    sim = stats.get(\"similarity_ratio\")\n",
    "    sim_s = f\"{float(sim):.2f}\" if isinstance(sim, (int, float)) else \"-\"\n",
    "\n",
    "    diffs = (stats.get(\"diffs\") or {})\n",
    "    new_flags = len(((diffs.get(\"flags\") or {}).get(\"new\") or []))\n",
    "    new_nums = len(((diffs.get(\"numbers\") or {}).get(\"new\") or [])) + len(((diffs.get(\"number_units\") or {}).get(\"new\") or []))\n",
    "    new_verbs = len(((diffs.get(\"verbs\") or {}).get(\"new\") or []))\n",
    "    new_fields = len(((diffs.get(\"field_like\") or {}).get(\"new\") or []))\n",
    "    missing_total = (\n",
    "        len(((diffs.get(\"flags\") or {}).get(\"missing\") or [])) +\n",
    "        len(((diffs.get(\"numbers\") or {}).get(\"missing\") or [])) +\n",
    "        len(((diffs.get(\"number_units\") or {}).get(\"missing\") or [])) +\n",
    "        len(((diffs.get(\"verbs\") or {}).get(\"missing\") or [])) +\n",
    "        len(((diffs.get(\"field_like\") or {}).get(\"missing\") or [])) +\n",
    "        len(((diffs.get(\"snake\") or {}).get(\"missing\") or [])) +\n",
    "        len(((diffs.get(\"camel\") or {}).get(\"missing\") or []))\n",
    "    )\n",
    "\n",
    "    clen = stats.get(\"cand_len_chars\")\n",
    "    cwords = stats.get(\"cand_words\")\n",
    "    csent = stats.get(\"cand_sentences\")\n",
    "\n",
    "    clen_s = str(clen) if isinstance(clen, int) else \"-\"\n",
    "    cwords_s = str(cwords) if isinstance(cwords, int) else \"-\"\n",
    "    csent_s = str(csent) if isinstance(csent, int) else \"-\"\n",
    "\n",
    "    # Length diagnostics\n",
    "    lr = stats.get(\"len_ratio\")\n",
    "    lr_s = f\"{float(lr):.2f}\" if isinstance(lr, (int, float)) else \"-\"\n",
    "    ld = stats.get(\"len_delta_chars\")\n",
    "    ld_s = f\"{int(ld):+d}\" if isinstance(ld, int) else \"-\"\n",
    "\n",
    "    # Concise target diagnostics (if applicable)\n",
    "    t_applied = bool(stats.get(\"concise_soft_target_applied\", False))\n",
    "    t_chars = stats.get(\"concise_soft_target_chars\")\n",
    "    within = stats.get(\"within_soft_target\")\n",
    "    target_s = \"-\"\n",
    "    if t_applied and isinstance(t_chars, int):\n",
    "        if within is True:\n",
    "            target_s = f\"target<={t_chars} ok\"\n",
    "        elif within is False:\n",
    "            target_s = f\"target<={t_chars} NO\"\n",
    "        else:\n",
    "            target_s = f\"target<={t_chars}\"\n",
    "\n",
    "    print(\n",
    "        f\"  [{i}] status={status}; risk={risk}; sim={sim_s}; \"\n",
    "        f\"cand(chars={clen_s}, words={cwords_s}, sent={csent_s}); \"\n",
    "        f\"len_ratio={lr_s}; Δchars={ld_s}; {target_s}; \"\n",
    "        f\"new(flags={new_flags}, fields={new_fields}, nums={new_nums}, verbs={new_verbs}); missing_total={missing_total}\"\n",
    "    )\n",
    "\n",
    "    # Compact preview of the most actionable deltas.\n",
    "    if isinstance(diffs, dict) and txt and not err:\n",
    "        nf = (diffs.get(\"flags\") or {}).get(\"new\") or []\n",
    "        nfv = (diffs.get(\"field_like\") or {}).get(\"new\") or []\n",
    "        nn = (diffs.get(\"numbers\") or {}).get(\"new\") or []\n",
    "        nv = (diffs.get(\"verbs\") or {}).get(\"new\") or []\n",
    "        if nf or nfv or nn or nv:\n",
    "            print(\n",
    "                \"      new-previews:\"\n",
    "                f\" flags=[{_format_token_preview(list(nf), max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "                f\" fields=[{_format_token_preview(list(nfv), max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "                f\" numbers=[{_format_token_preview(list(nn), max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "                f\" verbs=[{_format_token_preview(list(nv), max_items=max_preview, max_len=max_tok_len)}]\"\n",
    "            )\n",
    "\n",
    "    # Show a compact snippet of the candidate text to enable selection without extra commands.\n",
    "    if txt and not err and int(snippet_chars) > 0:\n",
    "        sn = \" \".join(txt.split())\n",
    "        max_sn = int(snippet_chars)\n",
    "        if len(sn) > max_sn:\n",
    "            sn = sn[: max_sn - 1] + \"…\"\n",
    "        print(f\"      text: {sn}\")\n",
    "\n",
    "\n",
    "def _print_candidate_full(\n",
    "    i: int,\n",
    "    cand: Dict[str, Any],\n",
    "    *,\n",
    "    max_preview: int,\n",
    "    max_tok_len: int,\n",
    ") -> None:\n",
    "    txt = (cand.get(\"text\") or \"\").strip()\n",
    "    err = cand.get(\"error\")\n",
    "    stats = cand.get(\"stats\") or {}\n",
    "    diffs = (stats.get(\"diffs\") or {})\n",
    "\n",
    "    print(f\"\\nCandidate [{i}]:\")\n",
    "    if err:\n",
    "        print(f\"  Generation error: {err}\")\n",
    "        if txt:\n",
    "            print(\"  Partial text:\")\n",
    "            print(txt)\n",
    "        return\n",
    "    if not txt:\n",
    "        print(\"  (empty)\")\n",
    "        return\n",
    "\n",
    "    print(txt)\n",
    "\n",
    "    risk = stats.get(\"risk_label\") or \"-\"\n",
    "    reasons = stats.get(\"risk_reasons\") or []\n",
    "    soft = stats.get(\"soft_flags\") or []\n",
    "\n",
    "    print(\"\\n  Candidate statistics:\")\n",
    "    sim = stats.get(\"similarity_ratio\")\n",
    "    sim_s = f\"{float(sim):.2f}\" if isinstance(sim, (int, float)) else \"-\"\n",
    "    lr = stats.get(\"len_ratio\")\n",
    "    lr_s = f\"{float(lr):.2f}\" if isinstance(lr, (int, float)) else \"-\"\n",
    "    ld = stats.get(\"len_delta_chars\")\n",
    "    ld_s = f\"{int(ld):+d}\" if isinstance(ld, int) else \"-\"\n",
    "    print(f\"    risk={risk}; reasons={reasons if reasons else '[]'}; similarity={sim_s}; len_ratio={lr_s}; Δchars={ld_s}\")\n",
    "\n",
    "    if soft:\n",
    "        print(f\"    soft_flags={soft}\")\n",
    "\n",
    "    for key in (\"flags\", \"field_like\", \"numbers\", \"number_units\", \"verbs\", \"snake\", \"camel\"):\n",
    "        d = diffs.get(key) or {}\n",
    "        new_items = d.get(\"new\") or []\n",
    "        missing_items = d.get(\"missing\") or []\n",
    "        if not new_items and not missing_items:\n",
    "            continue\n",
    "        print(\n",
    "            f\"    {key}:\"\n",
    "            f\" new({len(new_items)})=[{_format_token_preview(list(new_items), max_items=max_preview, max_len=max_tok_len)}];\"\n",
    "            f\" missing({len(missing_items)})=[{_format_token_preview(list(missing_items), max_items=max_preview, max_len=max_tok_len)}]\"\n",
    "        )\n",
    "\n",
    "\n",
    "# ========= Raw JSON-string patcher (for tools stored as JSON strings) =========\n",
    "def _extract_json_string_value(raw_json: str, key: str) -> Optional[str]:\n",
    "    token = f'\"{key}\"'\n",
    "    i = raw_json.find(token)\n",
    "    if i < 0:\n",
    "        return None\n",
    "    i = raw_json.find(\":\", i + len(token))\n",
    "    if i < 0:\n",
    "        return None\n",
    "    i += 1\n",
    "    n = len(raw_json)\n",
    "    while i < n and raw_json[i] in \" \\t\\r\\n\":\n",
    "        i += 1\n",
    "    if i >= n or raw_json[i] != '\"':\n",
    "        return None\n",
    "    start = i\n",
    "    i += 1\n",
    "    esc = False\n",
    "    while i < n:\n",
    "        c = raw_json[i]\n",
    "        if esc:\n",
    "            esc = False\n",
    "        else:\n",
    "            if c == \"\\\\\":\n",
    "                esc = True\n",
    "            elif c == '\"':\n",
    "                return raw_json[start : i + 1]\n",
    "        i += 1\n",
    "    return None\n",
    "\n",
    "\n",
    "def _decode_raw_json_string(raw_json_string_with_quotes: str) -> str:\n",
    "    try:\n",
    "        obj = json.loads('{\"description\":' + raw_json_string_with_quotes + \"}\")\n",
    "        return obj.get(\"description\") or \"\"\n",
    "    except json.JSONDecodeError:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def _get_description_for_print(entry: Any) -> Tuple[str, str]:\n",
    "    if isinstance(entry, str):\n",
    "        raw = _extract_json_string_value(entry, \"description\")\n",
    "        if raw is not None:\n",
    "            return raw, \"raw_json\"\n",
    "        try:\n",
    "            obj = json.loads(entry)\n",
    "            return obj.get(\"description\") or \"\", \"rendered\"\n",
    "        except json.JSONDecodeError:\n",
    "            return \"\", \"rendered\"\n",
    "    if isinstance(entry, dict):\n",
    "        return entry.get(\"description\") or \"\", \"rendered\"\n",
    "    return \"\", \"rendered\"\n",
    "\n",
    "\n",
    "def _load_tool(entry: Any) -> Tuple[Optional[Dict[str, Any]], str]:\n",
    "    if isinstance(entry, str):\n",
    "        try:\n",
    "            return json.loads(entry), \"json_str\"\n",
    "        except json.JSONDecodeError:\n",
    "            return None, \"other\"\n",
    "    if isinstance(entry, dict):\n",
    "        return entry, \"dict\"\n",
    "    return None, \"other\"\n",
    "\n",
    "\n",
    "def _skip_ws(s: str, i: int) -> int:\n",
    "    n = len(s)\n",
    "    while i < n and s[i] in \" \\t\\r\\n\":\n",
    "        i += 1\n",
    "    return i\n",
    "\n",
    "\n",
    "def _scan_string_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    n = len(s)\n",
    "    if i >= n or s[i] != '\"':\n",
    "        return None\n",
    "    j = i + 1\n",
    "    esc = False\n",
    "    while j < n:\n",
    "        c = s[j]\n",
    "        if esc:\n",
    "            esc = False\n",
    "        else:\n",
    "            if c == \"\\\\\":\n",
    "                esc = True\n",
    "            elif c == '\"':\n",
    "                return (i, j + 1)\n",
    "        j += 1\n",
    "    return None\n",
    "\n",
    "\n",
    "def _scan_number_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    n = len(s)\n",
    "    j = i\n",
    "    if j < n and s[j] == \"-\":\n",
    "        j += 1\n",
    "    if j >= n:\n",
    "        return None\n",
    "    if s[j] == \"0\":\n",
    "        j += 1\n",
    "    elif s[j].isdigit():\n",
    "        while j < n and s[j].isdigit():\n",
    "            j += 1\n",
    "    else:\n",
    "        return None\n",
    "    if j < n and s[j] == \".\":\n",
    "        j += 1\n",
    "        if j >= n or not s[j].isdigit():\n",
    "            return None\n",
    "        while j < n and s[j].isdigit():\n",
    "            j += 1\n",
    "    if j < n and s[j] in \"eE\":\n",
    "        j += 1\n",
    "        if j < n and s[j] in \"+-\":\n",
    "            j += 1\n",
    "        if j >= n or not s[j].isdigit():\n",
    "            return None\n",
    "        while j < n and s[j].isdigit():\n",
    "            j += 1\n",
    "    return (i, j)\n",
    "\n",
    "\n",
    "def _scan_literal_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    for lit in (\"true\", \"false\", \"null\"):\n",
    "        if s.startswith(lit, i):\n",
    "            return (i, i + len(lit))\n",
    "    return None\n",
    "\n",
    "\n",
    "def _scan_container_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    n = len(s)\n",
    "    if i >= n:\n",
    "        return None\n",
    "\n",
    "    opener = s[i]\n",
    "    if opener not in \"{[\":\n",
    "        return None\n",
    "\n",
    "    stack: List[str] = [\"}\" if opener == \"{\" else \"]\"]\n",
    "    j = i + 1\n",
    "    in_str = False\n",
    "    esc = False\n",
    "\n",
    "    while j < n:\n",
    "        c = s[j]\n",
    "\n",
    "        if in_str:\n",
    "            if esc:\n",
    "                esc = False\n",
    "            else:\n",
    "                if c == \"\\\\\":\n",
    "                    esc = True\n",
    "                elif c == '\"':\n",
    "                    in_str = False\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        if c == '\"':\n",
    "            in_str = True\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        if c == \"{\":\n",
    "            stack.append(\"}\")\n",
    "            j += 1\n",
    "            continue\n",
    "        if c == \"[\":\n",
    "            stack.append(\"]\")\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        if c in \"}]\":\n",
    "            if not stack:\n",
    "                return None\n",
    "            expected = stack[-1]\n",
    "            if c != expected:\n",
    "                return None\n",
    "            stack.pop()\n",
    "            j += 1\n",
    "            if not stack:\n",
    "                return (i, j)\n",
    "            continue\n",
    "\n",
    "        j += 1\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def _is_value_delim(c: str) -> bool:\n",
    "    return c in \",}]\"\n",
    "\n",
    "\n",
    "def _scan_value_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    n = len(s)\n",
    "    i = _skip_ws(s, i)\n",
    "    if i >= n:\n",
    "        return None\n",
    "\n",
    "    c = s[i]\n",
    "    if c == '\"':\n",
    "        return _scan_string_span(s, i)\n",
    "    if c in \"{[\":\n",
    "        return _scan_container_span(s, i)\n",
    "\n",
    "    span: Optional[Tuple[int, int]]\n",
    "    if c == \"-\" or c.isdigit():\n",
    "        span = _scan_number_span(s, i)\n",
    "    else:\n",
    "        span = _scan_literal_span(s, i)\n",
    "\n",
    "    if not span:\n",
    "        return None\n",
    "\n",
    "    _, end = span\n",
    "    k = _skip_ws(s, end)\n",
    "    if k >= n:\n",
    "        return span\n",
    "    if _is_value_delim(s[k]):\n",
    "        return span\n",
    "    return None\n",
    "\n",
    "\n",
    "def _replace_top_level_string_field_in_raw_object(raw_json_obj: str, key: str, new_value: str) -> Tuple[str, bool, str]:\n",
    "    s = raw_json_obj\n",
    "    n = len(s)\n",
    "\n",
    "    i = _skip_ws(s, 0)\n",
    "    if i >= n or s[i] != \"{\":\n",
    "        return raw_json_obj, False, \"not_object\"\n",
    "\n",
    "    i += 1\n",
    "    found_any_key = False\n",
    "    expect_key = True\n",
    "\n",
    "    while True:\n",
    "        i = _skip_ws(s, i)\n",
    "        if i >= n:\n",
    "            return raw_json_obj, False, \"cannot_scan_value\"\n",
    "\n",
    "        if expect_key:\n",
    "            if s[i] == \"}\":\n",
    "                return raw_json_obj, False, \"key_not_found\"\n",
    "            if s[i] != '\"':\n",
    "                return raw_json_obj, False, \"invalid_key_string\"\n",
    "\n",
    "            key_span = _scan_string_span(s, i)\n",
    "            if not key_span:\n",
    "                return raw_json_obj, False, \"invalid_key_string\"\n",
    "\n",
    "            found_any_key = True\n",
    "            k_start, k_end = key_span\n",
    "            try:\n",
    "                key_decoded = json.loads(s[k_start:k_end])\n",
    "            except Exception:\n",
    "                return raw_json_obj, False, \"invalid_key_string\"\n",
    "\n",
    "            i = _skip_ws(s, k_end)\n",
    "            if i >= n or s[i] != \":\":\n",
    "                return raw_json_obj, False, \"missing_colon\"\n",
    "\n",
    "            v_span = _scan_value_span(s, i + 1)\n",
    "            if not v_span:\n",
    "                return raw_json_obj, False, \"cannot_scan_value\"\n",
    "\n",
    "            v_start, v_end = v_span\n",
    "\n",
    "            if key_decoded == key:\n",
    "                if v_start >= n or s[v_start] != '\"':\n",
    "                    return raw_json_obj, False, \"value_not_string\"\n",
    "\n",
    "                replacement_literal = json.dumps(new_value, ensure_ascii=False)\n",
    "                patched = s[:v_start] + replacement_literal + s[v_end:]\n",
    "\n",
    "                try:\n",
    "                    obj = json.loads(patched)\n",
    "                except Exception:\n",
    "                    return raw_json_obj, False, \"json_load_failed_after_patch\"\n",
    "\n",
    "                if isinstance(obj, dict) and obj.get(key) == new_value:\n",
    "                    return patched, True, \"ok\"\n",
    "                return raw_json_obj, False, \"validation_failed_after_patch\"\n",
    "\n",
    "            i = v_end\n",
    "            expect_key = False\n",
    "            continue\n",
    "\n",
    "        i = _skip_ws(s, i)\n",
    "        if i >= n:\n",
    "            return raw_json_obj, False, \"cannot_scan_value\"\n",
    "\n",
    "        if s[i] == \",\":\n",
    "            i += 1\n",
    "            expect_key = True\n",
    "            continue\n",
    "        if s[i] == \"}\":\n",
    "            return raw_json_obj, False, (\"key_not_found\" if found_any_key else \"key_not_found\")\n",
    "        return raw_json_obj, False, \"cannot_scan_value\"\n",
    "\n",
    "\n",
    "# ========= IDs =========\n",
    "def _tool_fingerprint_excluding_description(tool_obj: Dict[str, Any]) -> str:\n",
    "    filtered = {k: v for k, v in tool_obj.items() if k != \"description\"}\n",
    "    payload = _canonical_json(filtered)\n",
    "    return hashlib.sha256(payload.encode(\"utf-8\")).hexdigest()[:HASH_HEX_LEN]\n",
    "\n",
    "\n",
    "def _record_id(record_obj: Dict[str, Any], tool_field: str) -> str:\n",
    "    rec = dict(record_obj)\n",
    "    tools = rec.get(tool_field)\n",
    "    if isinstance(tools, list):\n",
    "        canon_tools: List[Any] = []\n",
    "        for entry in tools:\n",
    "            tool_obj, kind = _load_tool(entry)\n",
    "            if tool_obj is None:\n",
    "                canon_tools.append({\"_unparsed\": entry, \"_kind\": kind})\n",
    "            else:\n",
    "                canon_tools.append({k: v for k, v in tool_obj.items() if k != \"description\"})\n",
    "        rec[tool_field] = canon_tools\n",
    "    payload = _canonical_json(rec)\n",
    "    return hashlib.sha256(payload.encode(\"utf-8\")).hexdigest()[:HASH_HEX_LEN]\n",
    "\n",
    "\n",
    "def _tool_instance_key(record_id: str, tool_index: int, tool_obj: Dict[str, Any]) -> str:\n",
    "    fp = _tool_fingerprint_excluding_description(tool_obj)\n",
    "    return f\"rec:{record_id}:t{tool_index}:{fp}\"\n",
    "\n",
    "\n",
    "# ========= Audit (single file, resumable) =========\n",
    "def _audit_identity(dataset_path: Path, *, mode_key: str, model: str, tool_field: str, num_candidates: int) -> str:\n",
    "    stable = f\"{dataset_path.resolve()}|{mode_key}|{model}|{tool_field}|K={int(num_candidates)}\"\n",
    "    return hashlib.sha256(stable.encode(\"utf-8\")).hexdigest()[:12]\n",
    "\n",
    "\n",
    "def _audit_file_path(\n",
    "    dataset_path: Path,\n",
    "    *,\n",
    "    audit_dir: Path,\n",
    "    mode_key: str,\n",
    "    model: str,\n",
    "    tool_field: str,\n",
    "    num_candidates: int,\n",
    ") -> Path:\n",
    "    audit_key = _audit_identity(dataset_path, mode_key=mode_key, model=model, tool_field=tool_field, num_candidates=num_candidates)\n",
    "    safe_model = \"\".join(ch if ch.isalnum() or ch in (\"-\", \"_\", \".\") else \"_\" for ch in model)\n",
    "    out_dir = audit_dir / audit_key\n",
    "    filename = f\"{dataset_path.stem}.{audit_key}.{mode_key}.{safe_model}.K{int(num_candidates)}.audit.jsonl\"\n",
    "    return out_dir / filename\n",
    "\n",
    "\n",
    "def _append_audit_event(audit_file: Path, event: Dict[str, Any]) -> None:\n",
    "    audit_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    safe_event = _json_safe(event)\n",
    "    with audit_file.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(safe_event, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "def _load_resume_state(\n",
    "    audit_file: Path,\n",
    ") -> Tuple[\n",
    "    Dict[str, Tuple[str, Optional[str], Optional[Dict[str, Any]]]],\n",
    "    Dict[str, int],\n",
    "    Dict[str, Optional[str]],\n",
    "    Optional[Dict[str, Any]],\n",
    "]:\n",
    "    decisions: Dict[str, Tuple[str, Optional[str], Optional[Dict[str, Any]]]] = {}\n",
    "    regen_counts: Dict[str, int] = {}\n",
    "    last_rejected_text: Dict[str, Optional[str]] = {}\n",
    "    prior_run_start: Optional[Dict[str, Any]] = None\n",
    "\n",
    "    if not audit_file.exists():\n",
    "        return decisions, regen_counts, last_rejected_text, None\n",
    "\n",
    "    best_round: Dict[str, int] = {}\n",
    "\n",
    "    with audit_file.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                ev = json.loads(line)\n",
    "            except Exception:\n",
    "                continue\n",
    "            if not isinstance(ev, dict):\n",
    "                continue\n",
    "\n",
    "            et = ev.get(\"event_type\")\n",
    "            if et == \"run_start\" and prior_run_start is None:\n",
    "                prior_run_start = ev\n",
    "\n",
    "            if et == \"regenerate\":\n",
    "                ik = ev.get(\"instance_key\")\n",
    "                rr = ev.get(\"generation_round\")\n",
    "                txt = ev.get(\"last_generated_text\")\n",
    "                if isinstance(ik, str) and isinstance(rr, int) and rr >= 0:\n",
    "                    prev = regen_counts.get(ik, 0)\n",
    "                    if rr > prev:\n",
    "                        regen_counts[ik] = rr\n",
    "                    prev_best = best_round.get(ik, -1)\n",
    "                    if rr >= prev_best:\n",
    "                        best_round[ik] = rr\n",
    "                        last_rejected_text[ik] = txt if isinstance(txt, str) else None\n",
    "\n",
    "            if et == \"decision\":\n",
    "                ik = ev.get(\"instance_key\")\n",
    "                status = ev.get(\"status\")\n",
    "                final_desc = ev.get(\"final_description\")\n",
    "                llm_bundle = ev.get(\"llm_bundle\")\n",
    "                if isinstance(ik, str) and isinstance(status, str):\n",
    "                    decisions[ik] = (\n",
    "                        status,\n",
    "                        final_desc if isinstance(final_desc, str) else None,\n",
    "                        llm_bundle if isinstance(llm_bundle, dict) else None,\n",
    "                    )\n",
    "\n",
    "    return decisions, regen_counts, last_rejected_text, prior_run_start\n",
    "\n",
    "\n",
    "# ========= LLM helpers =========\n",
    "def _sanitize_llm_output(text: str) -> str:\n",
    "    t = (text or \"\").strip()\n",
    "    if t.startswith(\"{\") and \"description\" in t:\n",
    "        try:\n",
    "            obj = json.loads(t)\n",
    "            if isinstance(obj, dict) and isinstance(obj.get(\"description\"), str):\n",
    "                t = obj[\"description\"].strip()\n",
    "        except Exception:\n",
    "            pass\n",
    "    if (t.startswith('\"') and t.endswith('\"')) or (t.startswith(\"'\") and t.endswith(\"'\")):\n",
    "        t = t[1:-1].strip()\n",
    "    return t\n",
    "\n",
    "\n",
    "def _llm_chat_completion(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    model: str,\n",
    "    messages: List[Dict[str, str]],\n",
    "    temperature: float,\n",
    "    max_tokens: int,\n",
    "    seed: Optional[int],\n",
    ") -> Tuple[str, Dict[str, Any]]:\n",
    "    meta: Dict[str, Any] = {\n",
    "        \"seed_requested\": seed,\n",
    "        \"seed_applied\": False,\n",
    "        \"seed_error\": None,\n",
    "        \"finish_reason\": None,\n",
    "        \"usage\": None,\n",
    "        \"max_tokens_requested\": int(max_tokens),\n",
    "        \"max_param_used\": None,\n",
    "    }\n",
    "\n",
    "    base_kwargs: Dict[str, Any] = dict(model=model, messages=messages, temperature=temperature)\n",
    "\n",
    "    def attempt(max_param_used: str, include_seed: bool) -> Tuple[str, Dict[str, Any]]:\n",
    "        req = dict(base_kwargs)\n",
    "        if max_param_used == \"max_completion_tokens\":\n",
    "            req[\"max_completion_tokens\"] = int(max_tokens)\n",
    "        else:\n",
    "            req[\"max_tokens\"] = int(max_tokens)\n",
    "        if include_seed and seed is not None:\n",
    "            req[\"seed\"] = int(seed)\n",
    "\n",
    "        resp = client.chat.completions.create(**req)\n",
    "        text = (resp.choices[0].message.content or \"\").strip()\n",
    "\n",
    "        meta_local = dict(meta)\n",
    "        meta_local[\"max_param_used\"] = max_param_used\n",
    "        meta_local[\"finish_reason\"] = getattr(resp.choices[0], \"finish_reason\", None)\n",
    "        meta_local[\"usage\"] = getattr(resp, \"usage\", None)\n",
    "        meta_local[\"seed_applied\"] = bool(include_seed and seed is not None)\n",
    "        return text, meta_local\n",
    "\n",
    "    def is_seed_error(e: Exception) -> bool:\n",
    "        s = str(e).lower()\n",
    "        return (\"seed\" in s) and (\"unknown\" in s or \"unsupported\" in s or \"invalid\" in s)\n",
    "\n",
    "    try:\n",
    "        return attempt(\"max_completion_tokens\", include_seed=True)\n",
    "    except Exception as e1:\n",
    "        if seed is not None and is_seed_error(e1):\n",
    "            meta[\"seed_error\"] = str(e1)\n",
    "            try:\n",
    "                return attempt(\"max_completion_tokens\", include_seed=False)\n",
    "            except Exception:\n",
    "                pass\n",
    "        try:\n",
    "            return attempt(\"max_tokens\", include_seed=True)\n",
    "        except Exception as e2:\n",
    "            if seed is not None and is_seed_error(e2):\n",
    "                meta[\"seed_error\"] = str(e2)\n",
    "                return attempt(\"max_tokens\", include_seed=False)\n",
    "            raise\n",
    "\n",
    "\n",
    "def generate_description_via_llm(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    tool_name: str,\n",
    "    base_description: str,\n",
    "    model: str,\n",
    "    seed: Optional[int],\n",
    "    max_tokens: int,\n",
    "    retry_on_length: bool,\n",
    "    retry_max_tokens: int,\n",
    "    mode_key: str,\n",
    "    style_spec: Dict[str, Any],\n",
    "    regen_index: int = 0,\n",
    "    previous_rewrite: Optional[str] = None,\n",
    "    length_policy: Optional[Dict[str, Any]] = None,\n",
    ") -> Tuple[str, Dict[str, Any]]:\n",
    "    system = str(style_spec[\"system\"])\n",
    "    regen_instr = str(style_spec.get(\"regen_diversity_instruction\") or \"\")\n",
    "    max_prev = int(style_spec.get(\"max_prev_rewrite_chars\") or DEFAULT_MAX_PREV_REWRITE_CHARS)\n",
    "\n",
    "    user_parts: List[str] = []\n",
    "    user_parts.append(f\"Tool name: {tool_name}\")\n",
    "    user_parts.append(\"Base description:\")\n",
    "    user_parts.append(base_description.strip() or \"(empty)\")\n",
    "    user_parts.append(\"\")\n",
    "    user_parts.append(f\"Rewrite in '{mode_key}' under the constraints.\")\n",
    "\n",
    "    # Soft length guidance (concise only): target is optional and non-binding.\n",
    "    if mode_key == \"style_concise\" and isinstance(length_policy, dict):\n",
    "        ct = length_policy.get(\"concise_soft_target\") if isinstance(length_policy.get(\"concise_soft_target\"), dict) else {}\n",
    "        applied = bool(ct.get(\"applied\", False))\n",
    "        target_chars = ct.get(\"target_chars\") if isinstance(ct.get(\"target_chars\"), int) else None\n",
    "        ratio = ct.get(\"target_ratio\")\n",
    "        if applied and isinstance(target_chars, int):\n",
    "            pct = int(float(ratio) * 100) if isinstance(ratio, (int, float)) else 70\n",
    "            user_parts.append(\"\")\n",
    "            user_parts.append(f\"Length guidance (soft target): aim for <= {target_chars} characters (~{pct}% of base).\")\n",
    "            user_parts.append(\n",
    "                \"You may exceed the target if strictly necessary to preserve meaning; \"\n",
    "                \"do not omit any explicitly stated details.\"\n",
    "            )\n",
    "        else:\n",
    "            user_parts.append(\"\")\n",
    "            user_parts.append(\n",
    "                \"Length guidance: the base description is short or cannot be shortened safely; \"\n",
    "                \"do not exceed the base length; keep it as brief as possible.\"\n",
    "            )\n",
    "\n",
    "    if regen_index > 0:\n",
    "        user_parts.append(\"\")\n",
    "        user_parts.append(f\"Regeneration request: {regen_index}\")\n",
    "        if regen_instr:\n",
    "            user_parts.append(regen_instr)\n",
    "        if previous_rewrite and previous_rewrite.strip():\n",
    "            prev = previous_rewrite.strip()\n",
    "            if len(prev) > max_prev:\n",
    "                prev = prev[:max_prev].rstrip()\n",
    "            user_parts.append(\"\")\n",
    "            user_parts.append(\"Previous rewrite (do not reuse wording):\")\n",
    "            user_parts.append(prev)\n",
    "\n",
    "    user = \"\\n\".join(user_parts)\n",
    "\n",
    "    raw1, meta1 = _llm_chat_completion(\n",
    "        client=client,\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": user}],\n",
    "        temperature=0.0,\n",
    "        max_tokens=max_tokens,\n",
    "        seed=seed,\n",
    "    )\n",
    "    san1 = _sanitize_llm_output(raw1)\n",
    "    finish1 = (meta1.get(\"finish_reason\") or \"\").lower()\n",
    "    looks_truncated_1 = (finish1 == \"length\")\n",
    "\n",
    "    if not looks_truncated_1:\n",
    "        return san1, {\n",
    "            \"proposal_origin\": \"primary\",\n",
    "            \"proposal_sanitized_final\": san1,\n",
    "            \"llm_text_raw_primary\": raw1,\n",
    "            \"llm_text_raw_retry\": None,\n",
    "            \"primary\": meta1,\n",
    "            \"retry\": None,\n",
    "            \"mode_key\": mode_key,\n",
    "            \"length_policy\": length_policy,\n",
    "        }\n",
    "\n",
    "    raw2 = None\n",
    "    meta2 = None\n",
    "    san2 = None\n",
    "    best_san = san1\n",
    "    origin = \"primary\"\n",
    "\n",
    "    if retry_on_length and retry_max_tokens > max_tokens:\n",
    "        raw2, meta2 = _llm_chat_completion(\n",
    "            client=client,\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": user}],\n",
    "            temperature=0.0,\n",
    "            max_tokens=int(retry_max_tokens),\n",
    "            seed=seed,\n",
    "        )\n",
    "        san2 = _sanitize_llm_output(raw2)\n",
    "        if san2 and len(san2) >= len(best_san):\n",
    "            best_san = san2\n",
    "            origin = \"retry\"\n",
    "\n",
    "    return best_san, {\n",
    "        \"proposal_origin\": origin,\n",
    "        \"proposal_sanitized_final\": best_san,\n",
    "        \"llm_text_raw_primary\": raw1,\n",
    "        \"llm_text_raw_retry\": raw2,\n",
    "        \"primary\": meta1,\n",
    "        \"retry\": meta2,\n",
    "        \"mode_key\": mode_key,\n",
    "        \"length_policy\": length_policy,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_k_candidates_with_stats(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    tool_name: str,\n",
    "    base_description: str,\n",
    "    model: str,\n",
    "    seed: Optional[int],\n",
    "    max_tokens: int,\n",
    "    retry_on_length: bool,\n",
    "    retry_max_tokens: int,\n",
    "    mode_key: str,\n",
    "    style_spec: Dict[str, Any],\n",
    "    generation_round: int,\n",
    "    k: int,\n",
    "    previous_rewrite_hint: Optional[str],\n",
    "    min_sleep_sec_between_calls: float,\n",
    "    length_policy: Optional[Dict[str, Any]],\n",
    ") -> Tuple[List[Dict[str, Any]], Optional[str]]:\n",
    "    base_desc = (base_description or \"\").strip()\n",
    "    k_eff = max(1, int(k))\n",
    "\n",
    "    candidates: List[Dict[str, Any]] = []\n",
    "    seen: set = set()\n",
    "\n",
    "    prev = previous_rewrite_hint.strip() if isinstance(previous_rewrite_hint, str) and previous_rewrite_hint.strip() else None\n",
    "    last_generated_text: Optional[str] = None\n",
    "\n",
    "    for i in range(0, k_eff):\n",
    "        regen_index = int(generation_round) * 1000 + i  # stable, monotonically increasing per round\n",
    "        text = \"\"\n",
    "        bundle: Optional[Dict[str, Any]] = None\n",
    "        err: Optional[str] = None\n",
    "\n",
    "        try:\n",
    "            text, bundle = generate_description_via_llm(\n",
    "                client=client,\n",
    "                tool_name=tool_name,\n",
    "                base_description=base_desc,\n",
    "                model=model,\n",
    "                seed=seed,\n",
    "                max_tokens=max_tokens,\n",
    "                retry_on_length=retry_on_length,\n",
    "                retry_max_tokens=retry_max_tokens,\n",
    "                mode_key=mode_key,\n",
    "                style_spec=style_spec,\n",
    "                regen_index=regen_index,\n",
    "                previous_rewrite=prev,\n",
    "                length_policy=length_policy,\n",
    "            )\n",
    "            text = (text or \"\").strip()\n",
    "            last_generated_text = text if text else last_generated_text\n",
    "        except Exception as e:\n",
    "            err = str(e)\n",
    "            text = \"\"\n",
    "\n",
    "        duplicate = False\n",
    "        if text:\n",
    "            if text in seen:\n",
    "                duplicate = True\n",
    "            else:\n",
    "                seen.add(text)\n",
    "\n",
    "        stats = compute_candidate_stats(\n",
    "            base_text=base_desc,\n",
    "            cand_text=text,\n",
    "            mode_key=mode_key,\n",
    "            length_policy=length_policy,\n",
    "        ) if text else None\n",
    "\n",
    "        candidates.append(\n",
    "            {\n",
    "                \"candidate_index\": i + 1,  # 1-based for interactive selection\n",
    "                \"text\": text,\n",
    "                \"error\": err,\n",
    "                \"bundle\": bundle,\n",
    "                \"duplicate\": duplicate,\n",
    "                \"stats\": stats,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        prev = text if text else prev\n",
    "\n",
    "        if min_sleep_sec_between_calls > 0:\n",
    "            time.sleep(float(min_sleep_sec_between_calls))\n",
    "\n",
    "    return candidates, last_generated_text\n",
    "\n",
    "\n",
    "# ========= IO =========\n",
    "def make_working_copy(input_jsonl: str, output_jsonl: str, *, overwrite: bool = False) -> str:\n",
    "    src = Path(input_jsonl)\n",
    "    dst = Path(output_jsonl)\n",
    "\n",
    "    if not src.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {src}\")\n",
    "\n",
    "    if dst.exists() and not overwrite:\n",
    "        return str(dst)\n",
    "\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(src, dst)\n",
    "    return str(dst)\n",
    "\n",
    "\n",
    "def _normalize_cmd(raw: str) -> str:\n",
    "    c = (raw or \"\").strip().lower()\n",
    "    if c in (\"\", \"y\", \"yes\", \"ok\", \"okay\", \"si\", \"sì\"):\n",
    "        return \"y\"\n",
    "    if c in (\"r\", \"retry\", \"again\", \"prova\", \"prova ancora\", \"rigenera\"):\n",
    "        return \"r\"\n",
    "    if c in (\"e\", \"edit\", \"modifica\"):\n",
    "        return \"e\"\n",
    "    if c in (\"m\", \"manual\", \"mine\", \"mio\", \"mia\", \"custom\"):\n",
    "        return \"m\"\n",
    "    if c in (\"s\", \"skip\", \"salta\", \"pass\"):\n",
    "        return \"s\"\n",
    "    if c in (\"q\", \"quit\", \"exit\", \"esci\"):\n",
    "        return \"q\"\n",
    "    return c\n",
    "\n",
    "\n",
    "def _parse_candidate_choice(cmd: str, *, k: int) -> Optional[int]:\n",
    "    c = (cmd or \"\").strip()\n",
    "    if not c:\n",
    "        return None\n",
    "    if c.isdigit():\n",
    "        v = int(c)\n",
    "        if 1 <= v <= int(k):\n",
    "            return v\n",
    "    return None\n",
    "\n",
    "\n",
    "# ========= Main interactive =========\n",
    "def interactive_llm_tools_in_jsonl(\n",
    "    jsonl_path: str,\n",
    "    *,\n",
    "    tool_field: str,\n",
    "    create_backup_of_target: bool,\n",
    "    llm_model: str,\n",
    "    seed: Optional[int],\n",
    "    max_tokens: int,\n",
    "    retry_on_length: bool,\n",
    "    retry_max_tokens: int,\n",
    "    allow_reserialize_fallback: bool,\n",
    "    min_sleep_sec_between_calls: float,\n",
    "    audit_dir: str,\n",
    "    mode_key: str,\n",
    "    num_candidates: int,\n",
    "    max_token_preview: int,\n",
    "    max_token_string_len: int,\n",
    "    candidate_snippet_chars: int,\n",
    "    concise_target_ratio: float,\n",
    "    concise_target_min_base_len: int,\n",
    "    concise_target_min_chars: int,\n",
    ") -> None:\n",
    "    mode_key, style_spec = _resolve_style(mode_key)\n",
    "\n",
    "    path = Path(jsonl_path)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {jsonl_path}\")\n",
    "\n",
    "    client = make_gemini_client()\n",
    "    audit_file = _audit_file_path(\n",
    "        path,\n",
    "        audit_dir=Path(audit_dir),\n",
    "        mode_key=mode_key,\n",
    "        model=llm_model,\n",
    "        tool_field=tool_field,\n",
    "        num_candidates=int(num_candidates),\n",
    "    )\n",
    "\n",
    "    decisions_by_instance, regen_counts, last_rejected_text_by_instance, prior_run_start = _load_resume_state(audit_file)\n",
    "\n",
    "    tool_order: List[Dict[str, Any]] = []\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for raw_line in f:\n",
    "            line = raw_line.rstrip(\"\\n\")\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            try:\n",
    "                record = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "            if not isinstance(record, dict):\n",
    "                continue\n",
    "\n",
    "            rid = _record_id(record, tool_field=tool_field)\n",
    "            tools = record.get(tool_field)\n",
    "            if not isinstance(tools, list):\n",
    "                continue\n",
    "\n",
    "            for tool_index, entry in enumerate(tools):\n",
    "                tool_obj, kind = _load_tool(entry)\n",
    "                if not tool_obj:\n",
    "                    continue\n",
    "                name = (tool_obj.get(\"name\") or \"\").strip()\n",
    "                if not name:\n",
    "                    continue\n",
    "\n",
    "                desc_print, desc_mode = _get_description_for_print(entry)\n",
    "                instance_key = _tool_instance_key(rid, tool_index, tool_obj)\n",
    "\n",
    "                tool_order.append(\n",
    "                    {\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_index,\n",
    "                        \"tool_name\": name,\n",
    "                        \"desc_print\": desc_print,\n",
    "                        \"desc_mode\": desc_mode,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"entry_kind\": kind,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    n_total = len(tool_order)\n",
    "    n_prev_reviewed = len(decisions_by_instance)\n",
    "\n",
    "    start_pos = 0\n",
    "    while start_pos < n_total and tool_order[start_pos][\"instance_key\"] in decisions_by_instance:\n",
    "        start_pos += 1\n",
    "\n",
    "    session_id = hashlib.sha256(f\"{time.time_ns()}\".encode(\"utf-8\")).hexdigest()[:12]\n",
    "    before_sha = _sha256_file(path)\n",
    "\n",
    "    length_policy_config = {\n",
    "        \"concise_soft_target\": {\n",
    "            \"ratio\": float(concise_target_ratio),\n",
    "            \"min_base_len\": int(concise_target_min_base_len),\n",
    "            \"min_chars\": int(concise_target_min_chars),\n",
    "            \"policy_name\": \"concise_soft_target_v1\",\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if prior_run_start is None:\n",
    "        _append_audit_event(\n",
    "            audit_file,\n",
    "            {\n",
    "                \"event_type\": \"run_start\",\n",
    "                \"ts\": int(time.time()),\n",
    "                \"session_id\": session_id,\n",
    "                \"mode\": mode_key,\n",
    "                \"model\": llm_model,\n",
    "                \"seed\": seed,\n",
    "                \"dataset_path\": str(path),\n",
    "                \"dataset_sha256_at_session_start\": before_sha,\n",
    "                \"tool_field\": tool_field,\n",
    "                \"n_total_occurrences\": n_total,\n",
    "                \"max_tokens_requested\": int(max_tokens),\n",
    "                \"retry_on_length\": bool(retry_on_length),\n",
    "                \"retry_max_tokens\": int(retry_max_tokens),\n",
    "                \"allow_reserialize_fallback\": bool(allow_reserialize_fallback),\n",
    "                \"num_candidates\": int(num_candidates),\n",
    "                \"min_sleep_sec_between_calls\": float(min_sleep_sec_between_calls),\n",
    "                \"stats_max_token_preview\": int(max_token_preview),\n",
    "                \"stats_max_token_string_len\": int(max_token_string_len),\n",
    "                \"candidate_snippet_chars\": int(candidate_snippet_chars),\n",
    "                \"length_policy_config\": length_policy_config,\n",
    "            },\n",
    "        )\n",
    "    else:\n",
    "        _append_audit_event(\n",
    "            audit_file,\n",
    "            {\n",
    "                \"event_type\": \"run_resume\",\n",
    "                \"ts\": int(time.time()),\n",
    "                \"session_id\": session_id,\n",
    "                \"mode\": mode_key,\n",
    "                \"model\": llm_model,\n",
    "                \"seed\": seed,\n",
    "                \"dataset_path\": str(path),\n",
    "                \"dataset_sha256_at_session_start\": before_sha,\n",
    "                \"tool_field\": tool_field,\n",
    "                \"n_total_occurrences\": n_total,\n",
    "                \"n_previously_reviewed\": n_prev_reviewed,\n",
    "                \"resume_from_index_1based\": (start_pos + 1) if start_pos < n_total else (n_total + 1),\n",
    "                \"num_candidates\": int(num_candidates),\n",
    "                \"candidate_snippet_chars\": int(candidate_snippet_chars),\n",
    "                \"length_policy_config\": length_policy_config,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    print(f\"Target: {path}\")\n",
    "    print(f\"Mode: {mode_key}\")\n",
    "    print(f\"Audit file (RESUMABLE): {audit_file}\")\n",
    "    print(f\"Tool occurrences total: {n_total}\")\n",
    "    if start_pos < n_total:\n",
    "        print(f\"Resume position: [{start_pos + 1}/{n_total}] (previously reviewed: {n_prev_reviewed})\")\n",
    "    else:\n",
    "        print(f\"Resume position: completed (previously reviewed: {n_prev_reviewed})\")\n",
    "    print(f\"LLM: {llm_model} @ {GEMINI_BASE_URL}\")\n",
    "    print(f\"Candidates per tool: {int(num_candidates)}\")\n",
    "    print(f\"Candidate snippet chars: {int(candidate_snippet_chars)}\")\n",
    "    if mode_key == \"style_concise\":\n",
    "        print(\n",
    "            \"Concise soft target: \"\n",
    "            f\"ratio={float(concise_target_ratio):.2f}, \"\n",
    "            f\"min_base_len={int(concise_target_min_base_len)}, \"\n",
    "            f\"min_chars={int(concise_target_min_chars)}\"\n",
    "        )\n",
    "    print(f\"Max tokens: {int(max_tokens)}; retry_on_length={bool(retry_on_length)}; retry_max_tokens={int(retry_max_tokens)}\")\n",
    "    print(\n",
    "        \"Commands: ENTER/ok=accept #1, 1..K=accept candidate, r=regenerate K, \"\n",
    "        \"e=edit candidate, m=manual, s=skip, q=quit, p<idx>=preview (e.g., p2)\\n\"\n",
    "    )\n",
    "\n",
    "    quit_requested = False\n",
    "    resume_next_index_1based: Optional[int] = None\n",
    "\n",
    "    max_prev = int(style_spec.get(\"max_prev_rewrite_chars\") or DEFAULT_MAX_PREV_REWRITE_CHARS)\n",
    "\n",
    "    # Session-level statistics (best-effort; heuristic).\n",
    "    session_summary: Dict[str, Any] = {\n",
    "        \"accepted\": 0,\n",
    "        \"edited\": 0,\n",
    "        \"manual\": 0,\n",
    "        \"skipped\": 0,\n",
    "        \"accepted_risk_labels\": {\"LOW\": 0, \"MED\": 0, \"HIGH\": 0, \"NA\": 0},\n",
    "        \"accepted_similarity_sum\": 0.0,\n",
    "        \"accepted_similarity_n\": 0,\n",
    "        # Length reporting\n",
    "        \"accepted_base_chars_sum\": 0,\n",
    "        \"accepted_cand_chars_sum\": 0,\n",
    "        \"accepted_len_ratio_sum\": 0.0,\n",
    "        \"accepted_len_ratio_n\": 0,\n",
    "        \"accepted_len_delta_sum\": 0,\n",
    "        \"accepted_soft_target_applicable_n\": 0,\n",
    "        \"accepted_within_soft_target_n\": 0,\n",
    "    }\n",
    "\n",
    "    for pos in range(start_pos, n_total):\n",
    "        item = tool_order[pos]\n",
    "        idx = pos + 1\n",
    "\n",
    "        name = item[\"tool_name\"]\n",
    "        desc_mode = item[\"desc_mode\"]\n",
    "        old_desc_print = item[\"desc_print\"]\n",
    "        instance_key = item[\"instance_key\"]\n",
    "        rid = item[\"record_id\"]\n",
    "        tool_i = item[\"tool_index\"]\n",
    "\n",
    "        generation_round = int(regen_counts.get(instance_key, 0))\n",
    "        previous_rewrite_hint: Optional[str] = last_rejected_text_by_instance.get(instance_key)\n",
    "\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"[{idx}/{n_total}] {name}\")\n",
    "        print(f\"instance_key: {instance_key} (record_id={rid}, tool_index={tool_i})\")\n",
    "\n",
    "        if desc_mode == \"raw_json\":\n",
    "            print(\"Current description RAW (escaped):\")\n",
    "            print(old_desc_print if old_desc_print else \"(empty)\")\n",
    "            base_desc = _decode_raw_json_string(old_desc_print) if old_desc_print else \"\"\n",
    "            print(\"\\nCurrent description DECODED:\")\n",
    "            print(base_desc if base_desc else \"(empty)\")\n",
    "        else:\n",
    "            base_desc = old_desc_print or \"\"\n",
    "            print(\"Current description:\")\n",
    "            print(base_desc if base_desc else \"(empty)\")\n",
    "\n",
    "        base_desc = (base_desc or \"\").strip()\n",
    "        base_len_chars = len(base_desc)\n",
    "\n",
    "        # Build policy once per instance (stable for candidate set).\n",
    "        length_policy = _make_length_policy(\n",
    "            base_desc=base_desc,\n",
    "            mode_key=mode_key,\n",
    "            concise_ratio=float(concise_target_ratio),\n",
    "            concise_min_base_len=int(concise_target_min_base_len),\n",
    "            concise_min_chars=int(concise_target_min_chars),\n",
    "        )\n",
    "\n",
    "        _print_base_stats(base_desc, max_preview=int(max_token_preview), max_tok_len=int(max_token_string_len))\n",
    "        if mode_key == \"style_concise\":\n",
    "            ct = length_policy.get(\"concise_soft_target\", {}) if isinstance(length_policy.get(\"concise_soft_target\"), dict) else {}\n",
    "            if ct.get(\"applied\") and isinstance(ct.get(\"target_chars\"), int):\n",
    "                print(f\"Concise soft target (applied): target_chars={ct.get('target_chars')} (base_len={base_len_chars})\")\n",
    "            else:\n",
    "                print(f\"Concise soft target (not applied): reason={ct.get('reason')} (base_len={base_len_chars})\")\n",
    "\n",
    "        candidates: List[Dict[str, Any]] = []\n",
    "        last_generated_text: Optional[str] = None\n",
    "\n",
    "        while True:\n",
    "            if not candidates:\n",
    "                try:\n",
    "                    candidates, last_generated_text = generate_k_candidates_with_stats(\n",
    "                        client=client,\n",
    "                        tool_name=name,\n",
    "                        base_description=base_desc,\n",
    "                        model=llm_model,\n",
    "                        seed=seed,\n",
    "                        max_tokens=max_tokens,\n",
    "                        retry_on_length=retry_on_length,\n",
    "                        retry_max_tokens=retry_max_tokens,\n",
    "                        mode_key=mode_key,\n",
    "                        style_spec=style_spec,\n",
    "                        generation_round=generation_round,\n",
    "                        k=int(num_candidates),\n",
    "                        previous_rewrite_hint=previous_rewrite_hint,\n",
    "                        min_sleep_sec_between_calls=float(min_sleep_sec_between_calls),\n",
    "                        length_policy=length_policy,\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nLLM ERROR (candidate set generation): {e}\")\n",
    "                    cmd = _normalize_cmd(input(\"Choice [m=manual, s=skip, q=quit] > \"))\n",
    "                    now = int(time.time())\n",
    "\n",
    "                    if cmd == \"q\":\n",
    "                        quit_requested = True\n",
    "                        resume_next_index_1based = idx\n",
    "                        break\n",
    "\n",
    "                    if cmd == \"s\":\n",
    "                        decisions_by_instance[instance_key] = (\"skipped\", None, None)\n",
    "                        _append_audit_event(\n",
    "                            audit_file,\n",
    "                            {\n",
    "                                \"event_type\": \"decision\",\n",
    "                                \"ts\": now,\n",
    "                                \"session_id\": session_id,\n",
    "                                \"status\": \"skipped\",\n",
    "                                \"tool_name\": name,\n",
    "                                \"instance_key\": instance_key,\n",
    "                                \"record_id\": rid,\n",
    "                                \"tool_index\": tool_i,\n",
    "                                \"model\": llm_model,\n",
    "                                \"seed\": seed,\n",
    "                                \"mode\": mode_key,\n",
    "                                \"base_description\": base_desc,\n",
    "                                \"final_description\": None,\n",
    "                                \"source\": \"user\",\n",
    "                                \"note\": \"skip_after_llm_error\",\n",
    "                                \"length_policy\": length_policy,\n",
    "                            },\n",
    "                        )\n",
    "                        session_summary[\"skipped\"] += 1\n",
    "                        break\n",
    "\n",
    "                    if cmd == \"m\":\n",
    "                        manual_final = input(\"Manual final description (empty cancels) > \").rstrip(\"\\n\").strip()\n",
    "                        status = \"manual\" if manual_final else \"skipped\"\n",
    "                        decisions_by_instance[instance_key] = (status, manual_final or None, None)\n",
    "                        diff_stats = compute_candidate_stats(\n",
    "                            base_text=base_desc,\n",
    "                            cand_text=manual_final,\n",
    "                            mode_key=mode_key,\n",
    "                            length_policy=length_policy,\n",
    "                        ) if manual_final else None\n",
    "\n",
    "                        _append_audit_event(\n",
    "                            audit_file,\n",
    "                            {\n",
    "                                \"event_type\": \"decision\",\n",
    "                                \"ts\": now,\n",
    "                                \"session_id\": session_id,\n",
    "                                \"status\": status,\n",
    "                                \"tool_name\": name,\n",
    "                                \"instance_key\": instance_key,\n",
    "                                \"record_id\": rid,\n",
    "                                \"tool_index\": tool_i,\n",
    "                                \"model\": llm_model,\n",
    "                                \"seed\": seed,\n",
    "                                \"mode\": mode_key,\n",
    "                                \"base_description\": base_desc,\n",
    "                                \"final_description\": manual_final or None,\n",
    "                                \"source\": \"user\",\n",
    "                                \"note\": \"manual_after_llm_error\",\n",
    "                                \"diff_stats\": diff_stats,\n",
    "                                \"length_policy\": length_policy,\n",
    "                            },\n",
    "                        )\n",
    "                        if status == \"manual\":\n",
    "                            session_summary[\"manual\"] += 1\n",
    "                        else:\n",
    "                            session_summary[\"skipped\"] += 1\n",
    "                        break\n",
    "\n",
    "                    candidates = []\n",
    "                    continue\n",
    "\n",
    "                # Candidate-set generation event is logged for auditability (include length metrics).\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"candidates_generated\",\n",
    "                        \"ts\": int(time.time()),\n",
    "                        \"session_id\": session_id,\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"mode\": mode_key,\n",
    "                        \"model\": llm_model,\n",
    "                        \"seed\": seed,\n",
    "                        \"generation_round\": int(generation_round),\n",
    "                        \"num_candidates_requested\": int(num_candidates),\n",
    "                        \"base_len_chars\": int(base_len_chars),\n",
    "                        \"length_policy\": length_policy,\n",
    "                        \"candidates_summary\": [\n",
    "                            {\n",
    "                                \"candidate_index\": c.get(\"candidate_index\"),\n",
    "                                \"text_sha256\": _sha256_text((c.get(\"text\") or \"\").strip()),\n",
    "                                \"text_len\": len((c.get(\"text\") or \"\").strip()),\n",
    "                                \"error\": c.get(\"error\"),\n",
    "                                \"duplicate\": bool(c.get(\"duplicate\", False)),\n",
    "                                \"risk_label\": ((c.get(\"stats\") or {}).get(\"risk_label\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"similarity_ratio\": ((c.get(\"stats\") or {}).get(\"similarity_ratio\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"len_ratio\": ((c.get(\"stats\") or {}).get(\"len_ratio\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"len_delta_chars\": ((c.get(\"stats\") or {}).get(\"len_delta_chars\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"concise_soft_target_applied\": ((c.get(\"stats\") or {}).get(\"concise_soft_target_applied\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"concise_soft_target_chars\": ((c.get(\"stats\") or {}).get(\"concise_soft_target_chars\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                                \"within_soft_target\": ((c.get(\"stats\") or {}).get(\"within_soft_target\") if isinstance(c.get(\"stats\"), dict) else None),\n",
    "                            }\n",
    "                            for c in candidates\n",
    "                        ],\n",
    "                    },\n",
    "                )\n",
    "\n",
    "            print(\"\\nCandidates overview:\")\n",
    "            for c in candidates:\n",
    "                _print_candidate_summary_line(\n",
    "                    int(c.get(\"candidate_index\") or 0),\n",
    "                    c,\n",
    "                    max_preview=int(max_token_preview),\n",
    "                    max_tok_len=int(max_token_string_len),\n",
    "                    snippet_chars=int(candidate_snippet_chars),\n",
    "                )\n",
    "\n",
    "            cmd = _normalize_cmd(\n",
    "                input(\n",
    "                    f\"\\nChoice [ENTER=accept #1, 1..{int(num_candidates)}=accept, r=regen, e=edit, m=manual, s=skip, q=quit, p<idx>=preview] > \"\n",
    "                )\n",
    "            )\n",
    "            now = int(time.time())\n",
    "\n",
    "            if cmd == \"q\":\n",
    "                quit_requested = True\n",
    "                resume_next_index_1based = idx\n",
    "                break\n",
    "\n",
    "            if cmd == \"s\":\n",
    "                decisions_by_instance[instance_key] = (\"skipped\", None, None)\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"decision\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"status\": \"skipped\",\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"model\": llm_model,\n",
    "                        \"seed\": seed,\n",
    "                        \"mode\": mode_key,\n",
    "                        \"base_description\": base_desc,\n",
    "                        \"final_description\": None,\n",
    "                        \"source\": \"user\",\n",
    "                        \"note\": \"skip\",\n",
    "                        \"length_policy\": length_policy,\n",
    "                    },\n",
    "                )\n",
    "                session_summary[\"skipped\"] += 1\n",
    "                break\n",
    "\n",
    "            if cmd == \"r\":\n",
    "                generation_round += 1\n",
    "                regen_counts[instance_key] = int(generation_round)\n",
    "\n",
    "                if last_generated_text and isinstance(last_generated_text, str) and last_generated_text.strip():\n",
    "                    hint = last_generated_text.strip()\n",
    "                    if len(hint) > max_prev:\n",
    "                        hint = hint[:max_prev].rstrip()\n",
    "                    previous_rewrite_hint = hint\n",
    "                    last_rejected_text_by_instance[instance_key] = hint\n",
    "\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"regenerate\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"mode\": mode_key,\n",
    "                        \"generation_round\": int(generation_round),\n",
    "                        \"last_generated_text\": previous_rewrite_hint,\n",
    "                        \"last_generated_text_sha256\": _sha256_text(previous_rewrite_hint or \"\"),\n",
    "                        \"length_policy\": length_policy,\n",
    "                    },\n",
    "                )\n",
    "\n",
    "                candidates = []\n",
    "                last_generated_text = None\n",
    "                if min_sleep_sec_between_calls > 0:\n",
    "                    time.sleep(float(min_sleep_sec_between_calls))\n",
    "                continue\n",
    "\n",
    "            if cmd == \"m\":\n",
    "                manual_final = input(\"Manual final description (empty cancels) > \").rstrip(\"\\n\").strip()\n",
    "                status = \"manual\" if manual_final else \"skipped\"\n",
    "                decisions_by_instance[instance_key] = (status, manual_final or None, None)\n",
    "\n",
    "                diff_stats = compute_candidate_stats(\n",
    "                    base_text=base_desc,\n",
    "                    cand_text=manual_final,\n",
    "                    mode_key=mode_key,\n",
    "                    length_policy=length_policy,\n",
    "                ) if manual_final else None\n",
    "\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"decision\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"status\": status,\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"model\": llm_model,\n",
    "                        \"seed\": seed,\n",
    "                        \"mode\": mode_key,\n",
    "                        \"base_description\": base_desc,\n",
    "                        \"final_description\": manual_final or None,\n",
    "                        \"source\": \"user\",\n",
    "                        \"note\": \"manual_replace\",\n",
    "                        \"diff_stats\": diff_stats,\n",
    "                        \"length_policy\": length_policy,\n",
    "                    },\n",
    "                )\n",
    "                if status == \"manual\":\n",
    "                    session_summary[\"manual\"] += 1\n",
    "                else:\n",
    "                    session_summary[\"skipped\"] += 1\n",
    "                break\n",
    "\n",
    "            if cmd == \"e\":\n",
    "                raw_idx = input(f\"Candidate index to edit [1..{int(num_candidates)}] (empty=1) > \").strip()\n",
    "                chosen_i = 1\n",
    "                if raw_idx and raw_idx.isdigit():\n",
    "                    chosen_i = int(raw_idx)\n",
    "                if not (1 <= chosen_i <= int(num_candidates)):\n",
    "                    print(\"Invalid candidate index.\")\n",
    "                    continue\n",
    "\n",
    "                cand = candidates[chosen_i - 1] if (chosen_i - 1) < len(candidates) else None\n",
    "                base_text = (cand.get(\"text\") or \"\").strip() if isinstance(cand, dict) else \"\"\n",
    "                if base_text:\n",
    "                    print(\"\\nSelected candidate text:\")\n",
    "                    print(base_text)\n",
    "                else:\n",
    "                    print(\"\\nSelected candidate is empty; editing starts from empty string.\")\n",
    "                    base_text = \"\"\n",
    "\n",
    "                edited = input(\"Edit final description (empty cancels) > \").rstrip(\"\\n\").strip()\n",
    "                status = \"edited\" if edited else \"skipped\"\n",
    "                bundle = cand.get(\"bundle\") if isinstance(cand, dict) else None\n",
    "                stats = compute_candidate_stats(\n",
    "                    base_text=base_desc,\n",
    "                    cand_text=edited,\n",
    "                    mode_key=mode_key,\n",
    "                    length_policy=length_policy,\n",
    "                ) if edited else None\n",
    "\n",
    "                decisions_by_instance[instance_key] = (status, edited or None, bundle if isinstance(bundle, dict) else None)\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"decision\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"status\": status,\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"model\": llm_model,\n",
    "                        \"seed\": seed,\n",
    "                        \"mode\": mode_key,\n",
    "                        \"base_description\": base_desc,\n",
    "                        \"final_description\": edited or None,\n",
    "                        \"source\": \"user\",\n",
    "                        \"note\": \"edit_candidate\",\n",
    "                        \"chosen_candidate_index\": int(chosen_i),\n",
    "                        \"llm_bundle\": bundle if isinstance(bundle, dict) else None,\n",
    "                        \"diff_stats\": stats,\n",
    "                        \"generation_round\": int(generation_round),\n",
    "                        \"length_policy\": length_policy,\n",
    "                    },\n",
    "                )\n",
    "                if status == \"edited\":\n",
    "                    session_summary[\"edited\"] += 1\n",
    "                else:\n",
    "                    session_summary[\"skipped\"] += 1\n",
    "                break\n",
    "\n",
    "            choice_i = 1 if cmd == \"y\" else _parse_candidate_choice(cmd, k=int(num_candidates))\n",
    "            if choice_i is not None:\n",
    "                if not (1 <= int(choice_i) <= int(num_candidates)):\n",
    "                    print(\"Invalid candidate index.\")\n",
    "                    continue\n",
    "                cand = candidates[int(choice_i) - 1] if (int(choice_i) - 1) < len(candidates) else None\n",
    "                if not isinstance(cand, dict):\n",
    "                    print(\"Candidate not available.\")\n",
    "                    continue\n",
    "                if cand.get(\"error\") or not (cand.get(\"text\") or \"\").strip():\n",
    "                    print(\"Selected candidate is not acceptable (empty or error).\")\n",
    "                    _print_candidate_full(int(choice_i), cand, max_preview=int(max_token_preview), max_tok_len=int(max_token_string_len))\n",
    "                    continue\n",
    "\n",
    "                final_desc = (cand.get(\"text\") or \"\").strip()\n",
    "                bundle = cand.get(\"bundle\") if isinstance(cand.get(\"bundle\"), dict) else None\n",
    "                stats = cand.get(\"stats\") if isinstance(cand.get(\"stats\"), dict) else compute_candidate_stats(\n",
    "                    base_text=base_desc,\n",
    "                    cand_text=final_desc,\n",
    "                    mode_key=mode_key,\n",
    "                    length_policy=length_policy,\n",
    "                )\n",
    "\n",
    "                decisions_by_instance[instance_key] = (\"accepted\", final_desc, bundle)\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"decision\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"status\": \"accepted\",\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"model\": llm_model,\n",
    "                        \"seed\": seed,\n",
    "                        \"mode\": mode_key,\n",
    "                        \"base_description\": base_desc,\n",
    "                        \"final_description\": final_desc,\n",
    "                        \"source\": \"llm\",\n",
    "                        \"chosen_candidate_index\": int(choice_i),\n",
    "                        \"generation_round\": int(generation_round),\n",
    "                        \"llm_bundle\": bundle,\n",
    "                        \"diff_stats\": stats,\n",
    "                        \"length_policy\": length_policy,\n",
    "                    },\n",
    "                )\n",
    "\n",
    "                # Session summary update.\n",
    "                session_summary[\"accepted\"] += 1\n",
    "                rl = (stats.get(\"risk_label\") if isinstance(stats, dict) else None) or \"NA\"\n",
    "                if rl not in session_summary[\"accepted_risk_labels\"]:\n",
    "                    rl = \"NA\"\n",
    "                session_summary[\"accepted_risk_labels\"][rl] += 1\n",
    "\n",
    "                sim = stats.get(\"similarity_ratio\") if isinstance(stats, dict) else None\n",
    "                if isinstance(sim, (int, float)):\n",
    "                    session_summary[\"accepted_similarity_sum\"] += float(sim)\n",
    "                    session_summary[\"accepted_similarity_n\"] += 1\n",
    "\n",
    "                # Length summary\n",
    "                bl = stats.get(\"base_len_chars\") if isinstance(stats, dict) else None\n",
    "                cl = stats.get(\"cand_len_chars\") if isinstance(stats, dict) else None\n",
    "                lr = stats.get(\"len_ratio\") if isinstance(stats, dict) else None\n",
    "                ld = stats.get(\"len_delta_chars\") if isinstance(stats, dict) else None\n",
    "                if isinstance(bl, int) and isinstance(cl, int):\n",
    "                    session_summary[\"accepted_base_chars_sum\"] += int(bl)\n",
    "                    session_summary[\"accepted_cand_chars_sum\"] += int(cl)\n",
    "                if isinstance(lr, (int, float)):\n",
    "                    session_summary[\"accepted_len_ratio_sum\"] += float(lr)\n",
    "                    session_summary[\"accepted_len_ratio_n\"] += 1\n",
    "                if isinstance(ld, int):\n",
    "                    session_summary[\"accepted_len_delta_sum\"] += int(ld)\n",
    "\n",
    "                wst = stats.get(\"within_soft_target\") if isinstance(stats, dict) else None\n",
    "                st_applied = bool(stats.get(\"concise_soft_target_applied\", False)) if isinstance(stats, dict) else False\n",
    "                if st_applied:\n",
    "                    session_summary[\"accepted_soft_target_applicable_n\"] += 1\n",
    "                    if wst is True:\n",
    "                        session_summary[\"accepted_within_soft_target_n\"] += 1\n",
    "\n",
    "                break\n",
    "\n",
    "            if cmd.startswith(\"p\"):\n",
    "                raw_idx = cmd[1:].strip()\n",
    "                if raw_idx.isdigit():\n",
    "                    vi = int(raw_idx)\n",
    "                    if 1 <= vi <= int(num_candidates):\n",
    "                        _print_candidate_full(vi, candidates[vi - 1], max_preview=int(max_token_preview), max_tok_len=int(max_token_string_len))\n",
    "                        continue\n",
    "                print(\"Preview command format: p<index>, for example: p2\")\n",
    "                continue\n",
    "\n",
    "            print(\"Invalid command. Preview: p<index> (example: p2).\")\n",
    "\n",
    "        if quit_requested:\n",
    "            break\n",
    "\n",
    "    # ========= Apply decisions to file =========\n",
    "    tmp_path = path.with_suffix(path.suffix + \".tmp\")\n",
    "    updated_count = 0\n",
    "    patch_failures = 0\n",
    "\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as fin, tmp_path.open(\"w\", encoding=\"utf-8\") as fout:\n",
    "        for raw_line in fin:\n",
    "            line = raw_line.rstrip(\"\\n\")\n",
    "            if not line.strip():\n",
    "                fout.write(line + \"\\n\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                record = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                fout.write(line + \"\\n\")\n",
    "                continue\n",
    "\n",
    "            if not isinstance(record, dict):\n",
    "                fout.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "                continue\n",
    "\n",
    "            rid = _record_id(record, tool_field=tool_field)\n",
    "            tools = record.get(tool_field)\n",
    "\n",
    "            if isinstance(tools, list):\n",
    "                new_tools: List[Any] = []\n",
    "                for tool_index, entry in enumerate(tools):\n",
    "                    tool_obj, kind = _load_tool(entry)\n",
    "                    if not tool_obj:\n",
    "                        new_tools.append(entry)\n",
    "                        continue\n",
    "\n",
    "                    instance_key = _tool_instance_key(rid, tool_index, tool_obj)\n",
    "                    decision = decisions_by_instance.get(instance_key)\n",
    "\n",
    "                    if decision is None:\n",
    "                        new_tools.append(entry)\n",
    "                        continue\n",
    "\n",
    "                    status, new_desc, llm_bundle = decision\n",
    "                    if status in (\"accepted\", \"edited\", \"manual\") and new_desc:\n",
    "                        if kind == \"json_str\" and isinstance(entry, str):\n",
    "                            already_ok = False\n",
    "                            try:\n",
    "                                obj0 = json.loads(entry)\n",
    "                                if isinstance(obj0, dict) and obj0.get(\"description\") == new_desc:\n",
    "                                    already_ok = True\n",
    "                            except Exception:\n",
    "                                already_ok = False\n",
    "\n",
    "                            if already_ok:\n",
    "                                new_tools.append(entry)\n",
    "                                continue\n",
    "\n",
    "                            patched, ok, reason = _replace_top_level_string_field_in_raw_object(entry, \"description\", new_desc)\n",
    "                            if ok:\n",
    "                                new_tools.append(patched)\n",
    "                                updated_count += 1\n",
    "                            else:\n",
    "                                fallback_ok = False\n",
    "                                fallback_patched = entry\n",
    "                                if allow_reserialize_fallback:\n",
    "                                    try:\n",
    "                                        obj = json.loads(entry)\n",
    "                                        if isinstance(obj, dict):\n",
    "                                            obj[\"description\"] = new_desc\n",
    "                                            fallback_patched = json.dumps(obj, ensure_ascii=False)\n",
    "                                            fallback_ok = True\n",
    "                                    except Exception:\n",
    "                                        fallback_ok = False\n",
    "\n",
    "                                if fallback_ok:\n",
    "                                    new_tools.append(fallback_patched)\n",
    "                                    updated_count += 1\n",
    "                                    _append_audit_event(\n",
    "                                        audit_file,\n",
    "                                        {\n",
    "                                            \"event_type\": \"patch_fallback_reserialize\",\n",
    "                                            \"ts\": int(time.time()),\n",
    "                                            \"session_id\": session_id,\n",
    "                                            \"instance_key\": instance_key,\n",
    "                                            \"record_id\": rid,\n",
    "                                            \"tool_index\": tool_index,\n",
    "                                            \"tool_name\": tool_obj.get(\"name\"),\n",
    "                                            \"mode\": mode_key,\n",
    "                                            \"entry_sha256_before\": _sha256_text(entry),\n",
    "                                            \"entry_sha256_after\": _sha256_text(fallback_patched),\n",
    "                                            \"patch_reason\": reason,\n",
    "                                        },\n",
    "                                    )\n",
    "                                else:\n",
    "                                    new_tools.append(entry)\n",
    "                                    patch_failures += 1\n",
    "                        else:\n",
    "                            if tool_obj.get(\"description\") == new_desc:\n",
    "                                new_tools.append(tool_obj)\n",
    "                                continue\n",
    "                            tool_obj[\"description\"] = new_desc\n",
    "                            new_tools.append(tool_obj)\n",
    "                            updated_count += 1\n",
    "                    else:\n",
    "                        new_tools.append(entry)\n",
    "\n",
    "                record[tool_field] = new_tools\n",
    "\n",
    "            fout.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    if create_backup_of_target:\n",
    "        bak_path = path.with_suffix(path.suffix + \".bak\")\n",
    "        if not bak_path.exists():\n",
    "            shutil.copy2(path, bak_path)\n",
    "\n",
    "    tmp_path.replace(path)\n",
    "    after_sha = _sha256_file(path)\n",
    "\n",
    "    n_reviewed = len(decisions_by_instance)\n",
    "    n_skipped = sum(1 for st, _, _ in decisions_by_instance.values() if st == \"skipped\")\n",
    "    completed = (n_reviewed >= n_total) and (not quit_requested)\n",
    "\n",
    "    avg_sim = None\n",
    "    if int(session_summary[\"accepted_similarity_n\"]) > 0:\n",
    "        avg_sim = float(session_summary[\"accepted_similarity_sum\"]) / float(session_summary[\"accepted_similarity_n\"])\n",
    "\n",
    "    avg_len_ratio = None\n",
    "    if int(session_summary[\"accepted_len_ratio_n\"]) > 0:\n",
    "        avg_len_ratio = float(session_summary[\"accepted_len_ratio_sum\"]) / float(session_summary[\"accepted_len_ratio_n\"])\n",
    "\n",
    "    avg_len_delta = None\n",
    "    if int(session_summary[\"accepted\"]) > 0:\n",
    "        avg_len_delta = float(session_summary[\"accepted_len_delta_sum\"]) / float(session_summary[\"accepted\"])\n",
    "\n",
    "    avg_base_len = None\n",
    "    avg_cand_len = None\n",
    "    if int(session_summary[\"accepted\"]) > 0:\n",
    "        avg_base_len = float(session_summary[\"accepted_base_chars_sum\"]) / float(session_summary[\"accepted\"])\n",
    "        avg_cand_len = float(session_summary[\"accepted_cand_chars_sum\"]) / float(session_summary[\"accepted\"])\n",
    "\n",
    "    _append_audit_event(\n",
    "        audit_file,\n",
    "        {\n",
    "            \"event_type\": \"run_end\",\n",
    "            \"ts\": int(time.time()),\n",
    "            \"session_id\": session_id,\n",
    "            \"mode\": mode_key,\n",
    "            \"model\": llm_model,\n",
    "            \"seed\": seed,\n",
    "            \"dataset_path\": str(path),\n",
    "            \"dataset_sha256_at_session_start\": before_sha,\n",
    "            \"dataset_sha256_at_session_end\": after_sha,\n",
    "            \"n_total_occurrences\": n_total,\n",
    "            \"n_reviewed_total\": n_reviewed,\n",
    "            \"n_updated_this_session\": updated_count,\n",
    "            \"n_skipped_total\": n_skipped,\n",
    "            \"completed\": bool(completed),\n",
    "            \"quit_requested\": bool(quit_requested),\n",
    "            \"raw_patch_failures_this_session\": patch_failures,\n",
    "            \"resume_next_index_1based\": resume_next_index_1based if quit_requested else (n_total + 1 if completed else None),\n",
    "            \"session_summary\": {\n",
    "                \"accepted\": int(session_summary[\"accepted\"]),\n",
    "                \"edited\": int(session_summary[\"edited\"]),\n",
    "                \"manual\": int(session_summary[\"manual\"]),\n",
    "                \"skipped\": int(session_summary[\"skipped\"]),\n",
    "                \"accepted_risk_labels\": session_summary[\"accepted_risk_labels\"],\n",
    "                \"accepted_avg_similarity\": avg_sim,\n",
    "                \"accepted_similarity_n\": int(session_summary[\"accepted_similarity_n\"]),\n",
    "                \"accepted_avg_len_ratio\": avg_len_ratio,\n",
    "                \"accepted_len_ratio_n\": int(session_summary[\"accepted_len_ratio_n\"]),\n",
    "                \"accepted_avg_len_delta_chars\": avg_len_delta,\n",
    "                \"accepted_avg_base_len_chars\": avg_base_len,\n",
    "                \"accepted_avg_cand_len_chars\": avg_cand_len,\n",
    "                \"accepted_soft_target_applicable_n\": int(session_summary[\"accepted_soft_target_applicable_n\"]),\n",
    "                \"accepted_within_soft_target_n\": int(session_summary[\"accepted_within_soft_target_n\"]),\n",
    "            },\n",
    "            \"length_policy_config\": length_policy_config,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(\"\\nChanges applied.\")\n",
    "    print(f\"Mode: {mode_key}\")\n",
    "    print(f\"Candidates per tool: {int(num_candidates)}\")\n",
    "    print(f\"Candidate snippet chars: {int(candidate_snippet_chars)}\")\n",
    "    print(f\"Descriptions updated (this session): {updated_count}\")\n",
    "    if patch_failures:\n",
    "        print(f\"Raw JSON-string patch failures (left unchanged): {patch_failures}\")\n",
    "    print(f\"Reviewed total (from audit): {n_reviewed} / {n_total}\")\n",
    "    print(f\"Completed: {completed} (quit_requested={quit_requested})\")\n",
    "    if quit_requested and resume_next_index_1based is not None:\n",
    "        print(f\"Resume next time from: [{resume_next_index_1based}/{n_total}]\")\n",
    "    print(f\"Updated file: {path}\")\n",
    "    print(f\"Audit file (same on resume): {audit_file}\")\n",
    "\n",
    "    print(\"\\nSession summary (heuristic):\")\n",
    "    print(\n",
    "        f\"  accepted={int(session_summary['accepted'])}, edited={int(session_summary['edited'])}, \"\n",
    "        f\"manual={int(session_summary['manual'])}, skipped={int(session_summary['skipped'])}\"\n",
    "    )\n",
    "    print(f\"  accepted_risk_labels={session_summary['accepted_risk_labels']}\")\n",
    "    if avg_sim is not None:\n",
    "        print(f\"  accepted_avg_similarity={avg_sim:.2f} (n={int(session_summary['accepted_similarity_n'])})\")\n",
    "    if avg_len_ratio is not None:\n",
    "        print(f\"  accepted_avg_len_ratio={avg_len_ratio:.2f} (n={int(session_summary['accepted_len_ratio_n'])})\")\n",
    "    if avg_len_delta is not None:\n",
    "        print(f\"  accepted_avg_len_delta_chars={avg_len_delta:+.1f}\")\n",
    "    if avg_base_len is not None and avg_cand_len is not None:\n",
    "        print(f\"  accepted_avg_base_len_chars={avg_base_len:.1f}; accepted_avg_cand_len_chars={avg_cand_len:.1f}\")\n",
    "    if mode_key == \"style_concise\":\n",
    "        print(\n",
    "            \"  accepted_soft_target: \"\n",
    "            f\"applicable={int(session_summary['accepted_soft_target_applicable_n'])}, \"\n",
    "            f\"within={int(session_summary['accepted_within_soft_target_n'])}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def _derive_working_copy_path(input_path: str, mode_key: str) -> str:\n",
    "    p = Path(input_path)\n",
    "    return str(p.with_name(f\"{p.stem}.WORKING_COPY.{mode_key}{p.suffix}\"))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ----- Inputs -----\n",
    "    INPUT_JSONL = os.environ.get(\"INPUT_JSONL\") or \"When2Call/data/test/when2call_test_llm_judge.jsonl\"\n",
    "    MODE_KEY = os.environ.get(\"MODE_KEY\") or \"style_concise\"   # style_verbose | style_concise (aliases: style_coicnoso, style_coinceise)\n",
    "    LLM_MODEL = os.environ.get(\"LLM_MODEL\") or LLM_MODEL_DEFAULT\n",
    "\n",
    "    mode_key_resolved, _ = _resolve_style(MODE_KEY)\n",
    "\n",
    "    # Per-style working copy (separate dataset per style, by default).\n",
    "    OUTPUT_JSONL = os.environ.get(\"OUTPUT_JSONL\") or _derive_working_copy_path(INPUT_JSONL, mode_key_resolved)\n",
    "\n",
    "    working = make_working_copy(INPUT_JSONL, OUTPUT_JSONL, overwrite=False)\n",
    "    print(f\"Working copy: {working}\")\n",
    "\n",
    "    # ----- Runtime knobs -----\n",
    "    seed_env = os.environ.get(\"GEMINI_SEED\")\n",
    "    seed_val: Optional[int] = int(seed_env.strip()) if (seed_env and seed_env.strip()) else None\n",
    "\n",
    "    max_tokens_env = os.environ.get(\"GEMINI_MAX_TOKENS\")\n",
    "    max_tokens_val = int(max_tokens_env.strip()) if (max_tokens_env and max_tokens_env.strip()) else DEFAULT_MAX_TOKENS\n",
    "\n",
    "    retry_max_tokens_env = os.environ.get(\"GEMINI_RETRY_MAX_TOKENS\")\n",
    "    retry_max_tokens_val = int(retry_max_tokens_env.strip()) if (retry_max_tokens_env and retry_max_tokens_env.strip()) else RETRY_MAX_TOKENS\n",
    "\n",
    "    allow_reserialize_env = os.environ.get(\"ALLOW_RESERIALIZE_FALLBACK\")\n",
    "    allow_reserialize_val = (\n",
    "        bool(int(allow_reserialize_env.strip()))\n",
    "        if (allow_reserialize_env and allow_reserialize_env.strip())\n",
    "        else DEFAULT_ALLOW_RESERIALIZE_FALLBACK\n",
    "    )\n",
    "\n",
    "    num_candidates_val = _safe_int_env(\"NUM_CANDIDATES\", DEFAULT_NUM_CANDIDATES)\n",
    "    min_sleep_val = _safe_float_env(\"MIN_SLEEP_SEC_BETWEEN_CALLS\", 0.0)\n",
    "\n",
    "    max_preview_val = _safe_int_env(\"STATS_MAX_TOKEN_PREVIEW\", DEFAULT_MAX_TOKEN_PREVIEW)\n",
    "    max_tok_len_val = _safe_int_env(\"STATS_MAX_TOKEN_STRING_LEN\", DEFAULT_MAX_TOKEN_STRING_LEN)\n",
    "\n",
    "    cand_snippet_val = _safe_int_env(\"CANDIDATE_SNIPPET_CHARS\", DEFAULT_CANDIDATE_SNIPPET_CHARS)\n",
    "\n",
    "    # Concise soft target (reviewer-proof): configurable via env.\n",
    "    concise_ratio_val = _safe_float_env(\"CONCISE_TARGET_RATIO\", DEFAULT_CONCISE_TARGET_RATIO)\n",
    "    concise_min_base_len_val = _safe_int_env(\"CONCISE_TARGET_MIN_BASE_LEN\", DEFAULT_CONCISE_TARGET_MIN_BASE_LEN)\n",
    "    concise_min_chars_val = _safe_int_env(\"CONCISE_TARGET_MIN_CHARS\", DEFAULT_CONCISE_TARGET_MIN_CHARS)\n",
    "\n",
    "    interactive_llm_tools_in_jsonl(\n",
    "        working,\n",
    "        tool_field=\"tools\",\n",
    "        create_backup_of_target=False,\n",
    "        llm_model=LLM_MODEL,\n",
    "        seed=seed_val,\n",
    "        max_tokens=max_tokens_val,\n",
    "        retry_on_length=RETRY_ON_LENGTH,\n",
    "        retry_max_tokens=retry_max_tokens_val,\n",
    "        allow_reserialize_fallback=allow_reserialize_val,\n",
    "        min_sleep_sec_between_calls=float(min_sleep_val),\n",
    "        audit_dir=os.environ.get(\"AUDIT_DIR\") or \"audit\",\n",
    "        mode_key=mode_key_resolved,\n",
    "        num_candidates=int(num_candidates_val),\n",
    "        max_token_preview=int(max_preview_val),\n",
    "        max_token_string_len=int(max_tok_len_val),\n",
    "        candidate_snippet_chars=int(cand_snippet_val),\n",
    "        concise_target_ratio=float(concise_ratio_val),\n",
    "        concise_target_min_base_len=int(concise_min_base_len_val),\n",
    "        concise_target_min_chars=int(concise_min_chars_val),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e3e2441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working copy: When2Call/data/test/when2call_test_llm_judge.WORKING_COPY.style_concise.jsonl\n",
      "Target: When2Call/data/test/when2call_test_llm_judge.WORKING_COPY.style_concise.jsonl\n",
      "Mode: style_concise\n",
      "Audit file (RESUMABLE): audit/7805585800e6/when2call_test_llm_judge.WORKING_COPY.style_concise.7805585800e6.style_concise.gemini-2.5-flash.audit.jsonl\n",
      "Tool occurrences total: 978\n",
      "Resume position: [3/978] (previously reviewed: 2)\n",
      "LLM: gemini-2.5-flash @ https://generativelanguage.googleapis.com/v1beta/openai/\n",
      "Max tokens: 512; retry_on_length=True; retry_max_tokens=1024\n",
      "Commands: ENTER/ok=accept, r=regenerate, e=edit, m=manual, s=skip, q=quit\n",
      "\n",
      "================================================================================\n",
      "[3/978] Buses_3_FindBus\n",
      "instance_key: rec:64cbc7e8819e45258b49e186164c9fad:t0:9eb0bebb83fe4602fcb0390818dc2b64 (record_id=64cbc7e8819e45258b49e186164c9fad, tool_index=0)\n",
      "Current description RAW (escaped):\n",
      "\"Search for a bus itinerary between two cities on a specific date.\"\n",
      "\n",
      "Current description DECODED:\n",
      "Search for a bus itinerary between two cities on a specific date.\n",
      "\n",
      "LLM proposal:\n",
      "Find a bus itinerary between two cities on a specific date.\n",
      "\n",
      "LLM proposal:\n",
      "Retrieve a bus itinerary between two cities for a specific date.\n",
      "================================================================================\n",
      "[4/978] Buses_3_BuyBusTicket\n",
      "instance_key: rec:64cbc7e8819e45258b49e186164c9fad:t1:9a77a4750b12a8be645d3b59a745bc6f (record_id=64cbc7e8819e45258b49e186164c9fad, tool_index=1)\n",
      "Current description RAW (escaped):\n",
      "\"Purchase bus tickets for a specified route, date, and time. Options for the number of passengers and additional luggage are available.\"\n",
      "\n",
      "Current description DECODED:\n",
      "Purchase bus tickets for a specified route, date, and time. Options for the number of passengers and additional luggage are available.\n",
      "\n",
      "LLM proposal:\n",
      "Purchase bus tickets for a specified route, date, and time, with options for the number of passengers and additional luggage.\n",
      "\n",
      "LLM proposal:\n",
      "Purchase bus tickets by specifying the route, date, and time, with configurable options for passenger count and luggage\n",
      "================================================================================\n",
      "[5/978] Events_3_BuyEventTickets\n",
      "instance_key: rec:64cbc7e8819e45258b49e186164c9fad:t2:f7ea47f45d40a99ab97120828159bb35 (record_id=64cbc7e8819e45258b49e186164c9fad, tool_index=2)\n",
      "Current description RAW (escaped):\n",
      "\"Facilitates the purchase of tickets for a cultural event on a specific date in a designated city.\"\n",
      "\n",
      "Current description DECODED:\n",
      "Facilitates the purchase of tickets for a cultural event on a specific date in a designated city.\n",
      "\n",
      "LLM proposal:\n",
      "Purchases tickets for a cultural event on a specific date in a designated city.\n",
      "\n",
      "Changes applied.\n",
      "Mode: style_concise\n",
      "Descriptions updated (this session): 2\n",
      "Reviewed total (from audit): 4 / 978\n",
      "Completed: False (quit_requested=True)\n",
      "Resume next time from: [5/978]\n",
      "Updated file: When2Call/data/test/when2call_test_llm_judge.WORKING_COPY.style_concise.jsonl\n",
      "Audit file (same on resume): audit/7805585800e6/when2call_test_llm_judge.WORKING_COPY.style_concise.7805585800e6.style_concise.gemini-2.5-flash.audit.jsonl\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3 december 28 \n",
    "# two styles\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional, Tuple, List\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# ========= Config =========\n",
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "LLM_MODEL_DEFAULT = \"gemini-2.5-flash\"\n",
    "\n",
    "HASH_HEX_LEN = 32\n",
    "\n",
    "DEFAULT_MAX_TOKENS = 512\n",
    "RETRY_ON_LENGTH = True\n",
    "RETRY_MAX_TOKENS = 1024\n",
    "\n",
    "DEFAULT_ALLOW_RESERIALIZE_FALLBACK = False\n",
    "\n",
    "# How much of the rejected previous rewrite to store in audit (for resume) and to feed back into prompt.\n",
    "DEFAULT_MAX_PREV_REWRITE_CHARS = 800\n",
    "\n",
    "\n",
    "# ========= Styles =========\n",
    "STYLE_SPECS: Dict[str, Dict[str, Any]] = {\n",
    "    \"style_verbose\": {\n",
    "        \"system\": (\n",
    "            \"Rewrite tool descriptions.\\n\"\n",
    "            \"Hard constraints:\\n\"\n",
    "            \"- Preserve meaning exactly; do not add new capabilities, steps, motivations, benefits, or context.\\n\"\n",
    "            \"- Do not delete information present in the original description.\\n\"\n",
    "            \"- Do not introduce new parameter names, IDs, field names, flags, or implementation details.\\n\"\n",
    "            \"- If parameter/field names/IDs/flags already appear in the original description, keep them (do not remove them).\\n\"\n",
    "            \"- Do not add examples, normative language, or assumptions.\\n\"\n",
    "            \"- Keep the same subject (the tool) and the same scope.\\n\"\n",
    "            \"- Output only the rewritten description text, nothing else.\\n\"\n",
    "            \"- Style: verbose but controlled; keep it concise and complete (1–2 sentences), clear and direct.\\n\"\n",
    "        ),\n",
    "        \"regen_diversity_instruction\": (\n",
    "            \"Return a meaning-equivalent rewrite that is lexically different from your previous rewrite; \"\n",
    "            \"avoid repeating the same sentence structure.\"\n",
    "        ),\n",
    "        \"max_prev_rewrite_chars\": 800,\n",
    "    },\n",
    "    \"style_concise\": {\n",
    "        \"system\": (\n",
    "            \"Rewrite tool descriptions.\\n\"\n",
    "            \"Hard constraints:\\n\"\n",
    "            \"- Preserve meaning exactly; do not add new capabilities, steps, motivations, benefits, or context.\\n\"\n",
    "            \"- Do not delete information present in the original description.\\n\"\n",
    "            \"- Do not introduce new parameter names, IDs, field names, flags, or implementation details.\\n\"\n",
    "            \"- If parameter/field names/IDs/flags already appear in the original description, keep them (do not remove them).\\n\"\n",
    "            \"- Do not add examples, normative language, or assumptions.\\n\"\n",
    "            \"- Keep the same subject (the tool) and the same scope.\\n\"\n",
    "            \"- Output only the rewritten description text, nothing else.\\n\"\n",
    "            \" - Style: concise and controlled; 1 sentence preferred, 2 max.\\n\"\n",
    "            \" - Length constraint: aim to be shorter than the base description; if the base description is already short, do not exceed its length.\\n\"\n",
    "            \" - Compression rule: remove redundancy, filler, and hedging; keep all explicitly stated constraints/details.\\n\"\n",
    "\n",
    "        ),\n",
    "        \"regen_diversity_instruction\": (\n",
    "            \"You must produce a different paraphrase than the previous rewrite. \"\n",
    "            \"Do not reuse the same sentence skeleton or distinctive phrases. \"\n",
    "            \"Keep meaning exactly the same; only vary wording and structure.\"\n",
    "        ),\n",
    "        \"max_prev_rewrite_chars\": 600,\n",
    "    },\n",
    "    # Alias to tolerate the user's misspelling \"coicnoso/coinceise\"\n",
    "    \"style_coicnoso\": {},   # filled after dict creation\n",
    "    \"style_coinceise\": {},  # filled after dict creation\n",
    "}\n",
    "STYLE_SPECS[\"style_coicnoso\"] = STYLE_SPECS[\"style_concise\"]\n",
    "STYLE_SPECS[\"style_coinceise\"] = STYLE_SPECS[\"style_concise\"]\n",
    "\n",
    "\n",
    "def _resolve_style(mode_key: str) -> Tuple[str, Dict[str, Any]]:\n",
    "    mk = (mode_key or \"\").strip()\n",
    "    if not mk:\n",
    "        mk = \"style_verbose\"\n",
    "    if mk not in STYLE_SPECS:\n",
    "        raise ValueError(f\"Unknown MODE_KEY='{mk}'. Supported: {', '.join(sorted(STYLE_SPECS.keys()))}\")\n",
    "    return mk, STYLE_SPECS[mk]\n",
    "\n",
    "\n",
    "# ========= Client =========\n",
    "def make_gemini_client() -> OpenAI:\n",
    "    token = os.environ.get(\"TOKEN_GEMINI\")\n",
    "    if not token:\n",
    "        raise RuntimeError(\"TOKEN_GEMINI environment variable is not set.\")\n",
    "    return OpenAI(api_key=token, base_url=GEMINI_BASE_URL)\n",
    "\n",
    "\n",
    "# ========= Small utils =========\n",
    "def _json_safe(obj: Any) -> Any:\n",
    "    if obj is None or isinstance(obj, (str, int, float, bool)):\n",
    "        return obj\n",
    "    if isinstance(obj, dict):\n",
    "        return {str(k): _json_safe(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return [_json_safe(x) for x in obj]\n",
    "    if hasattr(obj, \"model_dump\") and callable(getattr(obj, \"model_dump\")):\n",
    "        try:\n",
    "            return _json_safe(obj.model_dump())\n",
    "        except Exception:\n",
    "            pass\n",
    "    if hasattr(obj, \"dict\") and callable(getattr(obj, \"dict\")):\n",
    "        try:\n",
    "            return _json_safe(obj.dict())\n",
    "        except Exception:\n",
    "            pass\n",
    "    if hasattr(obj, \"__dict__\"):\n",
    "        try:\n",
    "            return _json_safe(vars(obj))\n",
    "        except Exception:\n",
    "            pass\n",
    "    try:\n",
    "        return str(obj)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def _sha256_text(s: str) -> str:\n",
    "    return hashlib.sha256((s or \"\").encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "def _canonical_json(obj: Any) -> str:\n",
    "    return json.dumps(obj, ensure_ascii=False, sort_keys=True, separators=(\",\", \":\"))\n",
    "\n",
    "\n",
    "def _sha256_file(path: Path) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with path.open(\"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(1024 * 1024), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "\n",
    "# ========= Raw JSON-string patcher (for tools stored as JSON strings) =========\n",
    "def _extract_json_string_value(raw_json: str, key: str) -> Optional[str]:\n",
    "    token = f'\"{key}\"'\n",
    "    i = raw_json.find(token)\n",
    "    if i < 0:\n",
    "        return None\n",
    "    i = raw_json.find(\":\", i + len(token))\n",
    "    if i < 0:\n",
    "        return None\n",
    "    i += 1\n",
    "    n = len(raw_json)\n",
    "    while i < n and raw_json[i] in \" \\t\\r\\n\":\n",
    "        i += 1\n",
    "    if i >= n or raw_json[i] != '\"':\n",
    "        return None\n",
    "    start = i\n",
    "    i += 1\n",
    "    esc = False\n",
    "    while i < n:\n",
    "        c = raw_json[i]\n",
    "        if esc:\n",
    "            esc = False\n",
    "        else:\n",
    "            if c == \"\\\\\":\n",
    "                esc = True\n",
    "            elif c == '\"':\n",
    "                return raw_json[start : i + 1]\n",
    "        i += 1\n",
    "    return None\n",
    "\n",
    "\n",
    "def _decode_raw_json_string(raw_json_string_with_quotes: str) -> str:\n",
    "    try:\n",
    "        obj = json.loads('{\"description\":' + raw_json_string_with_quotes + \"}\")\n",
    "        return obj.get(\"description\") or \"\"\n",
    "    except json.JSONDecodeError:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def _get_description_for_print(entry: Any) -> Tuple[str, str]:\n",
    "    if isinstance(entry, str):\n",
    "        raw = _extract_json_string_value(entry, \"description\")\n",
    "        if raw is not None:\n",
    "            return raw, \"raw_json\"\n",
    "        try:\n",
    "            obj = json.loads(entry)\n",
    "            return obj.get(\"description\") or \"\", \"rendered\"\n",
    "        except json.JSONDecodeError:\n",
    "            return \"\", \"rendered\"\n",
    "    if isinstance(entry, dict):\n",
    "        return entry.get(\"description\") or \"\", \"rendered\"\n",
    "    return \"\", \"rendered\"\n",
    "\n",
    "\n",
    "def _load_tool(entry: Any) -> Tuple[Optional[Dict[str, Any]], str]:\n",
    "    if isinstance(entry, str):\n",
    "        try:\n",
    "            return json.loads(entry), \"json_str\"\n",
    "        except json.JSONDecodeError:\n",
    "            return None, \"other\"\n",
    "    if isinstance(entry, dict):\n",
    "        return entry, \"dict\"\n",
    "    return None, \"other\"\n",
    "\n",
    "\n",
    "def _skip_ws(s: str, i: int) -> int:\n",
    "    n = len(s)\n",
    "    while i < n and s[i] in \" \\t\\r\\n\":\n",
    "        i += 1\n",
    "    return i\n",
    "\n",
    "\n",
    "def _scan_string_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    n = len(s)\n",
    "    if i >= n or s[i] != '\"':\n",
    "        return None\n",
    "    j = i + 1\n",
    "    esc = False\n",
    "    while j < n:\n",
    "        c = s[j]\n",
    "        if esc:\n",
    "            esc = False\n",
    "        else:\n",
    "            if c == \"\\\\\":\n",
    "                esc = True\n",
    "            elif c == '\"':\n",
    "                return (i, j + 1)\n",
    "        j += 1\n",
    "    return None\n",
    "\n",
    "\n",
    "def _scan_number_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    n = len(s)\n",
    "    j = i\n",
    "    if j < n and s[j] == \"-\":\n",
    "        j += 1\n",
    "    if j >= n:\n",
    "        return None\n",
    "    if s[j] == \"0\":\n",
    "        j += 1\n",
    "    elif s[j].isdigit():\n",
    "        while j < n and s[j].isdigit():\n",
    "            j += 1\n",
    "    else:\n",
    "        return None\n",
    "    if j < n and s[j] == \".\":\n",
    "        j += 1\n",
    "        if j >= n or not s[j].isdigit():\n",
    "            return None\n",
    "        while j < n and s[j].isdigit():\n",
    "            j += 1\n",
    "    if j < n and s[j] in \"eE\":\n",
    "        j += 1\n",
    "        if j < n and s[j] in \"+-\":\n",
    "            j += 1\n",
    "        if j >= n or not s[j].isdigit():\n",
    "            return None\n",
    "        while j < n and s[j].isdigit():\n",
    "            j += 1\n",
    "    return (i, j)\n",
    "\n",
    "\n",
    "def _scan_literal_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    for lit in (\"true\", \"false\", \"null\"):\n",
    "        if s.startswith(lit, i):\n",
    "            return (i, i + len(lit))\n",
    "    return None\n",
    "\n",
    "\n",
    "def _scan_container_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    n = len(s)\n",
    "    if i >= n:\n",
    "        return None\n",
    "\n",
    "    opener = s[i]\n",
    "    if opener not in \"{[\":\n",
    "        return None\n",
    "\n",
    "    stack: List[str] = [\"}\" if opener == \"{\" else \"]\"]\n",
    "    j = i + 1\n",
    "    in_str = False\n",
    "    esc = False\n",
    "\n",
    "    while j < n:\n",
    "        c = s[j]\n",
    "\n",
    "        if in_str:\n",
    "            if esc:\n",
    "                esc = False\n",
    "            else:\n",
    "                if c == \"\\\\\":\n",
    "                    esc = True\n",
    "                elif c == '\"':\n",
    "                    in_str = False\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        if c == '\"':\n",
    "            in_str = True\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        if c == \"{\":\n",
    "            stack.append(\"}\")\n",
    "            j += 1\n",
    "            continue\n",
    "        if c == \"[\":\n",
    "            stack.append(\"]\")\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        if c in \"}]\":\n",
    "            if not stack:\n",
    "                return None\n",
    "            expected = stack[-1]\n",
    "            if c != expected:\n",
    "                return None\n",
    "            stack.pop()\n",
    "            j += 1\n",
    "            if not stack:\n",
    "                return (i, j)\n",
    "            continue\n",
    "\n",
    "        j += 1\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def _is_value_delim(c: str) -> bool:\n",
    "    return c in \",}]\"\n",
    "\n",
    "\n",
    "def _scan_value_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    n = len(s)\n",
    "    i = _skip_ws(s, i)\n",
    "    if i >= n:\n",
    "        return None\n",
    "\n",
    "    c = s[i]\n",
    "    if c == '\"':\n",
    "        return _scan_string_span(s, i)\n",
    "    if c in \"{[\":\n",
    "        return _scan_container_span(s, i)\n",
    "\n",
    "    span: Optional[Tuple[int, int]]\n",
    "    if c == \"-\" or c.isdigit():\n",
    "        span = _scan_number_span(s, i)\n",
    "    else:\n",
    "        span = _scan_literal_span(s, i)\n",
    "\n",
    "    if not span:\n",
    "        return None\n",
    "\n",
    "    _, end = span\n",
    "    k = _skip_ws(s, end)\n",
    "    if k >= n:\n",
    "        return span\n",
    "    if _is_value_delim(s[k]):\n",
    "        return span\n",
    "    return None\n",
    "\n",
    "\n",
    "def _replace_top_level_string_field_in_raw_object(raw_json_obj: str, key: str, new_value: str) -> Tuple[str, bool, str]:\n",
    "    s = raw_json_obj\n",
    "    n = len(s)\n",
    "\n",
    "    i = _skip_ws(s, 0)\n",
    "    if i >= n or s[i] != \"{\":\n",
    "        return raw_json_obj, False, \"not_object\"\n",
    "\n",
    "    i += 1\n",
    "    found_any_key = False\n",
    "    expect_key = True\n",
    "\n",
    "    while True:\n",
    "        i = _skip_ws(s, i)\n",
    "        if i >= n:\n",
    "            return raw_json_obj, False, \"cannot_scan_value\"\n",
    "\n",
    "        if expect_key:\n",
    "            if s[i] == \"}\":\n",
    "                return raw_json_obj, False, \"key_not_found\"\n",
    "            if s[i] != '\"':\n",
    "                return raw_json_obj, False, \"invalid_key_string\"\n",
    "\n",
    "            key_span = _scan_string_span(s, i)\n",
    "            if not key_span:\n",
    "                return raw_json_obj, False, \"invalid_key_string\"\n",
    "\n",
    "            found_any_key = True\n",
    "            k_start, k_end = key_span\n",
    "            try:\n",
    "                key_decoded = json.loads(s[k_start:k_end])\n",
    "            except Exception:\n",
    "                return raw_json_obj, False, \"invalid_key_string\"\n",
    "\n",
    "            i = _skip_ws(s, k_end)\n",
    "            if i >= n or s[i] != \":\":\n",
    "                return raw_json_obj, False, \"missing_colon\"\n",
    "\n",
    "            v_span = _scan_value_span(s, i + 1)\n",
    "            if not v_span:\n",
    "                return raw_json_obj, False, \"cannot_scan_value\"\n",
    "\n",
    "            v_start, v_end = v_span\n",
    "\n",
    "            if key_decoded == key:\n",
    "                if v_start >= n or s[v_start] != '\"':\n",
    "                    return raw_json_obj, False, \"value_not_string\"\n",
    "\n",
    "                replacement_literal = json.dumps(new_value, ensure_ascii=False)\n",
    "                patched = s[:v_start] + replacement_literal + s[v_end:]\n",
    "\n",
    "                try:\n",
    "                    obj = json.loads(patched)\n",
    "                except Exception:\n",
    "                    return raw_json_obj, False, \"json_load_failed_after_patch\"\n",
    "\n",
    "                if isinstance(obj, dict) and obj.get(key) == new_value:\n",
    "                    return patched, True, \"ok\"\n",
    "                return raw_json_obj, False, \"validation_failed_after_patch\"\n",
    "\n",
    "            i = v_end\n",
    "            expect_key = False\n",
    "            continue\n",
    "\n",
    "        i = _skip_ws(s, i)\n",
    "        if i >= n:\n",
    "            return raw_json_obj, False, \"cannot_scan_value\"\n",
    "\n",
    "        if s[i] == \",\":\n",
    "            i += 1\n",
    "            expect_key = True\n",
    "            continue\n",
    "        if s[i] == \"}\":\n",
    "            return raw_json_obj, False, (\"key_not_found\" if found_any_key else \"key_not_found\")\n",
    "        return raw_json_obj, False, \"cannot_scan_value\"\n",
    "\n",
    "\n",
    "# ========= IDs =========\n",
    "def _tool_fingerprint_excluding_description(tool_obj: Dict[str, Any]) -> str:\n",
    "    filtered = {k: v for k, v in tool_obj.items() if k != \"description\"}\n",
    "    payload = _canonical_json(filtered)\n",
    "    return hashlib.sha256(payload.encode(\"utf-8\")).hexdigest()[:HASH_HEX_LEN]\n",
    "\n",
    "\n",
    "def _record_id(record_obj: Dict[str, Any], tool_field: str) -> str:\n",
    "    rec = dict(record_obj)\n",
    "    tools = rec.get(tool_field)\n",
    "    if isinstance(tools, list):\n",
    "        canon_tools: List[Any] = []\n",
    "        for entry in tools:\n",
    "            tool_obj, kind = _load_tool(entry)\n",
    "            if tool_obj is None:\n",
    "                canon_tools.append({\"_unparsed\": entry, \"_kind\": kind})\n",
    "            else:\n",
    "                canon_tools.append({k: v for k, v in tool_obj.items() if k != \"description\"})\n",
    "        rec[tool_field] = canon_tools\n",
    "    payload = _canonical_json(rec)\n",
    "    return hashlib.sha256(payload.encode(\"utf-8\")).hexdigest()[:HASH_HEX_LEN]\n",
    "\n",
    "\n",
    "def _tool_instance_key(record_id: str, tool_index: int, tool_obj: Dict[str, Any]) -> str:\n",
    "    fp = _tool_fingerprint_excluding_description(tool_obj)\n",
    "    return f\"rec:{record_id}:t{tool_index}:{fp}\"\n",
    "\n",
    "\n",
    "# ========= Audit (single file, resumable) =========\n",
    "def _audit_identity(dataset_path: Path, *, mode_key: str, model: str, tool_field: str) -> str:\n",
    "    stable = f\"{dataset_path.resolve()}|{mode_key}|{model}|{tool_field}\"\n",
    "    return hashlib.sha256(stable.encode(\"utf-8\")).hexdigest()[:12]\n",
    "\n",
    "\n",
    "def _audit_file_path(\n",
    "    dataset_path: Path,\n",
    "    *,\n",
    "    audit_dir: Path,\n",
    "    mode_key: str,\n",
    "    model: str,\n",
    "    tool_field: str,\n",
    ") -> Path:\n",
    "    audit_key = _audit_identity(dataset_path, mode_key=mode_key, model=model, tool_field=tool_field)\n",
    "    safe_model = \"\".join(ch if ch.isalnum() or ch in (\"-\", \"_\", \".\") else \"_\" for ch in model)\n",
    "    out_dir = audit_dir / audit_key\n",
    "    filename = f\"{dataset_path.stem}.{audit_key}.{mode_key}.{safe_model}.audit.jsonl\"\n",
    "    return out_dir / filename\n",
    "\n",
    "\n",
    "def _append_audit_event(audit_file: Path, event: Dict[str, Any]) -> None:\n",
    "    audit_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    safe_event = _json_safe(event)\n",
    "    with audit_file.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(safe_event, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "def _load_resume_state(\n",
    "    audit_file: Path,\n",
    ") -> Tuple[\n",
    "    Dict[str, Tuple[str, Optional[str], Optional[Dict[str, Any]]]],\n",
    "    Dict[str, int],\n",
    "    Dict[str, Optional[str]],\n",
    "    Optional[Dict[str, Any]],\n",
    "]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - decisions_by_instance: instance_key -> (status, final_description, llm_bundle)\n",
    "      - regen_counts: instance_key -> max regen_index observed\n",
    "      - last_rejected_text: instance_key -> last rejected proposal text (from regenerate events)\n",
    "      - prior_run_start: first run_start event (if any)\n",
    "    \"\"\"\n",
    "    decisions: Dict[str, Tuple[str, Optional[str], Optional[Dict[str, Any]]]] = {}\n",
    "    regen_counts: Dict[str, int] = {}\n",
    "    last_rejected_text: Dict[str, Optional[str]] = {}\n",
    "    prior_run_start: Optional[Dict[str, Any]] = None\n",
    "\n",
    "    if not audit_file.exists():\n",
    "        return decisions, regen_counts, last_rejected_text, None\n",
    "\n",
    "    best_ri: Dict[str, int] = {}\n",
    "\n",
    "    with audit_file.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                ev = json.loads(line)\n",
    "            except Exception:\n",
    "                continue\n",
    "            if not isinstance(ev, dict):\n",
    "                continue\n",
    "\n",
    "            et = ev.get(\"event_type\")\n",
    "            if et == \"run_start\" and prior_run_start is None:\n",
    "                prior_run_start = ev\n",
    "\n",
    "            if et == \"regenerate\":\n",
    "                ik = ev.get(\"instance_key\")\n",
    "                ri = ev.get(\"regen_index\")\n",
    "                txt = ev.get(\"last_proposal_text\")\n",
    "                if isinstance(ik, str) and isinstance(ri, int) and ri >= 0:\n",
    "                    prev = regen_counts.get(ik, 0)\n",
    "                    if ri > prev:\n",
    "                        regen_counts[ik] = ri\n",
    "                    prev_best = best_ri.get(ik, -1)\n",
    "                    if ri >= prev_best:\n",
    "                        best_ri[ik] = ri\n",
    "                        last_rejected_text[ik] = txt if isinstance(txt, str) else None\n",
    "\n",
    "            if et == \"decision\":\n",
    "                ik = ev.get(\"instance_key\")\n",
    "                status = ev.get(\"status\")\n",
    "                final_desc = ev.get(\"final_description\")\n",
    "                llm_bundle = ev.get(\"llm_bundle\")\n",
    "                if isinstance(ik, str) and isinstance(status, str):\n",
    "                    decisions[ik] = (\n",
    "                        status,\n",
    "                        final_desc if isinstance(final_desc, str) else None,\n",
    "                        llm_bundle if isinstance(llm_bundle, dict) else None,\n",
    "                    )\n",
    "\n",
    "    return decisions, regen_counts, last_rejected_text, prior_run_start\n",
    "\n",
    "\n",
    "# ========= LLM helpers =========\n",
    "def _sanitize_llm_output(text: str) -> str:\n",
    "    t = (text or \"\").strip()\n",
    "    if t.startswith(\"{\") and \"description\" in t:\n",
    "        try:\n",
    "            obj = json.loads(t)\n",
    "            if isinstance(obj, dict) and isinstance(obj.get(\"description\"), str):\n",
    "                t = obj[\"description\"].strip()\n",
    "        except Exception:\n",
    "            pass\n",
    "    if (t.startswith('\"') and t.endswith('\"')) or (t.startswith(\"'\") and t.endswith(\"'\")):\n",
    "        t = t[1:-1].strip()\n",
    "    return t\n",
    "\n",
    "\n",
    "def _llm_chat_completion(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    model: str,\n",
    "    messages: List[Dict[str, str]],\n",
    "    temperature: float,\n",
    "    max_tokens: int,\n",
    "    seed: Optional[int],\n",
    ") -> Tuple[str, Dict[str, Any]]:\n",
    "    meta: Dict[str, Any] = {\n",
    "        \"seed_requested\": seed,\n",
    "        \"seed_applied\": False,\n",
    "        \"seed_error\": None,\n",
    "        \"finish_reason\": None,\n",
    "        \"usage\": None,\n",
    "        \"max_tokens_requested\": int(max_tokens),\n",
    "        \"max_param_used\": None,\n",
    "    }\n",
    "\n",
    "    base_kwargs: Dict[str, Any] = dict(model=model, messages=messages, temperature=temperature)\n",
    "\n",
    "    def attempt(max_param_used: str, include_seed: bool) -> Tuple[str, Dict[str, Any]]:\n",
    "        req = dict(base_kwargs)\n",
    "        if max_param_used == \"max_completion_tokens\":\n",
    "            req[\"max_completion_tokens\"] = int(max_tokens)\n",
    "        else:\n",
    "            req[\"max_tokens\"] = int(max_tokens)\n",
    "        if include_seed and seed is not None:\n",
    "            req[\"seed\"] = int(seed)\n",
    "\n",
    "        resp = client.chat.completions.create(**req)\n",
    "        text = (resp.choices[0].message.content or \"\").strip()\n",
    "\n",
    "        meta_local = dict(meta)\n",
    "        meta_local[\"max_param_used\"] = max_param_used\n",
    "        meta_local[\"finish_reason\"] = getattr(resp.choices[0], \"finish_reason\", None)\n",
    "        meta_local[\"usage\"] = getattr(resp, \"usage\", None)\n",
    "        meta_local[\"seed_applied\"] = bool(include_seed and seed is not None)\n",
    "        return text, meta_local\n",
    "\n",
    "    def is_seed_error(e: Exception) -> bool:\n",
    "        s = str(e).lower()\n",
    "        return (\"seed\" in s) and (\"unknown\" in s or \"unsupported\" in s or \"invalid\" in s)\n",
    "\n",
    "    try:\n",
    "        return attempt(\"max_completion_tokens\", include_seed=True)\n",
    "    except Exception as e1:\n",
    "        if seed is not None and is_seed_error(e1):\n",
    "            meta[\"seed_error\"] = str(e1)\n",
    "            try:\n",
    "                return attempt(\"max_completion_tokens\", include_seed=False)\n",
    "            except Exception:\n",
    "                pass\n",
    "        try:\n",
    "            return attempt(\"max_tokens\", include_seed=True)\n",
    "        except Exception as e2:\n",
    "            if seed is not None and is_seed_error(e2):\n",
    "                meta[\"seed_error\"] = str(e2)\n",
    "                return attempt(\"max_tokens\", include_seed=False)\n",
    "            raise\n",
    "\n",
    "\n",
    "def generate_description_via_llm(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    tool_name: str,\n",
    "    base_description: str,\n",
    "    model: str,\n",
    "    seed: Optional[int],\n",
    "    max_tokens: int,\n",
    "    retry_on_length: bool,\n",
    "    retry_max_tokens: int,\n",
    "    mode_key: str,\n",
    "    style_spec: Dict[str, Any],\n",
    "    regen_index: int = 0,\n",
    "    previous_rewrite: Optional[str] = None,\n",
    ") -> Tuple[str, Dict[str, Any]]:\n",
    "    system = str(style_spec[\"system\"])\n",
    "    regen_instr = str(style_spec.get(\"regen_diversity_instruction\") or \"\")\n",
    "    max_prev = int(style_spec.get(\"max_prev_rewrite_chars\") or DEFAULT_MAX_PREV_REWRITE_CHARS)\n",
    "\n",
    "    user_parts: List[str] = []\n",
    "    user_parts.append(f\"Tool name: {tool_name}\")\n",
    "    user_parts.append(\"Base description:\")\n",
    "    user_parts.append(base_description.strip() or \"(empty)\")\n",
    "    user_parts.append(\"\")\n",
    "    user_parts.append(f\"Rewrite in '{mode_key}' under the constraints.\")\n",
    "\n",
    "    if regen_index > 0:\n",
    "        user_parts.append(\"\")\n",
    "        user_parts.append(f\"Regeneration request: {regen_index}\")\n",
    "        if regen_instr:\n",
    "            user_parts.append(regen_instr)\n",
    "        if previous_rewrite and previous_rewrite.strip():\n",
    "            prev = previous_rewrite.strip()\n",
    "            if len(prev) > max_prev:\n",
    "                prev = prev[:max_prev].rstrip()\n",
    "            user_parts.append(\"\")\n",
    "            user_parts.append(\"Previous rewrite (do not reuse wording):\")\n",
    "            user_parts.append(prev)\n",
    "\n",
    "    user = \"\\n\".join(user_parts)\n",
    "\n",
    "    raw1, meta1 = _llm_chat_completion(\n",
    "        client=client,\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": user}],\n",
    "        temperature=0.0,\n",
    "        max_tokens=max_tokens,\n",
    "        seed=seed,\n",
    "    )\n",
    "    san1 = _sanitize_llm_output(raw1)\n",
    "    finish1 = (meta1.get(\"finish_reason\") or \"\").lower()\n",
    "    looks_truncated_1 = (finish1 == \"length\")\n",
    "\n",
    "    if not looks_truncated_1:\n",
    "        return san1, {\n",
    "            \"proposal_origin\": \"primary\",\n",
    "            \"proposal_sanitized_final\": san1,\n",
    "            \"llm_text_raw_primary\": raw1,\n",
    "            \"llm_text_raw_retry\": None,\n",
    "            \"primary\": meta1,\n",
    "            \"retry\": None,\n",
    "            \"mode_key\": mode_key,\n",
    "        }\n",
    "\n",
    "    raw2 = None\n",
    "    meta2 = None\n",
    "    san2 = None\n",
    "    best_san = san1\n",
    "    origin = \"primary\"\n",
    "\n",
    "    if retry_on_length and retry_max_tokens > max_tokens:\n",
    "        raw2, meta2 = _llm_chat_completion(\n",
    "            client=client,\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": user}],\n",
    "            temperature=0.0,\n",
    "            max_tokens=int(retry_max_tokens),\n",
    "            seed=seed,\n",
    "        )\n",
    "        san2 = _sanitize_llm_output(raw2)\n",
    "        if san2 and len(san2) >= len(best_san):\n",
    "            best_san = san2\n",
    "            origin = \"retry\"\n",
    "\n",
    "    return best_san, {\n",
    "        \"proposal_origin\": origin,\n",
    "        \"proposal_sanitized_final\": best_san,\n",
    "        \"llm_text_raw_primary\": raw1,\n",
    "        \"llm_text_raw_retry\": raw2,\n",
    "        \"primary\": meta1,\n",
    "        \"retry\": meta2,\n",
    "        \"mode_key\": mode_key,\n",
    "    }\n",
    "\n",
    "\n",
    "# ========= IO =========\n",
    "def make_working_copy(input_jsonl: str, output_jsonl: str, *, overwrite: bool = False) -> str:\n",
    "    src = Path(input_jsonl)\n",
    "    dst = Path(output_jsonl)\n",
    "\n",
    "    if not src.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {src}\")\n",
    "\n",
    "    if dst.exists() and not overwrite:\n",
    "        return str(dst)\n",
    "\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(src, dst)\n",
    "    return str(dst)\n",
    "\n",
    "\n",
    "def _normalize_cmd(raw: str) -> str:\n",
    "    c = (raw or \"\").strip().lower()\n",
    "    if c in (\"\", \"y\", \"yes\", \"ok\", \"okay\", \"si\", \"sì\"):\n",
    "        return \"y\"\n",
    "    if c in (\"r\", \"retry\", \"again\", \"prova\", \"prova ancora\", \"rigenera\"):\n",
    "        return \"r\"\n",
    "    if c in (\"e\", \"edit\", \"modifica\"):\n",
    "        return \"e\"\n",
    "    if c in (\"m\", \"manual\", \"mine\", \"mio\", \"mia\", \"custom\"):\n",
    "        return \"m\"\n",
    "    if c in (\"s\", \"skip\", \"salta\", \"pass\"):\n",
    "        return \"s\"\n",
    "    if c in (\"q\", \"quit\", \"exit\", \"esci\"):\n",
    "        return \"q\"\n",
    "    return c\n",
    "\n",
    "\n",
    "# ========= Main interactive =========\n",
    "def interactive_llm_tools_in_jsonl(\n",
    "    jsonl_path: str,\n",
    "    *,\n",
    "    tool_field: str,\n",
    "    create_backup_of_target: bool,\n",
    "    llm_model: str,\n",
    "    seed: Optional[int],\n",
    "    max_tokens: int,\n",
    "    retry_on_length: bool,\n",
    "    retry_max_tokens: int,\n",
    "    allow_reserialize_fallback: bool,\n",
    "    min_sleep_sec_between_calls: float,\n",
    "    audit_dir: str,\n",
    "    mode_key: str,\n",
    ") -> None:\n",
    "    mode_key, style_spec = _resolve_style(mode_key)\n",
    "\n",
    "    path = Path(jsonl_path)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {jsonl_path}\")\n",
    "\n",
    "    client = make_gemini_client()\n",
    "    audit_file = _audit_file_path(\n",
    "        path,\n",
    "        audit_dir=Path(audit_dir),\n",
    "        mode_key=mode_key,\n",
    "        model=llm_model,\n",
    "        tool_field=tool_field,\n",
    "    )\n",
    "\n",
    "    decisions_by_instance, regen_counts, last_rejected_text_by_instance, prior_run_start = _load_resume_state(audit_file)\n",
    "\n",
    "    tool_order: List[Dict[str, Any]] = []\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for raw_line in f:\n",
    "            line = raw_line.rstrip(\"\\n\")\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            try:\n",
    "                record = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "            if not isinstance(record, dict):\n",
    "                continue\n",
    "\n",
    "            rid = _record_id(record, tool_field=tool_field)\n",
    "            tools = record.get(tool_field)\n",
    "            if not isinstance(tools, list):\n",
    "                continue\n",
    "\n",
    "            for tool_index, entry in enumerate(tools):\n",
    "                tool_obj, kind = _load_tool(entry)\n",
    "                if not tool_obj:\n",
    "                    continue\n",
    "                name = (tool_obj.get(\"name\") or \"\").strip()\n",
    "                if not name:\n",
    "                    continue\n",
    "\n",
    "                desc_print, desc_mode = _get_description_for_print(entry)\n",
    "                instance_key = _tool_instance_key(rid, tool_index, tool_obj)\n",
    "\n",
    "                tool_order.append(\n",
    "                    {\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_index,\n",
    "                        \"tool_name\": name,\n",
    "                        \"desc_print\": desc_print,\n",
    "                        \"desc_mode\": desc_mode,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"entry_kind\": kind,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    n_total = len(tool_order)\n",
    "    n_prev_reviewed = len(decisions_by_instance)\n",
    "\n",
    "    start_pos = 0\n",
    "    while start_pos < n_total and tool_order[start_pos][\"instance_key\"] in decisions_by_instance:\n",
    "        start_pos += 1\n",
    "\n",
    "    session_id = hashlib.sha256(f\"{time.time_ns()}\".encode(\"utf-8\")).hexdigest()[:12]\n",
    "    before_sha = _sha256_file(path)\n",
    "\n",
    "    if prior_run_start is None:\n",
    "        _append_audit_event(\n",
    "            audit_file,\n",
    "            {\n",
    "                \"event_type\": \"run_start\",\n",
    "                \"ts\": int(time.time()),\n",
    "                \"session_id\": session_id,\n",
    "                \"mode\": mode_key,\n",
    "                \"model\": llm_model,\n",
    "                \"seed\": seed,\n",
    "                \"dataset_path\": str(path),\n",
    "                \"dataset_sha256_at_session_start\": before_sha,\n",
    "                \"tool_field\": tool_field,\n",
    "                \"n_total_occurrences\": n_total,\n",
    "                \"max_tokens_requested\": int(max_tokens),\n",
    "                \"retry_on_length\": bool(retry_on_length),\n",
    "                \"retry_max_tokens\": int(retry_max_tokens),\n",
    "                \"allow_reserialize_fallback\": bool(allow_reserialize_fallback),\n",
    "            },\n",
    "        )\n",
    "    else:\n",
    "        _append_audit_event(\n",
    "            audit_file,\n",
    "            {\n",
    "                \"event_type\": \"run_resume\",\n",
    "                \"ts\": int(time.time()),\n",
    "                \"session_id\": session_id,\n",
    "                \"mode\": mode_key,\n",
    "                \"model\": llm_model,\n",
    "                \"seed\": seed,\n",
    "                \"dataset_path\": str(path),\n",
    "                \"dataset_sha256_at_session_start\": before_sha,\n",
    "                \"tool_field\": tool_field,\n",
    "                \"n_total_occurrences\": n_total,\n",
    "                \"n_previously_reviewed\": n_prev_reviewed,\n",
    "                \"resume_from_index_1based\": (start_pos + 1) if start_pos < n_total else (n_total + 1),\n",
    "            },\n",
    "        )\n",
    "\n",
    "    print(f\"Target: {path}\")\n",
    "    print(f\"Mode: {mode_key}\")\n",
    "    print(f\"Audit file (RESUMABLE): {audit_file}\")\n",
    "    print(f\"Tool occurrences total: {n_total}\")\n",
    "    if start_pos < n_total:\n",
    "        print(f\"Resume position: [{start_pos + 1}/{n_total}] (previously reviewed: {n_prev_reviewed})\")\n",
    "    else:\n",
    "        print(f\"Resume position: completed (previously reviewed: {n_prev_reviewed})\")\n",
    "    print(f\"LLM: {llm_model} @ {GEMINI_BASE_URL}\")\n",
    "    print(f\"Max tokens: {int(max_tokens)}; retry_on_length={bool(retry_on_length)}; retry_max_tokens={int(retry_max_tokens)}\")\n",
    "    print(\"Commands: ENTER/ok=accept, r=regenerate, e=edit, m=manual, s=skip, q=quit\\n\")\n",
    "\n",
    "    quit_requested = False\n",
    "    resume_next_index_1based: Optional[int] = None\n",
    "\n",
    "    max_prev = int(style_spec.get(\"max_prev_rewrite_chars\") or DEFAULT_MAX_PREV_REWRITE_CHARS)\n",
    "\n",
    "    for pos in range(start_pos, n_total):\n",
    "        item = tool_order[pos]\n",
    "        idx = pos + 1\n",
    "\n",
    "        name = item[\"tool_name\"]\n",
    "        desc_mode = item[\"desc_mode\"]\n",
    "        old_desc_print = item[\"desc_print\"]\n",
    "        instance_key = item[\"instance_key\"]\n",
    "        rid = item[\"record_id\"]\n",
    "        tool_i = item[\"tool_index\"]\n",
    "\n",
    "        regen_index_local = int(regen_counts.get(instance_key, 0))\n",
    "        previous_rewrite_local: Optional[str] = last_rejected_text_by_instance.get(instance_key)\n",
    "\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"[{idx}/{n_total}] {name}\")\n",
    "        print(f\"instance_key: {instance_key} (record_id={rid}, tool_index={tool_i})\")\n",
    "\n",
    "        if desc_mode == \"raw_json\":\n",
    "            print(\"Current description RAW (escaped):\")\n",
    "            print(old_desc_print if old_desc_print else \"(empty)\")\n",
    "            base_desc = _decode_raw_json_string(old_desc_print) if old_desc_print else \"\"\n",
    "            print(\"\\nCurrent description DECODED:\")\n",
    "            print(base_desc if base_desc else \"(empty)\")\n",
    "        else:\n",
    "            base_desc = old_desc_print or \"\"\n",
    "            print(\"Current description:\")\n",
    "            print(base_desc if base_desc else \"(empty)\")\n",
    "\n",
    "        proposal = \"\"\n",
    "        llm_bundle: Optional[Dict[str, Any]] = None\n",
    "\n",
    "        while True:\n",
    "            if not proposal:\n",
    "                try:\n",
    "                    proposal, llm_bundle = generate_description_via_llm(\n",
    "                        client=client,\n",
    "                        tool_name=name,\n",
    "                        base_description=base_desc,\n",
    "                        model=llm_model,\n",
    "                        seed=seed,\n",
    "                        max_tokens=max_tokens,\n",
    "                        retry_on_length=retry_on_length,\n",
    "                        retry_max_tokens=retry_max_tokens,\n",
    "                        mode_key=mode_key,\n",
    "                        style_spec=style_spec,\n",
    "                        regen_index=regen_index_local,\n",
    "                        previous_rewrite=previous_rewrite_local,\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nLLM ERROR: {e}\")\n",
    "                    cmd = _normalize_cmd(input(\"Choice [m=manual, e=edit, s=skip, q=quit] > \"))\n",
    "                    now = int(time.time())\n",
    "\n",
    "                    if cmd == \"q\":\n",
    "                        quit_requested = True\n",
    "                        resume_next_index_1based = idx\n",
    "                        break\n",
    "\n",
    "                    if cmd == \"s\":\n",
    "                        decisions_by_instance[instance_key] = (\"skipped\", None, None)\n",
    "                        _append_audit_event(\n",
    "                            audit_file,\n",
    "                            {\n",
    "                                \"event_type\": \"decision\",\n",
    "                                \"ts\": now,\n",
    "                                \"session_id\": session_id,\n",
    "                                \"status\": \"skipped\",\n",
    "                                \"tool_name\": name,\n",
    "                                \"instance_key\": instance_key,\n",
    "                                \"record_id\": rid,\n",
    "                                \"tool_index\": tool_i,\n",
    "                                \"model\": llm_model,\n",
    "                                \"seed\": seed,\n",
    "                                \"mode\": mode_key,\n",
    "                                \"base_description\": base_desc,\n",
    "                                \"final_description\": None,\n",
    "                                \"source\": \"user\",\n",
    "                                \"note\": \"skip_after_llm_error\",\n",
    "                            },\n",
    "                        )\n",
    "                        break\n",
    "\n",
    "                    if cmd in (\"m\", \"e\"):\n",
    "                        manual_final = input(\"Manual final description (empty cancels) > \").rstrip(\"\\n\").strip()\n",
    "                        status = \"manual\" if (cmd == \"m\" and manual_final) else (\"edited\" if (cmd == \"e\" and manual_final) else \"skipped\")\n",
    "                        decisions_by_instance[instance_key] = (status, manual_final or None, None)\n",
    "                        _append_audit_event(\n",
    "                            audit_file,\n",
    "                            {\n",
    "                                \"event_type\": \"decision\",\n",
    "                                \"ts\": now,\n",
    "                                \"session_id\": session_id,\n",
    "                                \"status\": status,\n",
    "                                \"tool_name\": name,\n",
    "                                \"instance_key\": instance_key,\n",
    "                                \"record_id\": rid,\n",
    "                                \"tool_index\": tool_i,\n",
    "                                \"model\": llm_model,\n",
    "                                \"seed\": seed,\n",
    "                                \"mode\": mode_key,\n",
    "                                \"base_description\": base_desc,\n",
    "                                \"final_description\": manual_final or None,\n",
    "                                \"source\": \"user\",\n",
    "                                \"note\": \"manual_or_edit_after_llm_error\",\n",
    "                            },\n",
    "                        )\n",
    "                        break\n",
    "\n",
    "                    proposal = \"\"\n",
    "                    continue\n",
    "\n",
    "                proposal = (proposal or \"\").strip()\n",
    "\n",
    "            print(\"\\nLLM proposal:\")\n",
    "            print(proposal if proposal else \"(empty)\")\n",
    "\n",
    "            cmd = _normalize_cmd(input(\"\\nChoice [ENTER=accept, r=regen, e=edit, m=manual, s=skip, q=quit] > \"))\n",
    "            now = int(time.time())\n",
    "\n",
    "            if cmd == \"y\":\n",
    "                if proposal.strip():\n",
    "                    decisions_by_instance[instance_key] = (\"accepted\", proposal.strip(), llm_bundle)\n",
    "                    _append_audit_event(\n",
    "                        audit_file,\n",
    "                        {\n",
    "                            \"event_type\": \"decision\",\n",
    "                            \"ts\": now,\n",
    "                            \"session_id\": session_id,\n",
    "                            \"status\": \"accepted\",\n",
    "                            \"tool_name\": name,\n",
    "                            \"instance_key\": instance_key,\n",
    "                            \"record_id\": rid,\n",
    "                            \"tool_index\": tool_i,\n",
    "                            \"model\": llm_model,\n",
    "                            \"seed\": seed,\n",
    "                            \"mode\": mode_key,\n",
    "                            \"base_description\": base_desc,\n",
    "                            \"final_description\": proposal.strip(),\n",
    "                            \"source\": \"llm\",\n",
    "                            \"llm_bundle\": llm_bundle,\n",
    "                        },\n",
    "                    )\n",
    "                else:\n",
    "                    decisions_by_instance[instance_key] = (\"skipped\", None, llm_bundle)\n",
    "                    _append_audit_event(\n",
    "                        audit_file,\n",
    "                        {\n",
    "                            \"event_type\": \"decision\",\n",
    "                            \"ts\": now,\n",
    "                            \"session_id\": session_id,\n",
    "                            \"status\": \"skipped\",\n",
    "                            \"tool_name\": name,\n",
    "                            \"instance_key\": instance_key,\n",
    "                            \"record_id\": rid,\n",
    "                            \"tool_index\": tool_i,\n",
    "                            \"model\": llm_model,\n",
    "                            \"seed\": seed,\n",
    "                            \"mode\": mode_key,\n",
    "                            \"base_description\": base_desc,\n",
    "                            \"final_description\": None,\n",
    "                            \"source\": \"llm\",\n",
    "                            \"note\": \"empty_proposal\",\n",
    "                            \"llm_bundle\": llm_bundle,\n",
    "                        },\n",
    "                    )\n",
    "                break\n",
    "\n",
    "            if cmd == \"r\":\n",
    "                previous_rewrite_local = proposal.strip() if proposal else None\n",
    "                if previous_rewrite_local and len(previous_rewrite_local) > max_prev:\n",
    "                    previous_rewrite_local = previous_rewrite_local[:max_prev].rstrip()\n",
    "\n",
    "                regen_counts[instance_key] = regen_counts.get(instance_key, 0) + 1\n",
    "                regen_index_local = int(regen_counts[instance_key])\n",
    "                last_rejected_text_by_instance[instance_key] = previous_rewrite_local\n",
    "\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"regenerate\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"mode\": mode_key,\n",
    "                        \"regen_index\": regen_index_local,\n",
    "                        \"last_proposal_sha256\": _sha256_text(proposal),\n",
    "                        \"last_proposal_text\": previous_rewrite_local,\n",
    "                        \"last_proposal_origin\": (llm_bundle or {}).get(\"proposal_origin\") if llm_bundle else None,\n",
    "                    },\n",
    "                )\n",
    "\n",
    "                proposal = \"\"\n",
    "                llm_bundle = None\n",
    "                if min_sleep_sec_between_calls > 0:\n",
    "                    time.sleep(min_sleep_sec_between_calls)\n",
    "                continue\n",
    "\n",
    "            if cmd == \"e\":\n",
    "                edited = input(\"Edit proposal (empty cancels) > \").rstrip(\"\\n\").strip()\n",
    "                status = \"edited\" if edited else \"skipped\"\n",
    "                decisions_by_instance[instance_key] = (status, edited or None, llm_bundle)\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"decision\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"status\": status,\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"model\": llm_model,\n",
    "                        \"seed\": seed,\n",
    "                        \"mode\": mode_key,\n",
    "                        \"base_description\": base_desc,\n",
    "                        \"final_description\": edited or None,\n",
    "                        \"source\": \"user\",\n",
    "                        \"note\": \"edit_proposal\",\n",
    "                        \"llm_bundle\": llm_bundle,\n",
    "                    },\n",
    "                )\n",
    "                break\n",
    "\n",
    "            if cmd == \"m\":\n",
    "                manual_final = input(\"Manual final description (empty cancels) > \").rstrip(\"\\n\").strip()\n",
    "                status = \"manual\" if manual_final else \"skipped\"\n",
    "                decisions_by_instance[instance_key] = (status, manual_final or None, llm_bundle)\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"decision\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"status\": status,\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"model\": llm_model,\n",
    "                        \"seed\": seed,\n",
    "                        \"mode\": mode_key,\n",
    "                        \"base_description\": base_desc,\n",
    "                        \"final_description\": manual_final or None,\n",
    "                        \"source\": \"user\",\n",
    "                        \"note\": \"manual_replace\",\n",
    "                        \"llm_bundle\": llm_bundle,\n",
    "                    },\n",
    "                )\n",
    "                break\n",
    "\n",
    "            if cmd == \"s\":\n",
    "                decisions_by_instance[instance_key] = (\"skipped\", None, llm_bundle)\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"decision\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"status\": \"skipped\",\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"model\": llm_model,\n",
    "                        \"seed\": seed,\n",
    "                        \"mode\": mode_key,\n",
    "                        \"base_description\": base_desc,\n",
    "                        \"final_description\": None,\n",
    "                        \"source\": \"user\",\n",
    "                        \"note\": \"skip\",\n",
    "                        \"llm_bundle\": llm_bundle,\n",
    "                    },\n",
    "                )\n",
    "                break\n",
    "\n",
    "            if cmd == \"q\":\n",
    "                quit_requested = True\n",
    "                resume_next_index_1based = idx\n",
    "                break\n",
    "\n",
    "            print(\"Invalid command.\")\n",
    "\n",
    "        if quit_requested:\n",
    "            break\n",
    "\n",
    "    # ========= Apply decisions to file =========\n",
    "    tmp_path = path.with_suffix(path.suffix + \".tmp\")\n",
    "    updated_count = 0\n",
    "    patch_failures = 0\n",
    "\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as fin, tmp_path.open(\"w\", encoding=\"utf-8\") as fout:\n",
    "        for raw_line in fin:\n",
    "            line = raw_line.rstrip(\"\\n\")\n",
    "            if not line.strip():\n",
    "                fout.write(line + \"\\n\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                record = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                fout.write(line + \"\\n\")\n",
    "                continue\n",
    "\n",
    "            if not isinstance(record, dict):\n",
    "                fout.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "                continue\n",
    "\n",
    "            rid = _record_id(record, tool_field=tool_field)\n",
    "            tools = record.get(tool_field)\n",
    "\n",
    "            if isinstance(tools, list):\n",
    "                new_tools: List[Any] = []\n",
    "                for tool_index, entry in enumerate(tools):\n",
    "                    tool_obj, kind = _load_tool(entry)\n",
    "                    if not tool_obj:\n",
    "                        new_tools.append(entry)\n",
    "                        continue\n",
    "\n",
    "                    instance_key = _tool_instance_key(rid, tool_index, tool_obj)\n",
    "                    decision = decisions_by_instance.get(instance_key)\n",
    "\n",
    "                    if decision is None:\n",
    "                        new_tools.append(entry)\n",
    "                        continue\n",
    "\n",
    "                    status, new_desc, llm_bundle = decision\n",
    "                    if status in (\"accepted\", \"edited\", \"manual\") and new_desc:\n",
    "                        if kind == \"json_str\" and isinstance(entry, str):\n",
    "                            already_ok = False\n",
    "                            try:\n",
    "                                obj0 = json.loads(entry)\n",
    "                                if isinstance(obj0, dict) and obj0.get(\"description\") == new_desc:\n",
    "                                    already_ok = True\n",
    "                            except Exception:\n",
    "                                already_ok = False\n",
    "\n",
    "                            if already_ok:\n",
    "                                new_tools.append(entry)\n",
    "                                continue\n",
    "\n",
    "                            patched, ok, reason = _replace_top_level_string_field_in_raw_object(entry, \"description\", new_desc)\n",
    "                            if ok:\n",
    "                                new_tools.append(patched)\n",
    "                                updated_count += 1\n",
    "                            else:\n",
    "                                fallback_ok = False\n",
    "                                fallback_patched = entry\n",
    "                                if allow_reserialize_fallback:\n",
    "                                    try:\n",
    "                                        obj = json.loads(entry)\n",
    "                                        if isinstance(obj, dict):\n",
    "                                            obj[\"description\"] = new_desc\n",
    "                                            fallback_patched = json.dumps(obj, ensure_ascii=False)\n",
    "                                            fallback_ok = True\n",
    "                                    except Exception:\n",
    "                                        fallback_ok = False\n",
    "\n",
    "                                if fallback_ok:\n",
    "                                    new_tools.append(fallback_patched)\n",
    "                                    updated_count += 1\n",
    "                                    _append_audit_event(\n",
    "                                        audit_file,\n",
    "                                        {\n",
    "                                            \"event_type\": \"patch_fallback_reserialize\",\n",
    "                                            \"ts\": int(time.time()),\n",
    "                                            \"session_id\": session_id,\n",
    "                                            \"instance_key\": instance_key,\n",
    "                                            \"record_id\": rid,\n",
    "                                            \"tool_index\": tool_index,\n",
    "                                            \"tool_name\": tool_obj.get(\"name\"),\n",
    "                                            \"mode\": mode_key,\n",
    "                                            \"entry_sha256_before\": _sha256_text(entry),\n",
    "                                            \"entry_sha256_after\": _sha256_text(fallback_patched),\n",
    "                                            \"patch_reason\": reason,\n",
    "                                        },\n",
    "                                    )\n",
    "                                else:\n",
    "                                    new_tools.append(entry)\n",
    "                                    patch_failures += 1\n",
    "                        else:\n",
    "                            if tool_obj.get(\"description\") == new_desc:\n",
    "                                new_tools.append(tool_obj)\n",
    "                                continue\n",
    "                            tool_obj[\"description\"] = new_desc\n",
    "                            new_tools.append(tool_obj)\n",
    "                            updated_count += 1\n",
    "                    else:\n",
    "                        new_tools.append(entry)\n",
    "\n",
    "                record[tool_field] = new_tools\n",
    "\n",
    "            fout.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    if create_backup_of_target:\n",
    "        bak_path = path.with_suffix(path.suffix + \".bak\")\n",
    "        if not bak_path.exists():\n",
    "            shutil.copy2(path, bak_path)\n",
    "\n",
    "    tmp_path.replace(path)\n",
    "    after_sha = _sha256_file(path)\n",
    "\n",
    "    n_reviewed = len(decisions_by_instance)\n",
    "    n_skipped = sum(1 for st, _, _ in decisions_by_instance.values() if st == \"skipped\")\n",
    "    completed = (n_reviewed >= n_total) and (not quit_requested)\n",
    "\n",
    "    _append_audit_event(\n",
    "        audit_file,\n",
    "        {\n",
    "            \"event_type\": \"run_end\",\n",
    "            \"ts\": int(time.time()),\n",
    "            \"session_id\": session_id,\n",
    "            \"mode\": mode_key,\n",
    "            \"model\": llm_model,\n",
    "            \"seed\": seed,\n",
    "            \"dataset_path\": str(path),\n",
    "            \"dataset_sha256_at_session_start\": before_sha,\n",
    "            \"dataset_sha256_at_session_end\": after_sha,\n",
    "            \"n_total_occurrences\": n_total,\n",
    "            \"n_reviewed_total\": n_reviewed,\n",
    "            \"n_updated_this_session\": updated_count,\n",
    "            \"n_skipped_total\": n_skipped,\n",
    "            \"completed\": bool(completed),\n",
    "            \"quit_requested\": bool(quit_requested),\n",
    "            \"raw_patch_failures_this_session\": patch_failures,\n",
    "            \"resume_next_index_1based\": resume_next_index_1based if quit_requested else (n_total + 1 if completed else None),\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(\"\\nChanges applied.\")\n",
    "    print(f\"Mode: {mode_key}\")\n",
    "    print(f\"Descriptions updated (this session): {updated_count}\")\n",
    "    if patch_failures:\n",
    "        print(f\"Raw JSON-string patch failures (left unchanged): {patch_failures}\")\n",
    "    print(f\"Reviewed total (from audit): {n_reviewed} / {n_total}\")\n",
    "    print(f\"Completed: {completed} (quit_requested={quit_requested})\")\n",
    "    if quit_requested and resume_next_index_1based is not None:\n",
    "        print(f\"Resume next time from: [{resume_next_index_1based}/{n_total}]\")\n",
    "    print(f\"Updated file: {path}\")\n",
    "    print(f\"Audit file (same on resume): {audit_file}\")\n",
    "\n",
    "\n",
    "def _derive_working_copy_path(input_path: str, mode_key: str) -> str:\n",
    "    \"\"\"\n",
    "    Ensures per-style dataset separation (so you can interrupt/resume per style without collisions).\n",
    "    Example:\n",
    "      input:  foo.jsonl\n",
    "      mode:   style_verbose\n",
    "      output: foo.WORKING_COPY.style_verbose.jsonl\n",
    "    \"\"\"\n",
    "    p = Path(input_path)\n",
    "    return str(p.with_name(f\"{p.stem}.WORKING_COPY.{mode_key}{p.suffix}\"))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ----- Inputs -----\n",
    "    INPUT_JSONL = os.environ.get(\"INPUT_JSONL\") or \"When2Call/data/test/when2call_test_llm_judge.jsonl\"\n",
    "    MODE_KEY = os.environ.get(\"MODE_KEY\") or \"style_concise\"   # style_verbose | style_concise (aliases: style_coicnoso, style_coinceise)\n",
    "    LLM_MODEL = os.environ.get(\"LLM_MODEL\") or LLM_MODEL_DEFAULT\n",
    "\n",
    "    mode_key_resolved, _ = _resolve_style(MODE_KEY)\n",
    "\n",
    "    # Per-style working copy (separate dataset per style, by default)\n",
    "    OUTPUT_JSONL = os.environ.get(\"OUTPUT_JSONL\") or _derive_working_copy_path(INPUT_JSONL, mode_key_resolved)\n",
    "\n",
    "    working = make_working_copy(INPUT_JSONL, OUTPUT_JSONL, overwrite=False)\n",
    "    print(f\"Working copy: {working}\")\n",
    "\n",
    "    # ----- Runtime knobs -----\n",
    "    seed_env = os.environ.get(\"GEMINI_SEED\")\n",
    "    seed_val: Optional[int] = int(seed_env.strip()) if (seed_env and seed_env.strip()) else None\n",
    "\n",
    "    max_tokens_env = os.environ.get(\"GEMINI_MAX_TOKENS\")\n",
    "    max_tokens_val = int(max_tokens_env.strip()) if (max_tokens_env and max_tokens_env.strip()) else DEFAULT_MAX_TOKENS\n",
    "\n",
    "    retry_max_tokens_env = os.environ.get(\"GEMINI_RETRY_MAX_TOKENS\")\n",
    "    retry_max_tokens_val = int(retry_max_tokens_env.strip()) if (retry_max_tokens_env and retry_max_tokens_env.strip()) else RETRY_MAX_TOKENS\n",
    "\n",
    "    allow_reserialize_env = os.environ.get(\"ALLOW_RESERIALIZE_FALLBACK\")\n",
    "    allow_reserialize_val = (\n",
    "        bool(int(allow_reserialize_env.strip()))\n",
    "        if (allow_reserialize_env and allow_reserialize_env.strip())\n",
    "        else DEFAULT_ALLOW_RESERIALIZE_FALLBACK\n",
    "    )\n",
    "\n",
    "    interactive_llm_tools_in_jsonl(\n",
    "        working,\n",
    "        tool_field=\"tools\",\n",
    "        create_backup_of_target=False,\n",
    "        llm_model=LLM_MODEL,\n",
    "        seed=seed_val,\n",
    "        max_tokens=max_tokens_val,\n",
    "        retry_on_length=RETRY_ON_LENGTH,\n",
    "        retry_max_tokens=retry_max_tokens_val,\n",
    "        allow_reserialize_fallback=allow_reserialize_val,\n",
    "        min_sleep_sec_between_calls=0.0,\n",
    "        audit_dir=\"audit\",\n",
    "        mode_key=mode_key_resolved,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273c004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3  28 dicembre\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional, Tuple, List\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# ========= Config =========\n",
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "LLM_MODEL = \"gemini-2.5-flash\"\n",
    "MODE_KEY = \"style_verbose\"\n",
    "\n",
    "HASH_HEX_LEN = 32\n",
    "\n",
    "DEFAULT_MAX_TOKENS = 512\n",
    "RETRY_ON_LENGTH = True\n",
    "RETRY_MAX_TOKENS = 1024\n",
    "\n",
    "DEFAULT_ALLOW_RESERIALIZE_FALLBACK = False\n",
    "\n",
    "REGEN_DIVERSITY_INSTRUCTION = (\n",
    "    \"Return a meaning-equivalent rewrite that is lexically different from your previous rewrite; \"\n",
    "    \"avoid repeating the same sentence structure.\"\n",
    ")\n",
    "\n",
    "# How much of the rejected previous rewrite to store in audit (for resume) and to feed back into prompt.\n",
    "MAX_PREV_REWRITE_CHARS = 800\n",
    "\n",
    "\n",
    "# ========= Client =========\n",
    "def make_gemini_client() -> OpenAI:\n",
    "    token = os.environ.get(\"TOKEN_GEMINI\")\n",
    "    if not token:\n",
    "        raise RuntimeError(\"TOKEN_GEMINI environment variable is not set.\")\n",
    "    return OpenAI(api_key=token, base_url=GEMINI_BASE_URL)\n",
    "\n",
    "\n",
    "# ========= Small utils =========\n",
    "def _json_safe(obj: Any) -> Any:\n",
    "    if obj is None or isinstance(obj, (str, int, float, bool)):\n",
    "        return obj\n",
    "    if isinstance(obj, dict):\n",
    "        return {str(k): _json_safe(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return [_json_safe(x) for x in obj]\n",
    "    if hasattr(obj, \"model_dump\") and callable(getattr(obj, \"model_dump\")):\n",
    "        try:\n",
    "            return _json_safe(obj.model_dump())\n",
    "        except Exception:\n",
    "            pass\n",
    "    if hasattr(obj, \"dict\") and callable(getattr(obj, \"dict\")):\n",
    "        try:\n",
    "            return _json_safe(obj.dict())\n",
    "        except Exception:\n",
    "            pass\n",
    "    if hasattr(obj, \"__dict__\"):\n",
    "        try:\n",
    "            return _json_safe(vars(obj))\n",
    "        except Exception:\n",
    "            pass\n",
    "    try:\n",
    "        return str(obj)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def _sha256_text(s: str) -> str:\n",
    "    return hashlib.sha256((s or \"\").encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "def _canonical_json(obj: Any) -> str:\n",
    "    return json.dumps(obj, ensure_ascii=False, sort_keys=True, separators=(\",\", \":\"))\n",
    "\n",
    "\n",
    "def _sha256_file(path: Path) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with path.open(\"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(1024 * 1024), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "\n",
    "# ========= Raw JSON-string patcher (for tools stored as JSON strings) =========\n",
    "def _extract_json_string_value(raw_json: str, key: str) -> Optional[str]:\n",
    "    token = f'\"{key}\"'\n",
    "    i = raw_json.find(token)\n",
    "    if i < 0:\n",
    "        return None\n",
    "    i = raw_json.find(\":\", i + len(token))\n",
    "    if i < 0:\n",
    "        return None\n",
    "    i += 1\n",
    "    n = len(raw_json)\n",
    "    while i < n and raw_json[i] in \" \\t\\r\\n\":\n",
    "        i += 1\n",
    "    if i >= n or raw_json[i] != '\"':\n",
    "        return None\n",
    "    start = i\n",
    "    i += 1\n",
    "    esc = False\n",
    "    while i < n:\n",
    "        c = raw_json[i]\n",
    "        if esc:\n",
    "            esc = False\n",
    "        else:\n",
    "            if c == \"\\\\\":\n",
    "                esc = True\n",
    "            elif c == '\"':\n",
    "                return raw_json[start : i + 1]\n",
    "        i += 1\n",
    "    return None\n",
    "\n",
    "\n",
    "def _decode_raw_json_string(raw_json_string_with_quotes: str) -> str:\n",
    "    try:\n",
    "        obj = json.loads('{\"description\":' + raw_json_string_with_quotes + \"}\")\n",
    "        return obj.get(\"description\") or \"\"\n",
    "    except json.JSONDecodeError:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def _get_description_for_print(entry: Any) -> Tuple[str, str]:\n",
    "    if isinstance(entry, str):\n",
    "        raw = _extract_json_string_value(entry, \"description\")\n",
    "        if raw is not None:\n",
    "            return raw, \"raw_json\"\n",
    "        try:\n",
    "            obj = json.loads(entry)\n",
    "            return obj.get(\"description\") or \"\", \"rendered\"\n",
    "        except json.JSONDecodeError:\n",
    "            return \"\", \"rendered\"\n",
    "    if isinstance(entry, dict):\n",
    "        return entry.get(\"description\") or \"\", \"rendered\"\n",
    "    return \"\", \"rendered\"\n",
    "\n",
    "\n",
    "def _load_tool(entry: Any) -> Tuple[Optional[Dict[str, Any]], str]:\n",
    "    if isinstance(entry, str):\n",
    "        try:\n",
    "            return json.loads(entry), \"json_str\"\n",
    "        except json.JSONDecodeError:\n",
    "            return None, \"other\"\n",
    "    if isinstance(entry, dict):\n",
    "        return entry, \"dict\"\n",
    "    return None, \"other\"\n",
    "\n",
    "\n",
    "def _skip_ws(s: str, i: int) -> int:\n",
    "    n = len(s)\n",
    "    while i < n and s[i] in \" \\t\\r\\n\":\n",
    "        i += 1\n",
    "    return i\n",
    "\n",
    "\n",
    "def _scan_string_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    n = len(s)\n",
    "    if i >= n or s[i] != '\"':\n",
    "        return None\n",
    "    j = i + 1\n",
    "    esc = False\n",
    "    while j < n:\n",
    "        c = s[j]\n",
    "        if esc:\n",
    "            esc = False\n",
    "        else:\n",
    "            if c == \"\\\\\":\n",
    "                esc = True\n",
    "            elif c == '\"':\n",
    "                return (i, j + 1)\n",
    "        j += 1\n",
    "    return None\n",
    "\n",
    "\n",
    "def _scan_number_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    n = len(s)\n",
    "    j = i\n",
    "    if j < n and s[j] == \"-\":\n",
    "        j += 1\n",
    "    if j >= n:\n",
    "        return None\n",
    "    if s[j] == \"0\":\n",
    "        j += 1\n",
    "    elif s[j].isdigit():\n",
    "        while j < n and s[j].isdigit():\n",
    "            j += 1\n",
    "    else:\n",
    "        return None\n",
    "    if j < n and s[j] == \".\":\n",
    "        j += 1\n",
    "        if j >= n or not s[j].isdigit():\n",
    "            return None\n",
    "        while j < n and s[j].isdigit():\n",
    "            j += 1\n",
    "    if j < n and s[j] in \"eE\":\n",
    "        j += 1\n",
    "        if j < n and s[j] in \"+-\":\n",
    "            j += 1\n",
    "        if j >= n or not s[j].isdigit():\n",
    "            return None\n",
    "        while j < n and s[j].isdigit():\n",
    "            j += 1\n",
    "    return (i, j)\n",
    "\n",
    "\n",
    "def _scan_literal_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    for lit in (\"true\", \"false\", \"null\"):\n",
    "        if s.startswith(lit, i):\n",
    "            return (i, i + len(lit))\n",
    "    return None\n",
    "\n",
    "\n",
    "def _scan_container_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    n = len(s)\n",
    "    if i >= n:\n",
    "        return None\n",
    "\n",
    "    opener = s[i]\n",
    "    if opener not in \"{[\":\n",
    "        return None\n",
    "\n",
    "    stack: List[str] = [\"}\" if opener == \"{\" else \"]\"]\n",
    "    j = i + 1\n",
    "    in_str = False\n",
    "    esc = False\n",
    "\n",
    "    while j < n:\n",
    "        c = s[j]\n",
    "\n",
    "        if in_str:\n",
    "            if esc:\n",
    "                esc = False\n",
    "            else:\n",
    "                if c == \"\\\\\":\n",
    "                    esc = True\n",
    "                elif c == '\"':\n",
    "                    in_str = False\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        if c == '\"':\n",
    "            in_str = True\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        if c == \"{\":\n",
    "            stack.append(\"}\")\n",
    "            j += 1\n",
    "            continue\n",
    "        if c == \"[\":\n",
    "            stack.append(\"]\")\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        if c in \"}]\":\n",
    "            if not stack:\n",
    "                return None\n",
    "            expected = stack[-1]\n",
    "            if c != expected:\n",
    "                return None\n",
    "            stack.pop()\n",
    "            j += 1\n",
    "            if not stack:\n",
    "                return (i, j)\n",
    "            continue\n",
    "\n",
    "        j += 1\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def _is_value_delim(c: str) -> bool:\n",
    "    return c in \",}]\"\n",
    "\n",
    "\n",
    "def _scan_value_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    n = len(s)\n",
    "    i = _skip_ws(s, i)\n",
    "    if i >= n:\n",
    "        return None\n",
    "\n",
    "    c = s[i]\n",
    "    if c == '\"':\n",
    "        return _scan_string_span(s, i)\n",
    "    if c in \"{[\":\n",
    "        return _scan_container_span(s, i)\n",
    "\n",
    "    span: Optional[Tuple[int, int]]\n",
    "    if c == \"-\" or c.isdigit():\n",
    "        span = _scan_number_span(s, i)\n",
    "    else:\n",
    "        span = _scan_literal_span(s, i)\n",
    "\n",
    "    if not span:\n",
    "        return None\n",
    "\n",
    "    _, end = span\n",
    "    k = _skip_ws(s, end)\n",
    "    if k >= n:\n",
    "        return span\n",
    "    if _is_value_delim(s[k]):\n",
    "        return span\n",
    "    return None\n",
    "\n",
    "\n",
    "def _replace_top_level_string_field_in_raw_object(raw_json_obj: str, key: str, new_value: str) -> Tuple[str, bool, str]:\n",
    "    s = raw_json_obj\n",
    "    n = len(s)\n",
    "\n",
    "    i = _skip_ws(s, 0)\n",
    "    if i >= n or s[i] != \"{\":\n",
    "        return raw_json_obj, False, \"not_object\"\n",
    "\n",
    "    i += 1\n",
    "    found_any_key = False\n",
    "    expect_key = True\n",
    "\n",
    "    while True:\n",
    "        i = _skip_ws(s, i)\n",
    "        if i >= n:\n",
    "            return raw_json_obj, False, \"cannot_scan_value\"\n",
    "\n",
    "        if expect_key:\n",
    "            if s[i] == \"}\":\n",
    "                return raw_json_obj, False, \"key_not_found\"\n",
    "            if s[i] != '\"':\n",
    "                return raw_json_obj, False, \"invalid_key_string\"\n",
    "\n",
    "            key_span = _scan_string_span(s, i)\n",
    "            if not key_span:\n",
    "                return raw_json_obj, False, \"invalid_key_string\"\n",
    "\n",
    "            found_any_key = True\n",
    "            k_start, k_end = key_span\n",
    "            try:\n",
    "                key_decoded = json.loads(s[k_start:k_end])\n",
    "            except Exception:\n",
    "                return raw_json_obj, False, \"invalid_key_string\"\n",
    "\n",
    "            i = _skip_ws(s, k_end)\n",
    "            if i >= n or s[i] != \":\":\n",
    "                return raw_json_obj, False, \"missing_colon\"\n",
    "\n",
    "            v_span = _scan_value_span(s, i + 1)\n",
    "            if not v_span:\n",
    "                return raw_json_obj, False, \"cannot_scan_value\"\n",
    "\n",
    "            v_start, v_end = v_span\n",
    "\n",
    "            if key_decoded == key:\n",
    "                if v_start >= n or s[v_start] != '\"':\n",
    "                    return raw_json_obj, False, \"value_not_string\"\n",
    "\n",
    "                replacement_literal = json.dumps(new_value, ensure_ascii=False)\n",
    "                patched = s[:v_start] + replacement_literal + s[v_end:]\n",
    "\n",
    "                try:\n",
    "                    obj = json.loads(patched)\n",
    "                except Exception:\n",
    "                    return raw_json_obj, False, \"json_load_failed_after_patch\"\n",
    "\n",
    "                if isinstance(obj, dict) and obj.get(key) == new_value:\n",
    "                    return patched, True, \"ok\"\n",
    "                return raw_json_obj, False, \"validation_failed_after_patch\"\n",
    "\n",
    "            i = v_end\n",
    "            expect_key = False\n",
    "            continue\n",
    "\n",
    "        i = _skip_ws(s, i)\n",
    "        if i >= n:\n",
    "            return raw_json_obj, False, \"cannot_scan_value\"\n",
    "\n",
    "        if s[i] == \",\":\n",
    "            i += 1\n",
    "            expect_key = True\n",
    "            continue\n",
    "        if s[i] == \"}\":\n",
    "            return raw_json_obj, False, (\"key_not_found\" if found_any_key else \"key_not_found\")\n",
    "        return raw_json_obj, False, \"cannot_scan_value\"\n",
    "\n",
    "\n",
    "# ========= IDs =========\n",
    "def _tool_fingerprint_excluding_description(tool_obj: Dict[str, Any]) -> str:\n",
    "    filtered = {k: v for k, v in tool_obj.items() if k != \"description\"}\n",
    "    payload = _canonical_json(filtered)\n",
    "    return hashlib.sha256(payload.encode(\"utf-8\")).hexdigest()[:HASH_HEX_LEN]\n",
    "\n",
    "\n",
    "def _record_id(record_obj: Dict[str, Any], tool_field: str) -> str:\n",
    "    rec = dict(record_obj)\n",
    "    tools = rec.get(tool_field)\n",
    "    if isinstance(tools, list):\n",
    "        canon_tools: List[Any] = []\n",
    "        for entry in tools:\n",
    "            tool_obj, kind = _load_tool(entry)\n",
    "            if tool_obj is None:\n",
    "                canon_tools.append({\"_unparsed\": entry, \"_kind\": kind})\n",
    "            else:\n",
    "                canon_tools.append({k: v for k, v in tool_obj.items() if k != \"description\"})\n",
    "        rec[tool_field] = canon_tools\n",
    "    payload = _canonical_json(rec)\n",
    "    return hashlib.sha256(payload.encode(\"utf-8\")).hexdigest()[:HASH_HEX_LEN]\n",
    "\n",
    "\n",
    "def _tool_instance_key(record_id: str, tool_index: int, tool_obj: Dict[str, Any]) -> str:\n",
    "    fp = _tool_fingerprint_excluding_description(tool_obj)\n",
    "    return f\"rec:{record_id}:t{tool_index}:{fp}\"\n",
    "\n",
    "\n",
    "# ========= Audit (single file, resumable) =========\n",
    "def _audit_identity(dataset_path: Path, *, mode_key: str, model: str, tool_field: str) -> str:\n",
    "    stable = f\"{dataset_path.resolve()}|{mode_key}|{model}|{tool_field}\"\n",
    "    return hashlib.sha256(stable.encode(\"utf-8\")).hexdigest()[:12]\n",
    "\n",
    "\n",
    "def _audit_file_path(\n",
    "    dataset_path: Path,\n",
    "    *,\n",
    "    audit_dir: Path,\n",
    "    mode_key: str,\n",
    "    model: str,\n",
    "    tool_field: str,\n",
    ") -> Path:\n",
    "    audit_key = _audit_identity(dataset_path, mode_key=mode_key, model=model, tool_field=tool_field)\n",
    "    safe_model = \"\".join(ch if ch.isalnum() or ch in (\"-\", \"_\", \".\") else \"_\" for ch in model)\n",
    "    out_dir = audit_dir / audit_key\n",
    "    filename = f\"{dataset_path.stem}.{audit_key}.{mode_key}.{safe_model}.audit.jsonl\"\n",
    "    return out_dir / filename\n",
    "\n",
    "\n",
    "def _append_audit_event(audit_file: Path, event: Dict[str, Any]) -> None:\n",
    "    audit_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    safe_event = _json_safe(event)\n",
    "    with audit_file.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(safe_event, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "def _load_resume_state(\n",
    "    audit_file: Path,\n",
    ") -> Tuple[\n",
    "    Dict[str, Tuple[str, Optional[str], Optional[Dict[str, Any]]]],\n",
    "    Dict[str, int],\n",
    "    Dict[str, Optional[str]],\n",
    "    Optional[Dict[str, Any]],\n",
    "]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - decisions_by_instance: instance_key -> (status, final_description, llm_bundle)\n",
    "      - regen_counts: instance_key -> max regen_index observed\n",
    "      - last_rejected_text: instance_key -> last rejected proposal text (from regenerate events)\n",
    "      - prior_run_start: first run_start event (if any)\n",
    "    \"\"\"\n",
    "    decisions: Dict[str, Tuple[str, Optional[str], Optional[Dict[str, Any]]]] = {}\n",
    "    regen_counts: Dict[str, int] = {}\n",
    "    last_rejected_text: Dict[str, Optional[str]] = {}\n",
    "    prior_run_start: Optional[Dict[str, Any]] = None\n",
    "\n",
    "    if not audit_file.exists():\n",
    "        return decisions, regen_counts, last_rejected_text, None\n",
    "\n",
    "    # Track per-instance best regen index so we keep the latest text\n",
    "    best_ri: Dict[str, int] = {}\n",
    "\n",
    "    with audit_file.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                ev = json.loads(line)\n",
    "            except Exception:\n",
    "                continue\n",
    "            if not isinstance(ev, dict):\n",
    "                continue\n",
    "\n",
    "            et = ev.get(\"event_type\")\n",
    "            if et == \"run_start\" and prior_run_start is None:\n",
    "                prior_run_start = ev\n",
    "\n",
    "            if et == \"regenerate\":\n",
    "                ik = ev.get(\"instance_key\")\n",
    "                ri = ev.get(\"regen_index\")\n",
    "                txt = ev.get(\"last_proposal_text\")\n",
    "                if isinstance(ik, str) and isinstance(ri, int) and ri >= 0:\n",
    "                    prev = regen_counts.get(ik, 0)\n",
    "                    if ri > prev:\n",
    "                        regen_counts[ik] = ri\n",
    "                    prev_best = best_ri.get(ik, -1)\n",
    "                    if ri >= prev_best:\n",
    "                        best_ri[ik] = ri\n",
    "                        last_rejected_text[ik] = txt if isinstance(txt, str) else None\n",
    "\n",
    "            if et == \"decision\":\n",
    "                ik = ev.get(\"instance_key\")\n",
    "                status = ev.get(\"status\")\n",
    "                final_desc = ev.get(\"final_description\")\n",
    "                llm_bundle = ev.get(\"llm_bundle\")\n",
    "                if isinstance(ik, str) and isinstance(status, str):\n",
    "                    decisions[ik] = (\n",
    "                        status,\n",
    "                        final_desc if isinstance(final_desc, str) else None,\n",
    "                        llm_bundle if isinstance(llm_bundle, dict) else None,\n",
    "                    )\n",
    "\n",
    "    return decisions, regen_counts, last_rejected_text, prior_run_start\n",
    "\n",
    "\n",
    "# ========= LLM helpers =========\n",
    "def _ends_like_complete_sentence(text: str) -> bool:\n",
    "    t = (text or \"\").strip()\n",
    "    return bool(t) and t.endswith((\".\", \"!\", \"?\", \"”\", '\"', \"’\", \"'\"))\n",
    "\n",
    "\n",
    "def _sanitize_llm_output(text: str) -> str:\n",
    "    t = (text or \"\").strip()\n",
    "    if t.startswith(\"{\") and \"description\" in t:\n",
    "        try:\n",
    "            obj = json.loads(t)\n",
    "            if isinstance(obj, dict) and isinstance(obj.get(\"description\"), str):\n",
    "                t = obj[\"description\"].strip()\n",
    "        except Exception:\n",
    "            pass\n",
    "    if (t.startswith('\"') and t.endswith('\"')) or (t.startswith(\"'\") and t.endswith(\"'\")):\n",
    "        t = t[1:-1].strip()\n",
    "    return t\n",
    "\n",
    "\n",
    "def _llm_chat_completion(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    model: str,\n",
    "    messages: List[Dict[str, str]],\n",
    "    temperature: float,\n",
    "    max_tokens: int,\n",
    "    seed: Optional[int],\n",
    ") -> Tuple[str, Dict[str, Any]]:\n",
    "    meta: Dict[str, Any] = {\n",
    "        \"seed_requested\": seed,\n",
    "        \"seed_applied\": False,\n",
    "        \"seed_error\": None,\n",
    "        \"finish_reason\": None,\n",
    "        \"usage\": None,\n",
    "        \"max_tokens_requested\": int(max_tokens),\n",
    "        \"max_param_used\": None,\n",
    "    }\n",
    "\n",
    "    base_kwargs: Dict[str, Any] = dict(model=model, messages=messages, temperature=temperature)\n",
    "\n",
    "    def attempt(max_param_used: str, include_seed: bool) -> Tuple[str, Dict[str, Any]]:\n",
    "        req = dict(base_kwargs)\n",
    "        if max_param_used == \"max_completion_tokens\":\n",
    "            req[\"max_completion_tokens\"] = int(max_tokens)\n",
    "        else:\n",
    "            req[\"max_tokens\"] = int(max_tokens)\n",
    "        if include_seed and seed is not None:\n",
    "            req[\"seed\"] = int(seed)\n",
    "\n",
    "        resp = client.chat.completions.create(**req)\n",
    "        text = (resp.choices[0].message.content or \"\").strip()\n",
    "\n",
    "        meta_local = dict(meta)\n",
    "        meta_local[\"max_param_used\"] = max_param_used\n",
    "        meta_local[\"finish_reason\"] = getattr(resp.choices[0], \"finish_reason\", None)\n",
    "        meta_local[\"usage\"] = getattr(resp, \"usage\", None)\n",
    "        meta_local[\"seed_applied\"] = bool(include_seed and seed is not None)\n",
    "        return text, meta_local\n",
    "\n",
    "    def is_seed_error(e: Exception) -> bool:\n",
    "        s = str(e).lower()\n",
    "        return (\"seed\" in s) and (\"unknown\" in s or \"unsupported\" in s or \"invalid\" in s)\n",
    "\n",
    "    try:\n",
    "        return attempt(\"max_completion_tokens\", include_seed=True)\n",
    "    except Exception as e1:\n",
    "        if seed is not None and is_seed_error(e1):\n",
    "            meta[\"seed_error\"] = str(e1)\n",
    "            try:\n",
    "                return attempt(\"max_completion_tokens\", include_seed=False)\n",
    "            except Exception:\n",
    "                pass\n",
    "        try:\n",
    "            return attempt(\"max_tokens\", include_seed=True)\n",
    "        except Exception as e2:\n",
    "            if seed is not None and is_seed_error(e2):\n",
    "                meta[\"seed_error\"] = str(e2)\n",
    "                return attempt(\"max_tokens\", include_seed=False)\n",
    "            raise\n",
    "\n",
    "\n",
    "def generate_verbose_description_via_llm(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    tool_name: str,\n",
    "    base_description: str,\n",
    "    model: str,\n",
    "    seed: Optional[int],\n",
    "    max_tokens: int,\n",
    "    retry_on_length: bool,\n",
    "    retry_max_tokens: int,\n",
    "    regen_index: int = 0,\n",
    "    previous_rewrite: Optional[str] = None,\n",
    ") -> Tuple[str, Dict[str, Any]]:\n",
    "    system = (\n",
    "        \"Rewrite tool descriptions.\\n\"\n",
    "        \"Hard constraints:\\n\"\n",
    "        \"- Preserve meaning exactly; do not add new capabilities, steps, motivations, benefits, or context.\\n\"\n",
    "        \"- Do not delete information present in the original description.\\n\"\n",
    "        \"- Do not introduce new parameter names, IDs, field names, flags, or implementation details.\\n\"\n",
    "        \"- If parameter/field names/IDs/flags already appear in the original description, keep them (do not remove them).\\n\"\n",
    "        \"- Do not add examples, normative language, or assumptions.\\n\"\n",
    "        \"- Keep the same subject (the tool) and the same scope.\\n\"\n",
    "        \"- Output only the rewritten description text, nothing else.\\n\"\n",
    "        \"- Style: verbose but controlled; keep it concise and complete (1–2 sentences), clear and direct.\\n\"\n",
    "    )\n",
    "\n",
    "    user_parts: List[str] = []\n",
    "    user_parts.append(f\"Tool name: {tool_name}\")\n",
    "    user_parts.append(\"Base description:\")\n",
    "    user_parts.append(base_description.strip() or \"(empty)\")\n",
    "    user_parts.append(\"\")\n",
    "    user_parts.append(\"Rewrite in 'style_verbose' under the constraints.\")\n",
    "\n",
    "    if regen_index > 0:\n",
    "        user_parts.append(\"\")\n",
    "        user_parts.append(f\"Regeneration request: {regen_index}\")\n",
    "        user_parts.append(REGEN_DIVERSITY_INSTRUCTION)\n",
    "        if previous_rewrite and previous_rewrite.strip():\n",
    "            prev = previous_rewrite.strip()\n",
    "            if len(prev) > MAX_PREV_REWRITE_CHARS:\n",
    "                prev = prev[:MAX_PREV_REWRITE_CHARS].rstrip()\n",
    "            user_parts.append(\"\")\n",
    "            user_parts.append(\"Previous rewrite (do not reuse wording):\")\n",
    "            user_parts.append(prev)\n",
    "\n",
    "    user = \"\\n\".join(user_parts)\n",
    "\n",
    "    raw1, meta1 = _llm_chat_completion(\n",
    "        client=client,\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": user}],\n",
    "        temperature=0.0,\n",
    "        max_tokens=max_tokens,\n",
    "        seed=seed,\n",
    "    )\n",
    "    san1 = _sanitize_llm_output(raw1)\n",
    "    finish1 = (meta1.get(\"finish_reason\") or \"\").lower()\n",
    "    looks_truncated_1 = (finish1 == \"length\") or (san1 and not _ends_like_complete_sentence(san1))\n",
    "\n",
    "    if not looks_truncated_1:\n",
    "        return san1, {\n",
    "            \"proposal_origin\": \"primary\",\n",
    "            \"proposal_sanitized_final\": san1,\n",
    "            \"llm_text_raw_primary\": raw1,\n",
    "            \"llm_text_raw_retry\": None,\n",
    "            \"primary\": meta1,\n",
    "            \"retry\": None,\n",
    "        }\n",
    "\n",
    "    raw2 = None\n",
    "    meta2 = None\n",
    "    san2 = None\n",
    "    best_san = san1\n",
    "    origin = \"primary\"\n",
    "\n",
    "    if retry_on_length and retry_max_tokens > max_tokens:\n",
    "        raw2, meta2 = _llm_chat_completion(\n",
    "            client=client,\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": user}],\n",
    "            temperature=0.0,\n",
    "            max_tokens=int(retry_max_tokens),\n",
    "            seed=seed,\n",
    "        )\n",
    "        san2 = _sanitize_llm_output(raw2)\n",
    "        finish2 = (meta2.get(\"finish_reason\") or \"\").lower()\n",
    "        looks_truncated_2 = (finish2 == \"length\") or (san2 and not _ends_like_complete_sentence(san2))\n",
    "\n",
    "        if san2 and len(san2) >= len(best_san):\n",
    "            best_san = san2\n",
    "            origin = \"retry\"\n",
    "\n",
    "        if not looks_truncated_2 and san2:\n",
    "            return san2, {\n",
    "                \"proposal_origin\": \"retry\",\n",
    "                \"proposal_sanitized_final\": san2,\n",
    "                \"llm_text_raw_primary\": raw1,\n",
    "                \"llm_text_raw_retry\": raw2,\n",
    "                \"primary\": meta1,\n",
    "                \"retry\": meta2,\n",
    "            }\n",
    "\n",
    "    return best_san, {\n",
    "        \"proposal_origin\": origin,\n",
    "        \"proposal_sanitized_final\": best_san,\n",
    "        \"llm_text_raw_primary\": raw1,\n",
    "        \"llm_text_raw_retry\": raw2,\n",
    "        \"primary\": meta1,\n",
    "        \"retry\": meta2,\n",
    "    }\n",
    "\n",
    "\n",
    "# ========= IO =========\n",
    "def make_working_copy(input_jsonl: str, output_jsonl: str, *, overwrite: bool = False) -> str:\n",
    "    src = Path(input_jsonl)\n",
    "    dst = Path(output_jsonl)\n",
    "\n",
    "    if not src.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {src}\")\n",
    "\n",
    "    if dst.exists() and not overwrite:\n",
    "        return str(dst)\n",
    "\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(src, dst)\n",
    "    return str(dst)\n",
    "\n",
    "\n",
    "def _normalize_cmd(raw: str) -> str:\n",
    "    c = (raw or \"\").strip().lower()\n",
    "    if c in (\"\", \"y\", \"yes\", \"ok\", \"okay\", \"si\", \"sì\"):\n",
    "        return \"y\"\n",
    "    if c in (\"r\", \"retry\", \"again\", \"prova\", \"prova ancora\", \"rigenera\"):\n",
    "        return \"r\"\n",
    "    if c in (\"e\", \"edit\", \"modifica\"):\n",
    "        return \"e\"\n",
    "    if c in (\"m\", \"manual\", \"mine\", \"mio\", \"mia\", \"custom\"):\n",
    "        return \"m\"\n",
    "    if c in (\"s\", \"skip\", \"salta\", \"pass\"):\n",
    "        return \"s\"\n",
    "    if c in (\"q\", \"quit\", \"exit\", \"esci\"):\n",
    "        return \"q\"\n",
    "    return c\n",
    "\n",
    "\n",
    "# ========= Main interactive =========\n",
    "def interactive_llm_verbose_tools_in_jsonl(\n",
    "    jsonl_path: str,\n",
    "    *,\n",
    "    tool_field: str,\n",
    "    create_backup_of_target: bool,\n",
    "    llm_model: str,\n",
    "    seed: Optional[int],\n",
    "    max_tokens: int,\n",
    "    retry_on_length: bool,\n",
    "    retry_max_tokens: int,\n",
    "    allow_reserialize_fallback: bool,\n",
    "    min_sleep_sec_between_calls: float,\n",
    "    audit_dir: str,\n",
    ") -> None:\n",
    "    path = Path(jsonl_path)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {jsonl_path}\")\n",
    "\n",
    "    client = make_gemini_client()\n",
    "    audit_file = _audit_file_path(\n",
    "        path,\n",
    "        audit_dir=Path(audit_dir),\n",
    "        mode_key=MODE_KEY,\n",
    "        model=llm_model,\n",
    "        tool_field=tool_field,\n",
    "    )\n",
    "\n",
    "    decisions_by_instance, regen_counts, last_rejected_text_by_instance, prior_run_start = _load_resume_state(audit_file)\n",
    "\n",
    "    tool_order: List[Dict[str, Any]] = []\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for raw_line in f:\n",
    "            line = raw_line.rstrip(\"\\n\")\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            try:\n",
    "                record = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "            if not isinstance(record, dict):\n",
    "                continue\n",
    "\n",
    "            rid = _record_id(record, tool_field=tool_field)\n",
    "            tools = record.get(tool_field)\n",
    "            if not isinstance(tools, list):\n",
    "                continue\n",
    "\n",
    "            for tool_index, entry in enumerate(tools):\n",
    "                tool_obj, kind = _load_tool(entry)\n",
    "                if not tool_obj:\n",
    "                    continue\n",
    "                name = (tool_obj.get(\"name\") or \"\").strip()\n",
    "                if not name:\n",
    "                    continue\n",
    "\n",
    "                desc_print, desc_mode = _get_description_for_print(entry)\n",
    "                instance_key = _tool_instance_key(rid, tool_index, tool_obj)\n",
    "\n",
    "                tool_order.append(\n",
    "                    {\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_index,\n",
    "                        \"tool_name\": name,\n",
    "                        \"desc_print\": desc_print,\n",
    "                        \"desc_mode\": desc_mode,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"entry_kind\": kind,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    n_total = len(tool_order)\n",
    "    n_prev_reviewed = len(decisions_by_instance)\n",
    "\n",
    "    start_pos = 0\n",
    "    while start_pos < n_total and tool_order[start_pos][\"instance_key\"] in decisions_by_instance:\n",
    "        start_pos += 1\n",
    "\n",
    "    session_id = hashlib.sha256(f\"{time.time_ns()}\".encode(\"utf-8\")).hexdigest()[:12]\n",
    "    before_sha = _sha256_file(path)\n",
    "\n",
    "    if prior_run_start is None:\n",
    "        _append_audit_event(\n",
    "            audit_file,\n",
    "            {\n",
    "                \"event_type\": \"run_start\",\n",
    "                \"ts\": int(time.time()),\n",
    "                \"session_id\": session_id,\n",
    "                \"mode\": MODE_KEY,\n",
    "                \"model\": llm_model,\n",
    "                \"seed\": seed,\n",
    "                \"dataset_path\": str(path),\n",
    "                \"dataset_sha256_at_session_start\": before_sha,\n",
    "                \"tool_field\": tool_field,\n",
    "                \"n_total_occurrences\": n_total,\n",
    "                \"max_tokens_requested\": int(max_tokens),\n",
    "                \"retry_on_length\": bool(retry_on_length),\n",
    "                \"retry_max_tokens\": int(retry_max_tokens),\n",
    "                \"allow_reserialize_fallback\": bool(allow_reserialize_fallback),\n",
    "            },\n",
    "        )\n",
    "    else:\n",
    "        _append_audit_event(\n",
    "            audit_file,\n",
    "            {\n",
    "                \"event_type\": \"run_resume\",\n",
    "                \"ts\": int(time.time()),\n",
    "                \"session_id\": session_id,\n",
    "                \"mode\": MODE_KEY,\n",
    "                \"model\": llm_model,\n",
    "                \"seed\": seed,\n",
    "                \"dataset_path\": str(path),\n",
    "                \"dataset_sha256_at_session_start\": before_sha,\n",
    "                \"tool_field\": tool_field,\n",
    "                \"n_total_occurrences\": n_total,\n",
    "                \"n_previously_reviewed\": n_prev_reviewed,\n",
    "                \"resume_from_index_1based\": (start_pos + 1) if start_pos < n_total else (n_total + 1),\n",
    "            },\n",
    "        )\n",
    "\n",
    "    print(f\"Target: {path}\")\n",
    "    print(f\"Audit file (RESUMABLE): {audit_file}\")\n",
    "    print(f\"Tool occurrences total: {n_total}\")\n",
    "    if start_pos < n_total:\n",
    "        print(f\"Resume position: [{start_pos + 1}/{n_total}] (previously reviewed: {n_prev_reviewed})\")\n",
    "    else:\n",
    "        print(f\"Resume position: completed (previously reviewed: {n_prev_reviewed})\")\n",
    "    print(f\"LLM: {llm_model} @ {GEMINI_BASE_URL}\")\n",
    "    print(f\"Max tokens: {int(max_tokens)}; retry_on_length={bool(retry_on_length)}; retry_max_tokens={int(retry_max_tokens)}\")\n",
    "    print(\"Commands: ENTER/ok=accept, r=regenerate, e=edit, m=manual, s=skip, q=quit\\n\")\n",
    "\n",
    "    quit_requested = False\n",
    "    resume_next_index_1based: Optional[int] = None\n",
    "\n",
    "    for pos in range(start_pos, n_total):\n",
    "        item = tool_order[pos]\n",
    "        idx = pos + 1\n",
    "\n",
    "        name = item[\"tool_name\"]\n",
    "        desc_mode = item[\"desc_mode\"]\n",
    "        old_desc_print = item[\"desc_print\"]\n",
    "        instance_key = item[\"instance_key\"]\n",
    "        rid = item[\"record_id\"]\n",
    "        tool_i = item[\"tool_index\"]\n",
    "\n",
    "        # Per-instance regen state (resumable for regen_index; previous rejected text is best-effort).\n",
    "        regen_index_local = int(regen_counts.get(instance_key, 0))\n",
    "        previous_rewrite_local: Optional[str] = last_rejected_text_by_instance.get(instance_key)\n",
    "\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"[{idx}/{n_total}] {name}\")\n",
    "        print(f\"instance_key: {instance_key} (record_id={rid}, tool_index={tool_i})\")\n",
    "\n",
    "        if desc_mode == \"raw_json\":\n",
    "            print(\"Current description RAW (escaped):\")\n",
    "            print(old_desc_print if old_desc_print else \"(empty)\")\n",
    "            base_desc = _decode_raw_json_string(old_desc_print) if old_desc_print else \"\"\n",
    "            print(\"\\nCurrent description DECODED:\")\n",
    "            print(base_desc if base_desc else \"(empty)\")\n",
    "        else:\n",
    "            base_desc = old_desc_print or \"\"\n",
    "            print(\"Current description:\")\n",
    "            print(base_desc if base_desc else \"(empty)\")\n",
    "\n",
    "        proposal = \"\"\n",
    "        llm_bundle: Optional[Dict[str, Any]] = None\n",
    "\n",
    "        while True:\n",
    "            if not proposal:\n",
    "                try:\n",
    "                    proposal, llm_bundle = generate_verbose_description_via_llm(\n",
    "                        client=client,\n",
    "                        tool_name=name,\n",
    "                        base_description=base_desc,\n",
    "                        model=llm_model,\n",
    "                        seed=seed,\n",
    "                        max_tokens=max_tokens,\n",
    "                        retry_on_length=retry_on_length,\n",
    "                        retry_max_tokens=retry_max_tokens,\n",
    "                        regen_index=regen_index_local,\n",
    "                        previous_rewrite=previous_rewrite_local,\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nLLM ERROR: {e}\")\n",
    "                    cmd = _normalize_cmd(input(\"Choice [m=manual, e=edit, s=skip, q=quit] > \"))\n",
    "                    now = int(time.time())\n",
    "\n",
    "                    if cmd == \"q\":\n",
    "                        quit_requested = True\n",
    "                        resume_next_index_1based = idx\n",
    "                        break\n",
    "\n",
    "                    if cmd == \"s\":\n",
    "                        decisions_by_instance[instance_key] = (\"skipped\", None, None)\n",
    "                        _append_audit_event(\n",
    "                            audit_file,\n",
    "                            {\n",
    "                                \"event_type\": \"decision\",\n",
    "                                \"ts\": now,\n",
    "                                \"session_id\": session_id,\n",
    "                                \"status\": \"skipped\",\n",
    "                                \"tool_name\": name,\n",
    "                                \"instance_key\": instance_key,\n",
    "                                \"record_id\": rid,\n",
    "                                \"tool_index\": tool_i,\n",
    "                                \"model\": llm_model,\n",
    "                                \"seed\": seed,\n",
    "                                \"base_description\": base_desc,\n",
    "                                \"final_description\": None,\n",
    "                                \"source\": \"user\",\n",
    "                                \"note\": \"skip_after_llm_error\",\n",
    "                            },\n",
    "                        )\n",
    "                        break\n",
    "\n",
    "                    if cmd in (\"m\", \"e\"):\n",
    "                        manual_final = input(\"Manual final description (empty cancels) > \").rstrip(\"\\n\").strip()\n",
    "                        status = \"manual\" if (cmd == \"m\" and manual_final) else (\"edited\" if (cmd == \"e\" and manual_final) else \"skipped\")\n",
    "                        decisions_by_instance[instance_key] = (status, manual_final or None, None)\n",
    "                        _append_audit_event(\n",
    "                            audit_file,\n",
    "                            {\n",
    "                                \"event_type\": \"decision\",\n",
    "                                \"ts\": now,\n",
    "                                \"session_id\": session_id,\n",
    "                                \"status\": status,\n",
    "                                \"tool_name\": name,\n",
    "                                \"instance_key\": instance_key,\n",
    "                                \"record_id\": rid,\n",
    "                                \"tool_index\": tool_i,\n",
    "                                \"model\": llm_model,\n",
    "                                \"seed\": seed,\n",
    "                                \"base_description\": base_desc,\n",
    "                                \"final_description\": manual_final or None,\n",
    "                                \"source\": \"user\",\n",
    "                                \"note\": \"manual_or_edit_after_llm_error\",\n",
    "                            },\n",
    "                        )\n",
    "                        break\n",
    "\n",
    "                    proposal = \"\"\n",
    "                    continue\n",
    "\n",
    "                proposal = (proposal or \"\").strip()\n",
    "\n",
    "            print(\"\\nLLM proposal:\")\n",
    "            print(proposal if proposal else \"(empty)\")\n",
    "\n",
    "            if llm_bundle:\n",
    "                try:\n",
    "                    origin = llm_bundle.get(\"proposal_origin\")\n",
    "                    p = llm_bundle.get(\"primary\")\n",
    "                    r = llm_bundle.get(\"retry\")\n",
    "                    print(f\"\\nproposal_origin={origin}\")\n",
    "                    if p:\n",
    "                        print(f\"meta: finish_reason={p.get('finish_reason')}, max_param_used={p.get('max_param_used')}, usage={p.get('usage')}\")\n",
    "                    if r:\n",
    "                        print(f\"meta(retry): finish_reason={r.get('finish_reason')}, max_param_used={r.get('max_param_used')}, usage={r.get('usage')}\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            cmd = _normalize_cmd(input(\"\\nChoice [ENTER=accept, r=regen, e=edit, m=manual, s=skip, q=quit] > \"))\n",
    "            now = int(time.time())\n",
    "\n",
    "            if cmd == \"y\":\n",
    "                if proposal.strip():\n",
    "                    decisions_by_instance[instance_key] = (\"accepted\", proposal.strip(), llm_bundle)\n",
    "                    _append_audit_event(\n",
    "                        audit_file,\n",
    "                        {\n",
    "                            \"event_type\": \"decision\",\n",
    "                            \"ts\": now,\n",
    "                            \"session_id\": session_id,\n",
    "                            \"status\": \"accepted\",\n",
    "                            \"tool_name\": name,\n",
    "                            \"instance_key\": instance_key,\n",
    "                            \"record_id\": rid,\n",
    "                            \"tool_index\": tool_i,\n",
    "                            \"model\": llm_model,\n",
    "                            \"seed\": seed,\n",
    "                            \"base_description\": base_desc,\n",
    "                            \"final_description\": proposal.strip(),\n",
    "                            \"source\": \"llm\",\n",
    "                            \"llm_bundle\": llm_bundle,\n",
    "                        },\n",
    "                    )\n",
    "                else:\n",
    "                    decisions_by_instance[instance_key] = (\"skipped\", None, llm_bundle)\n",
    "                    _append_audit_event(\n",
    "                        audit_file,\n",
    "                        {\n",
    "                            \"event_type\": \"decision\",\n",
    "                            \"ts\": now,\n",
    "                            \"session_id\": session_id,\n",
    "                            \"status\": \"skipped\",\n",
    "                            \"tool_name\": name,\n",
    "                            \"instance_key\": instance_key,\n",
    "                            \"record_id\": rid,\n",
    "                            \"tool_index\": tool_i,\n",
    "                            \"model\": llm_model,\n",
    "                            \"seed\": seed,\n",
    "                            \"base_description\": base_desc,\n",
    "                            \"final_description\": None,\n",
    "                            \"source\": \"llm\",\n",
    "                            \"note\": \"empty_proposal\",\n",
    "                            \"llm_bundle\": llm_bundle,\n",
    "                        },\n",
    "                    )\n",
    "                break\n",
    "\n",
    "            if cmd == \"r\":\n",
    "                # Store the rejected output and feed it back as \"previous rewrite\" for the next generation.\n",
    "                previous_rewrite_local = proposal.strip() if proposal else None\n",
    "                if previous_rewrite_local and len(previous_rewrite_local) > MAX_PREV_REWRITE_CHARS:\n",
    "                    previous_rewrite_local = previous_rewrite_local[:MAX_PREV_REWRITE_CHARS].rstrip()\n",
    "\n",
    "                regen_counts[instance_key] = regen_counts.get(instance_key, 0) + 1\n",
    "                regen_index_local = int(regen_counts[instance_key])\n",
    "\n",
    "                # Persist the rejected text for resume.\n",
    "                last_rejected_text_by_instance[instance_key] = previous_rewrite_local\n",
    "\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"regenerate\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"regen_index\": regen_index_local,\n",
    "                        \"last_proposal_sha256\": _sha256_text(proposal),\n",
    "                        \"last_proposal_text\": previous_rewrite_local,\n",
    "                        \"last_proposal_origin\": (llm_bundle or {}).get(\"proposal_origin\") if llm_bundle else None,\n",
    "                    },\n",
    "                )\n",
    "\n",
    "                proposal = \"\"\n",
    "                llm_bundle = None\n",
    "                if min_sleep_sec_between_calls > 0:\n",
    "                    time.sleep(min_sleep_sec_between_calls)\n",
    "                continue\n",
    "\n",
    "            if cmd == \"e\":\n",
    "                edited = input(\"Edit proposal (empty cancels) > \").rstrip(\"\\n\").strip()\n",
    "                status = \"edited\" if edited else \"skipped\"\n",
    "                decisions_by_instance[instance_key] = (status, edited or None, llm_bundle)\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"decision\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"status\": status,\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"model\": llm_model,\n",
    "                        \"seed\": seed,\n",
    "                        \"base_description\": base_desc,\n",
    "                        \"final_description\": edited or None,\n",
    "                        \"source\": \"user\",\n",
    "                        \"note\": \"edit_proposal\",\n",
    "                        \"llm_bundle\": llm_bundle,\n",
    "                    },\n",
    "                )\n",
    "                break\n",
    "\n",
    "            if cmd == \"m\":\n",
    "                manual_final = input(\"Manual final description (empty cancels) > \").rstrip(\"\\n\").strip()\n",
    "                status = \"manual\" if manual_final else \"skipped\"\n",
    "                decisions_by_instance[instance_key] = (status, manual_final or None, llm_bundle)\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"decision\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"status\": status,\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"model\": llm_model,\n",
    "                        \"seed\": seed,\n",
    "                        \"base_description\": base_desc,\n",
    "                        \"final_description\": manual_final or None,\n",
    "                        \"source\": \"user\",\n",
    "                        \"note\": \"manual_replace\",\n",
    "                        \"llm_bundle\": llm_bundle,\n",
    "                    },\n",
    "                )\n",
    "                break\n",
    "\n",
    "            if cmd == \"s\":\n",
    "                decisions_by_instance[instance_key] = (\"skipped\", None, llm_bundle)\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"decision\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"status\": \"skipped\",\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"model\": llm_model,\n",
    "                        \"seed\": seed,\n",
    "                        \"base_description\": base_desc,\n",
    "                        \"final_description\": None,\n",
    "                        \"source\": \"user\",\n",
    "                        \"note\": \"skip\",\n",
    "                        \"llm_bundle\": llm_bundle,\n",
    "                    },\n",
    "                )\n",
    "                break\n",
    "\n",
    "            if cmd == \"q\":\n",
    "                quit_requested = True\n",
    "                resume_next_index_1based = idx\n",
    "                break\n",
    "\n",
    "            print(\"Invalid command.\")\n",
    "\n",
    "        if quit_requested:\n",
    "            break\n",
    "\n",
    "    # ========= Apply decisions to file =========\n",
    "    tmp_path = path.with_suffix(path.suffix + \".tmp\")\n",
    "    updated_count = 0\n",
    "    patch_failures = 0\n",
    "\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as fin, tmp_path.open(\"w\", encoding=\"utf-8\") as fout:\n",
    "        for raw_line in fin:\n",
    "            line = raw_line.rstrip(\"\\n\")\n",
    "            if not line.strip():\n",
    "                fout.write(line + \"\\n\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                record = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                fout.write(line + \"\\n\")\n",
    "                continue\n",
    "\n",
    "            if not isinstance(record, dict):\n",
    "                fout.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "                continue\n",
    "\n",
    "            rid = _record_id(record, tool_field=tool_field)\n",
    "            tools = record.get(tool_field)\n",
    "\n",
    "            if isinstance(tools, list):\n",
    "                new_tools: List[Any] = []\n",
    "                for tool_index, entry in enumerate(tools):\n",
    "                    tool_obj, kind = _load_tool(entry)\n",
    "                    if not tool_obj:\n",
    "                        new_tools.append(entry)\n",
    "                        continue\n",
    "\n",
    "                    instance_key = _tool_instance_key(rid, tool_index, tool_obj)\n",
    "                    decision = decisions_by_instance.get(instance_key)\n",
    "\n",
    "                    if decision is None:\n",
    "                        new_tools.append(entry)\n",
    "                        continue\n",
    "\n",
    "                    status, new_desc, llm_bundle = decision\n",
    "                    if status in (\"accepted\", \"edited\", \"manual\") and new_desc:\n",
    "                        if kind == \"json_str\" and isinstance(entry, str):\n",
    "                            # Skip patch if already correct\n",
    "                            already_ok = False\n",
    "                            try:\n",
    "                                obj0 = json.loads(entry)\n",
    "                                if isinstance(obj0, dict) and obj0.get(\"description\") == new_desc:\n",
    "                                    already_ok = True\n",
    "                            except Exception:\n",
    "                                already_ok = False\n",
    "\n",
    "                            if already_ok:\n",
    "                                new_tools.append(entry)\n",
    "                                continue\n",
    "\n",
    "                            patched, ok, reason = _replace_top_level_string_field_in_raw_object(entry, \"description\", new_desc)\n",
    "                            if ok:\n",
    "                                new_tools.append(patched)\n",
    "                                updated_count += 1\n",
    "                            else:\n",
    "                                fallback_ok = False\n",
    "                                fallback_patched = entry\n",
    "                                if allow_reserialize_fallback:\n",
    "                                    try:\n",
    "                                        obj = json.loads(entry)\n",
    "                                        if isinstance(obj, dict):\n",
    "                                            obj[\"description\"] = new_desc\n",
    "                                            fallback_patched = json.dumps(obj, ensure_ascii=False)\n",
    "                                            fallback_ok = True\n",
    "                                    except Exception:\n",
    "                                        fallback_ok = False\n",
    "\n",
    "                                if fallback_ok:\n",
    "                                    new_tools.append(fallback_patched)\n",
    "                                    updated_count += 1\n",
    "                                    _append_audit_event(\n",
    "                                        audit_file,\n",
    "                                        {\n",
    "                                            \"event_type\": \"patch_fallback_reserialize\",\n",
    "                                            \"ts\": int(time.time()),\n",
    "                                            \"session_id\": session_id,\n",
    "                                            \"instance_key\": instance_key,\n",
    "                                            \"record_id\": rid,\n",
    "                                            \"tool_index\": tool_index,\n",
    "                                            \"tool_name\": tool_obj.get(\"name\"),\n",
    "                                            \"entry_sha256_before\": _sha256_text(entry),\n",
    "                                            \"entry_sha256_after\": _sha256_text(fallback_patched),\n",
    "                                            \"patch_reason\": reason,\n",
    "                                        },\n",
    "                                    )\n",
    "                                else:\n",
    "                                    new_tools.append(entry)\n",
    "                                    patch_failures += 1\n",
    "                                    _append_audit_event(\n",
    "                                        audit_file,\n",
    "                                        {\n",
    "                                            \"event_type\": \"patch_failure\",\n",
    "                                            \"ts\": int(time.time()),\n",
    "                                            \"session_id\": session_id,\n",
    "                                            \"instance_key\": instance_key,\n",
    "                                            \"record_id\": rid,\n",
    "                                            \"tool_index\": tool_index,\n",
    "                                            \"tool_name\": tool_obj.get(\"name\"),\n",
    "                                            \"status\": status,\n",
    "                                            \"patch_reason\": reason,\n",
    "                                            \"final_description_sha256\": _sha256_text(new_desc),\n",
    "                                            \"entry_sha256\": _sha256_text(entry),\n",
    "                                            \"entry_excerpt\": entry[:240],\n",
    "                                            \"llm_text_raw_primary_sha256\": _sha256_text((llm_bundle or {}).get(\"llm_text_raw_primary\") or \"\"),\n",
    "                                            \"llm_text_raw_retry_sha256\": _sha256_text((llm_bundle or {}).get(\"llm_text_raw_retry\") or \"\"),\n",
    "                                            \"proposal_origin\": (llm_bundle or {}).get(\"proposal_origin\"),\n",
    "                                        },\n",
    "                                    )\n",
    "                        else:\n",
    "                            if tool_obj.get(\"description\") == new_desc:\n",
    "                                new_tools.append(tool_obj)\n",
    "                                continue\n",
    "                            tool_obj[\"description\"] = new_desc\n",
    "                            new_tools.append(tool_obj)\n",
    "                            updated_count += 1\n",
    "                    else:\n",
    "                        new_tools.append(entry)\n",
    "\n",
    "                record[tool_field] = new_tools\n",
    "\n",
    "            fout.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    if create_backup_of_target:\n",
    "        bak_path = path.with_suffix(path.suffix + \".bak\")\n",
    "        if not bak_path.exists():\n",
    "            shutil.copy2(path, bak_path)\n",
    "\n",
    "    tmp_path.replace(path)\n",
    "    after_sha = _sha256_file(path)\n",
    "\n",
    "    n_reviewed = len(decisions_by_instance)\n",
    "    n_skipped = sum(1 for st, _, _ in decisions_by_instance.values() if st == \"skipped\")\n",
    "    completed = (n_reviewed >= n_total) and (not quit_requested)\n",
    "\n",
    "    _append_audit_event(\n",
    "        audit_file,\n",
    "        {\n",
    "            \"event_type\": \"run_end\",\n",
    "            \"ts\": int(time.time()),\n",
    "            \"session_id\": session_id,\n",
    "            \"mode\": MODE_KEY,\n",
    "            \"model\": llm_model,\n",
    "            \"seed\": seed,\n",
    "            \"dataset_path\": str(path),\n",
    "            \"dataset_sha256_at_session_start\": before_sha,\n",
    "            \"dataset_sha256_at_session_end\": after_sha,\n",
    "            \"n_total_occurrences\": n_total,\n",
    "            \"n_reviewed_total\": n_reviewed,\n",
    "            \"n_updated_this_session\": updated_count,\n",
    "            \"n_skipped_total\": n_skipped,\n",
    "            \"completed\": bool(completed),\n",
    "            \"quit_requested\": bool(quit_requested),\n",
    "            \"raw_patch_failures_this_session\": patch_failures,\n",
    "            \"resume_next_index_1based\": resume_next_index_1based if quit_requested else (n_total + 1 if completed else None),\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(\"\\nChanges applied.\")\n",
    "    print(f\"Descriptions updated (this session): {updated_count}\")\n",
    "    if patch_failures:\n",
    "        print(f\"Raw JSON-string patch failures (left unchanged): {patch_failures}\")\n",
    "    print(f\"Reviewed total (from audit): {n_reviewed} / {n_total}\")\n",
    "    print(f\"Completed: {completed} (quit_requested={quit_requested})\")\n",
    "    if quit_requested and resume_next_index_1based is not None:\n",
    "        print(f\"Resume next time from: [{resume_next_index_1based}/{n_total}]\")\n",
    "    print(f\"Updated file: {path}\")\n",
    "    print(f\"Audit file (same on resume): {audit_file}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT_JSONL = \"When2Call/data/test/when2call_test_llm_judge.jsonl\"\n",
    "    OUTPUT_JSONL = \"When2Call/data/test/when2call_test_llm_judge.WORKING_COPY.jsonl\"\n",
    "\n",
    "    working = make_working_copy(INPUT_JSONL, OUTPUT_JSONL, overwrite=False)\n",
    "    print(f\"Working copy: {working}\")\n",
    "\n",
    "    seed_env = os.environ.get(\"GEMINI_SEED\")\n",
    "    seed_val: Optional[int] = int(seed_env.strip()) if (seed_env and seed_env.strip()) else None\n",
    "\n",
    "    max_tokens_env = os.environ.get(\"GEMINI_MAX_TOKENS\")\n",
    "    max_tokens_val = int(max_tokens_env.strip()) if (max_tokens_env and max_tokens_env.strip()) else DEFAULT_MAX_TOKENS\n",
    "\n",
    "    retry_max_tokens_env = os.environ.get(\"GEMINI_RETRY_MAX_TOKENS\")\n",
    "    retry_max_tokens_val = int(retry_max_tokens_env.strip()) if (retry_max_tokens_env and retry_max_tokens_env.strip()) else RETRY_MAX_TOKENS\n",
    "\n",
    "    allow_reserialize_env = os.environ.get(\"ALLOW_RESERIALIZE_FALLBACK\")\n",
    "    allow_reserialize_val = (\n",
    "        bool(int(allow_reserialize_env.strip()))\n",
    "        if (allow_reserialize_env and allow_reserialize_env.strip())\n",
    "        else DEFAULT_ALLOW_RESERIALIZE_FALLBACK\n",
    "    )\n",
    "\n",
    "    interactive_llm_verbose_tools_in_jsonl(\n",
    "        working,\n",
    "        tool_field=\"tools\",\n",
    "        create_backup_of_target=False,\n",
    "        llm_model=LLM_MODEL,\n",
    "        seed=seed_val,\n",
    "        max_tokens=max_tokens_val,\n",
    "        retry_on_length=RETRY_ON_LENGTH,\n",
    "        retry_max_tokens=retry_max_tokens_val,\n",
    "        allow_reserialize_fallback=allow_reserialize_val,\n",
    "        min_sleep_sec_between_calls=0.0,\n",
    "        audit_dir=\"audit\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514e0984",
   "metadata": {},
   "source": [
    "# Da qua in giu non usare. altre versioni automatiche di cerazione delle varianti ma non perfette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968cbb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# ================== BASE CONFIG ==================\n",
    "\n",
    "DEFAULT_INPUT_JSONL = \"When2Call/data/test/when2call_test_llm_judge.jsonl\"\n",
    "DEFAULT_OUTPUT_DIR = \"when2call_local_variants\"\n",
    "\n",
    "# Modalità di riscrittura delle descrizioni (semantica diversa)\n",
    "MODES: List[str] = [\n",
    "    \"no_desc\",            # 1) descrizione vuota\n",
    "    \"short_label\",        # 2) etichetta di 2–3 parole\n",
    "    \"verbose_examples\",   # 3) descrizione verbosa con esempi d'uso\n",
    "    \"verbose_normative\",  # 4) descrizione verbosa + linee guida comportamentali\n",
    "    \"misleading\",         # 5) descrizione ambigua/sottospecificata\n",
    "]\n",
    "\n",
    "# Timeout minimo tra una chiamata reale al modello e la successiva (in secondi)\n",
    "RATE_LIMIT_SLEEP = 3\n",
    "\n",
    "# Cache in-memory per non richiamare il modello sulle stesse specifiche\n",
    "_DESCRIPTION_CACHE: Dict[str, str] = {}\n",
    "\n",
    "# Timestamp dell'ultima chiamata reale al modello (per rate limiting globale)\n",
    "_LAST_CALL_TIME: float | None = None\n",
    "\n",
    "\n",
    "# ================== HELPER: MODEL CLIENT ==================\n",
    "\n",
    "def make_jrc_client() -> OpenAI:\n",
    "    \"\"\"\n",
    "    Create an OpenAI client for the JRC gateway.\n",
    "\n",
    "    Requires the environment variable TOKEN_JRC to be set.\n",
    "    \"\"\"\n",
    "    token = os.environ.get(\"TOKEN_JRC\")\n",
    "    if not token:\n",
    "        raise RuntimeError(\"TOKEN_JRC environment variable is not set.\")\n",
    "    client = OpenAI(\n",
    "        api_key=token,\n",
    "        base_url=\"https://api-gpt.jrc.ec.europa.eu/v1\",\n",
    "    )\n",
    "    return client\n",
    "\n",
    "\n",
    "# ================== HELPER: UTILS ==================\n",
    "\n",
    "def sanitize_model_name_for_path(model_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Sanitize a model name so it can safely be used as part of a filename.\n",
    "\n",
    "    - Keeps letters, digits, '-', '_', and '.' as-is.\n",
    "    - Replaces any other character with '-'.\n",
    "    \"\"\"\n",
    "    allowed = set(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-_.\")\n",
    "    return \"\".join(ch if ch in allowed else \"-\" for ch in model_name)\n",
    "\n",
    "\n",
    "def extract_parameters_for_prompt(spec: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Extract parameter info from a JSON-Schema-style 'parameters' field\n",
    "    without modifying the original spec.\n",
    "\n",
    "    Returns a list of dicts like:\n",
    "        {\"name\": ..., \"type\": ..., \"description\": ..., \"required\": bool}\n",
    "    \"\"\"\n",
    "    params = spec.get(\"parameters\", {}) or {}\n",
    "    if not isinstance(params, dict):\n",
    "        return []\n",
    "\n",
    "    props = params.get(\"properties\", {}) or {}\n",
    "    if not isinstance(props, dict):\n",
    "        props = {}\n",
    "\n",
    "    required_list = params.get(\"required\", []) or []\n",
    "    if not isinstance(required_list, list):\n",
    "        required_list = []\n",
    "\n",
    "    param_info_list: List[Dict[str, Any]] = []\n",
    "    for name, meta in props.items():\n",
    "        if not isinstance(meta, dict):\n",
    "            meta = {}\n",
    "        p_type = meta.get(\"type\", \"string\")\n",
    "        p_desc = (meta.get(\"description\") or \"\").strip()\n",
    "        param_info_list.append(\n",
    "            {\n",
    "                \"name\": name,\n",
    "                \"type\": p_type,\n",
    "                \"description\": p_desc,\n",
    "                \"required\": name in required_list,\n",
    "            }\n",
    "        )\n",
    "    return param_info_list\n",
    "\n",
    "\n",
    "def build_param_block_for_prompt(param_info: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"\n",
    "    Build a textual summary of parameters to provide as context to the LLM\n",
    "    (this text is NOT inserted into the JSON schema, only used in the prompt).\n",
    "    \"\"\"\n",
    "    if not param_info:\n",
    "        return \"This tool has no explicit structured parameters in the schema.\"\n",
    "\n",
    "    lines = [\"Here are the schema parameters:\"]\n",
    "    for p in param_info:\n",
    "        bits = [f\"name={p['name']}\"]\n",
    "        if p.get(\"type\"):\n",
    "            bits.append(f\"type={p['type']}\")\n",
    "        if p.get(\"required\"):\n",
    "            bits.append(\"required=true\")\n",
    "        if p.get(\"description\"):\n",
    "            bits.append(f\"description={p['description']}\")\n",
    "        lines.append(\"  - \" + \"; \".join(bits))\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def build_generation_prompt(\n",
    "    mode: str,\n",
    "    tool_name: str,\n",
    "    orig_desc: str,\n",
    "    param_info: List[Dict[str, Any]],\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Build the instruction prompt for the LLM that rewrites the tool description\n",
    "    according to the given 'mode'.\n",
    "    \"\"\"\n",
    "    if mode not in MODES:\n",
    "        raise ValueError(f\"Unknown mode for generation prompt: {mode}\")\n",
    "\n",
    "    param_block = build_param_block_for_prompt(param_info)\n",
    "    base_context = f\"\"\"You are helping to rewrite tool descriptions for a function-calling benchmark.\n",
    "\n",
    "We have a tool with:\n",
    "- Name: {tool_name}\n",
    "- Original description (may be empty): {orig_desc if orig_desc else \"[NONE]\"}\n",
    "\n",
    "{param_block}\n",
    "\n",
    "You must write a NEW description string for this tool.\n",
    "The description will be embedded directly into the tool JSON as the \"description\" field.\n",
    "\n",
    "GENERAL RULES (always apply):\n",
    "- Write in clear, concise English.\n",
    "- The description must be a single continuous text block (you can use short sentences).\n",
    "- Do NOT mention that you are an AI model.\n",
    "- Do NOT include markdown, bullet markers like '-', or backticks.\n",
    "- Do NOT refer to \"users\" as \"you\" if it becomes confusing; instead, describe what the tool does.\n",
    "- Do NOT talk about \"this schema\" or \"this prompt\"; just describe the tool.\n",
    "- Output ONLY the new description text, with no extra commentary.\n",
    "\"\"\"\n",
    "\n",
    "    if mode == \"short_label\":\n",
    "        mode_instructions = \"\"\"\n",
    "MODE: short_label\n",
    "\n",
    "- Write a VERY SHORT label (2–3 words) that summarizes what the tool does.\n",
    "- Use only plain English words, no punctuation, no numbers unless essential.\n",
    "- Do NOT include verbs like \"use\", \"get\", \"call\"; prefer noun phrases (e.g. \"Weather lookup\", \"Stock prices\").\n",
    "- Do NOT mention parameters explicitly.\n",
    "- The output MUST be at most 3 words.\n",
    "\"\"\"\n",
    "    elif mode == \"verbose_examples\":\n",
    "        mode_instructions = \"\"\"\n",
    "MODE: verbose_examples\n",
    "\n",
    "- Describe clearly what the tool does and what inputs it expects.\n",
    "- Incorporate the parameter information into the description in natural language.\n",
    "- Explain briefly what the tool returns.\n",
    "- Include 1–2 short conceptual usage examples embedded in the text (e.g. \"For example, ...\").\n",
    "- The examples must be consistent with the parameters and the tool's purpose.\n",
    "- Do NOT give explicit behavioral policies such as \"use this tool when...\".\n",
    "\"\"\"\n",
    "    elif mode == \"verbose_normative\":\n",
    "        mode_instructions = \"\"\"\n",
    "MODE: verbose_normative\n",
    "\n",
    "- Describe the tool, its inputs, and what it returns.\n",
    "- Incorporate the parameter information into the description in natural language.\n",
    "- Include 1–2 short conceptual usage examples embedded in the text.\n",
    "- Additionally, include explicit behavioral guidelines, such as:\n",
    "  - When the tool SHOULD be used.\n",
    "  - When a follow-up question is needed because required information is missing.\n",
    "  - When the tool SHOULD NOT be used (e.g., out-of-scope queries).\n",
    "- Phrase these guidelines in natural language, as part of the description.\n",
    "\"\"\"\n",
    "    elif mode == \"misleading\":\n",
    "        mode_instructions = \"\"\"\n",
    "MODE: misleading\n",
    "\n",
    "- Write a plausible but partially inaccurate description of the tool.\n",
    "- Keep the general topic related to the tool name and parameters, but:\n",
    "  - Over-emphasize a secondary or edge-case use, OR\n",
    "  - Omit an important limitation, OR\n",
    "  - Slightly misstate the typical purpose (for example, focus on historical data when the tool is mainly for real-time queries).\n",
    "- Do NOT claim that the tool can handle any possible request or \"everything\".\n",
    "- Do NOT change or contradict the parameter types, but you may downplay or fail to mention some of them.\n",
    "- The result should sound like realistic but sloppy documentation that could mislead an LLM.\n",
    "\"\"\"\n",
    "    elif mode == \"no_desc\":\n",
    "        # This mode does not use the LLM; handled separately.\n",
    "        mode_instructions = \"\"\n",
    "    else:\n",
    "        # Should not happen because of the check at the top\n",
    "        raise ValueError(f\"Unexpected mode in build_generation_prompt: {mode}\")\n",
    "\n",
    "    return base_context + \"\\n\" + mode_instructions.strip()\n",
    "\n",
    "\n",
    "def llm_generate_description(\n",
    "    client: OpenAI,\n",
    "    model: str,\n",
    "    mode: str,\n",
    "    tool_name: str,\n",
    "    orig_desc: str,\n",
    "    param_info: List[Dict[str, Any]],\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Call the LLM to generate a new description for a tool in a given mode.\n",
    "\n",
    "    Uses an in-memory cache to avoid duplicate calls and enforces a minimum\n",
    "    delay of RATE_LIMIT_SLEEP seconds between *real* LLM calls to respect\n",
    "    rate limits.\n",
    "    \"\"\"\n",
    "    global _LAST_CALL_TIME\n",
    "\n",
    "    # Build a cache key based on mode, model, name, original description, and parameters.\n",
    "    params_signature = json.dumps(param_info, sort_keys=True, ensure_ascii=False)\n",
    "    cache_key = f\"{model}||{mode}||{tool_name}||{orig_desc.strip()}||{params_signature}\"\n",
    "\n",
    "    # Cache hit: niente chiamata al modello, niente delay\n",
    "    if cache_key in _DESCRIPTION_CACHE:\n",
    "        return _DESCRIPTION_CACHE[cache_key]\n",
    "\n",
    "    # Applica rate limiting PRIMA della chiamata reale al modello\n",
    "    if _LAST_CALL_TIME is not None and RATE_LIMIT_SLEEP > 0:\n",
    "        elapsed = time.monotonic() - _LAST_CALL_TIME\n",
    "        if elapsed < RATE_LIMIT_SLEEP:\n",
    "            sleep_for = RATE_LIMIT_SLEEP - elapsed\n",
    "            # print(f\"[RATE LIMIT] Sleeping for {sleep_for:.2f} seconds before LLM call...\")\n",
    "            time.sleep(sleep_for)\n",
    "\n",
    "    # Build the prompt\n",
    "    prompt = build_generation_prompt(mode, tool_name, orig_desc, param_info)\n",
    "\n",
    "    # Call the LLM\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You rewrite tool descriptions for function-calling APIs.\"\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=256,\n",
    "    )\n",
    "    text = (response.choices[0].message.content or \"\").strip()\n",
    "\n",
    "    # Cache the result\n",
    "    _DESCRIPTION_CACHE[cache_key] = text\n",
    "\n",
    "    # Aggiorna l'istante dell'ultima chiamata reale\n",
    "    _LAST_CALL_TIME = time.monotonic()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# ================== CORE: TOOL REWRITING ==================\n",
    "\n",
    "def rewrite_tools_for_mode_with_llm(\n",
    "    client: OpenAI,\n",
    "    generation_model: str,\n",
    "    tools: List[Any],\n",
    "    mode: str,\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Given the 'tools' field of a When2Call example (list of JSON strings or dicts),\n",
    "    return a NEW list of JSON strings where ONLY the 'description' field of each tool\n",
    "    is rewritten using the LLM according to 'mode'.\n",
    "\n",
    "    Supported tool shapes:\n",
    "      1) {\"type\": \"function\", \"function\": { \"name\": ..., \"description\": ..., \"parameters\": ... }}\n",
    "      2) {\"name\": ..., \"description\": ..., \"parameters\": ...}\n",
    "    \"\"\"\n",
    "    if mode not in MODES:\n",
    "        raise ValueError(f\"Unknown mode in rewrite_tools_for_mode_with_llm: {mode}\")\n",
    "\n",
    "    new_tools: List[str] = []\n",
    "\n",
    "    for tool_entry in tools or []:\n",
    "        # Normalize to dict\n",
    "        if isinstance(tool_entry, str):\n",
    "            tool_str = tool_entry\n",
    "            if not tool_str.strip():\n",
    "                new_tools.append(tool_str)\n",
    "                continue\n",
    "            try:\n",
    "                spec = json.loads(tool_str)\n",
    "            except json.JSONDecodeError:\n",
    "                # Malformed JSON, keep as-is\n",
    "                new_tools.append(tool_str)\n",
    "                continue\n",
    "        elif isinstance(tool_entry, dict):\n",
    "            spec = tool_entry\n",
    "        else:\n",
    "            # Unexpected type, just dump it back\n",
    "            new_tools.append(json.dumps(tool_entry, ensure_ascii=False))\n",
    "            continue\n",
    "\n",
    "        # Handle wrapper case: {\"type\": \"function\", \"function\": {...}}\n",
    "        if \"function\" in spec and isinstance(spec[\"function\"], dict):\n",
    "            fn = spec[\"function\"]\n",
    "            orig_desc = fn.get(\"description\", \"\") or \"\"\n",
    "            tool_name = fn.get(\"name\", \"unnamed_tool\")\n",
    "\n",
    "            if mode == \"no_desc\":\n",
    "                new_desc = \"\"\n",
    "            else:\n",
    "                param_info = extract_parameters_for_prompt(fn)\n",
    "                new_desc = llm_generate_description(\n",
    "                    client=client,\n",
    "                    model=generation_model,\n",
    "                    mode=mode,\n",
    "                    tool_name=tool_name,\n",
    "                    orig_desc=orig_desc,\n",
    "                    param_info=param_info,\n",
    "                )\n",
    "\n",
    "            fn[\"description\"] = new_desc\n",
    "            spec[\"function\"] = fn\n",
    "            new_tools.append(json.dumps(spec, ensure_ascii=False))\n",
    "\n",
    "        else:\n",
    "            # Flat case: {\"name\": ..., \"description\": ..., \"parameters\": ...}\n",
    "            fn = spec\n",
    "            orig_desc = fn.get(\"description\", \"\") or \"\"\n",
    "            tool_name = fn.get(\"name\", \"unnamed_tool\")\n",
    "\n",
    "            if mode == \"no_desc\":\n",
    "                new_desc = \"\"\n",
    "            else:\n",
    "                param_info = extract_parameters_for_prompt(fn)\n",
    "                new_desc = llm_generate_description(\n",
    "                    client=client,\n",
    "                    model=generation_model,\n",
    "                    mode=mode,\n",
    "                    tool_name=tool_name,\n",
    "                    orig_desc=orig_desc,\n",
    "                    param_info=param_info,\n",
    "                )\n",
    "\n",
    "            fn[\"description\"] = new_desc\n",
    "            new_tools.append(json.dumps(fn, ensure_ascii=False))\n",
    "\n",
    "    return new_tools\n",
    "\n",
    "\n",
    "# ================== BUILD JSONL VARIANT ==================\n",
    "\n",
    "def build_variant_jsonl_with_llm(\n",
    "    client: OpenAI,\n",
    "    generation_model: str,\n",
    "    input_path: str,\n",
    "    output_path: str,\n",
    "    mode: str,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Read a When2Call-style JSONL file and write a new JSONL file where ONLY the\n",
    "    tool descriptions are rewritten according to 'mode' using an LLM.\n",
    "\n",
    "    All fields EXCEPT 'tools[*].description' are preserved exactly.\n",
    "    \"\"\"\n",
    "    if mode not in MODES:\n",
    "        raise ValueError(f\"Unknown mode in build_variant_jsonl_with_llm: {mode}\")\n",
    "\n",
    "    num_lines = 0\n",
    "    num_modified = 0\n",
    "\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as fin, \\\n",
    "         open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "\n",
    "        for line in fin:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            num_lines += 1\n",
    "\n",
    "            obj = json.loads(line)\n",
    "\n",
    "            tools = obj.get(\"tools\", [])\n",
    "            if tools:\n",
    "                new_tools = rewrite_tools_for_mode_with_llm(\n",
    "                    client=client,\n",
    "                    generation_model=generation_model,\n",
    "                    tools=tools,\n",
    "                    mode=mode,\n",
    "                )\n",
    "                if new_tools != tools:\n",
    "                    num_modified += 1\n",
    "                obj[\"tools\"] = new_tools\n",
    "\n",
    "            # Everything else (uuid, question, answers, labels, etc.) is unchanged\n",
    "            fout.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(\n",
    "        f\"[{mode}] Wrote {output_path} \"\n",
    "        f\"(lines: {num_lines}, examples with tools modified: {num_modified})\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ================== ENTRYPOINT (ES. PER NOTEBOOK) ==================\n",
    "\n",
    "def run_when2call_variants(\n",
    "    client: OpenAI,\n",
    "    generation_model: str,\n",
    "    input_jsonl: str = DEFAULT_INPUT_JSONL,\n",
    "    output_dir: str = DEFAULT_OUTPUT_DIR,\n",
    "    modes: List[str] | None = None,\n",
    "    overwrite: bool = False,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Generate multiple When2Call dataset variants where ONLY tool descriptions\n",
    "    are changed via an LLM, under different 'modes'.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    client : OpenAI\n",
    "        OpenAI client already configured for the JRC gateway.\n",
    "    generation_model : str\n",
    "        Name of the LLM used to rewrite descriptions (e.g. \"gpt-4o\", \"llama-3.3-70b-instruct\").\n",
    "        This name will also be embedded in the output filenames.\n",
    "    input_jsonl : str\n",
    "        Path to the original When2Call JSONL test file.\n",
    "    output_dir : str\n",
    "        Directory where variant JSONL files will be written.\n",
    "    modes : List[str] or None\n",
    "        List of modes to generate (subset of MODES). If None, all MODES are used.\n",
    "    overwrite : bool\n",
    "        If False (default), existing files are skipped. If True, files are regenerated.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(input_jsonl):\n",
    "        raise FileNotFoundError(f\"Input file not found: {input_jsonl}\")\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    base_name = os.path.splitext(os.path.basename(input_jsonl))[0]\n",
    "    model_tag = sanitize_model_name_for_path(generation_model)\n",
    "\n",
    "    active_modes = modes if modes is not None else MODES\n",
    "\n",
    "    # Validate modes\n",
    "    unknown = [m for m in active_modes if m not in MODES]\n",
    "    if unknown:\n",
    "        raise ValueError(f\"Unknown modes requested: {unknown}. Allowed: {MODES}\")\n",
    "\n",
    "    print(f\"Using input file: {input_jsonl}\")\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    print(f\"Generation model tag for filenames: {model_tag}\")\n",
    "    print(\n",
    "        \"The original file acts as the 'original' condition (no modification). \"\n",
    "        f\"This function can create up to {len(active_modes)} additional variants.\"\n",
    "    )\n",
    "\n",
    "    for mode in active_modes:\n",
    "        out_name = f\"{base_name}_{model_tag}_{mode}.jsonl\"\n",
    "        out_path = os.path.join(output_dir, out_name)\n",
    "\n",
    "        if os.path.exists(out_path) and not overwrite:\n",
    "            print(f\"[{mode}] Skipping {out_path} (already exists, overwrite=False).\")\n",
    "            continue\n",
    "\n",
    "        build_variant_jsonl_with_llm(\n",
    "            client=client,\n",
    "            generation_model=generation_model,\n",
    "            input_path=input_jsonl,\n",
    "            output_path=out_path,\n",
    "            mode=mode,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75cd681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: When2Call/data/test/when2call_test_llm_judge.jsonl\n",
      "Output dir: when2call_local_variants\n",
      "Generator model: gpt-oss-120b\n",
      "Modes: ['style_concise', 'style_verbose', 'add_examples']\n",
      "Temperature: 0.0 | max_tokens: 256 | retries: 8 | repair_rounds: 3\n",
      "[style_concise] Wrote when2call_local_variants/when2call_test_llm_judge__gen-gpt-oss-120b__mode-style_concise.jsonl\n",
      "[style_concise] Audit directory: when2call_local_variants/audit/gpt-oss-120b__style_concise\n",
      "[style_concise] Cache DB: when2call_local_variants/tool_desc_cache.sqlite3\n",
      "[style_verbose] Wrote when2call_local_variants/when2call_test_llm_judge__gen-gpt-oss-120b__mode-style_verbose.jsonl\n",
      "[style_verbose] Audit directory: when2call_local_variants/audit/gpt-oss-120b__style_verbose\n",
      "[style_verbose] Cache DB: when2call_local_variants/tool_desc_cache.sqlite3\n",
      "[add_examples] Wrote when2call_local_variants/when2call_test_llm_judge__gen-gpt-oss-120b__mode-add_examples.jsonl\n",
      "[add_examples] Audit directory: when2call_local_variants/audit/gpt-oss-120b__add_examples\n",
      "[add_examples] Cache DB: when2call_local_variants/tool_desc_cache.sqlite3\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "When2Call Tool-Description Variant Generator (Reproducible, Auditable, Minimal-Edit)\n",
    "\n",
    "This script generates controlled dataset variants by modifying ONLY the tool description\n",
    "string(s) inside the `tools` field of each JSONL example, while preserving the original\n",
    "JSONL line formatting as much as technically feasible (i.e., without re-serializing the\n",
    "outer JSON object). The tool JSON strings inside `tools` are patched in-place at the\n",
    "exact JSON string-span level, so parameter sub-descriptions and unrelated keys remain\n",
    "bitwise-identical unless a fallback path is explicitly triggered and logged.\n",
    "\n",
    "Design goals:\n",
    "- Minimal-diff patching: only the tool-level \"description\" is modified, not the entire JSON.\n",
    "- Deterministic outputs: temperature defaults to 0, strict post-processing, validation+repair.\n",
    "- Persistent cache: SQLite-backed caching keyed by a cryptographic signature.\n",
    "- Full audit trail: JSONL logs with prompt, raw outputs, repairs, validations, and fallbacks.\n",
    "- Reviewer-grade perturbations: a small set (<=5) of widely accepted doc-perturbation axes.\n",
    "- Hard validators: mode-specific constraints are enforced; invalid outputs are repaired or rejected.\n",
    "- Schema-aware checks: required parameters coverage and unknown-parameter mention checks.\n",
    "\n",
    "Expected input:\n",
    "- JSONL where each line is a JSON object containing (optionally) \"tools\": a list.\n",
    "- Each `tools[i]` is typically a JSON-encoded string of a tool schema, but may also be a dict.\n",
    "\n",
    "Outputs:\n",
    "- One JSONL per mode where only tool description fields are updated per mode.\n",
    "- Sidecar files under output_dir: SQLite cache and audit logs.\n",
    "\n",
    "Environment variables:\n",
    "- TOKEN_JRC: required for JRC gateway access (OpenAI-compatible).\n",
    "- Optional: HTTP(S)_PROXY as needed by environment.\n",
    "\n",
    "Usage (CLI example):\n",
    "  python when2call_variants_art_5modes.py \\\n",
    "      --input When2Call/data/test/when2call_test_llm_judge.jsonl \\\n",
    "      --output-dir when2call_local_variants \\\n",
    "      --generation-model gpt-oss-120b \\\n",
    "      --modes empty_desc style_concise style_verbose add_examples normative_injection \\\n",
    "      --overwrite\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import dataclasses\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import sqlite3\n",
    "import sys\n",
    "import time\n",
    "from typing import Any, Dict, List, Optional, Sequence, Tuple\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# ================== CONFIGURATION ==================\n",
    "\n",
    "DEFAULT_INPUT_JSONL = \"When2Call/data/test/when2call_test_llm_judge.jsonl\"\n",
    "DEFAULT_OUTPUT_DIR = \"when2call_local_variants\"\n",
    "\n",
    "# Reviewer-grade perturbations (MAX 5):\n",
    "# 1) empty_desc: remove tool description entirely (description=\"\").\n",
    "# 2) style_concise: semantic-preserving rewrite, concise, no examples, no normative language.\n",
    "# 3) style_verbose: semantic-preserving rewrite, verbose, no examples, no normative language.\n",
    "# 4) add_examples: semantic-preserving rewrite + 1-2 conceptual examples (no normative language).\n",
    "# 5) normative_injection: semantic-preserving rewrite + prescriptive usage guidance + 1-2 examples.\n",
    "MODES: List[str] = [\n",
    "    \"empty_desc\",\n",
    "    \"style_concise\",\n",
    "    \"style_verbose\",\n",
    "    \"add_examples\",\n",
    "    \"normative_injection\",\n",
    "]\n",
    "\n",
    "# LLM call discipline\n",
    "DEFAULT_TEMPERATURE = 0.0\n",
    "DEFAULT_MAX_TOKENS = 256\n",
    "DEFAULT_RATE_LIMIT_SLEEP_SEC = 0.0\n",
    "DEFAULT_MAX_RETRIES = 8\n",
    "\n",
    "# Repair is the critical reliability lever (Option 2: guided repair).\n",
    "# Slightly higher default than 2 to reduce \"rejected -> unchanged\" collapse.\n",
    "DEFAULT_REPAIR_MAX_ROUNDS = 3\n",
    "\n",
    "# Output discipline (hard constraints)\n",
    "DESCRIPTION_MAX_CHARS = 1200\n",
    "\n",
    "# Persistent cache / audit\n",
    "CACHE_DB_NAME = \"tool_desc_cache.sqlite3\"\n",
    "AUDIT_DIR_NAME = \"audit\"\n",
    "AUDIT_CALLS_JSONL = \"generation_calls.jsonl\"\n",
    "AUDIT_EVENTS_JSONL = \"variant_events.jsonl\"\n",
    "AUDIT_SUMMARY_JSON = \"variant_summary.json\"\n",
    "AUDIT_FALLBACKS_JSONL = \"fallback_events.jsonl\"\n",
    "\n",
    "# Reproducibility\n",
    "DEFAULT_RANDOM_SEED = 1337\n",
    "\n",
    "\n",
    "# ================== CLIENT ==================\n",
    "\n",
    "def make_jrc_client() -> OpenAI:\n",
    "    \"\"\"\n",
    "    Create an OpenAI-compatible client for the JRC gateway.\n",
    "\n",
    "    Requires:\n",
    "    - TOKEN_JRC environment variable.\n",
    "    \"\"\"\n",
    "    token = os.environ.get(\"TOKEN_JRC\")\n",
    "    if not token:\n",
    "        raise RuntimeError(\"TOKEN_JRC environment variable is not set.\")\n",
    "    return OpenAI(api_key=token, base_url=\"https://api-gpt.jrc.ec.europa.eu/v1\")\n",
    "\n",
    "\n",
    "# ================== SMALL UTILITIES ==================\n",
    "\n",
    "def sanitize_model_name_for_path(model_name: str) -> str:\n",
    "    allowed = set(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-_.\")\n",
    "    return \"\".join(ch if ch in allowed else \"-\" for ch in model_name)\n",
    "\n",
    "\n",
    "def stable_sha256(text: str) -> str:\n",
    "    return hashlib.sha256(text.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "def json_escape_string(value: str) -> str:\n",
    "    # json.dumps returns a quoted JSON string; slice off quotes.\n",
    "    return json.dumps(value, ensure_ascii=False)[1:-1]\n",
    "\n",
    "\n",
    "def normalize_single_line(text: str) -> str:\n",
    "    return \" \".join((text or \"\").split()).strip()\n",
    "\n",
    "\n",
    "def now_unix() -> float:\n",
    "    return time.time()\n",
    "\n",
    "\n",
    "def ensure_dir(path: str) -> None:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "def _dedupe_preserve_order(items: Sequence[str]) -> List[str]:\n",
    "    seen = set()\n",
    "    out: List[str] = []\n",
    "    for x in items:\n",
    "        if x not in seen:\n",
    "            seen.add(x)\n",
    "            out.append(x)\n",
    "    return out\n",
    "\n",
    "\n",
    "# ================== JSON SPAN PARSER (MINIMAL-EDIT PATCHING) ==================\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class JsonNode:\n",
    "    kind: str  # \"object\" | \"array\" | \"string\" | \"number\" | \"true\" | \"false\" | \"null\"\n",
    "    start: int\n",
    "    end: int\n",
    "    value: Any = None\n",
    "    obj: Optional[Dict[str, \"JsonNode\"]] = None\n",
    "    arr: Optional[List[\"JsonNode\"]] = None\n",
    "\n",
    "\n",
    "class JsonSpanParseError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class JsonSpanParser:\n",
    "    \"\"\"\n",
    "    A JSON parser that returns both decoded values and exact source spans.\n",
    "\n",
    "    This parser is intentionally limited to valid JSON (RFC 8259).\n",
    "    It is used to patch tool-description substrings in-place without re-serializing\n",
    "    the entire JSON.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, s: str):\n",
    "        self.s = s\n",
    "        self.n = len(s)\n",
    "\n",
    "    def parse(self) -> JsonNode:\n",
    "        i = self._skip_ws(0)\n",
    "        node, j = self._parse_value(i)\n",
    "        j = self._skip_ws(j)\n",
    "        if j != self.n:\n",
    "            raise JsonSpanParseError(f\"Trailing content at index {j}\")\n",
    "        return node\n",
    "\n",
    "    def _skip_ws(self, i: int) -> int:\n",
    "        s = self.s\n",
    "        n = self.n\n",
    "        while i < n and s[i] in \" \\t\\r\\n\":\n",
    "            i += 1\n",
    "        return i\n",
    "\n",
    "    def _parse_value(self, i: int) -> Tuple[JsonNode, int]:\n",
    "        i = self._skip_ws(i)\n",
    "        if i >= self.n:\n",
    "            raise JsonSpanParseError(\"Unexpected end of input\")\n",
    "\n",
    "        ch = self.s[i]\n",
    "        if ch == \"{\":\n",
    "            return self._parse_object(i)\n",
    "        if ch == \"[\":\n",
    "            return self._parse_array(i)\n",
    "        if ch == '\"':\n",
    "            return self._parse_string(i)\n",
    "        if ch == \"-\" or ch.isdigit():\n",
    "            return self._parse_number(i)\n",
    "        if self.s.startswith(\"true\", i):\n",
    "            return JsonNode(kind=\"true\", start=i, end=i + 4, value=True), i + 4\n",
    "        if self.s.startswith(\"false\", i):\n",
    "            return JsonNode(kind=\"false\", start=i, end=i + 5, value=False), i + 5\n",
    "        if self.s.startswith(\"null\", i):\n",
    "            return JsonNode(kind=\"null\", start=i, end=i + 4, value=None), i + 4\n",
    "\n",
    "        raise JsonSpanParseError(f\"Unexpected token at index {i}: {ch!r}\")\n",
    "\n",
    "    def _parse_object(self, i: int) -> Tuple[JsonNode, int]:\n",
    "        s = self.s\n",
    "        if s[i] != \"{\":\n",
    "            raise JsonSpanParseError(\"Expected '{'\")\n",
    "        start = i\n",
    "        i += 1\n",
    "        i = self._skip_ws(i)\n",
    "\n",
    "        obj: Dict[str, JsonNode] = {}\n",
    "\n",
    "        if i < self.n and s[i] == \"}\":\n",
    "            end = i + 1\n",
    "            return JsonNode(kind=\"object\", start=start, end=end, obj=obj, value={}), end\n",
    "\n",
    "        while True:\n",
    "            i = self._skip_ws(i)\n",
    "            if i >= self.n or s[i] != '\"':\n",
    "                raise JsonSpanParseError(f\"Expected object key string at index {i}\")\n",
    "            key_node, i = self._parse_string(i)\n",
    "            key = key_node.value\n",
    "\n",
    "            i = self._skip_ws(i)\n",
    "            if i >= self.n or s[i] != \":\":\n",
    "                raise JsonSpanParseError(f\"Expected ':' after key at index {i}\")\n",
    "            i += 1\n",
    "\n",
    "            val_node, i = self._parse_value(i)\n",
    "            obj[key] = val_node\n",
    "\n",
    "            i = self._skip_ws(i)\n",
    "            if i >= self.n:\n",
    "                raise JsonSpanParseError(\"Unexpected end in object\")\n",
    "            if s[i] == \"}\":\n",
    "                end = i + 1\n",
    "                return JsonNode(kind=\"object\", start=start, end=end, obj=obj, value=None), end\n",
    "            if s[i] != \",\":\n",
    "                raise JsonSpanParseError(f\"Expected ',' or '}}' at index {i}\")\n",
    "            i += 1\n",
    "\n",
    "    def _parse_array(self, i: int) -> Tuple[JsonNode, int]:\n",
    "        s = self.s\n",
    "        if s[i] != \"[\":\n",
    "            raise JsonSpanParseError(\"Expected '['\")\n",
    "        start = i\n",
    "        i += 1\n",
    "        i = self._skip_ws(i)\n",
    "\n",
    "        arr: List[JsonNode] = []\n",
    "\n",
    "        if i < self.n and s[i] == \"]\":\n",
    "            end = i + 1\n",
    "            return JsonNode(kind=\"array\", start=start, end=end, arr=arr, value=[]), end\n",
    "\n",
    "        while True:\n",
    "            val_node, i = self._parse_value(i)\n",
    "            arr.append(val_node)\n",
    "\n",
    "            i = self._skip_ws(i)\n",
    "            if i >= self.n:\n",
    "                raise JsonSpanParseError(\"Unexpected end in array\")\n",
    "            if self.s[i] == \"]\":\n",
    "                end = i + 1\n",
    "                return JsonNode(kind=\"array\", start=start, end=end, arr=arr, value=None), end\n",
    "            if self.s[i] != \",\":\n",
    "                raise JsonSpanParseError(f\"Expected ',' or ']' at index {i}\")\n",
    "            i += 1\n",
    "            i = self._skip_ws(i)\n",
    "\n",
    "    def _parse_string(self, i: int) -> Tuple[JsonNode, int]:\n",
    "        s = self.s\n",
    "        if s[i] != '\"':\n",
    "            raise JsonSpanParseError(\"Expected '\\\"'\")\n",
    "        start = i\n",
    "        i += 1\n",
    "\n",
    "        out_chars: List[str] = []\n",
    "        spans: List[Tuple[int, int]] = []  # (raw_start, raw_end) per OGNI char decodificato\n",
    "\n",
    "        while i < self.n:\n",
    "            ch = s[i]\n",
    "\n",
    "            # Fine stringa\n",
    "            if ch == '\"':\n",
    "                end = i + 1\n",
    "                return JsonNode(\n",
    "                    kind=\"string\",\n",
    "                    start=start,\n",
    "                    end=end,\n",
    "                    value=\"\".join(out_chars),\n",
    "                    string_char_spans=spans,\n",
    "                ), end\n",
    "\n",
    "            # Escape\n",
    "            if ch == \"\\\\\":\n",
    "                bs = i  # backslash index\n",
    "                i += 1\n",
    "                if i >= self.n:\n",
    "                    raise JsonSpanParseError(\"Invalid escape at end of string\")\n",
    "                esc = s[i]\n",
    "\n",
    "                if esc in '\"\\\\/':\n",
    "                    out_chars.append(esc)\n",
    "                    spans.append((bs, i + 1))\n",
    "                elif esc == \"b\":\n",
    "                    out_chars.append(\"\\b\")\n",
    "                    spans.append((bs, i + 1))\n",
    "                elif esc == \"f\":\n",
    "                    out_chars.append(\"\\f\")\n",
    "                    spans.append((bs, i + 1))\n",
    "                elif esc == \"n\":\n",
    "                    out_chars.append(\"\\n\")\n",
    "                    spans.append((bs, i + 1))\n",
    "                elif esc == \"r\":\n",
    "                    out_chars.append(\"\\r\")\n",
    "                    spans.append((bs, i + 1))\n",
    "                elif esc == \"t\":\n",
    "                    out_chars.append(\"\\t\")\n",
    "                    spans.append((bs, i + 1))\n",
    "                elif esc == \"u\":\n",
    "                    # \\uXXXX\n",
    "                    if i + 4 >= self.n:\n",
    "                        raise JsonSpanParseError(\"Invalid unicode escape (truncated)\")\n",
    "                    hex_part = s[i + 1 : i + 5]\n",
    "                    try:\n",
    "                        codepoint = int(hex_part, 16)\n",
    "                    except ValueError as e:\n",
    "                        raise JsonSpanParseError(\"Invalid unicode escape\") from e\n",
    "\n",
    "                    out_chars.append(chr(codepoint))\n",
    "                    spans.append((bs, i + 5))  # include \\uXXXX fully\n",
    "                    i += 4  # salta le 4 hex digits\n",
    "                else:\n",
    "                    raise JsonSpanParseError(f\"Invalid escape sequence: \\\\{esc}\")\n",
    "\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            # Carattere normale\n",
    "            out_chars.append(ch)\n",
    "            spans.append((i, i + 1))\n",
    "            i += 1\n",
    "\n",
    "        raise JsonSpanParseError(\"Unterminated string\")\n",
    "\n",
    "\n",
    "    def _parse_number(self, i: int) -> Tuple[JsonNode, int]:\n",
    "        s = self.s\n",
    "        start = i\n",
    "        n = self.n\n",
    "\n",
    "        if s[i] == \"-\":\n",
    "            i += 1\n",
    "            if i >= n:\n",
    "                raise JsonSpanParseError(\"Invalid number '-'\")\n",
    "\n",
    "        if i < n and s[i] == \"0\":\n",
    "            i += 1\n",
    "        else:\n",
    "            if i >= n or not s[i].isdigit():\n",
    "                raise JsonSpanParseError(\"Invalid number\")\n",
    "            while i < n and s[i].isdigit():\n",
    "                i += 1\n",
    "\n",
    "        if i < n and s[i] == \".\":\n",
    "            i += 1\n",
    "            if i >= n or not s[i].isdigit():\n",
    "                raise JsonSpanParseError(\"Invalid fraction\")\n",
    "            while i < n and s[i].isdigit():\n",
    "                i += 1\n",
    "\n",
    "        if i < n and s[i] in \"eE\":\n",
    "            i += 1\n",
    "            if i < n and s[i] in \"+-\":\n",
    "                i += 1\n",
    "            if i >= n or not s[i].isdigit():\n",
    "                raise JsonSpanParseError(\"Invalid exponent\")\n",
    "            while i < n and s[i].isdigit():\n",
    "                i += 1\n",
    "\n",
    "        end = i\n",
    "        num_text = s[start:end]\n",
    "        try:\n",
    "            val: Any\n",
    "            if \".\" in num_text or \"e\" in num_text or \"E\" in num_text:\n",
    "                val = float(num_text)\n",
    "            else:\n",
    "                val = int(num_text)\n",
    "        except ValueError:\n",
    "            val = num_text\n",
    "\n",
    "        return JsonNode(kind=\"number\", start=start, end=end, value=val), end\n",
    "\n",
    "\n",
    "def patch_json_string_field_in_place(\n",
    "    src_json: str,\n",
    "    path: Sequence[str],\n",
    "    new_string_value: str,\n",
    ") -> Tuple[str, bool, str]:\n",
    "    \"\"\"\n",
    "    Patch a JSON string field at a given object-path, modifying only the value span.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        root = JsonSpanParser(src_json).parse()\n",
    "    except Exception as e:\n",
    "        return src_json, False, f\"parse_error:{type(e).__name__}\"\n",
    "\n",
    "    if root.kind != \"object\" or not root.obj:\n",
    "        return src_json, False, \"root_not_object\"\n",
    "\n",
    "    node = root\n",
    "    for k in path:\n",
    "        if node.kind != \"object\" or not node.obj or k not in node.obj:\n",
    "            return src_json, False, \"path_missing\"\n",
    "        node = node.obj[k]\n",
    "\n",
    "    if node.kind != \"string\":\n",
    "        return src_json, False, \"target_not_string\"\n",
    "\n",
    "    escaped = json_escape_string(new_string_value)\n",
    "    replacement = '\"' + escaped + '\"'\n",
    "    patched = src_json[: node.start] + replacement + src_json[node.end :]\n",
    "    return patched, True, \"patched\"\n",
    "\n",
    "\n",
    "# ================== SCHEMA FLATTENING (FOR PROMPT CONTEXT) ==================\n",
    "\n",
    "@dataclasses.dataclass(frozen=True)\n",
    "class ParamSpec:\n",
    "    path: str\n",
    "    types: Tuple[str, ...]\n",
    "    description: str\n",
    "    required: bool\n",
    "    enum: Tuple[str, ...]\n",
    "    default: Optional[str]\n",
    "    fmt: Optional[str]\n",
    "    pattern: Optional[str]\n",
    "    minimum: Optional[str]\n",
    "    maximum: Optional[str]\n",
    "\n",
    "\n",
    "def _as_tuple_str(x: Any) -> Tuple[str, ...]:\n",
    "    if x is None:\n",
    "        return tuple()\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        return tuple(str(v) for v in x)\n",
    "    return (str(x),)\n",
    "\n",
    "\n",
    "def _schema_types(schema: Dict[str, Any]) -> Tuple[str, ...]:\n",
    "    t = schema.get(\"type\")\n",
    "    if isinstance(t, str):\n",
    "        return (t,)\n",
    "    if isinstance(t, list):\n",
    "        return tuple(str(v) for v in t)\n",
    "    if \"properties\" in schema:\n",
    "        return (\"object\",)\n",
    "    if \"items\" in schema:\n",
    "        return (\"array\",)\n",
    "    return (\"string\",)\n",
    "\n",
    "\n",
    "def flatten_json_schema_parameters(\n",
    "    parameters: Any,\n",
    "    *,\n",
    "    prefix: str = \"\",\n",
    "    required_paths: Optional[set] = None,\n",
    ") -> List[ParamSpec]:\n",
    "    if required_paths is None:\n",
    "        required_paths = set()\n",
    "\n",
    "    out: List[ParamSpec] = []\n",
    "    if not isinstance(parameters, dict):\n",
    "        return out\n",
    "\n",
    "    req = parameters.get(\"required\")\n",
    "    if isinstance(req, list):\n",
    "        for r in req:\n",
    "            if isinstance(r, str):\n",
    "                required_paths.add((prefix + \".\" + r).lstrip(\".\"))\n",
    "\n",
    "    for comb_key in (\"oneOf\", \"anyOf\", \"allOf\"):\n",
    "        comb = parameters.get(comb_key)\n",
    "        if isinstance(comb, list) and comb:\n",
    "            for sub in comb:\n",
    "                out.extend(flatten_json_schema_parameters(sub, prefix=prefix, required_paths=set(required_paths)))\n",
    "\n",
    "    tps = _schema_types(parameters)\n",
    "    desc = normalize_single_line(parameters.get(\"description\") or \"\")\n",
    "    enum = _as_tuple_str(parameters.get(\"enum\"))\n",
    "    default = parameters.get(\"default\")\n",
    "    default_s = None if default is None else normalize_single_line(str(default))\n",
    "    fmt = parameters.get(\"format\")\n",
    "    fmt_s = None if fmt is None else normalize_single_line(str(fmt))\n",
    "    pattern = parameters.get(\"pattern\")\n",
    "    pat_s = None if pattern is None else normalize_single_line(str(pattern))\n",
    "    minimum = parameters.get(\"minimum\")\n",
    "    maximum = parameters.get(\"maximum\")\n",
    "    min_s = None if minimum is None else normalize_single_line(str(minimum))\n",
    "    max_s = None if maximum is None else normalize_single_line(str(maximum))\n",
    "\n",
    "    if prefix and (\"properties\" not in parameters) and (\"items\" not in parameters):\n",
    "        out.append(\n",
    "            ParamSpec(\n",
    "                path=prefix,\n",
    "                types=tps,\n",
    "                description=desc,\n",
    "                required=(prefix in required_paths),\n",
    "                enum=enum,\n",
    "                default=default_s,\n",
    "                fmt=fmt_s,\n",
    "                pattern=pat_s,\n",
    "                minimum=min_s,\n",
    "                maximum=max_s,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    props = parameters.get(\"properties\")\n",
    "    if isinstance(props, dict):\n",
    "        for k, sub in props.items():\n",
    "            if isinstance(k, str) and isinstance(sub, dict):\n",
    "                sub_prefix = (prefix + \".\" + k).lstrip(\".\")\n",
    "                out.extend(flatten_json_schema_parameters(sub, prefix=sub_prefix, required_paths=required_paths))\n",
    "\n",
    "    items = parameters.get(\"items\")\n",
    "    if isinstance(items, dict):\n",
    "        sub_prefix = prefix + \"[]\" if prefix else \"[]\"\n",
    "        out.extend(flatten_json_schema_parameters(items, prefix=sub_prefix, required_paths=required_paths))\n",
    "\n",
    "    if prefix and (\"properties\" in parameters):\n",
    "        out.append(\n",
    "            ParamSpec(\n",
    "                path=prefix,\n",
    "                types=tps,\n",
    "                description=desc,\n",
    "                required=(prefix in required_paths),\n",
    "                enum=enum,\n",
    "                default=default_s,\n",
    "                fmt=fmt_s,\n",
    "                pattern=pat_s,\n",
    "                minimum=min_s,\n",
    "                maximum=max_s,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_param_context_for_prompt(param_specs: List[ParamSpec]) -> str:\n",
    "    if not param_specs:\n",
    "        return \"PARAMETERS: {\\\"note\\\": \\\"No structured parameters were found.\\\"}\"\n",
    "\n",
    "    items = sorted(param_specs, key=lambda p: p.path)\n",
    "    parts: List[str] = []\n",
    "    parts.append(\"PARAMETERS: [\")\n",
    "    for p in items:\n",
    "        parts.append(\n",
    "            \"  {\"\n",
    "            f\"\\\"path\\\": \\\"{p.path}\\\", \"\n",
    "            f\"\\\"types\\\": {list(p.types)}, \"\n",
    "            f\"\\\"required\\\": {str(bool(p.required)).lower()}, \"\n",
    "            f\"\\\"description\\\": \\\"{json_escape_string(p.description)}\\\", \"\n",
    "            f\"\\\"enum\\\": {list(p.enum)}, \"\n",
    "            f\"\\\"default\\\": {json.dumps(p.default, ensure_ascii=False)}, \"\n",
    "            f\"\\\"format\\\": {json.dumps(p.fmt, ensure_ascii=False)}, \"\n",
    "            f\"\\\"pattern\\\": {json.dumps(p.pattern, ensure_ascii=False)}, \"\n",
    "            f\"\\\"minimum\\\": {json.dumps(p.minimum, ensure_ascii=False)}, \"\n",
    "            f\"\\\"maximum\\\": {json.dumps(p.maximum, ensure_ascii=False)}\"\n",
    "            \"}\"\n",
    "        )\n",
    "    parts.append(\"]\")\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "\n",
    "# ================== MODE DEFINITIONS + VALIDATION ==================\n",
    "\n",
    "# NOTE: For the modes where allow_normative=False, we keep the detection conservative.\n",
    "# The repair step is guided to explicitly avoid these tokens.\n",
    "NORMATIVE_KEYWORDS = (\n",
    "    \"should\",\n",
    "    \"should not\",\n",
    "    \"must\",\n",
    "    \"must not\",\n",
    "    \"always\",\n",
    "    \"never\",\n",
    "    \"required to\",\n",
    "    \"do not\",\n",
    "    \"avoid\",\n",
    ")\n",
    "\n",
    "EXAMPLE_MARKERS = (\n",
    "    \"for example\",\n",
    "    \"e.g.\",\n",
    "    \"example:\",\n",
    ")\n",
    "\n",
    "\n",
    "@dataclasses.dataclass(frozen=True)\n",
    "class ModePolicy:\n",
    "    mode: str\n",
    "    allow_examples: bool\n",
    "    allow_normative: bool\n",
    "    target_length: str  # \"short\" | \"concise\" | \"verbose\"\n",
    "    must_preserve_semantics: bool\n",
    "\n",
    "\n",
    "MODE_POLICIES: Dict[str, ModePolicy] = {\n",
    "    \"empty_desc\": ModePolicy(\"empty_desc\", allow_examples=False, allow_normative=False, target_length=\"short\", must_preserve_semantics=True),\n",
    "    \"style_concise\": ModePolicy(\"style_concise\", allow_examples=False, allow_normative=False, target_length=\"concise\", must_preserve_semantics=True),\n",
    "    \"style_verbose\": ModePolicy(\"style_verbose\", allow_examples=False, allow_normative=False, target_length=\"verbose\", must_preserve_semantics=True),\n",
    "    \"add_examples\": ModePolicy(\"add_examples\", allow_examples=True, allow_normative=False, target_length=\"verbose\", must_preserve_semantics=True),\n",
    "    \"normative_injection\": ModePolicy(\"normative_injection\", allow_examples=True, allow_normative=True, target_length=\"verbose\", must_preserve_semantics=True),\n",
    "}\n",
    "\n",
    "\n",
    "def _contains_any_case_insensitive(text: str, needles: Sequence[str]) -> bool:\n",
    "    lt = text.lower()\n",
    "    return any(n in lt for n in needles)\n",
    "\n",
    "\n",
    "def validate_description(\n",
    "    mode: str,\n",
    "    desc: str,\n",
    "    *,\n",
    "    required_param_names: Sequence[str],\n",
    "    all_param_names: Sequence[str],\n",
    ") -> Tuple[bool, List[str]]:\n",
    "    \"\"\"\n",
    "    Hard validation for reproducible perturbations.\n",
    "\n",
    "    Key invariants:\n",
    "    - Single line\n",
    "    - Max length\n",
    "    - For modes with allow_examples=False: no \"For example\"/\"e.g.\" markers\n",
    "    - For modes with allow_normative=False: no normative keywords\n",
    "    - No mentions of unknown parameter tokens (conservative, token-based)\n",
    "    - For must_preserve_semantics modes (all non-empty_desc modes here):\n",
    "      every REQUIRED top-level parameter name must appear at least once (verbatim token match).\n",
    "\n",
    "    The last constraint is strict by design; the guided repair prompt is engineered to\n",
    "    make compliance easy and deterministic.\n",
    "    \"\"\"\n",
    "    errors: List[str] = []\n",
    "    policy = MODE_POLICIES.get(mode)\n",
    "    if policy is None:\n",
    "        return False, [f\"unknown_mode:{mode}\"]\n",
    "\n",
    "    if \"\\n\" in desc or \"\\r\" in desc:\n",
    "        errors.append(\"contains_newline\")\n",
    "\n",
    "    if len(desc) > DESCRIPTION_MAX_CHARS:\n",
    "        errors.append(\"too_long_chars\")\n",
    "\n",
    "    if mode != \"empty_desc\" and not desc.strip():\n",
    "        errors.append(\"empty_description_not_allowed\")\n",
    "\n",
    "    if mode == \"empty_desc\" and desc != \"\":\n",
    "        errors.append(\"empty_desc_must_be_exact_empty_string\")\n",
    "\n",
    "    if not policy.allow_examples and _contains_any_case_insensitive(desc, EXAMPLE_MARKERS):\n",
    "        errors.append(\"examples_not_allowed_in_mode\")\n",
    "\n",
    "    if not policy.allow_normative and _contains_any_case_insensitive(desc, NORMATIVE_KEYWORDS):\n",
    "        errors.append(\"normative_language_not_allowed_in_mode\")\n",
    "\n",
    "    # Normalize for token checks (keep underscores/dots/brackets).\n",
    "    lowered = \" \" + \"\".join((c.lower() if (c.isalnum() or c in \"_.[]\") else \" \") for c in desc) + \" \"\n",
    "\n",
    "    def has_token(token: str) -> bool:\n",
    "        t = token.lower()\n",
    "        return f\" {t} \" in lowered\n",
    "\n",
    "    # Unknown parameter mention check (conservative):\n",
    "    allowed = {p.lower() for p in all_param_names if p}\n",
    "    tokens = [t for t in lowered.split() if t]\n",
    "    for t in tokens:\n",
    "        if all(c.isalnum() or c in \"_.[]\" for c in t) and (\"_\" in t or \".\" in t or \"[\" in t):\n",
    "            if t in allowed:\n",
    "                continue\n",
    "            errors.append(f\"mentions_unknown_param:{t}\")\n",
    "\n",
    "    # Strict: required parameters must be mentioned for semantic-preserving modes (all here except empty_desc).\n",
    "    if policy.must_preserve_semantics and mode != \"empty_desc\":\n",
    "        for rp in required_param_names:\n",
    "            if rp and not has_token(rp):\n",
    "                errors.append(f\"missing_required_param_mention:{rp}\")\n",
    "\n",
    "    return (len(errors) == 0), errors\n",
    "\n",
    "\n",
    "# ================== PERSISTENT CACHE (SQLITE) ==================\n",
    "\n",
    "class DescCache:\n",
    "    \"\"\"\n",
    "    SQLite-backed cache for generated tool descriptions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, db_path: str):\n",
    "        self.db_path = db_path\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        self._init_db()\n",
    "\n",
    "    def _init_db(self) -> None:\n",
    "        cur = self.conn.cursor()\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS desc_cache (\n",
    "                key_hash TEXT PRIMARY KEY,\n",
    "                created_at REAL NOT NULL,\n",
    "                generation_model TEXT NOT NULL,\n",
    "                mode TEXT NOT NULL,\n",
    "                tool_name TEXT NOT NULL,\n",
    "                tool_signature TEXT NOT NULL,\n",
    "                prompt_hash TEXT NOT NULL,\n",
    "                prompt_text TEXT NOT NULL,\n",
    "                raw_output TEXT NOT NULL,\n",
    "                final_output TEXT NOT NULL,\n",
    "                status TEXT NOT NULL,\n",
    "                validation_errors TEXT NOT NULL\n",
    "            )\n",
    "            \"\"\"\n",
    "        )\n",
    "        self.conn.commit()\n",
    "\n",
    "    def get(self, key_hash: str) -> Optional[Dict[str, Any]]:\n",
    "        cur = self.conn.cursor()\n",
    "        cur.execute(\n",
    "            \"SELECT key_hash, created_at, generation_model, mode, tool_name, tool_signature, prompt_hash, prompt_text, raw_output, final_output, status, validation_errors FROM desc_cache WHERE key_hash=?\",\n",
    "            (key_hash,),\n",
    "        )\n",
    "        row = cur.fetchone()\n",
    "        if not row:\n",
    "            return None\n",
    "        return {\n",
    "            \"key_hash\": row[0],\n",
    "            \"created_at\": row[1],\n",
    "            \"generation_model\": row[2],\n",
    "            \"mode\": row[3],\n",
    "            \"tool_name\": row[4],\n",
    "            \"tool_signature\": row[5],\n",
    "            \"prompt_hash\": row[6],\n",
    "            \"prompt_text\": row[7],\n",
    "            \"raw_output\": row[8],\n",
    "            \"final_output\": row[9],\n",
    "            \"status\": row[10],\n",
    "            \"validation_errors\": json.loads(row[11]),\n",
    "        }\n",
    "\n",
    "    def put(\n",
    "        self,\n",
    "        *,\n",
    "        key_hash: str,\n",
    "        generation_model: str,\n",
    "        mode: str,\n",
    "        tool_name: str,\n",
    "        tool_signature: str,\n",
    "        prompt_hash: str,\n",
    "        prompt_text: str,\n",
    "        raw_output: str,\n",
    "        final_output: str,\n",
    "        status: str,\n",
    "        validation_errors: List[str],\n",
    "    ) -> None:\n",
    "        cur = self.conn.cursor()\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            INSERT OR REPLACE INTO desc_cache\n",
    "            (key_hash, created_at, generation_model, mode, tool_name, tool_signature, prompt_hash, prompt_text, raw_output, final_output, status, validation_errors)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\",\n",
    "            (\n",
    "                key_hash,\n",
    "                now_unix(),\n",
    "                generation_model,\n",
    "                mode,\n",
    "                tool_name,\n",
    "                tool_signature,\n",
    "                prompt_hash,\n",
    "                prompt_text,\n",
    "                raw_output,\n",
    "                final_output,\n",
    "                status,\n",
    "                json.dumps(validation_errors, ensure_ascii=False),\n",
    "            ),\n",
    "        )\n",
    "        self.conn.commit()\n",
    "\n",
    "    def close(self) -> None:\n",
    "        self.conn.close()\n",
    "\n",
    "\n",
    "# ================== AUDIT LOGGING ==================\n",
    "\n",
    "class AuditLogger:\n",
    "    \"\"\"\n",
    "    Append-only JSONL logs for reproducibility.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, audit_dir: str):\n",
    "        self.audit_dir = audit_dir\n",
    "        ensure_dir(audit_dir)\n",
    "        self.calls_path = os.path.join(audit_dir, AUDIT_CALLS_JSONL)\n",
    "        self.events_path = os.path.join(audit_dir, AUDIT_EVENTS_JSONL)\n",
    "        self.fallbacks_path = os.path.join(audit_dir, AUDIT_FALLBACKS_JSONL)\n",
    "        self.summary_path = os.path.join(audit_dir, AUDIT_SUMMARY_JSON)\n",
    "        self.summary: Dict[str, Any] = {\n",
    "            \"tools_seen\": 0,\n",
    "            \"tools_patched\": 0,\n",
    "            \"tools_unchanged\": 0,\n",
    "            \"tools_fallback_reserialized\": 0,\n",
    "            \"tools_parse_failed\": 0,\n",
    "            \"llm_calls\": 0,\n",
    "            \"llm_cache_hits\": 0,\n",
    "            \"llm_repaired\": 0,\n",
    "            \"llm_rejected\": 0,\n",
    "            \"lines_seen\": 0,\n",
    "            \"lines_written\": 0,\n",
    "        }\n",
    "\n",
    "    def log_call(self, record: Dict[str, Any]) -> None:\n",
    "        with open(self.calls_path, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    def log_event(self, record: Dict[str, Any]) -> None:\n",
    "        with open(self.events_path, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    def log_fallback(self, record: Dict[str, Any]) -> None:\n",
    "        with open(self.fallbacks_path, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    def inc(self, key: str, n: int = 1) -> None:\n",
    "        self.summary[key] = int(self.summary.get(key, 0)) + n\n",
    "\n",
    "    def flush_summary(self, extra: Optional[Dict[str, Any]] = None) -> None:\n",
    "        payload = dict(self.summary)\n",
    "        if extra:\n",
    "            payload.update(extra)\n",
    "        with open(self.summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps(payload, ensure_ascii=False, indent=2) + \"\\n\")\n",
    "\n",
    "\n",
    "# ================== PROMPT CONSTRUCTION ==================\n",
    "\n",
    "def _format_required_params(required_param_names: Sequence[str]) -> str:\n",
    "    req = [r for r in required_param_names if r]\n",
    "    req = _dedupe_preserve_order(req)\n",
    "    return \", \".join(req) if req else \"[NONE]\"\n",
    "\n",
    "\n",
    "def build_generation_prompt(\n",
    "    *,\n",
    "    mode: str,\n",
    "    tool_name: str,\n",
    "    original_description: str,\n",
    "    param_context: str,\n",
    "    required_param_names: Sequence[str],\n",
    ") -> str:\n",
    "    policy = MODE_POLICIES.get(mode)\n",
    "    if policy is None:\n",
    "        raise ValueError(f\"Unknown mode: {mode}\")\n",
    "\n",
    "    common = (\n",
    "        \"TASK: Produce exactly one English description string for a tool in a function-calling benchmark.\\n\"\n",
    "        \"OUTPUT FORMAT: Output only the description text, and nothing else.\\n\"\n",
    "        \"OUTPUT CONSTRAINTS:\\n\"\n",
    "        \"1) Output must be a single line (no newline characters).\\n\"\n",
    "        \"2) Do not output markdown, code fences, bullet characters, or backticks.\\n\"\n",
    "        \"3) Do not mention this task, prompts, schemas, or that an AI system is being used.\\n\"\n",
    "        \"4) Do not invent tool capabilities that are not supported by the provided parameters.\\n\"\n",
    "    )\n",
    "\n",
    "    mode_block = f\"MODE: {mode}\\n\"\n",
    "\n",
    "    if mode == \"empty_desc\":\n",
    "        return common + mode_block + \"INSTRUCTION: Output an empty string.\\n\"\n",
    "\n",
    "    req_line = f\"REQUIRED_PARAMETER_NAMES (must appear verbatim at least once): {_format_required_params(required_param_names)}\\n\"\n",
    "\n",
    "    if mode in {\"style_concise\", \"style_verbose\"}:\n",
    "        length_instr = (\n",
    "            \"Write a concise description (one to two short sentences).\"\n",
    "            if mode == \"style_concise\"\n",
    "            else \"Write a detailed description (three to six sentences) without examples.\"\n",
    "        )\n",
    "        return (\n",
    "            common\n",
    "            + mode_block\n",
    "            + \"INSTRUCTION: Rewrite the tool-level description while preserving the tool purpose and inputs.\\n\"\n",
    "            + req_line\n",
    "            + f\"LENGTH TARGET: {length_instr}\\n\"\n",
    "            + \"RESTRICTIONS:\\n\"\n",
    "            + \"A) Do not include usage examples.\\n\"\n",
    "            + \"B) Do not include behavioral guidance (avoid 'should', 'must', 'always', 'never', etc.).\\n\"\n",
    "            + f\"TOOL_NAME: {tool_name}\\n\"\n",
    "            + f\"ORIGINAL_DESCRIPTION: {normalize_single_line(original_description) if original_description else '[NONE]'}\\n\"\n",
    "            + param_context\n",
    "            + \"\\n\"\n",
    "        )\n",
    "\n",
    "    if mode == \"add_examples\":\n",
    "        return (\n",
    "            common\n",
    "            + mode_block\n",
    "            + \"INSTRUCTION: Rewrite the tool-level description while preserving the tool purpose and inputs.\\n\"\n",
    "            + req_line\n",
    "            + \"REQUIREMENTS:\\n\"\n",
    "            + \"A) Include one or two short conceptual examples inside the text using the exact phrase 'For example,'.\\n\"\n",
    "            + \"RESTRICTIONS:\\n\"\n",
    "            + \"A) Do not include behavioral guidance (avoid 'should', 'must', 'always', 'never', etc.).\\n\"\n",
    "            + f\"TOOL_NAME: {tool_name}\\n\"\n",
    "            + f\"ORIGINAL_DESCRIPTION: {normalize_single_line(original_description) if original_description else '[NONE]'}\\n\"\n",
    "            + param_context\n",
    "            + \"\\n\"\n",
    "        )\n",
    "\n",
    "    if mode == \"normative_injection\":\n",
    "        return (\n",
    "            common\n",
    "            + mode_block\n",
    "            + \"INSTRUCTION: Rewrite the tool-level description while preserving the tool purpose and inputs.\\n\"\n",
    "            + req_line\n",
    "            + \"REQUIREMENTS:\\n\"\n",
    "            + \"A) Include one or two short conceptual examples using the exact phrase 'For example,'.\\n\"\n",
    "            + \"B) Include explicit behavioral guidance about when the tool should be used, when follow-up information is needed, and when it should not be used.\\n\"\n",
    "            + f\"TOOL_NAME: {tool_name}\\n\"\n",
    "            + f\"ORIGINAL_DESCRIPTION: {normalize_single_line(original_description) if original_description else '[NONE]'}\\n\"\n",
    "            + param_context\n",
    "            + \"\\n\"\n",
    "        )\n",
    "\n",
    "    raise ValueError(f\"Unhandled mode: {mode}\")\n",
    "\n",
    "\n",
    "def _extract_missing_required_from_errors(errors: Sequence[str]) -> List[str]:\n",
    "    out: List[str] = []\n",
    "    for e in errors:\n",
    "        if e.startswith(\"missing_required_param_mention:\"):\n",
    "            out.append(e.split(\":\", 1)[1].strip())\n",
    "    return _dedupe_preserve_order([x for x in out if x])\n",
    "\n",
    "\n",
    "def _extract_unknown_params_from_errors(errors: Sequence[str]) -> List[str]:\n",
    "    out: List[str] = []\n",
    "    for e in errors:\n",
    "        if e.startswith(\"mentions_unknown_param:\"):\n",
    "            out.append(e.split(\":\", 1)[1].strip())\n",
    "    return _dedupe_preserve_order([x for x in out if x])\n",
    "\n",
    "\n",
    "def build_repair_prompt(\n",
    "    *,\n",
    "    mode: str,\n",
    "    tool_name: str,\n",
    "    candidate_output: str,\n",
    "    validation_errors: List[str],\n",
    "    param_context: str,\n",
    "    required_param_names: Sequence[str],\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Guided repair (Option 2): make validator compliance easy and deterministic.\n",
    "\n",
    "    Key idea:\n",
    "    - If required params are missing, explicitly list the exact tokens that MUST appear.\n",
    "    - If unknown param tokens were mentioned, explicitly list tokens that MUST be removed.\n",
    "    - Restate mode-specific bans (examples/normative) in an operational way.\n",
    "    \"\"\"\n",
    "    policy = MODE_POLICIES.get(mode)\n",
    "    if policy is None:\n",
    "        raise ValueError(f\"Unknown mode: {mode}\")\n",
    "\n",
    "    missing = _extract_missing_required_from_errors(validation_errors)\n",
    "    unknown = _extract_unknown_params_from_errors(validation_errors)\n",
    "\n",
    "    bans: List[str] = []\n",
    "    if not policy.allow_examples:\n",
    "        bans.append(\"No examples: do not include 'For example', 'e.g.', or 'example:'.\")\n",
    "    if not policy.allow_normative:\n",
    "        bans.append(\"No normative language: avoid 'should', 'must', 'always', 'never', 'do not', 'avoid', etc.\")\n",
    "\n",
    "    must_include_all = _dedupe_preserve_order([r for r in required_param_names if r])\n",
    "    must_include_text = \", \".join(must_include_all) if must_include_all else \"[NONE]\"\n",
    "    missing_text = \", \".join(missing) if missing else \"[NONE]\"\n",
    "    unknown_text = \", \".join(unknown) if unknown else \"[NONE]\"\n",
    "    bans_text = \" \".join(bans) if bans else \"[NONE]\"\n",
    "\n",
    "    # Strong operational constraints (single line, no markdown) remain.\n",
    "    return (\n",
    "        \"TASK: Fix a tool description so that it satisfies hard constraints exactly.\\n\"\n",
    "        \"OUTPUT FORMAT: Output only the corrected description text, and nothing else.\\n\"\n",
    "        \"HARD CONSTRAINTS:\\n\"\n",
    "        \"1) Output must be a single line (no newline characters).\\n\"\n",
    "        \"2) Do not output markdown, code fences, bullets, or backticks.\\n\"\n",
    "        \"3) Do not mention prompts, schemas, validators, or that an AI system is being used.\\n\"\n",
    "        f\"4) Mode is {mode}; satisfy the mode-specific rules.\\n\"\n",
    "        f\"MODE-SPECIFIC BANS: {bans_text}\\n\"\n",
    "        f\"REQUIRED_PARAMETER_NAMES (must appear verbatim at least once): {must_include_text}\\n\"\n",
    "        f\"MISSING_REQUIRED_IN_CANDIDATE: {missing_text}\\n\"\n",
    "        f\"UNKNOWN_PARAMETER_TOKENS_TO_REMOVE: {unknown_text}\\n\"\n",
    "        f\"TOOL_NAME: {tool_name}\\n\"\n",
    "        f\"PARAMETERS CONTEXT:\\n{param_context}\\n\"\n",
    "        f\"CANDIDATE OUTPUT:\\n{normalize_single_line(candidate_output)}\\n\"\n",
    "        \"INSTRUCTION:\\n\"\n",
    "        \"Rewrite the candidate so it passes validation. Ensure all required parameter tokens appear verbatim.\\n\"\n",
    "        \"If any unknown parameter tokens are present, remove them.\\n\"\n",
    "        \"Keep content consistent with the parameters; do not invent capabilities.\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ================== LLM CALLS WITH RETRY + AUDIT ==================\n",
    "\n",
    "def _sleep_with_jitter(seconds: float) -> None:\n",
    "    if seconds <= 0:\n",
    "        return\n",
    "    jitter = random.random() * min(0.25, seconds * 0.1)\n",
    "    time.sleep(seconds + jitter)\n",
    "\n",
    "\n",
    "def llm_call_chat_completions(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    model: str,\n",
    "    system_text: str,\n",
    "    user_text: str,\n",
    "    temperature: float,\n",
    "    max_tokens: int,\n",
    "    rate_limit_sleep_sec: float,\n",
    "    max_retries: int,\n",
    "    audit: AuditLogger,\n",
    "    call_tag: str,\n",
    ") -> str:\n",
    "    if rate_limit_sleep_sec > 0:\n",
    "        _sleep_with_jitter(rate_limit_sleep_sec)\n",
    "\n",
    "    prompt_hash = stable_sha256(system_text + \"\\n\\n\" + user_text)\n",
    "\n",
    "    last_exc: Optional[Exception] = None\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            audit.inc(\"llm_calls\", 1)\n",
    "            t0 = now_unix()\n",
    "            resp = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_text},\n",
    "                    {\"role\": \"user\", \"content\": user_text},\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens,\n",
    "            )\n",
    "            t1 = now_unix()\n",
    "            text = (resp.choices[0].message.content or \"\")\n",
    "            audit.log_call(\n",
    "                {\n",
    "                    \"ts\": t0,\n",
    "                    \"tag\": call_tag,\n",
    "                    \"attempt\": attempt,\n",
    "                    \"model\": model,\n",
    "                    \"temperature\": temperature,\n",
    "                    \"max_tokens\": max_tokens,\n",
    "                    \"prompt_hash\": prompt_hash,\n",
    "                    \"latency_sec\": round(t1 - t0, 6),\n",
    "                    \"raw_output_preview\": text[:2000],\n",
    "                }\n",
    "            )\n",
    "            return text\n",
    "\n",
    "        except Exception as e:\n",
    "            last_exc = e\n",
    "            backoff = min(30.0, 0.5 * (2 ** (attempt - 1)))\n",
    "            audit.log_call(\n",
    "                {\n",
    "                    \"ts\": now_unix(),\n",
    "                    \"tag\": call_tag,\n",
    "                    \"attempt\": attempt,\n",
    "                    \"model\": model,\n",
    "                    \"temperature\": temperature,\n",
    "                    \"max_tokens\": max_tokens,\n",
    "                    \"prompt_hash\": prompt_hash,\n",
    "                    \"error_type\": type(e).__name__,\n",
    "                    \"error_str\": str(e)[:2000],\n",
    "                    \"backoff_sec\": backoff,\n",
    "                }\n",
    "            )\n",
    "            _sleep_with_jitter(backoff)\n",
    "\n",
    "    raise RuntimeError(f\"LLM call failed after {max_retries} attempts: {type(last_exc).__name__}: {last_exc}\") from last_exc\n",
    "\n",
    "\n",
    "# ================== TOOL DESCRIPTION GENERATION PIPELINE ==================\n",
    "\n",
    "def tool_signature_for_cache(tool_obj: Dict[str, Any]) -> str:\n",
    "    name = str(tool_obj.get(\"name\") or tool_obj.get(\"function\", {}).get(\"name\") or \"unnamed_tool\")\n",
    "    if \"function\" in tool_obj and isinstance(tool_obj[\"function\"], dict):\n",
    "        params = tool_obj[\"function\"].get(\"parameters\")\n",
    "        orig_desc = tool_obj[\"function\"].get(\"description\") or \"\"\n",
    "    else:\n",
    "        params = tool_obj.get(\"parameters\")\n",
    "        orig_desc = tool_obj.get(\"description\") or \"\"\n",
    "\n",
    "    params_canon = json.dumps(params, ensure_ascii=False, sort_keys=True, separators=(\",\", \":\"))\n",
    "    base = f\"name={name}\\nparams={params_canon}\\norig_desc={normalize_single_line(orig_desc)}\"\n",
    "    return stable_sha256(base)\n",
    "\n",
    "\n",
    "def extract_tool_core(tool_obj: Dict[str, Any]) -> Tuple[str, str, Any, List[ParamSpec], List[str], List[str], Sequence[str]]:\n",
    "    if \"function\" in tool_obj and isinstance(tool_obj[\"function\"], dict):\n",
    "        fn = tool_obj[\"function\"]\n",
    "        tool_name = str(fn.get(\"name\") or \"unnamed_tool\")\n",
    "        orig_desc = str(fn.get(\"description\") or \"\")\n",
    "        params = fn.get(\"parameters\")\n",
    "        desc_path = (\"function\", \"description\")\n",
    "    else:\n",
    "        tool_name = str(tool_obj.get(\"name\") or \"unnamed_tool\")\n",
    "        orig_desc = str(tool_obj.get(\"description\") or \"\")\n",
    "        params = tool_obj.get(\"parameters\")\n",
    "        desc_path = (\"description\",)\n",
    "\n",
    "    param_specs = flatten_json_schema_parameters(params if isinstance(params, dict) else {})\n",
    "\n",
    "    required_names: List[str] = []\n",
    "    all_names: List[str] = []\n",
    "    if isinstance(params, dict):\n",
    "        props = params.get(\"properties\")\n",
    "        if isinstance(props, dict):\n",
    "            all_names = [k for k in props.keys() if isinstance(k, str)]\n",
    "        req = params.get(\"required\")\n",
    "        if isinstance(req, list):\n",
    "            required_names = [r for r in req if isinstance(r, str)]\n",
    "\n",
    "    return tool_name, orig_desc, params, param_specs, required_names, all_names, desc_path\n",
    "\n",
    "\n",
    "def generate_description_for_tool(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    generation_model: str,\n",
    "    mode: str,\n",
    "    tool_json_obj: Dict[str, Any],\n",
    "    cache: DescCache,\n",
    "    audit: AuditLogger,\n",
    "    temperature: float,\n",
    "    max_tokens: int,\n",
    "    rate_limit_sleep_sec: float,\n",
    "    max_retries: int,\n",
    "    repair_max_rounds: int,\n",
    ") -> Tuple[str, str, List[str], str]:\n",
    "    if mode not in MODES:\n",
    "        raise ValueError(f\"Unknown mode: {mode}\")\n",
    "\n",
    "    tool_name, orig_desc, _, param_specs, required_names, all_names, _ = extract_tool_core(tool_json_obj)\n",
    "    param_context = build_param_context_for_prompt(param_specs)\n",
    "\n",
    "    if mode == \"empty_desc\":\n",
    "        return \"\", \"ok\", [], stable_sha256(\"empty_desc\")\n",
    "\n",
    "    prompt = build_generation_prompt(\n",
    "        mode=mode,\n",
    "        tool_name=tool_name,\n",
    "        original_description=orig_desc,\n",
    "        param_context=param_context,\n",
    "        required_param_names=required_names,\n",
    "    )\n",
    "    prompt_hash = stable_sha256(prompt)\n",
    "\n",
    "    tool_sig = tool_signature_for_cache(tool_json_obj)\n",
    "    cache_key = stable_sha256(f\"{generation_model}||{mode}||{tool_sig}||{prompt_hash}\")\n",
    "\n",
    "    cached = cache.get(cache_key)\n",
    "    if cached is not None:\n",
    "        audit.inc(\"llm_cache_hits\", 1)\n",
    "        return cached[\"final_output\"], \"cached\", cached[\"validation_errors\"], prompt_hash\n",
    "\n",
    "    system_text = \"System role: Generate tool documentation strings for function-calling APIs.\"\n",
    "\n",
    "    raw = llm_call_chat_completions(\n",
    "        client=client,\n",
    "        model=generation_model,\n",
    "        system_text=system_text,\n",
    "        user_text=prompt,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        rate_limit_sleep_sec=rate_limit_sleep_sec,\n",
    "        max_retries=max_retries,\n",
    "        audit=audit,\n",
    "        call_tag=f\"generate::{mode}::{tool_name}\",\n",
    "    )\n",
    "\n",
    "    candidate = normalize_single_line(raw)\n",
    "\n",
    "    ok, errs = validate_description(\n",
    "        mode,\n",
    "        candidate,\n",
    "        required_param_names=required_names,\n",
    "        all_param_names=all_names,\n",
    "    )\n",
    "\n",
    "    status = \"ok\"\n",
    "    final = candidate\n",
    "    all_errs = list(errs)\n",
    "\n",
    "    repaired_rounds = 0\n",
    "    while not ok and repaired_rounds < repair_max_rounds:\n",
    "        repaired_rounds += 1\n",
    "        repair_prompt = build_repair_prompt(\n",
    "            mode=mode,\n",
    "            tool_name=tool_name,\n",
    "            candidate_output=final,\n",
    "            validation_errors=all_errs,\n",
    "            param_context=param_context,\n",
    "            required_param_names=required_names,\n",
    "        )\n",
    "        repair_raw = llm_call_chat_completions(\n",
    "            client=client,\n",
    "            model=generation_model,\n",
    "            system_text=system_text,\n",
    "            user_text=repair_prompt,\n",
    "            temperature=0.0,\n",
    "            max_tokens=max_tokens,\n",
    "            rate_limit_sleep_sec=rate_limit_sleep_sec,\n",
    "            max_retries=max_retries,\n",
    "            audit=audit,\n",
    "            call_tag=f\"repair::{mode}::{tool_name}::round{repaired_rounds}\",\n",
    "        )\n",
    "        final = normalize_single_line(repair_raw)\n",
    "        ok, all_errs = validate_description(\n",
    "            mode,\n",
    "            final,\n",
    "            required_param_names=required_names,\n",
    "            all_param_names=all_names,\n",
    "        )\n",
    "\n",
    "    if ok and repaired_rounds > 0:\n",
    "        status = \"repaired\"\n",
    "        audit.inc(\"llm_repaired\", 1)\n",
    "    elif not ok:\n",
    "        status = \"rejected\"\n",
    "        audit.inc(\"llm_rejected\", 1)\n",
    "        # Publication-grade conservative fallback: keep original if we cannot enforce constraints.\n",
    "        final = normalize_single_line(orig_desc)\n",
    "\n",
    "    cache.put(\n",
    "        key_hash=cache_key,\n",
    "        generation_model=generation_model,\n",
    "        mode=mode,\n",
    "        tool_name=tool_name,\n",
    "        tool_signature=tool_sig,\n",
    "        prompt_hash=prompt_hash,\n",
    "        prompt_text=prompt,\n",
    "        raw_output=raw,\n",
    "        final_output=final,\n",
    "        status=status,\n",
    "        validation_errors=all_errs,\n",
    "    )\n",
    "\n",
    "    return final, status, all_errs, prompt_hash\n",
    "\n",
    "\n",
    "# ================== TOOL STRING PATCHING INSIDE OUTER JSONL LINE ==================\n",
    "\n",
    "def parse_tool_json_string(tool_json_str: str) -> Optional[Dict[str, Any]]:\n",
    "    try:\n",
    "        obj = json.loads(tool_json_str)\n",
    "    except Exception:\n",
    "        return None\n",
    "    return obj if isinstance(obj, dict) else None\n",
    "\n",
    "\n",
    "def deterministic_tool_serialize(tool_obj: Dict[str, Any]) -> str:\n",
    "    return json.dumps(tool_obj, ensure_ascii=False, sort_keys=True, separators=(\",\", \":\"))\n",
    "\n",
    "\n",
    "def patch_tool_description_in_tool_json_string(\n",
    "    *,\n",
    "    tool_json_str: str,\n",
    "    new_desc: str,\n",
    "    desc_path: Sequence[str],\n",
    ") -> Tuple[str, bool, str]:\n",
    "    return patch_json_string_field_in_place(tool_json_str, desc_path, new_desc)\n",
    "\n",
    "\n",
    "def patch_outer_jsonl_line_tools(\n",
    "    *,\n",
    "    line: str,\n",
    "    client: OpenAI,\n",
    "    generation_model: str,\n",
    "    mode: str,\n",
    "    cache: DescCache,\n",
    "    audit: AuditLogger,\n",
    "    temperature: float,\n",
    "    max_tokens: int,\n",
    "    rate_limit_sleep_sec: float,\n",
    "    max_retries: int,\n",
    "    repair_max_rounds: int,\n",
    ") -> Tuple[str, Dict[str, Any]]:\n",
    "    stats = {\n",
    "        \"tools_in_line\": 0,\n",
    "        \"tools_patched\": 0,\n",
    "        \"tools_unchanged\": 0,\n",
    "        \"tools_fallback_reserialized\": 0,\n",
    "        \"tools_parse_failed\": 0,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        root = JsonSpanParser(line).parse()\n",
    "    except Exception:\n",
    "        stats[\"outer_parse_failed\"] = True\n",
    "        return line, stats\n",
    "\n",
    "    if root.kind != \"object\" or not root.obj or \"tools\" not in root.obj:\n",
    "        return line, stats\n",
    "\n",
    "    tools_node = root.obj[\"tools\"]\n",
    "    if tools_node.kind != \"array\" or not tools_node.arr:\n",
    "        return line, stats\n",
    "\n",
    "    patches: List[Tuple[int, int, str]] = []\n",
    "\n",
    "    for idx, el in enumerate(tools_node.arr):\n",
    "        stats[\"tools_in_line\"] += 1\n",
    "        audit.inc(\"tools_seen\", 1)\n",
    "\n",
    "        if el.kind != \"string\":\n",
    "            stats[\"tools_unchanged\"] += 1\n",
    "            audit.inc(\"tools_unchanged\", 1)\n",
    "            audit.log_event(\n",
    "                {\n",
    "                    \"ts\": now_unix(),\n",
    "                    \"event\": \"tool_entry_not_string_skipped\",\n",
    "                    \"mode\": mode,\n",
    "                    \"tool_index_in_line\": idx,\n",
    "                    \"kind\": el.kind,\n",
    "                }\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        tool_json_str = el.value\n",
    "        tool_obj = parse_tool_json_string(tool_json_str)\n",
    "        if tool_obj is None:\n",
    "            stats[\"tools_parse_failed\"] += 1\n",
    "            audit.inc(\"tools_parse_failed\", 1)\n",
    "            audit.log_event(\n",
    "                {\n",
    "                    \"ts\": now_unix(),\n",
    "                    \"event\": \"tool_string_parse_failed\",\n",
    "                    \"mode\": mode,\n",
    "                    \"tool_index_in_line\": idx,\n",
    "                }\n",
    "            )\n",
    "            stats[\"tools_unchanged\"] += 1\n",
    "            audit.inc(\"tools_unchanged\", 1)\n",
    "            continue\n",
    "\n",
    "        tool_name, orig_desc, _, param_specs, required_names, all_names, desc_path = extract_tool_core(tool_obj)\n",
    "\n",
    "        new_desc, status, val_errs, prompt_hash = generate_description_for_tool(\n",
    "            client=client,\n",
    "            generation_model=generation_model,\n",
    "            mode=mode,\n",
    "            tool_json_obj=tool_obj,\n",
    "            cache=cache,\n",
    "            audit=audit,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "            rate_limit_sleep_sec=rate_limit_sleep_sec,\n",
    "            max_retries=max_retries,\n",
    "            repair_max_rounds=repair_max_rounds,\n",
    "        )\n",
    "\n",
    "        patched_inner, did_patch, reason = patch_tool_description_in_tool_json_string(\n",
    "            tool_json_str=tool_json_str,\n",
    "            new_desc=new_desc,\n",
    "            desc_path=desc_path,\n",
    "        )\n",
    "\n",
    "        if not did_patch:\n",
    "            stats[\"tools_fallback_reserialized\"] += 1\n",
    "            audit.inc(\"tools_fallback_reserialized\", 1)\n",
    "\n",
    "            if len(desc_path) == 2 and desc_path[0] == \"function\":\n",
    "                if isinstance(tool_obj.get(\"function\"), dict):\n",
    "                    tool_obj[\"function\"][\"description\"] = new_desc\n",
    "            else:\n",
    "                tool_obj[\"description\"] = new_desc\n",
    "            patched_inner = deterministic_tool_serialize(tool_obj)\n",
    "\n",
    "            audit.log_fallback(\n",
    "                {\n",
    "                    \"ts\": now_unix(),\n",
    "                    \"event\": \"inplace_patch_failed_fallback_reserialize\",\n",
    "                    \"mode\": mode,\n",
    "                    \"tool_name\": tool_name,\n",
    "                    \"reason\": reason,\n",
    "                    \"generation_status\": status,\n",
    "                    \"validation_errors\": val_errs,\n",
    "                    \"prompt_hash\": prompt_hash,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        if normalize_single_line(orig_desc) == normalize_single_line(new_desc) and did_patch:\n",
    "            stats[\"tools_unchanged\"] += 1\n",
    "            audit.inc(\"tools_unchanged\", 1)\n",
    "        else:\n",
    "            stats[\"tools_patched\"] += 1\n",
    "            audit.inc(\"tools_patched\", 1)\n",
    "\n",
    "        replacement_outer = '\"' + json_escape_string(patched_inner) + '\"'\n",
    "        patches.append((el.start, el.end, replacement_outer))\n",
    "\n",
    "        audit.log_event(\n",
    "            {\n",
    "                \"ts\": now_unix(),\n",
    "                \"event\": \"tool_processed\",\n",
    "                \"mode\": mode,\n",
    "                \"tool_index_in_line\": idx,\n",
    "                \"tool_name\": tool_name,\n",
    "                \"generation_model\": generation_model,\n",
    "                \"generation_status\": status,\n",
    "                \"inplace_patch\": did_patch,\n",
    "                \"inplace_patch_reason\": reason,\n",
    "                \"original_desc_preview\": normalize_single_line(orig_desc)[:300],\n",
    "                \"new_desc_preview\": normalize_single_line(new_desc)[:300],\n",
    "                \"validation_errors\": val_errs[:50],  # keep bounded\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if not patches:\n",
    "        return line, stats\n",
    "\n",
    "    patches.sort(key=lambda x: x[0], reverse=True)\n",
    "    out = line\n",
    "    for start, end, repl in patches:\n",
    "        out = out[:start] + repl + out[end:]\n",
    "\n",
    "    return out, stats\n",
    "\n",
    "\n",
    "# ================== JSONL VARIANT GENERATION ==================\n",
    "\n",
    "def build_variant_jsonl_with_llm(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    generation_model: str,\n",
    "    input_path: str,\n",
    "    output_path: str,\n",
    "    mode: str,\n",
    "    output_dir: str,\n",
    "    temperature: float,\n",
    "    max_tokens: int,\n",
    "    rate_limit_sleep_sec: float,\n",
    "    max_retries: int,\n",
    "    repair_max_rounds: int,\n",
    "    seed: int,\n",
    "    overwrite: bool,\n",
    ") -> None:\n",
    "    if mode not in MODES:\n",
    "        raise ValueError(f\"Unknown mode in build_variant_jsonl_with_llm: {mode}\")\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    ensure_dir(output_dir)\n",
    "    audit_dir = os.path.join(output_dir, AUDIT_DIR_NAME, f\"{sanitize_model_name_for_path(generation_model)}__{mode}\")\n",
    "    ensure_dir(audit_dir)\n",
    "\n",
    "    cache_db = os.path.join(output_dir, CACHE_DB_NAME)\n",
    "    cache = DescCache(cache_db)\n",
    "    audit = AuditLogger(audit_dir)\n",
    "\n",
    "    if os.path.exists(output_path) and not overwrite:\n",
    "        raise FileExistsError(f\"Output exists and overwrite=False: {output_path}\")\n",
    "\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as fin, open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "        for line in fin:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            audit.inc(\"lines_seen\", 1)\n",
    "\n",
    "            patched_line, stats = patch_outer_jsonl_line_tools(\n",
    "                line=line.rstrip(\"\\n\"),\n",
    "                client=client,\n",
    "                generation_model=generation_model,\n",
    "                mode=mode,\n",
    "                cache=cache,\n",
    "                audit=audit,\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens,\n",
    "                rate_limit_sleep_sec=rate_limit_sleep_sec,\n",
    "                max_retries=max_retries,\n",
    "                repair_max_rounds=repair_max_rounds,\n",
    "            )\n",
    "\n",
    "            fout.write(patched_line + \"\\n\")\n",
    "            audit.inc(\"lines_written\", 1)\n",
    "\n",
    "            audit.log_event(\n",
    "                {\n",
    "                    \"ts\": now_unix(),\n",
    "                    \"event\": \"line_processed\",\n",
    "                    \"mode\": mode,\n",
    "                    \"tools_in_line\": stats.get(\"tools_in_line\", 0),\n",
    "                    \"tools_patched_in_line\": stats.get(\"tools_patched\", 0),\n",
    "                    \"tools_fallback_reserialized_in_line\": stats.get(\"tools_fallback_reserialized\", 0),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    audit.flush_summary(\n",
    "        extra={\n",
    "            \"input_path\": input_path,\n",
    "            \"output_path\": output_path,\n",
    "            \"mode\": mode,\n",
    "            \"generation_model\": generation_model,\n",
    "            \"temperature\": temperature,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"rate_limit_sleep_sec\": rate_limit_sleep_sec,\n",
    "            \"max_retries\": max_retries,\n",
    "            \"repair_max_rounds\": repair_max_rounds,\n",
    "            \"seed\": seed,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    cache.close()\n",
    "    print(f\"[{mode}] Wrote {output_path}\")\n",
    "    print(f\"[{mode}] Audit directory: {audit_dir}\")\n",
    "    print(f\"[{mode}] Cache DB: {cache_db}\")\n",
    "\n",
    "\n",
    "# ================== MULTI-VARIANT ENTRYPOINT ==================\n",
    "\n",
    "def run_when2call_variants(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    generation_model: str,\n",
    "    input_jsonl: str = DEFAULT_INPUT_JSONL,\n",
    "    output_dir: str = DEFAULT_OUTPUT_DIR,\n",
    "    modes: Optional[List[str]] = None,\n",
    "    overwrite: bool = False,\n",
    "    temperature: float = DEFAULT_TEMPERATURE,\n",
    "    max_tokens: int = DEFAULT_MAX_TOKENS,\n",
    "    rate_limit_sleep_sec: float = DEFAULT_RATE_LIMIT_SLEEP_SEC,\n",
    "    max_retries: int = DEFAULT_MAX_RETRIES,\n",
    "    repair_max_rounds: int = DEFAULT_REPAIR_MAX_ROUNDS,\n",
    "    seed: int = DEFAULT_RANDOM_SEED,\n",
    ") -> None:\n",
    "    if not os.path.exists(input_jsonl):\n",
    "        raise FileNotFoundError(f\"Input file not found: {input_jsonl}\")\n",
    "\n",
    "    ensure_dir(output_dir)\n",
    "\n",
    "    active_modes = modes if modes is not None else list(MODES)\n",
    "\n",
    "    unknown = [m for m in active_modes if m not in MODES]\n",
    "    if unknown:\n",
    "        raise ValueError(f\"Unknown modes requested: {unknown}. Allowed: {MODES}\")\n",
    "\n",
    "    base_name = os.path.splitext(os.path.basename(input_jsonl))[0]\n",
    "    model_tag = sanitize_model_name_for_path(generation_model)\n",
    "\n",
    "    print(f\"Input: {input_jsonl}\")\n",
    "    print(f\"Output dir: {output_dir}\")\n",
    "    print(f\"Generator model: {generation_model}\")\n",
    "    print(f\"Modes: {active_modes}\")\n",
    "    print(f\"Temperature: {temperature} | max_tokens: {max_tokens} | retries: {max_retries} | repair_rounds: {repair_max_rounds}\")\n",
    "\n",
    "    for mode in active_modes:\n",
    "        out_name = f\"{base_name}__gen-{model_tag}__mode-{mode}.jsonl\"\n",
    "        out_path = os.path.join(output_dir, out_name)\n",
    "\n",
    "        if os.path.exists(out_path) and not overwrite:\n",
    "            print(f\"[{mode}] Skipped (exists, overwrite=False): {out_path}\")\n",
    "            continue\n",
    "\n",
    "        build_variant_jsonl_with_llm(\n",
    "            client=client,\n",
    "            generation_model=generation_model,\n",
    "            input_path=input_jsonl,\n",
    "            output_path=out_path,\n",
    "            mode=mode,\n",
    "            output_dir=output_dir,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "            rate_limit_sleep_sec=rate_limit_sleep_sec,\n",
    "            max_retries=max_retries,\n",
    "            repair_max_rounds=repair_max_rounds,\n",
    "            seed=seed,\n",
    "            overwrite=overwrite,\n",
    "        )\n",
    "\n",
    "\n",
    "# ================== CLI ==================\n",
    "\n",
    "# def _parse_args(argv: Optional[Sequence[str]] = None) -> argparse.Namespace:\n",
    "#     p = argparse.ArgumentParser(description=\"When2Call tool-description variant generator (5 reviewer-grade modes).\")\n",
    "#     p.add_argument(\"--input\", default=DEFAULT_INPUT_JSONL, help=\"Input JSONL path.\")\n",
    "#     p.add_argument(\"--output-dir\", default=DEFAULT_OUTPUT_DIR, help=\"Output directory.\")\n",
    "#     p.add_argument(\"--generation-model\", required=True, help=\"Model name for the JRC gateway (OpenAI-compatible).\")\n",
    "#     p.add_argument(\n",
    "#         \"--modes\",\n",
    "#         nargs=\"*\",\n",
    "#         default=None,\n",
    "#         help=f\"Subset of modes to run. Allowed: {MODES}. If omitted, runs all.\",\n",
    "#     )\n",
    "#     p.add_argument(\"--overwrite\", action=\"store_true\", help=\"Overwrite existing outputs.\")\n",
    "#     p.add_argument(\"--temperature\", type=float, default=DEFAULT_TEMPERATURE)\n",
    "#     p.add_argument(\"--max-tokens\", type=int, default=DEFAULT_MAX_TOKENS)\n",
    "#     p.add_argument(\"--rate-limit-sleep-sec\", type=float, default=DEFAULT_RATE_LIMIT_SLEEP_SEC)\n",
    "#     p.add_argument(\"--max-retries\", type=int, default=DEFAULT_MAX_RETRIES)\n",
    "#     p.add_argument(\"--repair-max-rounds\", type=int, default=DEFAULT_REPAIR_MAX_ROUNDS)\n",
    "#     p.add_argument(\"--seed\", type=int, default=DEFAULT_RANDOM_SEED)\n",
    "#     return p.parse_args(argv)\n",
    "\n",
    "\n",
    "# def main(argv: Optional[Sequence[str]] = None) -> int:\n",
    "#     args = _parse_args(argv)\n",
    "#     client = make_jrc_client()\n",
    "#     run_when2call_variants(\n",
    "#         client=client,\n",
    "#         generation_model=args.generation_model,\n",
    "#         input_jsonl=args.input,\n",
    "#         output_dir=args.output_dir,\n",
    "#         modes=args.modes,\n",
    "#         overwrite=args.overwrite,\n",
    "#         temperature=args.temperature,\n",
    "#         max_tokens=args.max_tokens,\n",
    "#         rate_limit_sleep_sec=args.rate_limit_sleep_sec,\n",
    "#         max_retries=args.max_retries,\n",
    "#         repair_max_rounds=args.repair_max_rounds,\n",
    "#         seed=args.seed,\n",
    "#     )\n",
    "#     return 0\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     raise SystemExit(main())\n",
    "\n",
    "\n",
    "# ================== NOTEBOOK SNIPPET (OPTIONAL) ==================\n",
    "\n",
    "NB_INPUT_JSONL = DEFAULT_INPUT_JSONL\n",
    "NB_OUTPUT_DIR = DEFAULT_OUTPUT_DIR\n",
    "NB_GENERATION_MODEL = \"gpt-oss-120b\"\n",
    "NB_MODES = [\"style_concise\", \"style_verbose\", \"add_examples\"]  # or None to run all MODES\n",
    "NB_OVERWRITE = False\n",
    "\n",
    "NB_TEMPERATURE = DEFAULT_TEMPERATURE\n",
    "NB_MAX_TOKENS = DEFAULT_MAX_TOKENS\n",
    "NB_RATE_LIMIT_SLEEP_SEC = DEFAULT_RATE_LIMIT_SLEEP_SEC\n",
    "NB_MAX_RETRIES = DEFAULT_MAX_RETRIES\n",
    "NB_REPAIR_MAX_ROUNDS = DEFAULT_REPAIR_MAX_ROUNDS\n",
    "NB_SEED = DEFAULT_RANDOM_SEED\n",
    "\n",
    "NB_CLIENT = make_jrc_client()\n",
    "run_when2call_variants(\n",
    "    client=NB_CLIENT,\n",
    "    generation_model=NB_GENERATION_MODEL,\n",
    "    input_jsonl=NB_INPUT_JSONL,\n",
    "    output_dir=NB_OUTPUT_DIR,\n",
    "    modes=NB_MODES,\n",
    "    overwrite=NB_OVERWRITE,\n",
    "    temperature=NB_TEMPERATURE,\n",
    "    max_tokens=NB_MAX_TOKENS,\n",
    "    rate_limit_sleep_sec=NB_RATE_LIMIT_SLEEP_SEC,\n",
    "    max_retries=NB_MAX_RETRIES,\n",
    "    repair_max_rounds=NB_REPAIR_MAX_ROUNDS,\n",
    "    seed=NB_SEED,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a6acea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_tag</th>\n",
       "      <th>mode</th>\n",
       "      <th>tools_seen</th>\n",
       "      <th>%tools_patched</th>\n",
       "      <th>%tools_unchanged</th>\n",
       "      <th>%tools_parse_failed</th>\n",
       "      <th>%tools_fallback_reserialized</th>\n",
       "      <th>llm_calls</th>\n",
       "      <th>llm_cache_hits</th>\n",
       "      <th>llm_repaired</th>\n",
       "      <th>llm_rejected</th>\n",
       "      <th>%rejected_over_llm_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-oss-120b</td>\n",
       "      <td>add_examples</td>\n",
       "      <td>978</td>\n",
       "      <td>0.511247</td>\n",
       "      <td>99.488753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1903</td>\n",
       "      <td>501</td>\n",
       "      <td>3</td>\n",
       "      <td>474</td>\n",
       "      <td>24.908040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-oss-120b</td>\n",
       "      <td>style_concise</td>\n",
       "      <td>978</td>\n",
       "      <td>6.339468</td>\n",
       "      <td>93.660532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1877</td>\n",
       "      <td>501</td>\n",
       "      <td>24</td>\n",
       "      <td>453</td>\n",
       "      <td>24.134257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-oss-120b</td>\n",
       "      <td>style_verbose</td>\n",
       "      <td>978</td>\n",
       "      <td>3.374233</td>\n",
       "      <td>96.625767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1888</td>\n",
       "      <td>501</td>\n",
       "      <td>18</td>\n",
       "      <td>459</td>\n",
       "      <td>24.311441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_tag           mode  tools_seen  %tools_patched  %tools_unchanged  \\\n",
       "0  gpt-oss-120b   add_examples         978        0.511247         99.488753   \n",
       "1  gpt-oss-120b  style_concise         978        6.339468         93.660532   \n",
       "2  gpt-oss-120b  style_verbose         978        3.374233         96.625767   \n",
       "\n",
       "   %tools_parse_failed  %tools_fallback_reserialized  llm_calls  \\\n",
       "0                  0.0                           0.0       1903   \n",
       "1                  0.0                           0.0       1877   \n",
       "2                  0.0                           0.0       1888   \n",
       "\n",
       "   llm_cache_hits  llm_repaired  llm_rejected  %rejected_over_llm_calls  \n",
       "0             501             3           474                 24.908040  \n",
       "1             501            24           453                 24.134257  \n",
       "2             501            18           459                 24.311441  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, json, glob\n",
    "import pandas as pd\n",
    "\n",
    "# ====== CONFIG ======\n",
    "OUTPUT_DIR = \"when2call_local_variants\"   # <-- cambia se serve\n",
    "# Se vuoi filtrare per un solo modello, metti una stringa (es. \"gpt-oss-120b\"), altrimenti None\n",
    "MODEL_FILTER = None\n",
    "\n",
    "# ====== LOAD ALL variant_summary.json ======\n",
    "summary_paths = glob.glob(os.path.join(OUTPUT_DIR, \"audit\", \"*__*\", \"variant_summary.json\"))\n",
    "\n",
    "rows = []\n",
    "for path in summary_paths:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        s = json.load(f)\n",
    "\n",
    "    # audit/<model_tag>__<mode>/variant_summary.json\n",
    "    audit_leaf = os.path.basename(os.path.dirname(path))\n",
    "    if \"__\" in audit_leaf:\n",
    "        model_tag, mode = audit_leaf.split(\"__\", 1)\n",
    "    else:\n",
    "        model_tag, mode = audit_leaf, s.get(\"mode\", \"\")\n",
    "\n",
    "    if MODEL_FILTER and MODEL_FILTER not in model_tag:\n",
    "        continue\n",
    "\n",
    "    tools_seen = int(s.get(\"tools_seen\", 0))\n",
    "    tools_patched = int(s.get(\"tools_patched\", 0))\n",
    "    tools_unchanged = int(s.get(\"tools_unchanged\", 0))\n",
    "    tools_parse_failed = int(s.get(\"tools_parse_failed\", 0))\n",
    "    tools_fallback = int(s.get(\"tools_fallback_reserialized\", 0))\n",
    "\n",
    "    llm_calls = int(s.get(\"llm_calls\", 0))\n",
    "    llm_repaired = int(s.get(\"llm_repaired\", 0))\n",
    "    llm_rejected = int(s.get(\"llm_rejected\", 0))\n",
    "    llm_cache_hits = int(s.get(\"llm_cache_hits\", 0))\n",
    "\n",
    "    def pct(num, den):\n",
    "        return 0.0 if den <= 0 else 100.0 * num / den\n",
    "\n",
    "    rows.append({\n",
    "        \"model_tag\": model_tag,\n",
    "        \"mode\": mode,\n",
    "        \"tools_seen\": tools_seen,\n",
    "        \"tools_patched\": tools_patched,\n",
    "        \"tools_unchanged\": tools_unchanged,\n",
    "        \"tools_parse_failed\": tools_parse_failed,\n",
    "        \"tools_fallback_reserialized\": tools_fallback,\n",
    "        \"llm_calls\": llm_calls,\n",
    "        \"llm_cache_hits\": llm_cache_hits,\n",
    "        \"llm_repaired\": llm_repaired,\n",
    "        \"llm_rejected\": llm_rejected,\n",
    "        \"%tools_patched\": pct(tools_patched, tools_seen),\n",
    "        \"%tools_unchanged\": pct(tools_unchanged, tools_seen),\n",
    "        \"%tools_parse_failed\": pct(tools_parse_failed, tools_seen),\n",
    "        \"%tools_fallback_reserialized\": pct(tools_fallback, tools_seen),\n",
    "        \"%rejected_over_tools_seen\": pct(llm_rejected, tools_seen),\n",
    "        \"%rejected_over_llm_calls\": pct(llm_rejected, llm_calls),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "if df.empty:\n",
    "    print(\"Nessun variant_summary.json trovato. Controlla OUTPUT_DIR e che il run abbia scritto i log.\")\n",
    "else:\n",
    "    # Ordinamento utile: per modello e per mode\n",
    "    df = df.sort_values([\"model_tag\", \"mode\"]).reset_index(drop=True)\n",
    "\n",
    "    # Vista compatta (puoi rimuovere colonne se vuoi)\n",
    "    display_cols = [\n",
    "        \"model_tag\",\"mode\",\n",
    "        \"tools_seen\",\"%tools_patched\",\"%tools_unchanged\",\n",
    "        \"%tools_parse_failed\",\"%tools_fallback_reserialized\",\n",
    "        \"llm_calls\",\"llm_cache_hits\",\"llm_repaired\",\"llm_rejected\",\n",
    "        \"%rejected_over_llm_calls\",\n",
    "    ]\n",
    "    display(df[display_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "051010f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: When2Call/data/test/when2call_test_llm_judge.jsonl\n",
      "when2call_test_llm_judge__gen-gpt-oss-120b__mode-add_examples.jsonl  identical_examples=289/300 (96.33%)\n",
      "when2call_test_llm_judge__gen-gpt-oss-120b__mode-style_concise.jsonl  identical_examples=245/300 (81.67%)\n",
      "when2call_test_llm_judge__gen-gpt-oss-120b__mode-style_verbose.jsonl  identical_examples=272/300 (90.67%)\n",
      "when2call_test_llm_judge_llama-3.3-70b-instruct_no_desc.jsonl  identical_examples=15/300 (5.00%)\n",
      "when2call_test_llm_judge_llama-3.3-70b-instruct_short_label.jsonl  identical_examples=15/300 (5.00%)\n",
      "when2call_test_llm_judge_llama-3.3-70b-instruct_verbose_examples.jsonl  identical_examples=15/300 (5.00%)\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "\n",
    "# ====== CONFIG ======\n",
    "ORIGINAL_JSONL = \"When2Call/data/test/when2call_test_llm_judge.jsonl\"\n",
    "VARIANTS_DIR = \"when2call_local_variants\"   # dove scrivi i *.jsonl variant\n",
    "# opzionale: filtra solo i variant di un certo model tag o mode con una substring\n",
    "FILTER_SUBSTR = None   # es: \"mode-style_concise\" oppure \"gen-gpt-oss-120b\"\n",
    "\n",
    "def count_identical_lines(original_path: str, variant_path: str):\n",
    "    same = 0\n",
    "    total = 0\n",
    "    with open(original_path, \"r\", encoding=\"utf-8\") as fo, open(variant_path, \"r\", encoding=\"utf-8\") as fv:\n",
    "        for lo, lv in zip(fo, fv):\n",
    "            total += 1\n",
    "            if lo.rstrip(\"\\n\") == lv.rstrip(\"\\n\"):\n",
    "                same += 1\n",
    "\n",
    "        # se i file hanno lunghezze diverse, contiamo anche quello (dovrebbero essere uguali)\n",
    "        extra_o = sum(1 for _ in fo)\n",
    "        extra_v = sum(1 for _ in fv)\n",
    "        total += extra_o  # se original più lungo\n",
    "        # per extra_v non possiamo confrontare, quindi non incrementiamo same\n",
    "\n",
    "    return same, total\n",
    "\n",
    "variant_paths = sorted(glob.glob(os.path.join(VARIANTS_DIR, \"*.jsonl\")))\n",
    "if FILTER_SUBSTR:\n",
    "    variant_paths = [p for p in variant_paths if FILTER_SUBSTR in os.path.basename(p)]\n",
    "\n",
    "if not variant_paths:\n",
    "    print(\"Nessun file .jsonl variant trovato. Controlla VARIANTS_DIR / FILTER_SUBSTR.\")\n",
    "else:\n",
    "    print(f\"Original: {ORIGINAL_JSONL}\")\n",
    "    for vp in variant_paths:\n",
    "        same, total = count_identical_lines(ORIGINAL_JSONL, vp)\n",
    "        pct = 0.0 if total == 0 else 100.0 * same / total\n",
    "        print(f\"{os.path.basename(vp)}  identical_examples={same}/{total} ({pct:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c171ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "When2Call Tool-Description Variant Generator\n",
    "(Reproducible, Auditable, Minimal-Edit, Judge-Assisted, Dataset-Perturbation Oriented)\n",
    "\n",
    "This script generates controlled dataset variants by modifying ONLY the tool description\n",
    "string(s) inside the `tools` field of each JSONL example, while preserving the original\n",
    "JSONL line formatting as much as technically feasible (i.e., without re-serializing the\n",
    "outer JSON object). The tool JSON strings inside `tools` are patched in-place at the\n",
    "exact JSON string-span level, so unrelated keys remain unchanged unless a fallback\n",
    "path is triggered and logged.\n",
    "\n",
    "Key properties:\n",
    "- Minimal-diff patching on JSON spans (outer JSONL not re-serialized).\n",
    "- Deterministic generation defaults (temperature=0, normalized output).\n",
    "- Hard validators + guided repair + optional judge pass.\n",
    "- Persistent SQLite cache keyed by pipeline + models + mode + tool signature.\n",
    "- Full audit trail (calls, events, fallbacks) + manipulation checks outputs.\n",
    "\n",
    "Important change vs \"robustness\" confound-controls:\n",
    "- For dataset perturbation, we DO NOT ban parameter-name tokens in robustness modes.\n",
    "  (Banning top-level param tokens like date/city/name/time causes excessive false failures.)\n",
    "- We DO keep decision-boundary / label-leakage phrase bans for robustness modes.\n",
    "- We shift prompts to \"meaning-preserving paraphrase of ORIGINAL_DESCRIPTION\" (minimal edit),\n",
    "  to avoid template-y boilerplate like \"The <tool> tool ...\".\n",
    "\n",
    "Modes (MAX 5):\n",
    "1) empty_desc: description=\"\".\n",
    "2) style_concise: meaning-preserving paraphrase of ORIGINAL_DESCRIPTION, concise, no examples, no normative.\n",
    "3) style_verbose: meaning-preserving paraphrase of ORIGINAL_DESCRIPTION, verbose, no examples, no normative.\n",
    "4) add_examples: meaning-preserving paraphrase + 1-2 conceptual examples (must include 'For example,'), no normative.\n",
    "5) normative_injection: meaning-preserving paraphrase + guidance + 1-2 examples (may include leakage by design).\n",
    "\n",
    "Environment:\n",
    "- TOKEN_JRC must be set.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import dataclasses\n",
    "import difflib\n",
    "import hashlib\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sqlite3\n",
    "import time\n",
    "from typing import Any, Dict, List, Optional, Sequence, Tuple\n",
    "\n",
    "from openai import OpenAI\n",
    "import copy\n",
    "\n",
    "\n",
    "# ================== CONFIGURATION ==================\n",
    "\n",
    "PIPELINE_VERSION = \"5modes_judge_v3_dataset_perturbation_minimal_edit_with_checks\"\n",
    "\n",
    "DEFAULT_TEMPERATURE = 0.0\n",
    "DEFAULT_MAX_TOKENS = 256\n",
    "DEFAULT_RATE_LIMIT_SLEEP_SEC = 0.0\n",
    "DEFAULT_MAX_RETRIES = 8\n",
    "DEFAULT_REPAIR_MAX_ROUNDS = 3\n",
    "DEFAULT_JUDGE_MAX_ROUNDS = 1  # bounded for auditability\n",
    "\n",
    "DESCRIPTION_MAX_CHARS = 1200\n",
    "\n",
    "# Persistent cache / audit\n",
    "CACHE_DB_NAME = \"tool_desc_cache.sqlite3\"\n",
    "AUDIT_DIR_NAME = \"audit\"\n",
    "AUDIT_CALLS_JSONL = \"generation_calls.jsonl\"\n",
    "AUDIT_EVENTS_JSONL = \"variant_events.jsonl\"\n",
    "AUDIT_SUMMARY_JSON = \"variant_summary.json\"\n",
    "AUDIT_FALLBACKS_JSONL = \"fallback_events.jsonl\"\n",
    "\n",
    "# Manipulation checks outputs\n",
    "AUDIT_MANIPULATION_JSONL = \"manipulation_checks.jsonl\"\n",
    "AUDIT_MANIPULATION_SUMMARY_JSON = \"manipulation_checks_summary.json\"\n",
    "AUDIT_MANIPULATION_TABLE_MD = \"manipulation_checks_table.md\"\n",
    "\n",
    "DEFAULT_RANDOM_SEED = 1337\n",
    "\n",
    "\n",
    "# ================== SIMILARITY GATE (REVISED: BAND-PASS) ==================\n",
    "\n",
    "ENABLE_SIMILARITY_GATE = True\n",
    "ENABLE_SIMILARITY_UPPER_BOUND = True  # NEW: block near-identical outputs\n",
    "\n",
    "# Composite similarity must be within [min, max] (0..1)\n",
    "SIMILARITY_BAND_BY_MODE = {\n",
    "    \"empty_desc\": (0.0, 1.0),            # not applicable\n",
    "    \"style_concise\": (0.80, 0.999),      # upper bound ignored in robustness modes (see gate)\n",
    "    \"style_verbose\": (0.72, 0.999),\n",
    "    \"add_examples\": (0.78, 0.999),       # computed on base (pre \"For example,\")\n",
    "    \"normative_injection\": (0.74, 0.999) # computed on base (pre \"For example,\")\n",
    "}\n",
    "\n",
    "\n",
    "ENABLE_RULE_BASED_RECOVERY = True\n",
    "\n",
    "\n",
    "\n",
    "# ================== MODES ==================\n",
    "\n",
    "ROBUSTNESS_MODES: List[str] = [\n",
    "    \"empty_desc\",\n",
    "    \"style_concise\",\n",
    "    \"style_verbose\",\n",
    "    \"add_examples\",\n",
    "]\n",
    "INTERVENTION_MODES: List[str] = [\n",
    "    \"normative_injection\",\n",
    "]\n",
    "MODES: List[str] = ROBUSTNESS_MODES + INTERVENTION_MODES\n",
    "\n",
    "\n",
    "# ================== CLIENT ==================\n",
    "\n",
    "def make_jrc_client() -> OpenAI:\n",
    "    token = os.environ.get(\"TOKEN_JRC\")\n",
    "    if not token:\n",
    "        raise RuntimeError(\"TOKEN_JRC environment variable is not set.\")\n",
    "    return OpenAI(api_key=token, base_url=\"https://api-gpt.jrc.ec.europa.eu/v1\")\n",
    "\n",
    "\n",
    "# ================== SMALL UTILITIES ==================\n",
    "\n",
    "def sanitize_model_name_for_path(model_name: str) -> str:\n",
    "    allowed = set(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-_.\")\n",
    "    return \"\".join(ch if ch in allowed else \"-\" for ch in model_name)\n",
    "\n",
    "\n",
    "def stable_sha256(text: str) -> str:\n",
    "    return hashlib.sha256(text.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "def json_escape_string(value: str) -> str:\n",
    "    return json.dumps(value, ensure_ascii=False)[1:-1]\n",
    "\n",
    "\n",
    "def normalize_single_line(text: str) -> str:\n",
    "    return \" \".join((text or \"\").split()).strip()\n",
    "\n",
    "\n",
    "def now_unix() -> float:\n",
    "    return time.time()\n",
    "\n",
    "\n",
    "def ensure_dir(path: str) -> None:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "def _dedupe_preserve_order(items: Sequence[str]) -> List[str]:\n",
    "    seen = set()\n",
    "    out: List[str] = []\n",
    "    for x in items:\n",
    "        if x not in seen:\n",
    "            seen.add(x)\n",
    "            out.append(x)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _mean(xs: Sequence[float]) -> float:\n",
    "    return float(sum(xs) / len(xs)) if xs else 0.0\n",
    "\n",
    "\n",
    "def _std(xs: Sequence[float]) -> float:\n",
    "    if len(xs) < 2:\n",
    "        return 0.0\n",
    "    mu = _mean(xs)\n",
    "    var = sum((x - mu) ** 2 for x in xs) / (len(xs) - 1)\n",
    "    return float(math.sqrt(var))\n",
    "\n",
    "\n",
    "# ================== JSON SPAN PARSER (MINIMAL-EDIT PATCHING) ==================\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class JsonNode:\n",
    "    kind: str  # \"object\" | \"array\" | \"string\" | \"number\" | \"true\" | \"false\" | \"null\"\n",
    "    start: int\n",
    "    end: int\n",
    "    value: Any = None\n",
    "    obj: Optional[Dict[str, \"JsonNode\"]] = None\n",
    "    arr: Optional[List[\"JsonNode\"]] = None\n",
    "    string_char_spans: Optional[List[Tuple[int, int]]] = None  # NEW\n",
    "\n",
    "\n",
    "\n",
    "class JsonSpanParseError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class JsonSpanParser:\n",
    "    \"\"\"\n",
    "    JSON parser that returns decoded values AND exact source spans.\n",
    "    Used to patch JSON string fields in-place without re-serializing the outer JSON line.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, s: str):\n",
    "        self.s = s\n",
    "        self.n = len(s)\n",
    "\n",
    "    def parse(self) -> JsonNode:\n",
    "        i = self._skip_ws(0)\n",
    "        node, j = self._parse_value(i)\n",
    "        j = self._skip_ws(j)\n",
    "        if j != self.n:\n",
    "            raise JsonSpanParseError(f\"Trailing content at index {j}\")\n",
    "        return node\n",
    "\n",
    "    def _skip_ws(self, i: int) -> int:\n",
    "        s = self.s\n",
    "        n = self.n\n",
    "        while i < n and s[i] in \" \\t\\r\\n\":\n",
    "            i += 1\n",
    "        return i\n",
    "\n",
    "    def _parse_value(self, i: int) -> Tuple[JsonNode, int]:\n",
    "        i = self._skip_ws(i)\n",
    "        if i >= self.n:\n",
    "            raise JsonSpanParseError(\"Unexpected end of input\")\n",
    "\n",
    "        ch = self.s[i]\n",
    "        if ch == \"{\":\n",
    "            return self._parse_object(i)\n",
    "        if ch == \"[\":\n",
    "            return self._parse_array(i)\n",
    "        if ch == '\"':\n",
    "            return self._parse_string(i)\n",
    "        if ch == \"-\" or ch.isdigit():\n",
    "            return self._parse_number(i)\n",
    "        if self.s.startswith(\"true\", i):\n",
    "            return JsonNode(kind=\"true\", start=i, end=i + 4, value=True), i + 4\n",
    "        if self.s.startswith(\"false\", i):\n",
    "            return JsonNode(kind=\"false\", start=i, end=i + 5, value=False), i + 5\n",
    "        if self.s.startswith(\"null\", i):\n",
    "            return JsonNode(kind=\"null\", start=i, end=i + 4, value=None), i + 4\n",
    "\n",
    "        raise JsonSpanParseError(f\"Unexpected token at index {i}: {ch!r}\")\n",
    "\n",
    "    def _parse_object(self, i: int) -> Tuple[JsonNode, int]:\n",
    "        s = self.s\n",
    "        if s[i] != \"{\":\n",
    "            raise JsonSpanParseError(\"Expected '{'\")\n",
    "        start = i\n",
    "        i += 1\n",
    "        i = self._skip_ws(i)\n",
    "\n",
    "        obj: Dict[str, JsonNode] = {}\n",
    "\n",
    "        if i < self.n and s[i] == \"}\":\n",
    "            end = i + 1\n",
    "            return JsonNode(kind=\"object\", start=start, end=end, obj=obj, value={}), end\n",
    "\n",
    "        while True:\n",
    "            i = self._skip_ws(i)\n",
    "            if i >= self.n or s[i] != '\"':\n",
    "                raise JsonSpanParseError(f\"Expected object key string at index {i}\")\n",
    "            key_node, i = self._parse_string(i)\n",
    "            key = key_node.value\n",
    "\n",
    "            i = self._skip_ws(i)\n",
    "            if i >= self.n or s[i] != \":\":\n",
    "                raise JsonSpanParseError(f\"Expected ':' after key at index {i}\")\n",
    "            i += 1\n",
    "\n",
    "            val_node, i = self._parse_value(i)\n",
    "            obj[key] = val_node\n",
    "\n",
    "            i = self._skip_ws(i)\n",
    "            if i >= self.n:\n",
    "                raise JsonSpanParseError(\"Unexpected end in object\")\n",
    "            if s[i] == \"}\":\n",
    "                end = i + 1\n",
    "                return JsonNode(kind=\"object\", start=start, end=end, obj=obj, value=None), end\n",
    "            if s[i] != \",\":\n",
    "                raise JsonSpanParseError(f\"Expected ',' or '}}' at index {i}\")\n",
    "            i += 1\n",
    "\n",
    "    def _parse_array(self, i: int) -> Tuple[JsonNode, int]:\n",
    "        s = self.s\n",
    "        if s[i] != \"[\":\n",
    "            raise JsonSpanParseError(\"Expected '['\")\n",
    "        start = i\n",
    "        i += 1\n",
    "        i = self._skip_ws(i)\n",
    "\n",
    "        arr: List[JsonNode] = []\n",
    "\n",
    "        if i < self.n and s[i] == \"]\":\n",
    "            end = i + 1\n",
    "            return JsonNode(kind=\"array\", start=start, end=end, arr=arr, value=[]), end\n",
    "\n",
    "        while True:\n",
    "            val_node, i = self._parse_value(i)\n",
    "            arr.append(val_node)\n",
    "\n",
    "            i = self._skip_ws(i)\n",
    "            if i >= self.n:\n",
    "                raise JsonSpanParseError(\"Unexpected end in array\")\n",
    "            if s[i] == \"]\":\n",
    "                end = i + 1\n",
    "                return JsonNode(kind=\"array\", start=start, end=end, arr=arr, value=None), end\n",
    "            if s[i] != \",\":\n",
    "                raise JsonSpanParseError(f\"Expected ',' or ']' at index {i}\")\n",
    "            i += 1\n",
    "            i = self._skip_ws(i)\n",
    "\n",
    "    def _parse_string(self, i: int) -> Tuple[JsonNode, int]:\n",
    "        s = self.s\n",
    "        if s[i] != '\"':\n",
    "            raise JsonSpanParseError('Expected \\'\"\\'')\n",
    "        start = i\n",
    "        i += 1\n",
    "        out_chars: List[str] = []\n",
    "\n",
    "        while i < self.n:\n",
    "            ch = s[i]\n",
    "\n",
    "            if ch == '\"':\n",
    "                end = i + 1\n",
    "                # string_char_spans not used elsewhere; keep it None for safety.\n",
    "                return JsonNode(kind=\"string\", start=start, end=end, value=\"\".join(out_chars), string_char_spans=None), end\n",
    "\n",
    "            if ch == \"\\\\\":\n",
    "                i += 1\n",
    "                if i >= self.n:\n",
    "                    raise JsonSpanParseError(\"Invalid escape at end of string\")\n",
    "                esc = s[i]\n",
    "\n",
    "                if esc in '\"\\\\/':\n",
    "                    out_chars.append(esc)\n",
    "                elif esc == \"b\":\n",
    "                    out_chars.append(\"\\b\")\n",
    "                elif esc == \"f\":\n",
    "                    out_chars.append(\"\\f\")\n",
    "                elif esc == \"n\":\n",
    "                    out_chars.append(\"\\n\")\n",
    "                elif esc == \"r\":\n",
    "                    out_chars.append(\"\\r\")\n",
    "                elif esc == \"t\":\n",
    "                    out_chars.append(\"\\t\")\n",
    "                elif esc == \"u\":\n",
    "                    if i + 4 >= self.n:\n",
    "                        raise JsonSpanParseError(\"Invalid unicode escape (truncated)\")\n",
    "                    hex_part = s[i + 1 : i + 5]\n",
    "                    try:\n",
    "                        codepoint = int(hex_part, 16)\n",
    "                    except ValueError as e:\n",
    "                        raise JsonSpanParseError(\"Invalid unicode escape\") from e\n",
    "                    out_chars.append(chr(codepoint))\n",
    "                    i += 4\n",
    "                else:\n",
    "                    raise JsonSpanParseError(f\"Invalid escape sequence: \\\\{esc}\")\n",
    "\n",
    "            else:\n",
    "                # JSON forbids raw control chars 0x00-0x1F inside strings\n",
    "                if ord(ch) < 0x20:\n",
    "                    raise JsonSpanParseError(f\"Unescaped control character in string at index {i}\")\n",
    "                out_chars.append(ch)\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        raise JsonSpanParseError(\"Unterminated string\")\n",
    "\n",
    "    def _parse_number(self, i: int) -> Tuple[JsonNode, int]:\n",
    "        s = self.s\n",
    "        start = i\n",
    "        n = self.n\n",
    "\n",
    "        if s[i] == \"-\":\n",
    "            i += 1\n",
    "            if i >= n:\n",
    "                raise JsonSpanParseError(\"Invalid number '-'\")\n",
    "\n",
    "        if i < n and s[i] == \"0\":\n",
    "            i += 1\n",
    "        else:\n",
    "            if i >= n or not s[i].isdigit():\n",
    "                raise JsonSpanParseError(\"Invalid number\")\n",
    "            while i < n and s[i].isdigit():\n",
    "                i += 1\n",
    "\n",
    "        if i < n and s[i] == \".\":\n",
    "            i += 1\n",
    "            if i >= n or not s[i].isdigit():\n",
    "                raise JsonSpanParseError(\"Invalid fraction\")\n",
    "            while i < n and s[i].isdigit():\n",
    "                i += 1\n",
    "\n",
    "        if i < n and s[i] in \"eE\":\n",
    "            i += 1\n",
    "            if i < n and s[i] in \"+-\":\n",
    "                i += 1\n",
    "            if i >= n or not s[i].isdigit():\n",
    "                raise JsonSpanParseError(\"Invalid exponent\")\n",
    "            while i < n and s[i].isdigit():\n",
    "                i += 1\n",
    "\n",
    "        end = i\n",
    "        num_text = s[start:end]\n",
    "        try:\n",
    "            val: Any\n",
    "            if \".\" in num_text or \"e\" in num_text or \"E\" in num_text:\n",
    "                val = float(num_text)\n",
    "            else:\n",
    "                val = int(num_text)\n",
    "        except ValueError:\n",
    "            val = num_text\n",
    "\n",
    "        return JsonNode(kind=\"number\", start=start, end=end, value=val), end\n",
    "\n",
    "def escape_for_json_string_literal_minimal(s: str) -> str:\n",
    "    out = []\n",
    "    for ch in s:\n",
    "        o = ord(ch)\n",
    "        if ch == '\"':\n",
    "            out.append(r'\\\"')\n",
    "        elif ch == '\\\\':\n",
    "            out.append(r'\\\\')\n",
    "        elif ch == '\\b':\n",
    "            out.append(r'\\b')\n",
    "        elif ch == '\\f':\n",
    "            out.append(r'\\f')\n",
    "        elif ch == '\\n':\n",
    "            out.append(r'\\n')\n",
    "        elif ch == '\\r':\n",
    "            out.append(r'\\r')\n",
    "        elif ch == '\\t':\n",
    "            out.append(r'\\t')\n",
    "        elif o < 0x20:\n",
    "            out.append(f'\\\\u{o:04x}')\n",
    "        else:\n",
    "            out.append(ch)\n",
    "    return \"\".join(out)\n",
    "\n",
    "def patch_json_field_value_as_string_literal_in_place(\n",
    "    src_json: str,\n",
    "    path: Sequence[str],\n",
    "    new_string_value: str,\n",
    ") -> Tuple[str, bool, str]:\n",
    "    \"\"\"\n",
    "    Like patch_json_string_field_in_place, but replaces the target node span\n",
    "    with a JSON string literal even if the existing node is not a string (e.g., null).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        root = JsonSpanParser(src_json).parse()\n",
    "    except Exception as e:\n",
    "        return src_json, False, f\"parse_error:{type(e).__name__}\"\n",
    "\n",
    "    if root.kind != \"object\" or not root.obj:\n",
    "        return src_json, False, \"root_not_object\"\n",
    "\n",
    "    node = root\n",
    "    for k in path:\n",
    "        if node.kind != \"object\" or not node.obj or k not in node.obj:\n",
    "            return src_json, False, \"path_missing\"\n",
    "        node = node.obj[k]\n",
    "\n",
    "    replacement = '\"' + json_escape_string(new_string_value) + '\"'\n",
    "    patched = src_json[: node.start] + replacement + src_json[node.end :]\n",
    "    return patched, True, \"patched_value_as_string_literal\"\n",
    "\n",
    "\n",
    "def insert_json_string_field_into_object_text_in_place(\n",
    "    src_json: str,\n",
    "    obj_node: JsonNode,\n",
    "    key: str,\n",
    "    value: str,\n",
    ") -> Tuple[str, bool, str]:\n",
    "    \"\"\"\n",
    "    Insert a `\"key\":\"value\"` pair into an object node span, minimal-format.\n",
    "    Does not re-serialize the object; inserts just before the closing `}`.\n",
    "    \"\"\"\n",
    "    if obj_node.kind != \"object\":\n",
    "        return src_json, False, \"target_not_object\"\n",
    "\n",
    "    if obj_node.start < 0 or obj_node.end > len(src_json) or obj_node.end <= obj_node.start:\n",
    "        return src_json, False, \"object_span_out_of_bounds\"\n",
    "\n",
    "    # Determine if object is empty by checking last non-ws before closing brace.\n",
    "    close_brace = obj_node.end - 1\n",
    "    j = close_brace - 1\n",
    "    while j > obj_node.start and src_json[j] in \" \\t\\r\\n\":\n",
    "        j -= 1\n",
    "\n",
    "    # Build insertion text (minimal, compact)\n",
    "    pair = '\"' + json_escape_string(key) + '\":\"' + json_escape_string(value) + '\"'\n",
    "\n",
    "    if src_json[j] == \"{\":\n",
    "        # Empty object: {<pair>}\n",
    "        insert_text = pair\n",
    "        insert_pos = close_brace  # before '}'\n",
    "        patched = src_json[:insert_pos] + insert_text + src_json[insert_pos:]\n",
    "        return patched, True, \"inserted_field_into_empty_object\"\n",
    "\n",
    "    # Non-empty object: {...,<pair>}\n",
    "    insert_text = \",\" + pair\n",
    "    insert_pos = close_brace\n",
    "    patched = src_json[:insert_pos] + insert_text + src_json[insert_pos:]\n",
    "    return patched, True, \"inserted_field_into_nonempty_object\"\n",
    "\n",
    "def patch_or_insert_tool_description_in_inner_json_text(\n",
    "    *,\n",
    "    tool_json_str: str,\n",
    "    new_desc: str,\n",
    "    desc_path: Sequence[str],\n",
    ") -> Tuple[str, bool, str]:\n",
    "    \"\"\"\n",
    "    Inner-JSON micro-fallback:\n",
    "    - If desc exists: replace its value span with a JSON string literal (even if non-string).\n",
    "    - If missing: insert `\"description\":\"...\"` into the target object (root or function object).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        root = JsonSpanParser(tool_json_str).parse()\n",
    "    except Exception as e:\n",
    "        return tool_json_str, False, f\"inner_parse_error:{type(e).__name__}\"\n",
    "\n",
    "    if root.kind != \"object\" or not root.obj:\n",
    "        return tool_json_str, False, \"inner_root_not_object\"\n",
    "\n",
    "    # If path points to function.description, target object is function (if exists), else root.\n",
    "    # If path is just description, target object is root.\n",
    "    if len(desc_path) == 2 and desc_path[0] == \"function\" and desc_path[1] == \"description\":\n",
    "        fn_node = root.obj.get(\"function\")\n",
    "        if fn_node is None:\n",
    "            # No function object: cannot insert under function; fail (caller may reserialize)\n",
    "            return tool_json_str, False, \"inner_missing_function_object\"\n",
    "        if fn_node.kind != \"object\":\n",
    "            return tool_json_str, False, \"inner_function_not_object\"\n",
    "\n",
    "        # If description exists under function: replace value span (any kind -> string literal)\n",
    "        if fn_node.obj and \"description\" in fn_node.obj:\n",
    "            return patch_json_field_value_as_string_literal_in_place(\n",
    "                tool_json_str, (\"function\", \"description\"), new_desc\n",
    "            )\n",
    "\n",
    "        # Otherwise insert into function object span\n",
    "        return insert_json_string_field_into_object_text_in_place(\n",
    "            tool_json_str, fn_node, \"description\", new_desc\n",
    "        )\n",
    "\n",
    "    # Root-level description\n",
    "    if len(desc_path) == 1 and desc_path[0] == \"description\":\n",
    "        if root.obj and \"description\" in root.obj:\n",
    "            return patch_json_field_value_as_string_literal_in_place(\n",
    "                tool_json_str, (\"description\",), new_desc\n",
    "            )\n",
    "        return insert_json_string_field_into_object_text_in_place(\n",
    "            tool_json_str, root, \"description\", new_desc\n",
    "        )\n",
    "\n",
    "    return tool_json_str, False, \"inner_unsupported_desc_path\"\n",
    "\n",
    "\n",
    "def patch_json_string_field_in_place(\n",
    "    src_json: str,\n",
    "    path: Sequence[str],\n",
    "    new_string_value: str,\n",
    ") -> Tuple[str, bool, str]:\n",
    "    \"\"\"\n",
    "    Patch a JSON string field at a given object-path, modifying only the value span.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        root = JsonSpanParser(src_json).parse()\n",
    "    except Exception as e:\n",
    "        return src_json, False, f\"parse_error:{type(e).__name__}\"\n",
    "\n",
    "    if root.kind != \"object\" or not root.obj:\n",
    "        return src_json, False, \"root_not_object\"\n",
    "\n",
    "    node = root\n",
    "    for k in path:\n",
    "        if node.kind != \"object\" or not node.obj or k not in node.obj:\n",
    "            return src_json, False, \"path_missing\"\n",
    "        node = node.obj[k]\n",
    "\n",
    "    if node.kind != \"string\":\n",
    "        return src_json, False, \"target_not_string\"\n",
    "\n",
    "    escaped = json_escape_string(new_string_value)\n",
    "    replacement = '\"' + escaped + '\"'\n",
    "    patched = src_json[: node.start] + replacement + src_json[node.end :]\n",
    "    return patched, True, \"patched\"\n",
    "\n",
    "\n",
    "def find_node_by_key_path(root: JsonNode, path: Sequence[str]) -> Optional[JsonNode]:\n",
    "    node = root\n",
    "    for k in path:\n",
    "        if node.kind != \"object\" or not node.obj or k not in node.obj:\n",
    "            return None\n",
    "        node = node.obj[k]\n",
    "    return node\n",
    "\n",
    "\n",
    "\n",
    "# ================== SCHEMA HELPERS ==================\n",
    "\n",
    "_WORD_RE = re.compile(r\"[A-Za-z_][A-Za-z0-9_]*\")\n",
    "\n",
    "\n",
    "@dataclasses.dataclass(frozen=True)\n",
    "class ParamSpec:\n",
    "    path: str\n",
    "    types: Tuple[str, ...]\n",
    "    description: str\n",
    "    required: bool\n",
    "    enum: Tuple[str, ...]\n",
    "    default: Optional[str]\n",
    "    fmt: Optional[str]\n",
    "\n",
    "\n",
    "def _as_tuple_str(x: Any) -> Tuple[str, ...]:\n",
    "    if x is None:\n",
    "        return tuple()\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        return tuple(str(v) for v in x)\n",
    "    return (str(x),)\n",
    "\n",
    "\n",
    "def _schema_types(schema: Dict[str, Any]) -> Tuple[str, ...]:\n",
    "    t = schema.get(\"type\")\n",
    "    if isinstance(t, str):\n",
    "        return (t,)\n",
    "    if isinstance(t, list):\n",
    "        return tuple(str(v) for v in t)\n",
    "    if \"properties\" in schema:\n",
    "        return (\"object\",)\n",
    "    if \"items\" in schema:\n",
    "        return (\"array\",)\n",
    "    return (\"string\",)\n",
    "\n",
    "\n",
    "def flatten_json_schema_parameters(\n",
    "    parameters: Any,\n",
    "    *,\n",
    "    prefix: str = \"\",\n",
    "    required_paths: Optional[set] = None,\n",
    ") -> List[ParamSpec]:\n",
    "    if required_paths is None:\n",
    "        required_paths = set()\n",
    "\n",
    "    out: List[ParamSpec] = []\n",
    "    if not isinstance(parameters, dict):\n",
    "        return out\n",
    "\n",
    "    req = parameters.get(\"required\")\n",
    "    if isinstance(req, list):\n",
    "        for r in req:\n",
    "            if isinstance(r, str):\n",
    "                required_paths.add((prefix + \".\" + r).lstrip(\".\"))\n",
    "\n",
    "    for comb_key in (\"oneOf\", \"anyOf\", \"allOf\"):\n",
    "        comb = parameters.get(comb_key)\n",
    "        if isinstance(comb, list) and comb:\n",
    "            for sub in comb:\n",
    "                out.extend(flatten_json_schema_parameters(sub, prefix=prefix, required_paths=set(required_paths)))\n",
    "\n",
    "    tps = _schema_types(parameters)\n",
    "    desc = normalize_single_line(parameters.get(\"description\") or \"\")\n",
    "    enum = _as_tuple_str(parameters.get(\"enum\"))\n",
    "    default = parameters.get(\"default\")\n",
    "    default_s = None if default is None else normalize_single_line(str(default))\n",
    "    fmt = parameters.get(\"format\")\n",
    "    fmt_s = None if fmt is None else normalize_single_line(str(fmt))\n",
    "\n",
    "    if prefix and (\"properties\" not in parameters) and (\"items\" not in parameters):\n",
    "        out.append(\n",
    "            ParamSpec(\n",
    "                path=prefix,\n",
    "                types=tps,\n",
    "                description=desc,\n",
    "                required=(prefix in required_paths),\n",
    "                enum=enum,\n",
    "                default=default_s,\n",
    "                fmt=fmt_s,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    props = parameters.get(\"properties\")\n",
    "    if isinstance(props, dict):\n",
    "        for k, sub in props.items():\n",
    "            if isinstance(k, str) and isinstance(sub, dict):\n",
    "                sub_prefix = (prefix + \".\" + k).lstrip(\".\")\n",
    "                out.extend(flatten_json_schema_parameters(sub, prefix=sub_prefix, required_paths=required_paths))\n",
    "\n",
    "    items = parameters.get(\"items\")\n",
    "    if isinstance(items, dict):\n",
    "        sub_prefix = prefix + \"[]\" if prefix else \"[]\"\n",
    "        out.extend(flatten_json_schema_parameters(items, prefix=sub_prefix, required_paths=required_paths))\n",
    "\n",
    "    if prefix and (\"properties\" in parameters):\n",
    "        out.append(\n",
    "            ParamSpec(\n",
    "                path=prefix,\n",
    "                types=tps,\n",
    "                description=desc,\n",
    "                required=(prefix in required_paths),\n",
    "                enum=enum,\n",
    "                default=default_s,\n",
    "                fmt=fmt_s,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def extract_top_level_param_names(params: Any) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract top-level parameter names from a JSON schema object, if available.\n",
    "    Deterministic order by insertion in the schema 'properties' dict.\n",
    "    \"\"\"\n",
    "    if not isinstance(params, dict):\n",
    "        return []\n",
    "    props = params.get(\"properties\")\n",
    "    if not isinstance(props, dict):\n",
    "        return []\n",
    "    return [k for k in props.keys() if isinstance(k, str)]\n",
    "\n",
    "\n",
    "def build_param_context_for_prompt(param_specs: List[ParamSpec], *, max_items: int = 40) -> str:\n",
    "    \"\"\"\n",
    "    Option 1 (publication-friendly): provide a NEUTRAL, non-normative parameter context.\n",
    "\n",
    "    Rationale:\n",
    "    - The semantic gate is strict: any 'new constraint' not present in ORIGINAL_DESCRIPTION triggers FAIL.\n",
    "    - If we show the model required/optional, formats, defaults, enums, bounds, it tends to echo them,\n",
    "      which appears as adding constraints even if they exist in the schema.\n",
    "    - For dataset-perturbation minimal-edit, we only need light grounding on field NAMES (and coarse types),\n",
    "      not normative metadata.\n",
    "\n",
    "    Therefore:\n",
    "    - Provide field paths + coarse types only.\n",
    "    - Do NOT mention: required/optional, format, default, enum, min/max, pagination, etc.\n",
    "    - Keep it short and stable.\n",
    "    \"\"\"\n",
    "    if not param_specs:\n",
    "        return \"PARAMETERS_SUMMARY: No structured parameters were found.\"\n",
    "\n",
    "    items = sorted(param_specs, key=lambda p: p.path)\n",
    "\n",
    "    # Keep only unique paths; prefer the first occurrence deterministically.\n",
    "    seen = set()\n",
    "    uniq: List[ParamSpec] = []\n",
    "    for p in items:\n",
    "        if p.path in seen:\n",
    "            continue\n",
    "        seen.add(p.path)\n",
    "        uniq.append(p)\n",
    "\n",
    "    if len(uniq) > max_items:\n",
    "        uniq = uniq[:max_items]\n",
    "\n",
    "    lines: List[str] = []\n",
    "    lines.append(f\"PARAMETERS_SUMMARY (neutral grounding): {len(uniq)} field paths (possibly truncated).\")\n",
    "    for p in uniq:\n",
    "        tps = \"/\".join(p.types) if p.types else \"unspecified\"\n",
    "        lines.append(f\"- path={p.path}; type={tps}\")\n",
    "\n",
    "    lines.append(\n",
    "        \"NOTE: Do not mention required/optional, formats, defaults, enums, limits, pagination, or other constraints in the description \"\n",
    "        \"unless they already appear in ORIGINAL_DESCRIPTION.\"\n",
    "    )\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# ================== MODE POLICIES + VALIDATION ==================\n",
    "\n",
    "NORMATIVE_KEYWORDS = (\n",
    "    \"should\",\n",
    "    \"should not\",\n",
    "    \"must\",\n",
    "    \"must not\",\n",
    "    \"always\",\n",
    "    \"never\",\n",
    "    \"required to\",\n",
    "    \"do not\",\n",
    "    \"avoid\",\n",
    ")\n",
    "\n",
    "EXAMPLE_MARKERS = (\n",
    "    \"for example\",\n",
    "    \"e.g.\",\n",
    "    \"example:\",\n",
    "    \"for instance\",\n",
    ")\n",
    "\n",
    "LEAKAGE_PHRASES = (\n",
    "    \"follow-up\",\n",
    "    \"follow up\",\n",
    "    \"ask the user\",\n",
    "    \"ask user\",\n",
    "    \"request more information\",\n",
    "    \"need more information\",\n",
    "    \"insufficient information\",\n",
    "    \"not enough information\",\n",
    "    \"cannot answer\",\n",
    "    \"can't answer\",\n",
    "    \"unable to answer\",\n",
    "    \"missing information\",\n",
    ")\n",
    "\n",
    "REQUIRED_EXAMPLE_PHRASE = \"for example,\"  # enforced in add_examples / normative_injection (case-insensitive match)\n",
    "\n",
    "\n",
    "\n",
    "@dataclasses.dataclass(frozen=True)\n",
    "class ModePolicy:\n",
    "    mode: str\n",
    "    allow_examples: bool\n",
    "    require_examples: bool\n",
    "    allow_normative: bool\n",
    "    require_normative: bool\n",
    "    allow_leakage_phrases: bool\n",
    "    ban_param_name_tokens: bool\n",
    "    target_length: str\n",
    "    must_preserve_semantics: bool\n",
    "    is_intervention: bool\n",
    "\n",
    "\n",
    "MODE_POLICIES: Dict[str, ModePolicy] = {\n",
    "    \"empty_desc\": ModePolicy(\n",
    "        \"empty_desc\",\n",
    "        allow_examples=False,\n",
    "        require_examples=False,\n",
    "        allow_normative=False,\n",
    "        require_normative=False,\n",
    "        allow_leakage_phrases=False,\n",
    "        ban_param_name_tokens=False,\n",
    "        target_length=\"short\",\n",
    "        must_preserve_semantics=True,\n",
    "        is_intervention=False,\n",
    "    ),\n",
    "    # Dataset-perturbation: DO NOT ban param-name tokens for these modes.\n",
    "    \"style_concise\": ModePolicy(\n",
    "        \"style_concise\",\n",
    "        allow_examples=False,\n",
    "        require_examples=False,\n",
    "        allow_normative=False,\n",
    "        require_normative=False,\n",
    "        allow_leakage_phrases=False,\n",
    "        ban_param_name_tokens=False,  # <-- changed\n",
    "        target_length=\"concise\",\n",
    "        must_preserve_semantics=True,\n",
    "        is_intervention=False,\n",
    "    ),\n",
    "    \"style_verbose\": ModePolicy(\n",
    "        \"style_verbose\",\n",
    "        allow_examples=False,\n",
    "        require_examples=False,\n",
    "        allow_normative=False,\n",
    "        require_normative=False,\n",
    "        allow_leakage_phrases=False,\n",
    "        ban_param_name_tokens=False,  # <-- changed\n",
    "        target_length=\"verbose\",\n",
    "        must_preserve_semantics=True,\n",
    "        is_intervention=False,\n",
    "    ),\n",
    "    \"add_examples\": ModePolicy(\n",
    "        \"add_examples\",\n",
    "        allow_examples=True,\n",
    "        require_examples=True,\n",
    "        allow_normative=False,\n",
    "        require_normative=False,\n",
    "        allow_leakage_phrases=False,\n",
    "        ban_param_name_tokens=False,  # <-- changed\n",
    "        target_length=\"verbose\",\n",
    "        must_preserve_semantics=True,\n",
    "        is_intervention=False,\n",
    "    ),\n",
    "    \"normative_injection\": ModePolicy(\n",
    "        \"normative_injection\",\n",
    "        allow_examples=True,\n",
    "        require_examples=True,\n",
    "        allow_normative=True,\n",
    "        require_normative=True,\n",
    "        allow_leakage_phrases=True,   # allowed by design\n",
    "        ban_param_name_tokens=False,  # allowed by design\n",
    "        target_length=\"verbose\",\n",
    "        must_preserve_semantics=True,\n",
    "        is_intervention=True,\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def _contains_any_token_case_insensitive(text: str, tokens: Sequence[str]) -> bool:\n",
    "    words = {w.lower() for w in _WORD_RE.findall(text or \"\")}\n",
    "    return any((t or \"\").lower() in words for t in tokens if t)\n",
    "\n",
    "def original_has_normative(original_description: Optional[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if ORIGINAL_DESCRIPTION contains normative language (must/should/always/never/etc.).\n",
    "    Uses the same detector as validation to avoid mismatches.\n",
    "    \"\"\"\n",
    "    return _contains_any_case_insensitive(original_description or \"\", NORMATIVE_KEYWORDS)\n",
    "\n",
    "# ---- NEW: conditional marker handling (meaning-preserving) ----\n",
    "\n",
    "LISTING_MARKERS = (\n",
    "    \"including\",\n",
    "    \"such as\",\n",
    "    \"by specifying\",\n",
    "    \"by providing\",\n",
    "    \"with options to\",\n",
    "    \"with the option to\",\n",
    ")\n",
    "\n",
    "def _marker_set_case_insensitive(text: Optional[str], markers: Sequence[str]) -> set:\n",
    "    \"\"\"\n",
    "    Return the set of marker strings (lowercased) that appear in text (case-insensitive substring check).\n",
    "    Conservative and deterministic.\n",
    "    \"\"\"\n",
    "    lt = (text or \"\").lower()\n",
    "    found = set()\n",
    "    for m in markers or ():\n",
    "        ml = (m or \"\").lower()\n",
    "        if ml and (ml in lt):\n",
    "            found.add(ml)\n",
    "    return found\n",
    "\n",
    "def original_has_any_example_marker(original_description: Optional[str]) -> bool:\n",
    "    return bool(_marker_set_case_insensitive(original_description, EXAMPLE_MARKERS))\n",
    "\n",
    "def original_has_any_listing_marker(original_description: Optional[str]) -> bool:\n",
    "    return bool(_marker_set_case_insensitive(original_description, LISTING_MARKERS))\n",
    "\n",
    "\n",
    "def validate_description(\n",
    "    mode: str,\n",
    "    desc: str,\n",
    "    *,\n",
    "    raw_desc: Optional[str] = None,\n",
    "    top_level_param_names: Sequence[str],\n",
    "    original_description: Optional[str] = None,\n",
    ") -> Tuple[bool, List[str]]:\n",
    "    errors: List[str] = []\n",
    "    policy = MODE_POLICIES.get(mode)\n",
    "    if policy is None:\n",
    "        return False, [f\"unknown_mode:{mode}\"]\n",
    "\n",
    "    raw = raw_desc if raw_desc is not None else desc\n",
    "\n",
    "    # ---- Raw checks (hard) ----\n",
    "    if \"\\n\" in (raw or \"\") or \"\\r\" in (raw or \"\"):\n",
    "        errors.append(\"contains_newline_raw\")\n",
    "    if \"`\" in (raw or \"\"):\n",
    "        errors.append(\"contains_backticks_raw\")\n",
    "    if re.search(r\"(^|\\n|\\r)\\s*([-*•]|\\d+\\.)\\s+\", raw or \"\"):\n",
    "        errors.append(\"contains_bullets_raw\")\n",
    "\n",
    "    # ---- Normalized checks ----\n",
    "    if len(desc or \"\") > DESCRIPTION_MAX_CHARS:\n",
    "        errors.append(\"too_long_chars_global\")\n",
    "\n",
    "    if mode == \"empty_desc\":\n",
    "        if desc != \"\":\n",
    "            errors.append(\"empty_desc_must_be_exact_empty_string\")\n",
    "        return (len(errors) == 0), errors\n",
    "\n",
    "    if not (desc or \"\").strip():\n",
    "        errors.append(\"empty_description_not_allowed\")\n",
    "\n",
    "    # ---- Examples (conditional) ----\n",
    "    cand_example_markers = _marker_set_case_insensitive(desc, EXAMPLE_MARKERS)\n",
    "    orig_example_markers = _marker_set_case_insensitive(original_description, EXAMPLE_MARKERS)\n",
    "\n",
    "    if not policy.allow_examples:\n",
    "        new_markers = cand_example_markers - orig_example_markers\n",
    "        if new_markers:\n",
    "            errors.append(\"examples_not_allowed_in_mode\")\n",
    "\n",
    "    if policy.require_examples and not _contains_required_example_phrase(desc):\n",
    "        errors.append(\"missing_required_example_phrase:For example,\")\n",
    "\n",
    "    # ---- LISTING markers (conditional) - NEW ----\n",
    "    cand_listing = _marker_set_case_insensitive(desc, LISTING_MARKERS)\n",
    "    orig_listing = _marker_set_case_insensitive(original_description, LISTING_MARKERS)\n",
    "\n",
    "    # In robustness modes, do not allow introducing NEW listing markers (they often imply options/fields).\n",
    "    # If original has them, they are allowed (meaning-preserving), but do not expand into lists (handled elsewhere).\n",
    "    if mode in ROBUSTNESS_MODES:\n",
    "        new_listing = cand_listing - orig_listing\n",
    "        if new_listing:\n",
    "            errors.append(\"new_listing_marker_not_allowed\")\n",
    "\n",
    "    # ---- Normative (conditional vs original) ----\n",
    "    orig_has_norm = original_has_normative(original_description or \"\")\n",
    "    if not policy.allow_normative and not orig_has_norm:\n",
    "        if _contains_any_case_insensitive(desc, NORMATIVE_KEYWORDS):\n",
    "            errors.append(\"normative_language_not_allowed_in_mode\")\n",
    "\n",
    "    if policy.require_normative and not _contains_any_case_insensitive(desc, (\"should\", \"must\")):\n",
    "        errors.append(\"missing_required_normative_keyword\")\n",
    "\n",
    "    # ---- Leakage ----\n",
    "    if not policy.allow_leakage_phrases and _contains_any_case_insensitive(desc, LEAKAGE_PHRASES):\n",
    "        errors.append(\"label_leakage_phrase_not_allowed\")\n",
    "\n",
    "    # ---- Param tokens ban (off in your dataset-perturbation modes) ----\n",
    "    if policy.ban_param_name_tokens and _contains_any_token_case_insensitive(desc, top_level_param_names):\n",
    "        errors.append(\"mentions_param_name_token\")\n",
    "\n",
    "    # ---- Dynamic length budget ----\n",
    "    budget = compute_length_budget(mode=mode, original_description=original_description or \"\")\n",
    "    sent = _count_sentences_rough(desc)\n",
    "    words = _count_words(desc)\n",
    "    chars = len(desc or \"\")\n",
    "\n",
    "    if sent < budget.min_sentences or sent > budget.max_sentences:\n",
    "        errors.append(f\"sentence_count_out_of_budget:{sent}:expected_{budget.min_sentences}_to_{budget.max_sentences}\")\n",
    "\n",
    "    if words < budget.min_words:\n",
    "        errors.append(f\"word_count_too_small:{words}:min_{budget.min_words}\")\n",
    "    if words > budget.max_words:\n",
    "        errors.append(f\"word_count_too_large:{words}:max_{budget.max_words}\")\n",
    "\n",
    "    if chars > budget.max_chars:\n",
    "        errors.append(f\"too_long_for_mode_budget_chars:{chars}:max_{budget.max_chars}\")\n",
    "\n",
    "    return (len(errors) == 0), errors\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ================== PERSISTENT CACHE (SQLITE) ==================\n",
    "\n",
    "class DescCache:\n",
    "    \"\"\"\n",
    "    SQLite-backed cache for generated tool descriptions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, db_path: str):\n",
    "        self.db_path = db_path\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        self._init_db()\n",
    "\n",
    "    def _init_db(self) -> None:\n",
    "        cur = self.conn.cursor()\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS desc_cache (\n",
    "                key_hash TEXT PRIMARY KEY,\n",
    "                created_at REAL NOT NULL,\n",
    "                pipeline_version TEXT NOT NULL,\n",
    "                generation_model TEXT NOT NULL,\n",
    "                judge_model TEXT NOT NULL,\n",
    "                mode TEXT NOT NULL,\n",
    "                tool_name TEXT NOT NULL,\n",
    "                tool_signature TEXT NOT NULL,\n",
    "                prompt_hash TEXT NOT NULL,\n",
    "                prompt_text TEXT NOT NULL,\n",
    "                raw_output TEXT NOT NULL,\n",
    "                final_output TEXT NOT NULL,\n",
    "                status TEXT NOT NULL,\n",
    "                validation_errors TEXT NOT NULL\n",
    "            )\n",
    "            \"\"\"\n",
    "        )\n",
    "        self.conn.commit()\n",
    "\n",
    "    def get(self, key_hash: str) -> Optional[Dict[str, Any]]:\n",
    "        cur = self.conn.cursor()\n",
    "        cur.execute(\n",
    "            \"SELECT key_hash, created_at, pipeline_version, generation_model, judge_model, mode, tool_name, tool_signature, prompt_hash, prompt_text, raw_output, final_output, status, validation_errors FROM desc_cache WHERE key_hash=?\",\n",
    "            (key_hash,),\n",
    "        )\n",
    "        row = cur.fetchone()\n",
    "        if not row:\n",
    "            return None\n",
    "        return {\n",
    "            \"key_hash\": row[0],\n",
    "            \"created_at\": row[1],\n",
    "            \"pipeline_version\": row[2],\n",
    "            \"generation_model\": row[3],\n",
    "            \"judge_model\": row[4],\n",
    "            \"mode\": row[5],\n",
    "            \"tool_name\": row[6],\n",
    "            \"tool_signature\": row[7],\n",
    "            \"prompt_hash\": row[8],\n",
    "            \"prompt_text\": row[9],\n",
    "            \"raw_output\": row[10],\n",
    "            \"final_output\": row[11],\n",
    "            \"status\": row[12],\n",
    "            \"validation_errors\": json.loads(row[13]),\n",
    "        }\n",
    "\n",
    "    def put(\n",
    "        self,\n",
    "        *,\n",
    "        key_hash: str,\n",
    "        pipeline_version: str,\n",
    "        generation_model: str,\n",
    "        judge_model: str,\n",
    "        mode: str,\n",
    "        tool_name: str,\n",
    "        tool_signature: str,\n",
    "        prompt_hash: str,\n",
    "        prompt_text: str,\n",
    "        raw_output: str,\n",
    "        final_output: str,\n",
    "        status: str,\n",
    "        validation_errors: List[str],\n",
    "    ) -> None:\n",
    "        cur = self.conn.cursor()\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            INSERT OR REPLACE INTO desc_cache\n",
    "            (key_hash, created_at, pipeline_version, generation_model, judge_model, mode, tool_name, tool_signature, prompt_hash, prompt_text, raw_output, final_output, status, validation_errors)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\",\n",
    "            (\n",
    "                key_hash,\n",
    "                now_unix(),\n",
    "                pipeline_version,\n",
    "                generation_model,\n",
    "                judge_model,\n",
    "                mode,\n",
    "                tool_name,\n",
    "                tool_signature,\n",
    "                prompt_hash,\n",
    "                prompt_text,\n",
    "                raw_output,\n",
    "                final_output,\n",
    "                status,\n",
    "                json.dumps(validation_errors, ensure_ascii=False),\n",
    "            ),\n",
    "        )\n",
    "        self.conn.commit()\n",
    "\n",
    "    def close(self) -> None:\n",
    "        self.conn.close()\n",
    "\n",
    "\n",
    "# ================== AUDIT LOGGING + MANIPULATION CHECKS ==================\n",
    "\n",
    "\n",
    "class AuditLogger:\n",
    "    \"\"\"\n",
    "    Append-only JSONL logs for reproducibility.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, audit_dir: str):\n",
    "        self.audit_dir = audit_dir\n",
    "        ensure_dir(audit_dir)\n",
    "\n",
    "        self.calls_path = os.path.join(audit_dir, AUDIT_CALLS_JSONL)\n",
    "        self.events_path = os.path.join(audit_dir, AUDIT_EVENTS_JSONL)\n",
    "        self.fallbacks_path = os.path.join(audit_dir, AUDIT_FALLBACKS_JSONL)\n",
    "        self.summary_path = os.path.join(audit_dir, AUDIT_SUMMARY_JSON)\n",
    "\n",
    "        self.manip_jsonl_path = os.path.join(audit_dir, AUDIT_MANIPULATION_JSONL)\n",
    "        self.manip_summary_path = os.path.join(audit_dir, AUDIT_MANIPULATION_SUMMARY_JSON)\n",
    "        self.manip_table_md_path = os.path.join(audit_dir, AUDIT_MANIPULATION_TABLE_MD)\n",
    "\n",
    "        self.summary: Dict[str, Any] = {\n",
    "            \"pipeline_version\": PIPELINE_VERSION,\n",
    "            \"tools_seen\": 0,\n",
    "            \"tools_patched\": 0,\n",
    "            \"tools_unchanged\": 0,\n",
    "            \"tools_fallback_reserialized\": 0,\n",
    "            \"tools_parse_failed\": 0,\n",
    "            \"llm_calls\": 0,\n",
    "            \"llm_cache_hits\": 0,\n",
    "            \"llm_repaired\": 0,\n",
    "            \"llm_rejected\": 0,\n",
    "            \"llm_judge_calls\": 0,\n",
    "            \"llm_judge_fixed\": 0,\n",
    "            \"llm_judge_failed\": 0,\n",
    "            \"lines_seen\": 0,\n",
    "            \"lines_written\": 0,\n",
    "            \"outer_tools_string_literals_reescaped_canonically\": 0,\n",
    "            \"tools_entry_kind_string\": 0,\n",
    "            \"tools_entry_kind_object\": 0,\n",
    "\n",
    "            # Semantic gate accounting (first pass only)\n",
    "            \"semantic_gate_first_pass_total\": 0,\n",
    "            \"semantic_gate_first_pass_fail\": 0,\n",
    "\n",
    "            # NEW: similarity gate accounting (checked only when semantic_ok and ok)\n",
    "            \"similarity_gate_total\": 0,\n",
    "            \"similarity_gate_pass_total\": 0,\n",
    "            \"similarity_gate_fail_total\": 0,\n",
    "            \"similarity_gate_recovered_rule_based\": 0,\n",
    "            \"similarity_gate_fallback_original\": 0,\n",
    "        }\n",
    "\n",
    "        self._manip_rows: List[Dict[str, Any]] = []\n",
    "\n",
    "\n",
    "      \n",
    "    def log_call(self, record: Dict[str, Any]) -> None:\n",
    "        with open(self.calls_path, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    def log_event(self, record: Dict[str, Any]) -> None:\n",
    "        with open(self.events_path, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    def log_fallback(self, record: Dict[str, Any]) -> None:\n",
    "        with open(self.fallbacks_path, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    def inc(self, key: str, n: int = 1) -> None:\n",
    "        self.summary[key] = int(self.summary.get(key, 0)) + n\n",
    "\n",
    "    def flush_summary(self, extra: Optional[Dict[str, Any]] = None) -> None:\n",
    "        payload = dict(self.summary)\n",
    "        if extra:\n",
    "            payload.update(extra)\n",
    "\n",
    "        # Derived coverage metrics (paper-facing)\n",
    "        n_string = int(payload.get(\"tools_entry_kind_string\", 0))\n",
    "        n_object = int(payload.get(\"tools_entry_kind_object\", 0))\n",
    "        n_total = n_string + n_object\n",
    "\n",
    "        payload[\"tools_entry_kind_total_counted\"] = n_total\n",
    "        payload[\"tools_entry_kind_object_rate\"] = (float(n_object) / float(n_total)) if n_total > 0 else 0.0\n",
    "\n",
    "        # final_unchanged_rate (tools with final desc identical to original, as tracked by tools_unchanged)\n",
    "        tools_seen = int(payload.get(\"tools_seen\", 0))\n",
    "        tools_unchanged = int(payload.get(\"tools_unchanged\", 0))\n",
    "        payload[\"final_unchanged_rate\"] = (float(tools_unchanged) / float(tools_seen)) if tools_seen > 0 else 0.0\n",
    "\n",
    "        # semantic_fail_rate (first semantic gate pass)\n",
    "        sem_total = int(payload.get(\"semantic_gate_first_pass_total\", 0))\n",
    "        sem_fail = int(payload.get(\"semantic_gate_first_pass_fail\", 0))\n",
    "        payload[\"semantic_fail_rate\"] = (float(sem_fail) / float(sem_total)) if sem_total > 0 else 0.0\n",
    "\n",
    "        # NEW: similarity gate rates\n",
    "        sim_total = int(payload.get(\"similarity_gate_total\", 0))\n",
    "        sim_fail = int(payload.get(\"similarity_gate_fail_total\", 0))\n",
    "        sim_rb = int(payload.get(\"similarity_gate_recovered_rule_based\", 0))\n",
    "        sim_fb = int(payload.get(\"similarity_gate_fallback_original\", 0))\n",
    "        payload[\"similarity_fail_rate\"] = (float(sim_fail) / float(sim_total)) if sim_total > 0 else 0.0\n",
    "        payload[\"similarity_recovery_rule_based_rate\"] = (float(sim_rb) / float(sim_total)) if sim_total > 0 else 0.0\n",
    "        payload[\"similarity_fallback_original_rate\"] = (float(sim_fb) / float(sim_total)) if sim_total > 0 else 0.0\n",
    "\n",
    "        with open(self.summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps(payload, ensure_ascii=False, indent=2) + \"\\n\")\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def log_manipulation_row(self, row: Dict[str, Any]) -> None:\n",
    "        self._manip_rows.append(row)\n",
    "        with open(self.manip_jsonl_path, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    def flush_manipulation_summaries(self) -> None:\n",
    "        by_mode: Dict[str, List[Dict[str, Any]]] = {}\n",
    "        for r in self._manip_rows:\n",
    "            by_mode.setdefault(str(r.get(\"mode\")), []).append(r)\n",
    "\n",
    "        summary: Dict[str, Any] = {\"pipeline_version\": PIPELINE_VERSION, \"modes\": {}}\n",
    "        table_rows: List[Dict[str, Any]] = []\n",
    "\n",
    "        for mode, rows in sorted(by_mode.items(), key=lambda x: x[0]):\n",
    "            lens_new = [float(r[\"new_chars\"]) for r in rows]\n",
    "            lens_old = [float(r[\"orig_chars\"]) for r in rows]\n",
    "            sims = [float(r[\"char_similarity\"]) for r in rows]\n",
    "            deltas = [float(r[\"delta_chars\"]) for r in rows]\n",
    "\n",
    "            def rate(flag: str) -> float:\n",
    "                return float(sum(1 for r in rows if r.get(flag)) / len(rows)) if rows else 0.0\n",
    "\n",
    "            mode_summary = {\n",
    "                \"n_tools\": len(rows),\n",
    "                \"orig_chars_mean\": _mean(lens_old),\n",
    "                \"orig_chars_std\": _std(lens_old),\n",
    "                \"new_chars_mean\": _mean(lens_new),\n",
    "                \"new_chars_std\": _std(lens_new),\n",
    "                \"delta_chars_mean\": _mean(deltas),\n",
    "                \"delta_chars_std\": _std(deltas),\n",
    "                \"char_similarity_mean\": _mean(sims),\n",
    "                \"char_similarity_std\": _std(sims),\n",
    "                \"rate_unchanged\": rate(\"is_unchanged\"),\n",
    "                \"rate_repaired\": rate(\"status_is_repaired\"),\n",
    "                \"rate_rejected\": rate(\"status_is_rejected\"),\n",
    "                \"rate_judged\": rate(\"status_is_judged\"),\n",
    "                \"rate_contains_example\": rate(\"contains_example\"),\n",
    "                \"rate_contains_normative\": rate(\"contains_normative\"),\n",
    "                \"rate_contains_leakage\": rate(\"contains_leakage\"),\n",
    "                \"rate_mentions_param_token\": rate(\"mentions_param_token\"),\n",
    "                \"rate_failed_validation_final\": rate(\"final_failed_validation\"),\n",
    "            }\n",
    "            summary[\"modes\"][mode] = mode_summary\n",
    "\n",
    "            table_rows.append(\n",
    "                {\n",
    "                    \"mode\": mode,\n",
    "                    \"n\": len(rows),\n",
    "                    \"new_chars_mean\": round(mode_summary[\"new_chars_mean\"], 2),\n",
    "                    \"delta_chars_mean\": round(mode_summary[\"delta_chars_mean\"], 2),\n",
    "                    \"sim_mean\": round(mode_summary[\"char_similarity_mean\"], 3),\n",
    "                    \"unchanged\": round(mode_summary[\"rate_unchanged\"], 3),\n",
    "                    \"repaired\": round(mode_summary[\"rate_repaired\"], 3),\n",
    "                    \"judged\": round(mode_summary[\"rate_judged\"], 3),\n",
    "                    \"rejected\": round(mode_summary[\"rate_rejected\"], 3),\n",
    "                    \"leak\": round(mode_summary[\"rate_contains_leakage\"], 3),\n",
    "                    \"paramtok\": round(mode_summary[\"rate_mentions_param_token\"], 3),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        with open(self.manip_summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps(summary, ensure_ascii=False, indent=2) + \"\\n\")\n",
    "\n",
    "        md_lines: List[str] = []\n",
    "        md_lines.append(\"| mode | n | new_chars_mean | delta_chars_mean | sim_mean | unchanged | repaired | judged | rejected | leak | paramtok |\")\n",
    "        md_lines.append(\"|---|---:|---:|---:|---:|---:|---:|---:|---:|---:|---:|\")\n",
    "        for r in table_rows:\n",
    "            md_lines.append(\n",
    "                f\"| {r['mode']} | {r['n']} | {r['new_chars_mean']:.2f} | {r['delta_chars_mean']:.2f} | {r['sim_mean']:.3f} | \"\n",
    "                f\"{r['unchanged']:.3f} | {r['repaired']:.3f} | {r['judged']:.3f} | {r['rejected']:.3f} | {r['leak']:.3f} | {r['paramtok']:.3f} |\"\n",
    "            )\n",
    "\n",
    "        with open(self.manip_table_md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\".join(md_lines) + \"\\n\")\n",
    "\n",
    "\n",
    "# ================== PROMPT CONSTRUCTION ==================\n",
    "\n",
    "def is_schema_aware_verbose_mode(mode: str) -> bool:\n",
    "    \"\"\"\n",
    "    Dataset-perturbation policy:\n",
    "    - Disable schema-derived \"extra clarity\" for robustness modes.\n",
    "    Rationale:\n",
    "    - It systematically introduces confounds (parameter mentions, implied filters/options)\n",
    "      that inflate diffs and trigger semantic-gate failures.\n",
    "    - If you want schema-derived perturbations, create a dedicated separate mode.\n",
    "    \"\"\"\n",
    "    return False\n",
    "\n",
    "def select_schema_hint_param_names(\n",
    "    *,\n",
    "    top_level_param_names: Sequence[str],\n",
    "    param_specs: Sequence[ParamSpec],\n",
    "    max_names: int = 4,\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Deterministically select up to `max_names` top-level parameter names that are most\n",
    "    likely to be informative to mention in a verbose description, without enumerating.\n",
    "\n",
    "    Heuristics:\n",
    "    - Prefer canonical \"query/identifier\" inputs (id, token, name, query, text, from/to, date/city/location, ticker).\n",
    "    - Then consider common filter/option inputs (status, type, category, sort, order, limit, offset, page, class).\n",
    "    - Keep original schema insertion order when possible for reproducibility.\n",
    "    \"\"\"\n",
    "    names = [n for n in (top_level_param_names or []) if isinstance(n, str) and n.strip()]\n",
    "    if not names:\n",
    "        return []\n",
    "\n",
    "    lower = [n.lower() for n in names]\n",
    "\n",
    "    primary_keywords = (\n",
    "        \"id\", \"token\", \"name\", \"query\", \"text\",\n",
    "        \"from\", \"to\", \"start\", \"end\", \"date\", \"time\",\n",
    "        \"city\", \"location\", \"origin\", \"destination\",\n",
    "        \"ticker\", \"symbol\", \"airport\",\n",
    "    )\n",
    "    option_keywords = (\n",
    "        \"status\", \"type\", \"category\", \"sort\", \"order\",\n",
    "        \"limit\", \"offset\", \"page\", \"per_page\",\n",
    "        \"class\", \"rating\", \"rooms\", \"seats\",\n",
    "    )\n",
    "\n",
    "    primary_idx: List[int] = []\n",
    "    option_idx: List[int] = []\n",
    "    other_idx: List[int] = []\n",
    "\n",
    "    for i, nl in enumerate(lower):\n",
    "        if any(k in nl for k in primary_keywords):\n",
    "            primary_idx.append(i)\n",
    "        elif any(k in nl for k in option_keywords):\n",
    "            option_idx.append(i)\n",
    "        else:\n",
    "            other_idx.append(i)\n",
    "\n",
    "    chosen: List[str] = []\n",
    "    for i in primary_idx + option_idx + other_idx:\n",
    "        chosen.append(names[i])\n",
    "        if len(chosen) >= max_names:\n",
    "            break\n",
    "\n",
    "    return _dedupe_preserve_order(chosen)\n",
    "\n",
    "\n",
    "def build_schema_hints_block_for_prompt(\n",
    "    *,\n",
    "    mode: str,\n",
    "    top_level_param_names: Sequence[str],\n",
    "    param_specs: Sequence[ParamSpec],\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Compact, non-normative hint block for verbose descriptions.\n",
    "\n",
    "    Updated policy:\n",
    "    - Prefer not to mention parameter names at all.\n",
    "    - If mentioning is useful, mention at most ONE name, and never as a list.\n",
    "    \"\"\"\n",
    "    if not is_schema_aware_verbose_mode(mode):\n",
    "        return \"\"\n",
    "\n",
    "    hint_names = select_schema_hint_param_names(\n",
    "        top_level_param_names=top_level_param_names,\n",
    "        param_specs=list(param_specs or []),\n",
    "        max_names=1,  # <-- changed: at most one\n",
    "    )\n",
    "\n",
    "    if not hint_names:\n",
    "        return (\n",
    "            \"SCHEMA-AWARE VERBOSE GUIDANCE:\\n\"\n",
    "            \"- You may add a small amount of operational clarity (1–2 extra clauses) without adding constraints.\\n\"\n",
    "            \"- Prefer not to mention parameter names; use neutral phrasing (can/may) and avoid enumerations.\\n\"\n",
    "        )\n",
    "\n",
    "    names_text = \", \".join(hint_names)\n",
    "    return (\n",
    "        \"SCHEMA-AWARE VERBOSE GUIDANCE:\\n\"\n",
    "        \"- You may add limited operational clarity derived from the parameter schema.\\n\"\n",
    "        f\"- Prefer not to mention parameter names; if you do, mention at most one as an example: {names_text}.\\n\"\n",
    "        \"- Use epistemic phrasing (can/may) and avoid restrictive language (only, must, requires).\\n\"\n",
    "        \"- Do not turn this into a field list.\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "def canonical_outer_string_literal_from_decoded(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Canonical re-escaping for embedding a decoded Python string as a JSON string literal.\n",
    "\n",
    "    NOTE (Fix A): This intentionally normalizes escaping (e.g., may change \\\\uXXXX vs raw Unicode,\n",
    "    slash escaping, etc.). Outer JSON object is not reserialized, but the tools[] string literal is.\n",
    "    \"\"\"\n",
    "    return '\"' + json_escape_string(s) + '\"'\n",
    "\n",
    "\n",
    "def build_generation_prompt(\n",
    "    *,\n",
    "    mode: str,\n",
    "    tool_name: str,\n",
    "    original_description: str,\n",
    "    param_context: str,\n",
    "    top_level_param_names: Sequence[str],\n",
    ") -> str:\n",
    "    policy = MODE_POLICIES.get(mode)\n",
    "    if policy is None:\n",
    "        raise ValueError(f\"Unknown mode: {mode}\")\n",
    "\n",
    "    odesc = normalize_single_line(original_description or \"\")\n",
    "    short_orig = _orig_desc_is_short(odesc)\n",
    "    budget = compute_length_budget(mode=mode, original_description=odesc)\n",
    "\n",
    "    orig_has_norm = original_has_normative(odesc)\n",
    "    orig_has_examples = original_has_any_example_marker(odesc)\n",
    "    orig_has_listing = original_has_any_listing_marker(odesc)\n",
    "\n",
    "    listing_clause = (\n",
    "        \"10) Avoid enumeration/listing constructions (including 'including ...', 'such as ...', 'by specifying ...', 'with options to ...') \"\n",
    "        \"UNLESS those constructions already appear in ORIGINAL_DESCRIPTION; if they do, you may preserve them but do not expand into lists.\\n\"\n",
    "    )\n",
    "\n",
    "    example_clause = \"\"\n",
    "    if orig_has_examples:\n",
    "        example_clause = (\n",
    "            \"NOTE: ORIGINAL_DESCRIPTION contains example markers (e.g., 'for example'/'e.g.'); preserving them is allowed if needed to keep meaning.\\n\"\n",
    "        )\n",
    "\n",
    "    safe_ops = (\n",
    "        \"SAFE PARAPHRASE OPERATORS (allowed; do not add meaning):\\n\"\n",
    "        \"- Reorder clauses while preserving scope.\\n\"\n",
    "        \"- Replace one or two words with close synonyms already implied by the original.\\n\"\n",
    "        \"- Make small punctuation/segmentation changes (comma/period) without adding content.\\n\"\n",
    "        \"Do NOT introduce any new concepts (options/filters/criteria/parameters/pagination/etc.) unless present in ORIGINAL_DESCRIPTION.\\n\"\n",
    "    )\n",
    "\n",
    "    anti_copy = (\n",
    "        \"ANTI-COPY REQUIREMENT:\\n\"\n",
    "        \"- Output must NOT be identical to ORIGINAL_DESCRIPTION.\\n\"\n",
    "        \"- Make at least TWO minimal surface edits while preserving meaning (e.g., one synonym swap + one punctuation/word-order tweak).\\n\"\n",
    "        \"- Do NOT add any new information to satisfy this requirement.\\n\"\n",
    "    )\n",
    "\n",
    "    base_common = (\n",
    "        \"TASK: Produce exactly one English tool description string for a function-calling benchmark.\\n\"\n",
    "        \"OUTPUT FORMAT: Output only the description text, and nothing else.\\n\"\n",
    "        \"OUTPUT CONSTRAINTS:\\n\"\n",
    "        \"1) Output must be a single line (no newline characters).\\n\"\n",
    "        \"2) Do not output markdown, code fences, bullets, or backticks.\\n\"\n",
    "        \"3) Do not mention prompts, validators, schemas, or that an AI system is being used.\\n\"\n",
    "        \"4) Do not include the tool name itself in the description.\\n\"\n",
    "        \"5) Do NOT invent capabilities.\\n\"\n",
    "        \"6) Do NOT add constraints/requirements/decision rules; avoid introducing new 'only/must/requires' unless present in ORIGINAL_DESCRIPTION.\\n\"\n",
    "        \"7) Do NOT add any new features that are not explicitly stated in ORIGINAL_DESCRIPTION.\\n\"\n",
    "        \"8) Avoid purpose/benefit fluff unless it appears in ORIGINAL_DESCRIPTION.\\n\"\n",
    "        \"9) Do NOT list or name parameters, fields, filters, options, pagination, expiry/expired, or user/account concepts\\n\"\n",
    "        \"   unless those exact concepts appear in ORIGINAL_DESCRIPTION.\\n\"\n",
    "        + listing_clause\n",
    "        + \"11) Do not drop named entities or specific referents present in ORIGINAL_DESCRIPTION (e.g., person names like 'Adriel').\\n\"\n",
    "        + example_clause\n",
    "        + safe_ops\n",
    "        + anti_copy\n",
    "    )\n",
    "\n",
    "    mode_block = f\"MODE: {mode}\\n\"\n",
    "\n",
    "    confound_block = \"\"\n",
    "    if mode in ROBUSTNESS_MODES:\n",
    "        confound_block = (\n",
    "            \"ROBUSTNESS CONSTRAINTS:\\n\"\n",
    "            \"A) Do NOT include decision-boundary language (follow-up requests, insufficient information, cannot answer).\\n\"\n",
    "        )\n",
    "\n",
    "    if mode == \"empty_desc\":\n",
    "        return base_common + mode_block + \"INSTRUCTION: Output an empty string.\\n\"\n",
    "\n",
    "    # Numeric TARGETS (explicit), in addition to the band budget.\n",
    "    target_sent = max(budget.min_sentences, min(budget.max_sentences, int(round((budget.min_sentences + budget.max_sentences) / 2))))\n",
    "    target_words = max(budget.min_words, min(budget.max_words, int(round((budget.min_words + budget.max_words) / 2))))\n",
    "\n",
    "    length_instr = (\n",
    "        \"LENGTH BUDGET (must satisfy): \"\n",
    "        f\"sentences {budget.min_sentences}-{budget.max_sentences}; \"\n",
    "        f\"words {budget.min_words}-{budget.max_words}; \"\n",
    "        f\"chars <= {budget.max_chars}.\\n\"\n",
    "        f\"TARGET (aim for): about {target_words} words and {target_sent} sentence(s).\\n\"\n",
    "        \"IMPORTANT: Stay within the budget by paraphrasing, not by adding new details.\\n\"\n",
    "    )\n",
    "\n",
    "    requirements = \"\"\n",
    "    restrictions = \"\"\n",
    "\n",
    "    if mode in {\"style_concise\", \"style_verbose\"}:\n",
    "        if not orig_has_examples:\n",
    "            restrictions += \"RESTRICTIONS: Do not include examples.\\n\"\n",
    "        else:\n",
    "            restrictions += \"RESTRICTIONS: Do not introduce NEW examples; you may preserve example markers already present in ORIGINAL_DESCRIPTION if needed.\\n\"\n",
    "        if not orig_has_norm:\n",
    "            restrictions += \"RESTRICTIONS: Do not include normative language (avoid should/must/always/never).\\n\"\n",
    "    elif mode == \"add_examples\":\n",
    "        requirements += \"REQUIREMENTS: Include one or two conceptual examples using the exact phrase 'For example,'.\\n\"\n",
    "        if not orig_has_norm:\n",
    "            restrictions += \"RESTRICTIONS: Do not include normative language (avoid should/must/always/never).\\n\"\n",
    "    elif mode == \"normative_injection\":\n",
    "        requirements += \"REQUIREMENTS: Include one or two conceptual examples using the exact phrase 'For example,'.\\n\"\n",
    "        requirements += \"REQUIREMENTS: Include explicit usage guidance with at least one normative keyword (should or must).\\n\"\n",
    "\n",
    "    short_orig_block = \"\"\n",
    "    if short_orig:\n",
    "        short_orig_block = (\n",
    "            \"SHORT-ORIGINAL GUARDRAIL:\\n\"\n",
    "            \"- Keep the paraphrase extremely close to ORIGINAL_DESCRIPTION.\\n\"\n",
    "            \"- Do NOT add generic concepts like criteria, options, filters, pagination, parameters, results, control, management.\\n\"\n",
    "        )\n",
    "        if not orig_has_listing:\n",
    "            short_orig_block += \"- Do NOT add 'by providing/by specifying/using parameters like/such as ...' constructions.\\n\"\n",
    "        else:\n",
    "            short_orig_block += \"- If ORIGINAL_DESCRIPTION already uses listing constructions (e.g., 'such as'), you may preserve them but do not expand into lists.\\n\"\n",
    "\n",
    "    return (\n",
    "        base_common\n",
    "        + mode_block\n",
    "        + confound_block\n",
    "        + short_orig_block\n",
    "        + \"INSTRUCTION: Produce a meaning-preserving paraphrase of ORIGINAL_DESCRIPTION.\\n\"\n",
    "        + \"INSTRUCTION: Paraphrase only; do not enrich.\\n\"\n",
    "        + length_instr\n",
    "        + requirements\n",
    "        + restrictions\n",
    "        + f\"TOOL_NAME (do not copy): {tool_name}\\n\"\n",
    "        + f\"ORIGINAL_DESCRIPTION: {odesc if odesc else '[NONE]'}\\n\"\n",
    "        + \"PARAMETERS CONTEXT (do not copy; grounding only):\\n\"\n",
    "        + param_context\n",
    "        + \"\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_repair_prompt(\n",
    "    *,\n",
    "    mode: str,\n",
    "    tool_name: str,\n",
    "    params_context: str,\n",
    "    candidate_output: str,\n",
    "    validation_errors: List[str],\n",
    "    top_level_param_names: Sequence[str],\n",
    "    original_description: Optional[str] = None,\n",
    ") -> str:\n",
    "    policy = MODE_POLICIES.get(mode)\n",
    "    if policy is None:\n",
    "        raise ValueError(f\"Unknown mode: {mode}\")\n",
    "\n",
    "    orig_desc = normalize_single_line(original_description or \"\")\n",
    "    orig_has_norm = original_has_normative(orig_desc)\n",
    "    orig_has_examples = original_has_any_example_marker(orig_desc)\n",
    "    orig_has_listing = original_has_any_listing_marker(orig_desc)\n",
    "\n",
    "    budget = compute_length_budget(mode=mode, original_description=orig_desc)\n",
    "    target_sent = max(budget.min_sentences, min(budget.max_sentences, int(round((budget.min_sentences + budget.max_sentences) / 2))))\n",
    "    target_words = max(budget.min_words, min(budget.max_words, int(round((budget.min_words + budget.max_words) / 2))))\n",
    "\n",
    "    bans: List[str] = []\n",
    "\n",
    "    # Examples (conditional)\n",
    "    if not policy.allow_examples:\n",
    "        if not orig_has_examples:\n",
    "            bans.append(\"No examples.\")\n",
    "        else:\n",
    "            bans.append(\"Do not introduce NEW examples; you may preserve example markers already present in ORIGINAL_DESCRIPTION if needed.\")\n",
    "    if policy.require_examples:\n",
    "        bans.append(\"Must include the exact phrase 'For example,' at least once.\")\n",
    "\n",
    "    # Normative (conditional)\n",
    "    if not policy.allow_normative and not orig_has_norm:\n",
    "        bans.append(\"No normative language (avoid should/must/always/never/do not/avoid).\")\n",
    "    if policy.require_normative:\n",
    "        bans.append(\"Must include at least one of: should, must.\")\n",
    "\n",
    "    if not policy.allow_leakage_phrases:\n",
    "        bans.append(\"No decision-boundary leakage phrases (follow-up/need more information/cannot answer/etc.).\")\n",
    "\n",
    "    listing_ban = (\n",
    "        \"Avoid listing constructions: 'including ...', 'such as ...', 'by specifying ...', 'with options to ...'\"\n",
    "    )\n",
    "    if orig_has_listing:\n",
    "        listing_ban += \" unless they already appear in ORIGINAL_DESCRIPTION; if present, you may preserve but do not expand into lists.\"\n",
    "    else:\n",
    "        listing_ban += \".\"\n",
    "\n",
    "    bans.extend(\n",
    "        [\n",
    "            \"Do not include the tool name itself in the description.\",\n",
    "            \"Do not invent capabilities.\",\n",
    "            \"Do not add constraints/requirements/decision rules; avoid introducing new 'only/must/requires' unless present in ORIGINAL_DESCRIPTION (or required by mode).\",\n",
    "            \"Do not add purpose/benefit fluff unless present in ORIGINAL_DESCRIPTION.\",\n",
    "            \"Do not add or enumerate parameters/fields/filters/options/pagination/expiry unless present in ORIGINAL_DESCRIPTION.\",\n",
    "            listing_ban,\n",
    "            \"Do not add generic filler concepts like various details, relevant details, specific context, configurations, preferences, or other relevant details unless present in ORIGINAL_DESCRIPTION.\",\n",
    "            \"Do not introduce proper nouns or identifiers not present in ORIGINAL_DESCRIPTION (e.g., names like 'Adriel').\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    anti_copy = (\n",
    "        \"ANTI-COPY REQUIREMENT: The output must NOT be identical to ORIGINAL_DESCRIPTION, and must include at least TWO minimal surface edits \"\n",
    "        \"(synonym/punctuation/word-order) without adding any new meaning.\"\n",
    "    )\n",
    "\n",
    "    ban_text = \" \".join(bans) if bans else \"[NONE]\"\n",
    "\n",
    "    return (\n",
    "        \"TASK: Fix a tool description so that it satisfies hard constraints exactly.\\n\"\n",
    "        \"OUTPUT FORMAT: Output only the corrected description text, and nothing else.\\n\"\n",
    "        \"HARD CONSTRAINTS:\\n\"\n",
    "        \"1) Output must be a single line (no newline characters).\\n\"\n",
    "        \"2) Do not output markdown, code fences, bullets, or backticks.\\n\"\n",
    "        \"3) Do not mention prompts, validators, schemas, or that an AI system is being used.\\n\"\n",
    "        \"4) Prefer deleting or replacing problematic fragments; do NOT add new content.\\n\"\n",
    "        f\"5) Mode is {mode}; satisfy the mode-specific rules including sentence/word budget expectations.\\n\"\n",
    "        f\"6) LENGTH BUDGET: sentences {budget.min_sentences}-{budget.max_sentences}; words {budget.min_words}-{budget.max_words}; chars <= {budget.max_chars}. \"\n",
    "        f\"TARGET: about {target_words} words and {target_sent} sentence(s).\\n\"\n",
    "        f\"7) {anti_copy}\\n\"\n",
    "        f\"MODE-SPECIFIC BANS/RESTRICTIONS: {ban_text}\\n\"\n",
    "        f\"VALIDATION_ERRORS: {validation_errors}\\n\"\n",
    "        f\"TOOL_NAME (do not copy): {tool_name}\\n\"\n",
    "        f\"ORIGINAL_DESCRIPTION: {orig_desc if orig_desc else '[NONE]'}\\n\"\n",
    "        f\"PARAMETERS CONTEXT (grounding only):\\n{params_context}\\n\"\n",
    "        f\"CANDIDATE OUTPUT: {normalize_single_line(candidate_output)}\\n\"\n",
    "        \"INSTRUCTION: Rewrite the candidate so it passes validation while staying faithful to the original intent.\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_semantic_repair_prompt(\n",
    "    *,\n",
    "    tool_name: str,\n",
    "    mode: str,\n",
    "    original_description: str,\n",
    "    candidate_description: str,\n",
    "    semantic_judge_feedback: str,\n",
    ") -> str:\n",
    "    odesc = normalize_single_line(original_description or \"\")\n",
    "    cdesc = normalize_single_line(candidate_description or \"\")\n",
    "    short_orig = _orig_desc_is_short(odesc)\n",
    "\n",
    "    strict_block = (\n",
    "        \"CRITICAL:\\n\"\n",
    "        \"- Preserve meaning and scope of ORIGINAL_DESCRIPTION.\\n\"\n",
    "        \"- Do NOT add constraints/requirements/decision rules.\\n\"\n",
    "        \"- Do NOT add new purpose/benefit framing.\\n\"\n",
    "        \"- Do NOT add new concepts (criteria/options/filters/pagination/parameters/expiry/expired) unless present in ORIGINAL_DESCRIPTION.\\n\"\n",
    "        \"- Do NOT introduce proper nouns or identifiers not present in ORIGINAL_DESCRIPTION.\\n\"\n",
    "        \"- Prefer deleting or replacing the offending phrase; do not add new details.\\n\"\n",
    "    )\n",
    "    if short_orig:\n",
    "        strict_block += (\n",
    "            \"- SHORT ORIGINAL: stay extremely close; prefer a near-literal paraphrase.\\n\"\n",
    "            \"- Avoid 'including/such as/by specifying/with options to' constructions.\\n\"\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        \"TASK: Rewrite CANDIDATE_DESCRIPTION so it passes the semantic judge.\\n\"\n",
    "        \"OUTPUT FORMAT: Output only the rewritten description as a single line.\\n\"\n",
    "        f\"MODE: {mode}\\n\"\n",
    "        + strict_block +\n",
    "        f\"SEMANTIC_JUDGE_FEEDBACK: {normalize_single_line(semantic_judge_feedback)}\\n\"\n",
    "        f\"ORIGINAL_DESCRIPTION: {odesc}\\n\"\n",
    "        f\"CANDIDATE_DESCRIPTION: {cdesc}\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_judge_prompt(\n",
    "    *,\n",
    "    mode: str,\n",
    "    tool_name: str,\n",
    "    original_description: str,\n",
    "    last_candidate: str,\n",
    "    validation_errors: List[str],\n",
    "    params_context: str,\n",
    "    top_level_param_names: Sequence[str],\n",
    ") -> str:\n",
    "    policy = MODE_POLICIES.get(mode)\n",
    "    if policy is None:\n",
    "        raise ValueError(f\"Unknown mode: {mode}\")\n",
    "\n",
    "    odesc = normalize_single_line(original_description or \"\")\n",
    "    orig_has_norm = original_has_normative(odesc)\n",
    "\n",
    "    budget = compute_length_budget(mode=mode, original_description=odesc)\n",
    "    target_sent = max(budget.min_sentences, min(budget.max_sentences, int(round((budget.min_sentences + budget.max_sentences) / 2))))\n",
    "    target_words = max(budget.min_words, min(budget.max_words, int(round((budget.min_words + budget.max_words) / 2))))\n",
    "\n",
    "    bans: List[str] = []\n",
    "    if not policy.allow_examples:\n",
    "        bans.append(\"No examples.\")\n",
    "    if policy.require_examples:\n",
    "        bans.append(\"Include the exact phrase 'For example,' at least once.\")\n",
    "    if not policy.allow_normative and not orig_has_norm:\n",
    "        bans.append(\"No normative language (avoid should/must/always/never/do not/avoid).\")\n",
    "    if policy.require_normative:\n",
    "        bans.append(\"Include at least one of: should, must.\")\n",
    "    if not policy.allow_leakage_phrases:\n",
    "        bans.append(\"No decision-boundary leakage phrases (follow-up/need more information/cannot answer/etc.).\")\n",
    "    bans.append(\"Do not include the tool name itself in the description.\")\n",
    "\n",
    "    anti_copy = (\n",
    "        \"ANTI-COPY REQUIREMENT: Output must NOT be identical to ORIGINAL_DESCRIPTION, and must include at least TWO minimal surface edits \"\n",
    "        \"(synonym/punctuation/word-order) without adding any new meaning.\"\n",
    "    )\n",
    "\n",
    "    ban_text = \" \".join(bans) if bans else \"[NONE]\"\n",
    "    err_text = \", \".join(validation_errors) if validation_errors else \"[NONE]\"\n",
    "\n",
    "    return (\n",
    "        \"ROLE: You are a strict compliance editor for tool documentation strings.\\n\"\n",
    "        \"TASK: Produce a single-line English tool description that passes a fixed validator.\\n\"\n",
    "        \"OUTPUT FORMAT: Output only the description text, and nothing else.\\n\"\n",
    "        \"ABSOLUTE CONSTRAINTS:\\n\"\n",
    "        \"1) Single line only. No markdown. No bullets. No backticks.\\n\"\n",
    "        \"2) Do not mention prompts, validators, schemas, or that an AI system is being used.\\n\"\n",
    "        \"3) Do not invent capabilities.\\n\"\n",
    "        \"4) Do not include the tool name itself in the description.\\n\"\n",
    "        f\"5) LENGTH BUDGET: sentences {budget.min_sentences}-{budget.max_sentences}; words {budget.min_words}-{budget.max_words}; chars <= {budget.max_chars}. \"\n",
    "        f\"TARGET: about {target_words} words and {target_sent} sentence(s).\\n\"\n",
    "        f\"6) {anti_copy}\\n\"\n",
    "        f\"MODE: {mode}\\n\"\n",
    "        f\"MODE-SPECIFIC BANS/RESTRICTIONS: {ban_text}\\n\"\n",
    "        f\"VALIDATION_ERRORS_TO_FIX: {err_text}\\n\"\n",
    "        f\"TOOL_NAME (do not copy): {tool_name}\\n\"\n",
    "        f\"ORIGINAL_DESCRIPTION (context only): {odesc if odesc else '[NONE]'}\\n\"\n",
    "        f\"LAST_FAILED_CANDIDATE (context only): {normalize_single_line(last_candidate) if last_candidate else '[NONE]'}\\n\"\n",
    "        f\"PARAMETERS CONTEXT (grounding only):\\n{params_context}\\n\"\n",
    "        \"INSTRUCTION: Write a fresh description that satisfies all constraints and stays faithful to the original meaning.\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# ================== LLM CALLS WITH RETRY + AUDIT ==================\n",
    "\n",
    "def _sleep_with_jitter(seconds: float) -> None:\n",
    "    if seconds <= 0:\n",
    "        return\n",
    "    jitter = random.random() * min(0.25, seconds * 0.1)\n",
    "    time.sleep(seconds + jitter)\n",
    "\n",
    "def _orig_desc_is_short(orig_desc: str, *, max_chars: int = 140, max_words: int = 22) -> bool:\n",
    "    o = normalize_single_line(orig_desc or \"\")\n",
    "    if not o:\n",
    "        return False\n",
    "    if len(o) <= max_chars:\n",
    "        return True\n",
    "    if len(re.findall(r\"\\S+\", o)) <= max_words:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "def _looks_like_param_enumeration(text: str, *, original_description: Optional[str] = None) -> bool:\n",
    "    \"\"\"\n",
    "    Heuristic: candidate is likely listing parameters/options rather than paraphrasing intent.\n",
    "    NEW: allow listing markers that already appear in the original (meaning-preserving).\n",
    "    \"\"\"\n",
    "    t = (text or \"\").lower()\n",
    "    o = (original_description or \"\").lower()\n",
    "\n",
    "    patterns = [\n",
    "        \"by providing\",\n",
    "        \"by specifying\",\n",
    "        \"by entering\",\n",
    "        \"details such as\",\n",
    "        \"such as the\",\n",
    "        \"including the\",\n",
    "        \"including details\",\n",
    "        \"allowing users to\",\n",
    "        \"allow users to\",\n",
    "        \"with options to\",\n",
    "        \"with the option to\",\n",
    "        \"fields such as\",\n",
    "    ]\n",
    "\n",
    "    # If candidate uses these patterns but original has none of the listing markers,\n",
    "    # it's very likely template-y enumeration.\n",
    "    cand_listing = _marker_set_case_insensitive(t, LISTING_MARKERS)\n",
    "    orig_listing = _marker_set_case_insensitive(o, LISTING_MARKERS)\n",
    "\n",
    "    # If candidate introduces listing markers that weren't in the original -> suspicious.\n",
    "    if (cand_listing - orig_listing):\n",
    "        return True\n",
    "\n",
    "    # If it contains strong listing patterns and original had no listing markers at all -> suspicious.\n",
    "    if any(p in t for p in patterns) and not orig_listing:\n",
    "        return True\n",
    "\n",
    "    # Too many commas often indicates a field list\n",
    "    if t.count(\",\") >= 4 and o.count(\",\") < 4:\n",
    "        return True\n",
    "\n",
    "    # Colon lists like \"details: name, date, city\"\n",
    "    if (\":\" in t and t.count(\",\") >= 2) and not (\":\" in o and o.count(\",\") >= 2):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "# Phrases that frequently create \"new information\" under strict semantic judging.\n",
    "# We trigger a guardrail rewrite when these appear in the candidate but not in ORIGINAL_DESCRIPTION.\n",
    "\n",
    "SEMANTIC_FLUFF_PHRASES = (\n",
    "    \"comprehensive\",\n",
    "    \"comprehensive understanding\",\n",
    "    \"overall\",\n",
    "    \"insight\",\n",
    "    \"provides insight\",\n",
    "    \"providing insight\",\n",
    "    \"overview\",\n",
    "    \"provide an overview\",\n",
    "    \"providing an overview\",\n",
    "    \"help users\",\n",
    "    \"helping users\",\n",
    "    \"helpful\",\n",
    "    \"allowing users\",\n",
    "    \"enabling users\",\n",
    "    \"straightforward way\",\n",
    "    \"up-to-date\",\n",
    "    \"up to date\",\n",
    "    \"relevant details\",\n",
    "    \"relevant information\",\n",
    "    \"various factors\",\n",
    "    \"needs and preferences\",\n",
    "    \"purposes\",\n",
    "    \"interpretation\",\n",
    "    \"to get a\",\n",
    "    \"to gain a\",\n",
    "    \"to understand\",\n",
    ")\n",
    "\n",
    "def _contains_fluff_not_in_original(original_description: str, candidate_description: str) -> bool:\n",
    "    o = (original_description or \"\").lower()\n",
    "    c = (candidate_description or \"\").lower()\n",
    "    if not o or not c:\n",
    "        return False\n",
    "\n",
    "    for p in SEMANTIC_FLUFF_PHRASES:\n",
    "        if p in c and p not in o:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def should_trigger_pre_semantic_guardrail(\n",
    "    *,\n",
    "    original_description: str,\n",
    "    candidate_description: str,\n",
    "    top_level_param_names: Sequence[str],\n",
    "    mode: Optional[str] = None,\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Pre-semantic guardrail: detect common enrichment/template drift BEFORE semantic gate.\n",
    "\n",
    "    Update:\n",
    "    - In modes that require examples/normative, evaluate guardrail triggers on BASE only,\n",
    "      so the mode-allowed suffix does not cause spurious rewrites.\n",
    "    \"\"\"\n",
    "    cand_full = normalize_single_line(candidate_description or \"\")\n",
    "    if not cand_full:\n",
    "        return False\n",
    "\n",
    "    o_full = normalize_single_line(original_description or \"\")\n",
    "\n",
    "    # For example/normative modes: analyze BASE only (avoid punishing the required suffix).\n",
    "    if mode in {\"add_examples\", \"normative_injection\"}:\n",
    "        cand = semantic_base_text(mode, cand_full)\n",
    "        odesc = semantic_base_text(mode, o_full)\n",
    "    else:\n",
    "        cand = cand_full\n",
    "        odesc = o_full\n",
    "\n",
    "    if not cand:\n",
    "        return False\n",
    "\n",
    "    # Purpose/benefit fluff not in original -> rewrite\n",
    "    if _contains_fluff_not_in_original(odesc, cand):\n",
    "        return True\n",
    "\n",
    "    # Parameter-enumeration/template patterns -> rewrite\n",
    "    if _looks_like_param_enumeration(cand, original_description=odesc):\n",
    "        return True\n",
    "\n",
    "    # repetition heuristics (BASE-only when applicable)\n",
    "    o = (odesc or \"\").lower()\n",
    "    c = (cand or \"\").lower()\n",
    "    if c.count(\"returns\") >= 2 and o.count(\"returns\") < 2:\n",
    "        return True\n",
    "    if c.count(\"based on\") >= 2 and o.count(\"based on\") < 2:\n",
    "        return True\n",
    "\n",
    "    # Short originals: extra strict (BASE-only)\n",
    "    if _orig_desc_is_short(odesc):\n",
    "        bad_new_concepts = (\"criteria\", \"options\", \"filters\", \"pagination\", \"parameters\", \"paginated\", \"filtered\")\n",
    "        if any(w in c and w not in o for w in bad_new_concepts):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "def build_guardrail_rewrite_prompt(\n",
    "    *,\n",
    "    mode: str,\n",
    "    tool_name: str,\n",
    "    original_description: str,\n",
    "    candidate_description: str,\n",
    "    params_context: str,\n",
    ") -> str:\n",
    "    odesc = normalize_single_line(original_description or \"\")\n",
    "    budget = compute_length_budget(mode=mode, original_description=odesc)\n",
    "\n",
    "    orig_has_listing = original_has_any_listing_marker(odesc)\n",
    "    orig_has_examples = original_has_any_example_marker(odesc)\n",
    "\n",
    "    trigger_block = (\n",
    "        \"TRIGGER PHRASES POLICY:\\n\"\n",
    "        \"- If ANY of the following concepts/phrases appear in CANDIDATE_DESCRIPTION but do NOT appear in ORIGINAL_DESCRIPTION,\\n\"\n",
    "        \"  you MUST delete them (do not paraphrase them):\\n\"\n",
    "        \"  identifier, id, contact_id, default, based on provided details, provided details, filter, filtering,\\n\"\n",
    "        \"  options, preferences, criteria, parameters, fields, pagination, authenticate, authorization, authorize,\\n\"\n",
    "        \"  account, user account, user’s account.\\n\"\n",
    "    )\n",
    "\n",
    "    if mode == \"style_concise\":\n",
    "        req_block = \"EXAMPLES/NORMATIVE: No examples unless they already appear in ORIGINAL_DESCRIPTION. No normative language unless present in ORIGINAL_DESCRIPTION.\"\n",
    "    elif mode == \"style_verbose\":\n",
    "        req_block = \"EXAMPLES/NORMATIVE: No examples unless they already appear in ORIGINAL_DESCRIPTION. No normative language unless present in ORIGINAL_DESCRIPTION.\"\n",
    "    elif mode == \"add_examples\":\n",
    "        req_block = \"EXAMPLES/NORMATIVE: Include 1–2 conceptual examples using the exact phrase 'For example,' at least once. No normative language unless present in ORIGINAL_DESCRIPTION.\"\n",
    "    elif mode == \"normative_injection\":\n",
    "        req_block = \"EXAMPLES/NORMATIVE: Include 1–2 conceptual examples using the exact phrase 'For example,' at least once. Include usage guidance with 'should' or 'must'.\"\n",
    "    else:\n",
    "        req_block = \"EXAMPLES/NORMATIVE: Follow the mode policy.\"\n",
    "\n",
    "    length_block = (\n",
    "        \"LENGTH BUDGET (must satisfy): \"\n",
    "        f\"sentences {budget.min_sentences}-{budget.max_sentences}; \"\n",
    "        f\"words {budget.min_words}-{budget.max_words}; \"\n",
    "        f\"chars <= {budget.max_chars}.\\n\"\n",
    "    )\n",
    "\n",
    "    listing_rule = \"5) Avoid enumeration constructions: 'including', 'such as', 'by providing', 'by specifying', 'with options to'.\"\n",
    "    if orig_has_listing:\n",
    "        listing_rule += \" If ORIGINAL_DESCRIPTION already uses them, you may preserve them but do not expand into lists.\"\n",
    "    else:\n",
    "        listing_rule += \".\"\n",
    "\n",
    "    examples_rule = \"\"\n",
    "    if orig_has_examples:\n",
    "        examples_rule = \"NOTE: ORIGINAL_DESCRIPTION contains example markers; preserving them is allowed if needed to keep meaning, but do not introduce new examples.\\n\"\n",
    "\n",
    "    return (\n",
    "        \"TASK: Rewrite CANDIDATE_DESCRIPTION into a meaning-preserving paraphrase of ORIGINAL_DESCRIPTION.\\n\"\n",
    "        \"OUTPUT FORMAT: Output only the rewritten description text, single line.\\n\"\n",
    "        \"HARD RULES:\\n\"\n",
    "        \"1) Keep it a minimal-edit paraphrase; do not write a generic template.\\n\"\n",
    "        \"2) Do NOT add new concepts unless present in ORIGINAL_DESCRIPTION (e.g., criteria, options, filters, pagination, parameters, expiry/expired).\\n\"\n",
    "        \"3) Do NOT add purpose/benefit framing unless present in ORIGINAL_DESCRIPTION (overview/insight/comprehensive/relevant).\\n\"\n",
    "        \"4) Do NOT add new constraints/requirements/decision rules; avoid introducing new only/must/requires unless present in ORIGINAL_DESCRIPTION (or required by mode).\\n\"\n",
    "        + listing_rule + \"\\n\"\n",
    "        \"6) Do not introduce proper nouns or identifiers not present in ORIGINAL_DESCRIPTION.\\n\"\n",
    "        \"7) Do not include the tool name.\\n\"\n",
    "        + examples_rule +\n",
    "        trigger_block +\n",
    "        f\"MODE: {mode}\\n\"\n",
    "        + length_block +\n",
    "        f\"{req_block}\\n\"\n",
    "        f\"TOOL_NAME (do not copy): {tool_name}\\n\"\n",
    "        f\"ORIGINAL_DESCRIPTION: {odesc if odesc else '[NONE]'}\\n\"\n",
    "        f\"CANDIDATE_DESCRIPTION: {normalize_single_line(candidate_description) if candidate_description else '[NONE]'}\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def _mentions_multiple_param_tokens(text: str, top_level_param_names: Sequence[str], *, min_hits: int = 2) -> bool:\n",
    "    \"\"\"\n",
    "    Uses token-based match (word boundaries via _WORD_RE). This is cheap and consistent with your validator.\n",
    "    \"\"\"\n",
    "    words = {w.lower() for w in _WORD_RE.findall(text or \"\")}\n",
    "    hits = 0\n",
    "    for p in top_level_param_names or []:\n",
    "        pl = (p or \"\").lower()\n",
    "        if pl and pl in words:\n",
    "            hits += 1\n",
    "            if hits >= min_hits:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "def llm_call_chat_completions(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    model: str,\n",
    "    system_text: str,\n",
    "    user_text: str,\n",
    "    temperature: float,\n",
    "    max_tokens: int,\n",
    "    rate_limit_sleep_sec: float,\n",
    "    max_retries: int,\n",
    "    audit: \"AuditLogger\",\n",
    "    call_tag: str,\n",
    ") -> str:\n",
    "    if rate_limit_sleep_sec > 0:\n",
    "        _sleep_with_jitter(rate_limit_sleep_sec)\n",
    "\n",
    "    prompt_hash = stable_sha256(system_text + \"\\n\\n\" + user_text)\n",
    "\n",
    "    last_exc: Optional[Exception] = None\n",
    "    current_max_tokens = int(max_tokens)\n",
    "    max_tokens_cap = max(1024, current_max_tokens)  # conservative cap\n",
    "\n",
    "    def _is_rate_limit_exc(e: Exception) -> bool:\n",
    "        name = type(e).__name__.lower()\n",
    "        msg = str(e).lower()\n",
    "        return (\"ratelimit\" in name) or (\"429\" in msg) or (\"rate limit\" in msg)\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            audit.inc(\"llm_calls\", 1)\n",
    "            t0 = now_unix()\n",
    "\n",
    "            resp = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_text},\n",
    "                    {\"role\": \"user\", \"content\": user_text},\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "                max_tokens=current_max_tokens,\n",
    "            )\n",
    "\n",
    "            t1 = now_unix()\n",
    "\n",
    "            choice0 = resp.choices[0]\n",
    "            msg = choice0.message\n",
    "\n",
    "            content = getattr(msg, \"content\", None) or \"\"\n",
    "            tool_calls = getattr(msg, \"tool_calls\", None)\n",
    "            refusal = getattr(msg, \"refusal\", None)\n",
    "            finish_reason = getattr(choice0, \"finish_reason\", None)\n",
    "\n",
    "            text = content if isinstance(content, str) else str(content)\n",
    "            normalized = normalize_single_line(text)\n",
    "\n",
    "            audit.log_call(\n",
    "                {\n",
    "                    \"ts\": t0,\n",
    "                    \"tag\": call_tag,\n",
    "                    \"attempt\": attempt,\n",
    "                    \"model\": model,\n",
    "                    \"temperature\": temperature,\n",
    "                    \"max_tokens\": current_max_tokens,\n",
    "                    \"prompt_hash\": prompt_hash,\n",
    "                    \"latency_sec\": round(t1 - t0, 6),\n",
    "                    \"finish_reason\": finish_reason,\n",
    "                    \"has_tool_calls\": bool(tool_calls),\n",
    "                    \"has_refusal\": bool(refusal),\n",
    "                    \"raw_output_preview\": text[:2000] if isinstance(text, str) else str(text)[:2000],\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Treat truncation as failed attempt; retry with higher max_tokens.\n",
    "            if finish_reason == \"length\":\n",
    "                bump = 256 if current_max_tokens >= 256 else 128\n",
    "                next_tokens = min(max_tokens_cap, current_max_tokens + bump)\n",
    "\n",
    "                audit.log_call(\n",
    "                    {\n",
    "                        \"ts\": now_unix(),\n",
    "                        \"tag\": call_tag,\n",
    "                        \"attempt\": attempt,\n",
    "                        \"model\": model,\n",
    "                        \"prompt_hash\": prompt_hash,\n",
    "                        \"event\": \"finish_reason_length_retry\",\n",
    "                        \"prev_max_tokens\": current_max_tokens,\n",
    "                        \"next_max_tokens\": next_tokens,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                if next_tokens <= current_max_tokens or attempt == max_retries:\n",
    "                    raise RuntimeError(\n",
    "                        \"Model output truncated (finish_reason=length) and cannot increase max_tokens further.\"\n",
    "                    )\n",
    "                current_max_tokens = next_tokens\n",
    "                continue\n",
    "\n",
    "            if (\"empty_desc\" not in call_tag) and (normalized == \"\"):\n",
    "                raise RuntimeError(\n",
    "                    f\"Empty model output (finish_reason={finish_reason}, tool_calls={bool(tool_calls)}, refusal={bool(refusal)})\"\n",
    "                )\n",
    "\n",
    "            return text\n",
    "\n",
    "        except Exception as e:\n",
    "            last_exc = e\n",
    "\n",
    "            # Improved backoff for rate limits\n",
    "            if _is_rate_limit_exc(e):\n",
    "                # Start higher and grow slower; cap higher.\n",
    "                backoff = min(90.0, max(2.0, 2.0 * (1.8 ** (attempt - 1))))\n",
    "            else:\n",
    "                backoff = min(30.0, 0.5 * (2 ** (attempt - 1)))\n",
    "\n",
    "            audit.log_call(\n",
    "                {\n",
    "                    \"ts\": now_unix(),\n",
    "                    \"tag\": call_tag,\n",
    "                    \"attempt\": attempt,\n",
    "                    \"model\": model,\n",
    "                    \"temperature\": temperature,\n",
    "                    \"max_tokens\": current_max_tokens,\n",
    "                    \"prompt_hash\": prompt_hash,\n",
    "                    \"error_type\": type(e).__name__,\n",
    "                    \"error_str\": str(e)[:2000],\n",
    "                    \"backoff_sec\": backoff,\n",
    "                }\n",
    "            )\n",
    "            _sleep_with_jitter(backoff)\n",
    "\n",
    "    raise RuntimeError(\n",
    "        f\"LLM call failed after {max_retries} attempts: {type(last_exc).__name__}: {last_exc}\"\n",
    "    ) from last_exc\n",
    "\n",
    "\n",
    "\n",
    "# ==================  ROBUST DETECTORS (word boundaries) ==================\n",
    "\n",
    "def _contains_any_substring_ci(text: str, needles: Sequence[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Conservative substring match (case-insensitive). Use only when substring semantics are desired.\n",
    "    \"\"\"\n",
    "    lt = (text or \"\").lower()\n",
    "    return any((n or \"\").lower() in lt for n in (needles or ()) if n)\n",
    "\n",
    "\n",
    "def _compile_phrase_regex(phrases: Sequence[str]) -> re.Pattern:\n",
    "    r\"\"\"\n",
    "    Compile a single case-insensitive regex that matches any phrase with safe word boundaries.\n",
    "\n",
    "    - Pure word tokens -> \\b boundaries.\n",
    "    - Multi-token / punctuation phrases -> (?<!\\w) ... (?!\\w).\n",
    "    \"\"\"\n",
    "    alts: List[str] = []\n",
    "    for p in phrases:\n",
    "        if not p:\n",
    "            continue\n",
    "        p_norm = str(p).strip()\n",
    "        if not p_norm:\n",
    "            continue\n",
    "\n",
    "        if re.fullmatch(r\"[A-Za-z]+(?:'[A-Za-z]+)?\", p_norm):\n",
    "            alts.append(rf\"\\b{re.escape(p_norm)}\\b\")\n",
    "        else:\n",
    "            alts.append(rf\"(?<!\\w){re.escape(p_norm)}(?!\\w)\")\n",
    "\n",
    "    if not alts:\n",
    "        return re.compile(r\"(?!x)x\")\n",
    "    return re.compile(\"|\".join(alts), flags=re.IGNORECASE)\n",
    "\n",
    "\n",
    "# Precompiled regexes for the canonical phrase sets\n",
    "_NORMATIVE_RE = _compile_phrase_regex(NORMATIVE_KEYWORDS)\n",
    "_EXAMPLE_RE = _compile_phrase_regex(EXAMPLE_MARKERS)\n",
    "_LEAKAGE_RE = _compile_phrase_regex(LEAKAGE_PHRASES)\n",
    "_REQUIRED_EXAMPLE_RE = re.compile(r\"(?<!\\w)for example,(?!\\w)\", flags=re.IGNORECASE)\n",
    "\n",
    "\n",
    "def _contains_any_phrase_regex_ci(text: str, needles: Sequence[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Phrase match with word-boundary safety (regex). Default for validators/judges.\n",
    "    \"\"\"\n",
    "    t = text or \"\"\n",
    "    # Fast path for canonical sets (identity check is stable: they are module-level tuples)\n",
    "    if needles is NORMATIVE_KEYWORDS:\n",
    "        return bool(_NORMATIVE_RE.search(t))\n",
    "    if needles is EXAMPLE_MARKERS:\n",
    "        return bool(_EXAMPLE_RE.search(t))\n",
    "    if needles is LEAKAGE_PHRASES:\n",
    "        return bool(_LEAKAGE_RE.search(t))\n",
    "    return bool(_compile_phrase_regex(needles).search(t))\n",
    "\n",
    "\n",
    "def _contains_any_case_insensitive(text: str, needles: Sequence[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Backwards-compatible default: use regex-safe phrase detection.\n",
    "    \"\"\"\n",
    "    return _contains_any_phrase_regex_ci(text, needles)\n",
    "\n",
    "\n",
    "def _contains_required_example_phrase(text: str) -> bool:\n",
    "    return bool(_REQUIRED_EXAMPLE_RE.search(text or \"\"))\n",
    "\n",
    "\n",
    "\n",
    "# ================== SEMANTIC CHECK (judge gate) ==================\n",
    "\n",
    "\n",
    "def semantic_check_or_fail(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    judge_model: str,\n",
    "    tool_name: str,\n",
    "    original_description: str,\n",
    "    candidate_description: str,\n",
    "    params_context: str,\n",
    "    mode: str,\n",
    "    audit: \"AuditLogger\",\n",
    "    rate_limit_sleep_sec: float,\n",
    "    max_retries: int,\n",
    ") -> Tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    Returns (is_pass, judge_raw_line).\n",
    "    \"\"\"\n",
    "    prompt = build_semantic_judge_prompt(\n",
    "        tool_name=tool_name,\n",
    "        original_description=original_description,\n",
    "        candidate_description=candidate_description,\n",
    "        params_context=params_context,\n",
    "        mode=mode,\n",
    "    )\n",
    "\n",
    "    raw = llm_call_chat_completions(\n",
    "        client=client,\n",
    "        model=judge_model,\n",
    "        system_text=\"System role: Semantic equivalence judge for tool descriptions.\",\n",
    "        user_text=prompt,\n",
    "        temperature=0.0,\n",
    "        max_tokens=256,\n",
    "        rate_limit_sleep_sec=rate_limit_sleep_sec,\n",
    "        max_retries=max_retries,\n",
    "        audit=audit,\n",
    "        call_tag=f\"semantic_judge::{tool_name}\",\n",
    "    )\n",
    "\n",
    "    line = normalize_single_line(raw)\n",
    "    if line.upper() == \"PASS\":\n",
    "        return True, line\n",
    "    if line.upper().startswith(\"FAIL\"):\n",
    "        return False, line\n",
    "\n",
    "    return False, f\"FAIL: non_compliant_judge_output:{line[:120]}\"\n",
    "\n",
    "\n",
    "# ================== GENERATION PIPELINE ==================\n",
    "\n",
    "def tool_signature_for_cache(tool_obj: Dict[str, Any]) -> str:\n",
    "    name = str(tool_obj.get(\"name\") or tool_obj.get(\"function\", {}).get(\"name\") or \"unnamed_tool\")\n",
    "    if \"function\" in tool_obj and isinstance(tool_obj[\"function\"], dict):\n",
    "        params = tool_obj[\"function\"].get(\"parameters\")\n",
    "        orig_desc = tool_obj[\"function\"].get(\"description\") or \"\"\n",
    "    else:\n",
    "        params = tool_obj.get(\"parameters\")\n",
    "        orig_desc = tool_obj.get(\"description\") or \"\"\n",
    "\n",
    "    params_canon = json.dumps(params, ensure_ascii=False, sort_keys=True, separators=(\",\", \":\"))\n",
    "    base = f\"name={name}\\nparams={params_canon}\\norig_desc={normalize_single_line(orig_desc)}\"\n",
    "    return stable_sha256(base)\n",
    "\n",
    "def extract_tool_core(\n",
    "    tool_obj: Dict[str, Any]\n",
    ") -> Tuple[str, str, Any, List[ParamSpec], List[str], List[str], Sequence[str]]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      tool_name: str\n",
    "      orig_desc: str\n",
    "      params: Any\n",
    "      param_specs: List[ParamSpec]\n",
    "      required_names: List[str]\n",
    "      all_names: List[str]\n",
    "      desc_path: Sequence[str]\n",
    "    \"\"\"\n",
    "    if \"function\" in tool_obj and isinstance(tool_obj[\"function\"], dict):\n",
    "        fn = tool_obj[\"function\"]\n",
    "        tool_name = str(fn.get(\"name\") or \"unnamed_tool\")\n",
    "        orig_desc = str(fn.get(\"description\") or \"\")\n",
    "        params = fn.get(\"parameters\")\n",
    "        desc_path: Sequence[str] = (\"function\", \"description\")\n",
    "    else:\n",
    "        tool_name = str(tool_obj.get(\"name\") or \"unnamed_tool\")\n",
    "        orig_desc = str(tool_obj.get(\"description\") or \"\")\n",
    "        params = tool_obj.get(\"parameters\")\n",
    "        desc_path = (\"description\",)\n",
    "\n",
    "    param_specs = flatten_json_schema_parameters(params if isinstance(params, dict) else {})\n",
    "\n",
    "    all_names = extract_top_level_param_names(params)\n",
    "    required_names: List[str] = []\n",
    "    if isinstance(params, dict):\n",
    "        req = params.get(\"required\")\n",
    "        if isinstance(req, list):\n",
    "            required_names = [r for r in req if isinstance(r, str)]\n",
    "\n",
    "    return tool_name, orig_desc, params, param_specs, required_names, all_names, desc_path\n",
    "\n",
    "\n",
    "def _char_similarity(a: str, b: str) -> float:\n",
    "    return float(difflib.SequenceMatcher(None, a or \"\", b or \"\").ratio())\n",
    "\n",
    "def _token_jaccard_similarity(a: str, b: str) -> float:\n",
    "    wa = {w.lower() for w in _WORD_RE.findall(a or \"\")}\n",
    "    wb = {w.lower() for w in _WORD_RE.findall(b or \"\")}\n",
    "    if not wa and not wb:\n",
    "        return 1.0\n",
    "    inter = len(wa & wb)\n",
    "    uni = len(wa | wb)\n",
    "    return float(inter / uni) if uni else 0.0\n",
    "\n",
    "\n",
    "def strip_for_similarity_by_mode(mode: str, text: str) -> str:\n",
    "    \"\"\"\n",
    "    Per i mode con esempi/normative, la similarità va valutata sulla parte 'base'\n",
    "    (prima del primo 'For example,') per non penalizzare l'append di esempi.\n",
    "    \"\"\"\n",
    "    t = normalize_single_line(text or \"\")\n",
    "    if mode in {\"add_examples\", \"normative_injection\"}:\n",
    "        m = _REQUIRED_EXAMPLE_RE.search(t)\n",
    "        if m:\n",
    "            t = t[: m.start()].rstrip()\n",
    "    return t\n",
    "\n",
    "\n",
    "def split_base_and_suffix_by_mode(mode: str, text: str) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    For modes that require examples/normative, treat everything from the first\n",
    "    required 'For example,' onward as suffix (mode-allowed append).\n",
    "    Returns (base, suffix) both normalized single-line.\n",
    "    \"\"\"\n",
    "    t = normalize_single_line(text or \"\")\n",
    "    if mode in {\"add_examples\", \"normative_injection\"}:\n",
    "        m = _REQUIRED_EXAMPLE_RE.search(t)\n",
    "        if m:\n",
    "            base = t[: m.start()].rstrip()\n",
    "            suffix = t[m.start():].lstrip()\n",
    "            return normalize_single_line(base), normalize_single_line(suffix)\n",
    "    return t, \"\"\n",
    "\n",
    "\n",
    "def semantic_base_text(mode: str, text: str) -> str:\n",
    "    \"\"\"\n",
    "    Base text used for semantic equivalence comparisons in modes where examples/normative\n",
    "    are mode-allowed and should not be treated as semantic drift.\n",
    "    \"\"\"\n",
    "    base, _ = split_base_and_suffix_by_mode(mode, text)\n",
    "    return normalize_single_line(base)\n",
    "\n",
    "\n",
    "def compute_similarity_metrics(mode: str, original_desc: str, candidate_desc: str) -> Dict[str, float]:\n",
    "    o = strip_for_similarity_by_mode(mode, normalize_single_line(original_desc or \"\"))\n",
    "    c = strip_for_similarity_by_mode(mode, normalize_single_line(candidate_desc or \"\"))\n",
    "\n",
    "    char_sim = _char_similarity(o, c)\n",
    "    tok_sim = _token_jaccard_similarity(o, c)\n",
    "\n",
    "    # REVISED: make it less \"near-copy biased\" (still favors minimal edit)\n",
    "    comp = 0.55 * char_sim + 0.45 * tok_sim\n",
    "    return {\"char\": char_sim, \"token\": tok_sim, \"composite\": comp}\n",
    "\n",
    "\n",
    "\n",
    "def similarity_gate_pass(mode: str, original_desc: str, candidate_desc: str) -> Tuple[bool, Dict[str, float], str]:\n",
    "    if not ENABLE_SIMILARITY_GATE:\n",
    "        return True, {\"char\": 1.0, \"token\": 1.0, \"composite\": 1.0}, \"disabled\"\n",
    "\n",
    "    if mode == \"empty_desc\":\n",
    "        return True, {\"char\": 1.0, \"token\": 1.0, \"composite\": 1.0}, \"not_applicable\"\n",
    "\n",
    "    o_norm = normalize_single_line(original_desc or \"\")\n",
    "    c_norm = normalize_single_line(candidate_desc or \"\")\n",
    "\n",
    "    # Robustness modes: do NOT apply similarity upper bound.\n",
    "    local_enable_upper = bool(ENABLE_SIMILARITY_UPPER_BOUND) and (mode not in ROBUSTNESS_MODES)\n",
    "\n",
    "    # Always enforce not-identical (anti-copy).\n",
    "    if c_norm == o_norm:\n",
    "        m = compute_similarity_metrics(mode, o_norm, c_norm)\n",
    "        return False, m, \"fail:identical\"\n",
    "\n",
    "    # For short originals: keep only tau_min + not-identical.\n",
    "    if _orig_desc_is_short(o_norm):\n",
    "        band = SIMILARITY_BAND_BY_MODE.get(mode, (0.75, 0.999))\n",
    "        tau_min = float(band[0])\n",
    "        m = compute_similarity_metrics(mode, o_norm, c_norm)\n",
    "        comp = float(m[\"composite\"])\n",
    "        if comp < tau_min:\n",
    "            return False, m, f\"fail:too_different:min={tau_min}\"\n",
    "        return True, m, f\"pass:short_original_not_identical:min={tau_min}\"\n",
    "\n",
    "    band = SIMILARITY_BAND_BY_MODE.get(mode, (0.75, 0.999))\n",
    "    tau_min = float(band[0])\n",
    "    tau_max = float(band[1])\n",
    "\n",
    "    m = compute_similarity_metrics(mode, o_norm, c_norm)\n",
    "    comp = float(m[\"composite\"])\n",
    "\n",
    "    if comp < tau_min:\n",
    "        return False, m, f\"fail:too_different:min={tau_min}\"\n",
    "\n",
    "    if local_enable_upper and comp > tau_max:\n",
    "        return False, m, f\"fail:too_similar:max={tau_max}\"\n",
    "\n",
    "    return True, m, f\"pass:min={tau_min}\" + (f\",max={tau_max}\" if local_enable_upper else \",max=disabled_in_mode\")\n",
    "\n",
    "\n",
    "\n",
    "def deterministic_micro_edit_on_candidate(\n",
    "    *,\n",
    "    mode: str,\n",
    "    original_description: str,\n",
    "    candidate_description: str,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Deterministic minimal edit to ensure NOT identical and break near-copy.\n",
    "    Guarantees at least TWO surface edits when possible:\n",
    "      1) one safe synonym swap (if any match)\n",
    "      2) one punctuation/connector tweak\n",
    "    Does NOT add new semantic content.\n",
    "    \"\"\"\n",
    "    o = normalize_single_line(original_description or \"\")\n",
    "    c = normalize_single_line(candidate_description or \"\")\n",
    "    if not c:\n",
    "        return c\n",
    "    if not o:\n",
    "        return c\n",
    "\n",
    "    budget = compute_length_budget(mode=mode, original_description=o)\n",
    "\n",
    "    def _truncate_to_budget(t: str) -> str:\n",
    "        t = normalize_single_line(t)\n",
    "        if len(t) > budget.max_chars:\n",
    "            t = t[: budget.max_chars].rstrip()\n",
    "        while _count_words(t) > budget.max_words and len(t) > 10:\n",
    "            t = re.sub(r\"\\s+\\S+\\s*$\", \"\", t).strip()\n",
    "        if t and t[-1] not in \".!?\":\n",
    "            t += \".\"\n",
    "        return normalize_single_line(t)\n",
    "\n",
    "    edited = c\n",
    "\n",
    "    # Edit 1: synonym swap (at most one)\n",
    "    edited1 = _apply_one_safe_synonym_swap(edited)\n",
    "    if edited1 != edited:\n",
    "        edited = edited1\n",
    "    else:\n",
    "        # If no synonym swap possible, do a tiny reorder-free article tweak (very conservative):\n",
    "        # Replace first occurrence of \" the \" <-> \" a \" if present (English-only surface).\n",
    "        if re.search(r\"\\bthe\\b\", edited, flags=re.IGNORECASE):\n",
    "            edited = re.sub(r\"\\bthe\\b\", \"a\", edited, count=1, flags=re.IGNORECASE)\n",
    "        elif re.search(r\"\\ba\\b\", edited, flags=re.IGNORECASE):\n",
    "            edited = re.sub(r\"\\ba\\b\", \"the\", edited, count=1, flags=re.IGNORECASE)\n",
    "\n",
    "    # Edit 2: punctuation/connector tweak\n",
    "    # Prefer changing one comma into a period, else add/remove a comma before \"and\".\n",
    "    if \", \" in edited:\n",
    "        edited = edited.replace(\", \", \". \", 1)\n",
    "    else:\n",
    "        # add a comma before first \"and\" if present and not already punctuated\n",
    "        edited = re.sub(r\"\\s+and\\s+\", \", and \", edited, count=1, flags=re.IGNORECASE)\n",
    "\n",
    "    edited = _truncate_to_budget(edited)\n",
    "\n",
    "    # Ensure anti-copy: if still identical, force a final punctuation flip (period <-> no period)\n",
    "    if normalize_single_line(edited) == normalize_single_line(o):\n",
    "        if edited.endswith(\".\"):\n",
    "            edited = edited[:-1].rstrip()\n",
    "        else:\n",
    "            edited = edited + \".\"\n",
    "        edited = _truncate_to_budget(edited)\n",
    "\n",
    "    return normalize_single_line(edited)\n",
    "\n",
    "\n",
    "def build_similarity_pullback_prompt(\n",
    "    *,\n",
    "    mode: str,\n",
    "    tool_name: str,\n",
    "    original_description: str,\n",
    "    candidate_description: str,\n",
    "    params_context: str,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Targeted recovery when candidate is too different: pull back towards original\n",
    "    WITHOUT copying identically and with at least two micro-edits.\n",
    "    \"\"\"\n",
    "    o = normalize_single_line(original_description or \"\")\n",
    "    c = normalize_single_line(candidate_description or \"\")\n",
    "    budget = compute_length_budget(mode=mode, original_description=o)\n",
    "\n",
    "    target_sent = max(budget.min_sentences, min(budget.max_sentences, int(round((budget.min_sentences + budget.max_sentences) / 2))))\n",
    "    target_words = max(budget.min_words, min(budget.max_words, int(round((budget.min_words + budget.max_words) / 2))))\n",
    "\n",
    "    return (\n",
    "        \"TASK: Rewrite the description to be much closer to ORIGINAL_DESCRIPTION while preserving meaning.\\n\"\n",
    "        \"OUTPUT FORMAT: Output only the rewritten description text, single line.\\n\"\n",
    "        \"HARD RULES:\\n\"\n",
    "        \"1) Do NOT add any new concepts not present in ORIGINAL_DESCRIPTION.\\n\"\n",
    "        \"2) Do NOT add constraints/requirements/decision rules.\\n\"\n",
    "        \"3) Do NOT list parameters/fields/options/filters unless they already appear in ORIGINAL_DESCRIPTION.\\n\"\n",
    "        \"4) The output must NOT be identical to ORIGINAL_DESCRIPTION, and must include at least TWO minimal surface edits \"\n",
    "        \"(synonym/punctuation/word-order) without adding meaning.\\n\"\n",
    "        f\"5) LENGTH BUDGET: sentences {budget.min_sentences}-{budget.max_sentences}; words {budget.min_words}-{budget.max_words}; chars <= {budget.max_chars}. \"\n",
    "        f\"TARGET: about {target_words} words and {target_sent} sentence(s).\\n\"\n",
    "        f\"MODE: {mode}\\n\"\n",
    "        f\"TOOL_NAME (do not copy): {tool_name}\\n\"\n",
    "        f\"ORIGINAL_DESCRIPTION: {o if o else '[NONE]'}\\n\"\n",
    "        f\"CANDIDATE_DESCRIPTION (too different): {c if c else '[NONE]'}\\n\"\n",
    "        \"PARAMETERS CONTEXT (grounding only):\\n\"\n",
    "        f\"{params_context}\\n\"\n",
    "        \"INSTRUCTION: Produce a close, minimal-edit paraphrase of ORIGINAL_DESCRIPTION.\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _count_words(text: str) -> int:\n",
    "    return len([w for w in re.findall(r\"\\S+\", text or \"\") if w])\n",
    "\n",
    "\n",
    "def _count_sentences_rough(text: str) -> int:\n",
    "    t = (text or \"\").strip()\n",
    "    if not t:\n",
    "        return 0\n",
    "    return max(1, len(re.findall(r\"[.!?]+\", t)))\n",
    "\n",
    "def _split_one_sentence_minimally_deterministic(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Deterministic minimal split:\n",
    "    - If input is exactly 1 rough sentence, try to split into 2 sentences\n",
    "      by replacing a comma-separator or a connector (\"and\"/\"to\") near the middle.\n",
    "    - Does NOT add content; only changes punctuation/segmentation.\n",
    "    \"\"\"\n",
    "    t = normalize_single_line(text or \"\")\n",
    "    if not t:\n",
    "        return t\n",
    "    if _count_sentences_rough(t) != 1:\n",
    "        return t\n",
    "\n",
    "    # Prefer splitting at a comma near the midpoint.\n",
    "    comma_positions = [m.start() for m in re.finditer(r\",\\s+\", t)]\n",
    "    if comma_positions:\n",
    "        mid = len(t) // 2\n",
    "        candidates = [p for p in comma_positions if 40 <= p <= max(40, len(t) - 40)]\n",
    "        if not candidates:\n",
    "            candidates = comma_positions\n",
    "        split_pos = min(candidates, key=lambda p: abs(p - mid))\n",
    "        t2 = t[:split_pos] + \".\" + t[split_pos + 1 :]\n",
    "        return normalize_single_line(t2)\n",
    "\n",
    "    # Fallback: split on a connector near the midpoint.\n",
    "    mid = len(t) // 2\n",
    "    for pat in [r\"\\s+and\\s+\", r\"\\s+to\\s+\"]:\n",
    "        positions = [m.start() for m in re.finditer(pat, t)]\n",
    "        if positions:\n",
    "            split_pos = min(positions, key=lambda p: abs(p - mid))\n",
    "            t2 = t[:split_pos] + \". \" + t[split_pos + 1 :].lstrip()\n",
    "            return normalize_single_line(t2)\n",
    "\n",
    "    return t\n",
    "\n",
    "\n",
    "\n",
    "@dataclasses.dataclass(frozen=True)\n",
    "class LengthBudget:\n",
    "    min_sentences: int\n",
    "    max_sentences: int\n",
    "    min_words: int\n",
    "    max_words: int\n",
    "    max_chars: int\n",
    "\n",
    "_SAFE_SYNONYM_MAP = [\n",
    "    (r\"\\bpurchase\\b\", \"buy\"),\n",
    "    (r\"\\bbuy\\b\", \"purchase\"),\n",
    "    (r\"\\bsearch\\b\", \"find\"),\n",
    "    (r\"\\bfind\\b\", \"search\"),\n",
    "    (r\"\\bretrieve\\b\", \"get\"),\n",
    "    (r\"\\bget\\b\", \"retrieve\"),\n",
    "    (r\"\\bgenerate\\b\", \"create\"),\n",
    "    (r\"\\bcreate\\b\", \"generate\"),\n",
    "    (r\"\\breturn\\b\", \"provide\"),\n",
    "    (r\"\\bprovide\\b\", \"return\"),\n",
    "    (r\"\\blist\\b\", \"show\"),\n",
    "    (r\"\\bshow\\b\", \"list\"),\n",
    "    (r\"\\broute\\b\", \"itinerary\"),\n",
    "    (r\"\\bitinerary\\b\", \"route\"),\n",
    "    (r\"\\btickets\\b\", \"passes\"),\n",
    "    (r\"\\bpasses\\b\", \"tickets\"),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def _apply_one_safe_synonym_swap(text: str) -> str:\n",
    "    t = normalize_single_line(text or \"\")\n",
    "    if not t:\n",
    "        return t\n",
    "\n",
    "    # Applica al massimo UNA sostituzione (la prima che matcha, in ordine).\n",
    "    for pat, rep in _SAFE_SYNONYM_MAP:\n",
    "        if re.search(pat, t, flags=re.IGNORECASE):\n",
    "            t2 = re.sub(pat, rep, t, count=1, flags=re.IGNORECASE)\n",
    "            return normalize_single_line(t2)\n",
    "    return t\n",
    "\n",
    "\n",
    "def rule_based_paraphrase_operator(\n",
    "    *,\n",
    "    mode: str,\n",
    "    original_description: str,\n",
    "    top_level_param_names: Sequence[str],\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Baseline deterministica e auditabile:\n",
    "    - non inventa nulla, non enumera parametri, minimal-edit.\n",
    "    - soddisfa i requisiti per mode (esempi/normative) aggiungendo SOLO frasi ultra-neutre.\n",
    "    \"\"\"\n",
    "    o = normalize_single_line(original_description or \"\")\n",
    "    if not o:\n",
    "        return o if mode == \"empty_desc\" else \"\"\n",
    "\n",
    "    base = _apply_one_safe_synonym_swap(o)\n",
    "\n",
    "    if base and base[-1] not in \".!?\":\n",
    "        base += \".\"\n",
    "\n",
    "    budget = compute_length_budget(mode=mode, original_description=o)\n",
    "\n",
    "    def _force_single_sentence(t: str) -> str:\n",
    "        t = normalize_single_line(t)\n",
    "        t = re.sub(r\"[.!?]+\\s+\", \", \", t).strip()\n",
    "        if t and t[-1] not in \".!?\":\n",
    "            t += \".\"\n",
    "        return normalize_single_line(t)\n",
    "\n",
    "    def _ensure_sentence_count_for_verbose(t: str) -> str:\n",
    "        t = normalize_single_line(t)\n",
    "        if _count_sentences_rough(t) >= budget.min_sentences:\n",
    "            return t\n",
    "        # Deterministic split only (no content added)\n",
    "        return _split_one_sentence_minimally_deterministic(t)\n",
    "\n",
    "    def _truncate_to_budget(t: str) -> str:\n",
    "        t = normalize_single_line(t)\n",
    "        if len(t) > budget.max_chars:\n",
    "            t = t[: budget.max_chars].rstrip()\n",
    "        while _count_words(t) > budget.max_words and len(t) > 10:\n",
    "            t = re.sub(r\"\\s+\\S+\\s*$\", \"\", t).strip()\n",
    "        if t and t[-1] not in \".!?\":\n",
    "            t += \".\"\n",
    "        return normalize_single_line(t)\n",
    "\n",
    "    if mode == \"style_concise\":\n",
    "        t = _force_single_sentence(base)\n",
    "        t = _truncate_to_budget(t)\n",
    "        return t\n",
    "\n",
    "    if mode == \"style_verbose\":\n",
    "        t = _ensure_sentence_count_for_verbose(base)\n",
    "        t = _truncate_to_budget(t)\n",
    "        return t\n",
    "\n",
    "    if mode == \"add_examples\":\n",
    "        t = (\n",
    "            f\"{normalize_single_line(base)} \"\n",
    "            \"For example, use it in a case that matches the description above. \"\n",
    "            \"For example, apply it when you need the same operation described there.\"\n",
    "        )\n",
    "        t = _truncate_to_budget(t)\n",
    "        return t\n",
    "\n",
    "    if mode == \"normative_injection\":\n",
    "        t = (\n",
    "            f\"{normalize_single_line(base)} \"\n",
    "            \"For example, use it in a case that matches the description above. \"\n",
    "            \"You should use it in the intended context described there.\"\n",
    "        )\n",
    "        t = _truncate_to_budget(t)\n",
    "        return t\n",
    "\n",
    "    return _truncate_to_budget(base)\n",
    "\n",
    "\n",
    "\n",
    "def compute_length_budget(\n",
    "    *,\n",
    "    mode: str,\n",
    "    original_description: str,\n",
    ") -> LengthBudget:\n",
    "    o = normalize_single_line(original_description or \"\")\n",
    "    ow = _count_words(o)\n",
    "    osent = _count_sentences_rough(o)\n",
    "    och = len(o)\n",
    "\n",
    "    # POLICY: empty ORIGINAL_DESCRIPTION -> deterministic, avoid filler budgets.\n",
    "    if not o:\n",
    "        if mode == \"empty_desc\":\n",
    "            return LengthBudget(0, 0, 0, 0, 0)\n",
    "\n",
    "        if mode in {\"style_concise\", \"style_verbose\"}:\n",
    "            # Allow very short deterministic placeholder outputs\n",
    "            return LengthBudget(1, 2, 2, 20, min(240, DESCRIPTION_MAX_CHARS))\n",
    "\n",
    "        if mode == \"add_examples\":\n",
    "            # Must include 'For example,'\n",
    "            return LengthBudget(2, 5, 6, 60, min(420, DESCRIPTION_MAX_CHARS))\n",
    "\n",
    "        if mode == \"normative_injection\":\n",
    "            # Must include 'For example,' and should/must\n",
    "            return LengthBudget(2, 5, 8, 70, min(440, DESCRIPTION_MAX_CHARS))\n",
    "\n",
    "        return LengthBudget(1, 3, 2, 30, min(240, DESCRIPTION_MAX_CHARS))\n",
    "\n",
    "    short_orig = _orig_desc_is_short(o)\n",
    "\n",
    "    mode_hard_caps = {\n",
    "        \"style_concise\": 240,\n",
    "        \"style_verbose\": 560,\n",
    "        \"add_examples\": 780,\n",
    "        \"normative_injection\": 820,\n",
    "    }\n",
    "    hard_cap_chars = min(mode_hard_caps.get(mode, 560), DESCRIPTION_MAX_CHARS)\n",
    "\n",
    "    # Helper: relax min_words for very short originals (ow <= 6)\n",
    "    def _min_words_relaxed(default_min: int) -> int:\n",
    "        if ow <= 6:\n",
    "            # User-requested: min_words = ow (or max(ow,3)).\n",
    "            return max(ow, 3)\n",
    "        return default_min\n",
    "\n",
    "    if mode == \"style_concise\":\n",
    "        min_w = _min_words_relaxed(max(6, int(round(ow * 0.55))))\n",
    "        max_w = min(32, max(min_w + 6, int(round(ow * 0.95)) + 6))\n",
    "        max_c = min(hard_cap_chars, max(140, int(round(och * 0.95)) + 30))\n",
    "        return LengthBudget(1, 1, min_w, max_w, max_c)\n",
    "\n",
    "    if mode == \"style_verbose\":\n",
    "        if short_orig:\n",
    "            min_s, max_s = 1, 2\n",
    "            min_w = _min_words_relaxed(max(8, int(round(ow * 0.85))))\n",
    "            max_w = min(70, max(min_w + 10, int(round(ow * 2.1)) + 6))\n",
    "            max_c = min(hard_cap_chars, max(220, int(round(och * 2.1)) + 60))\n",
    "            return LengthBudget(min_s, max_s, min_w, max_w, max_c)\n",
    "\n",
    "        if osent == 1:\n",
    "            min_s, max_s = 1, 2\n",
    "            min_w = _min_words_relaxed(max(10, int(round(ow * 0.85))))\n",
    "            max_w = min(150, max(min_w + 14, int(round(ow * 1.75)) + 10))\n",
    "            max_c = min(hard_cap_chars, max(320, int(round(och * 1.75)) + 80))\n",
    "            return LengthBudget(min_s, max_s, min_w, max_w, max_c)\n",
    "\n",
    "        min_s = max(2, osent)\n",
    "        max_s = min(5, max(min_s, osent + 1))\n",
    "        min_w = _min_words_relaxed(max(10, int(round(ow * 0.85))))\n",
    "        max_w = min(150, max(min_w + 14, int(round(ow * 1.75)) + 10))\n",
    "        max_c = min(hard_cap_chars, max(320, int(round(och * 1.75)) + 80))\n",
    "        return LengthBudget(min_s, max_s, min_w, max_w, max_c)\n",
    "\n",
    "    if mode == \"add_examples\":\n",
    "        min_s, max_s = 3, 5\n",
    "        min_w = max(16, int(round(ow * 0.85)))\n",
    "        if ow <= 6:\n",
    "            min_w = max(min_w, 10)  # keep room for required 'For example,' without filler spam\n",
    "        max_w = min(200, max(min_w + 20, int(round(ow * 2.1)) + 18))\n",
    "        max_c = min(hard_cap_chars, max(420, int(round(och * 2.1)) + 120))\n",
    "        return LengthBudget(min_s, max_s, min_w, max_w, max_c)\n",
    "\n",
    "    if mode == \"normative_injection\":\n",
    "        min_s, max_s = 3, 5\n",
    "        min_w = max(16, int(round(ow * 0.85)))\n",
    "        if ow <= 6:\n",
    "            min_w = max(min_w, 12)  # room for 'For example,' + 'should/must'\n",
    "        max_w = min(220, max(min_w + 22, int(round(ow * 2.2)) + 24))\n",
    "        max_c = min(hard_cap_chars, max(440, int(round(och * 2.2)) + 140))\n",
    "        return LengthBudget(min_s, max_s, min_w, max_w, max_c)\n",
    "\n",
    "    return LengthBudget(\n",
    "        1,\n",
    "        4,\n",
    "        _min_words_relaxed(max(8, int(round(ow * 0.85)))),\n",
    "        min(150, max(_min_words_relaxed(int(round(ow * 0.85))) + 14, int(round(ow * 1.75)) + 10)),\n",
    "        hard_cap_chars,\n",
    "    )\n",
    "\n",
    "\n",
    "def _flag_contains_normative(text: str) -> bool:\n",
    "    return _contains_any_case_insensitive(text, NORMATIVE_KEYWORDS)\n",
    "\n",
    "\n",
    "def _flag_contains_example(text: str) -> bool:\n",
    "    return _contains_any_case_insensitive(text, EXAMPLE_MARKERS)\n",
    "\n",
    "\n",
    "def _flag_contains_leakage(text: str) -> bool:\n",
    "    return _contains_any_case_insensitive(text, LEAKAGE_PHRASES)\n",
    "\n",
    "def _build_manip_row(\n",
    "    *,\n",
    "    mode: str,\n",
    "    tool_name: str,\n",
    "    orig_desc: str,\n",
    "    new_desc: str,\n",
    "    status: str,\n",
    "    validation_errors: List[str],\n",
    "    top_level_param_names: Sequence[str],\n",
    ") -> Dict[str, Any]:\n",
    "    o = normalize_single_line(orig_desc)\n",
    "    n = normalize_single_line(new_desc)\n",
    "\n",
    "    ok_final, errs_final = validate_description(\n",
    "        mode,\n",
    "        n,\n",
    "        raw_desc=new_desc,\n",
    "        top_level_param_names=top_level_param_names,\n",
    "        original_description=orig_desc,  # <-- NEW\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"ts\": now_unix(),\n",
    "        \"mode\": mode,\n",
    "        \"tool_name\": tool_name,\n",
    "        \"status\": status,\n",
    "        \"status_is_repaired\": (status == \"repaired\"),\n",
    "        \"status_is_judged\": (status == \"judged\"),\n",
    "        \"status_is_rejected\": (\"fallback_original\" in status or status == \"rejected\"),\n",
    "        \"orig_chars\": len(o),\n",
    "        \"new_chars\": len(n),\n",
    "        \"delta_chars\": len(n) - len(o),\n",
    "        \"orig_words\": _count_words(o),\n",
    "        \"new_words\": _count_words(n),\n",
    "        \"delta_words\": _count_words(n) - _count_words(o),\n",
    "        \"orig_sentences_rough\": _count_sentences_rough(o),\n",
    "        \"new_sentences_rough\": _count_sentences_rough(n),\n",
    "        \"char_similarity\": _char_similarity(o, n),\n",
    "        \"contains_example\": _flag_contains_example(n),\n",
    "        \"contains_normative\": _flag_contains_normative(n),\n",
    "        \"contains_leakage\": _flag_contains_leakage(n),\n",
    "        \"mentions_param_token\": _contains_any_token_case_insensitive(n, top_level_param_names),\n",
    "        \"is_unchanged\": (o == n),\n",
    "        \"final_failed_validation\": (not ok_final),\n",
    "        \"final_validation_errors\": errs_final,\n",
    "        \"generation_validation_errors\": list(validation_errors),\n",
    "    }\n",
    "\n",
    "\n",
    "# ==================  JSON NODE MATERIALIZATION (object-tools fix) ==================\n",
    "\n",
    "\n",
    "def node_to_python(node: \"JsonNode\") -> Any:\n",
    "    \"\"\"\n",
    "    Convert a JsonNode tree into a plain Python object (dict/list/str/int/float/bool/None).\n",
    "\n",
    "    This is required because JsonSpanParser stores object/array children in `obj`/`arr`,\n",
    "    and does not necessarily populate `value` for composite nodes.\n",
    "    \"\"\"\n",
    "    if node.kind == \"object\":\n",
    "        if not node.obj:\n",
    "            return {}\n",
    "        return {str(k): node_to_python(v) for k, v in node.obj.items()}\n",
    "    if node.kind == \"array\":\n",
    "        if not node.arr:\n",
    "            return []\n",
    "        return [node_to_python(v) for v in node.arr]\n",
    "    if node.kind == \"string\":\n",
    "        return \"\" if node.value is None else str(node.value)\n",
    "    if node.kind == \"number\":\n",
    "        return node.value\n",
    "    if node.kind == \"true\":\n",
    "        return True\n",
    "    if node.kind == \"false\":\n",
    "        return False\n",
    "    if node.kind == \"null\":\n",
    "        return None\n",
    "    return node.value\n",
    "\n",
    "\n",
    "def build_semantic_judge_prompt(\n",
    "    *,\n",
    "    tool_name: str,\n",
    "    original_description: str,\n",
    "    candidate_description: str,\n",
    "    params_context: str,\n",
    "    mode: str = \"unknown\",\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Mode-aware semantic judge prompt.\n",
    "\n",
    "    Key rule:\n",
    "    - For add_examples / normative_injection: semantic equivalence is evaluated on BASE text only\n",
    "      (everything before the first required 'For example,').\n",
    "    - The suffix (examples/normative guidance) is mode-allowed and must NOT be treated as drift\n",
    "      unless it introduces new capabilities, constraints, refusal policies, or decision rules.\n",
    "    \"\"\"\n",
    "    odesc = normalize_single_line(original_description or \"\")\n",
    "    cdesc = normalize_single_line(candidate_description or \"\")\n",
    "\n",
    "    o_base = semantic_base_text(mode, odesc)\n",
    "    c_base = semantic_base_text(mode, cdesc)\n",
    "\n",
    "    short_orig = _orig_desc_is_short(odesc)\n",
    "\n",
    "    short_block = \"\"\n",
    "    if short_orig:\n",
    "        short_block = (\n",
    "            \"SHORT-ORIGINAL STRICTNESS:\\n\"\n",
    "            \"- Treat any newly introduced generic concept as a semantic change.\\n\"\n",
    "            \"- Disallowed new concepts unless present in original BASE: criteria, options, filters, pagination, parameters,\\n\"\n",
    "            \"  purpose/benefit framing (overview/insight/comprehensive/relevant), or implying extra inputs.\\n\"\n",
    "        )\n",
    "\n",
    "    mode_block = \"\"\n",
    "    if mode in {\"add_examples\", \"normative_injection\"}:\n",
    "        mode_block = (\n",
    "            \"MODE-AWARE RULE:\\n\"\n",
    "            \"- Evaluate semantic equivalence using BASE ONLY (text before the first 'For example,').\\n\"\n",
    "            \"- The suffix containing examples and/or normative guidance is allowed by mode.\\n\"\n",
    "            \"- Do NOT fail solely because the suffix exists or is tautological.\\n\"\n",
    "            \"- FAIL if the suffix introduces new capabilities, constraints, refusal policies, decision rules, or extra requirements.\\n\"\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        \"ROLE: You are a strict semantic consistency judge for tool description strings.\\n\"\n",
    "        \"TASK: Decide whether CANDIDATE_DESCRIPTION preserves the intent and scope of ORIGINAL_DESCRIPTION\\n\"\n",
    "        \"and does NOT introduce new requirements, constraints, refusal policies, decision rules, or new concepts.\\n\"\n",
    "        \"Focus on meaning, not style.\\n\"\n",
    "        \"OUTPUT FORMAT:\\n\"\n",
    "        \"- Output exactly one line.\\n\"\n",
    "        \"- If acceptable: output 'PASS'.\\n\"\n",
    "        \"- If not acceptable: output 'FAIL: <brief reason>'.\\n\"\n",
    "        \"DECISION CRITERIA:\\n\"\n",
    "        \"- FAIL if candidate invents capabilities.\\n\"\n",
    "        \"- FAIL if candidate adds restrictions/requirements (must/should/requires/only) unless required by the mode suffix.\\n\"\n",
    "        \"- FAIL if candidate adds new purpose/benefit framing not present in the original BASE.\\n\"\n",
    "        \"- FAIL if candidate drops essential specifics from original BASE.\\n\"\n",
    "        + mode_block\n",
    "        + short_block +\n",
    "        f\"TOOL_NAME (context only): {tool_name}\\n\"\n",
    "        f\"MODE: {mode}\\n\"\n",
    "        f\"ORIGINAL_DESCRIPTION: {odesc if odesc else '[NONE]'}\\n\"\n",
    "        f\"CANDIDATE_DESCRIPTION: {cdesc if cdesc else '[NONE]'}\\n\"\n",
    "        f\"ORIGINAL_BASE (use for equivalence): {o_base if o_base else '[NONE]'}\\n\"\n",
    "        f\"CANDIDATE_BASE (use for equivalence): {c_base if c_base else '[NONE]'}\\n\"\n",
    "        \"PARAMETERS CONTEXT (grounding only; do not treat as extra requirements):\\n\"\n",
    "        f\"{params_context}\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def make_validator_safe_fallback(\n",
    "    *,\n",
    "    mode: str,\n",
    "    original_description: str,\n",
    "    top_level_param_names: Sequence[str],\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Budget-aware fallback:\n",
    "    Goal order:\n",
    "      1) Pass validate_description(mode, ...) under dynamic budget\n",
    "      2) Stay as close as possible to ORIGINAL_DESCRIPTION (minimal edit, no enrichment)\n",
    "    \"\"\"\n",
    "    o = normalize_single_line(original_description or \"\")\n",
    "    if not o:\n",
    "        return o\n",
    "\n",
    "    ok, _ = validate_description(\n",
    "        mode,\n",
    "        o,\n",
    "        top_level_param_names=top_level_param_names,\n",
    "        original_description=o,\n",
    "    )\n",
    "    if ok:\n",
    "        return o\n",
    "\n",
    "    budget = compute_length_budget(mode=mode, original_description=o)\n",
    "\n",
    "    def _truncate_to_budget(t: str) -> str:\n",
    "        t = normalize_single_line(t)\n",
    "        if len(t) > budget.max_chars:\n",
    "            t = t[: budget.max_chars].rstrip()\n",
    "        while _count_words(t) > budget.max_words and len(t) > 10:\n",
    "            t = re.sub(r\"\\s+\\S+\\s*$\", \"\", t).strip()\n",
    "        if t and t[-1] not in \".!?\":\n",
    "            t += \".\"\n",
    "        return normalize_single_line(t)\n",
    "\n",
    "    if mode == \"style_concise\":\n",
    "        t = re.sub(r\"[.!?]+\\s+\", \", \", o).strip()\n",
    "        if t and t[-1] not in \".!?\":\n",
    "            t += \".\"\n",
    "        return _truncate_to_budget(t)\n",
    "\n",
    "    if mode == \"style_verbose\":\n",
    "        t = o\n",
    "        if _count_sentences_rough(t) < budget.min_sentences:\n",
    "            # Deterministic split only (no content added)\n",
    "            t = _split_one_sentence_minimally_deterministic(t)\n",
    "        return _truncate_to_budget(t)\n",
    "\n",
    "    if mode == \"add_examples\":\n",
    "        base = o\n",
    "        if base and base[-1] not in \".!?\":\n",
    "            base += \".\"\n",
    "        t = (\n",
    "            f\"{normalize_single_line(base)} \"\n",
    "            \"For example, use it in a case that matches the description above. \"\n",
    "            \"This is the same operation described in the original description.\"\n",
    "        )\n",
    "        return _truncate_to_budget(t)\n",
    "\n",
    "    if mode == \"normative_injection\":\n",
    "        base = o\n",
    "        if base and base[-1] not in \".!?\":\n",
    "            base += \".\"\n",
    "        t = (\n",
    "            f\"{normalize_single_line(base)} \"\n",
    "            \"For example, use it in a case that matches the description above. \"\n",
    "            \"You should use it in the intended context described there.\"\n",
    "        )\n",
    "        return _truncate_to_budget(t)\n",
    "\n",
    "    return _truncate_to_budget(o)\n",
    "\n",
    "def deterministic_description_for_empty_original(mode: str) -> str:\n",
    "    \"\"\"\n",
    "    Deterministic policy when ORIGINAL_DESCRIPTION is empty/missing.\n",
    "    Avoid calling LLM without anchoring (robustness).\n",
    "    \"\"\"\n",
    "    if mode == \"empty_desc\":\n",
    "        return \"\"\n",
    "\n",
    "    if mode == \"style_concise\":\n",
    "        return \"Description unavailable.\"\n",
    "\n",
    "    if mode == \"style_verbose\":\n",
    "        return \"Description unavailable.\"\n",
    "\n",
    "    if mode == \"add_examples\":\n",
    "        return \"Description unavailable. For example, use it only in a context consistent with the tool definition.\"\n",
    "\n",
    "    if mode == \"normative_injection\":\n",
    "        return \"Description unavailable. For example, use it only in a context consistent with the tool definition. You should consult the tool definition.\"\n",
    "\n",
    "    return \"Description unavailable.\"\n",
    "\n",
    "\n",
    "def generate_description_for_tool(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    generation_model: str,\n",
    "    judge_model: str,\n",
    "    enable_judge: bool,\n",
    "    mode: str,\n",
    "    tool_json_obj: Dict[str, Any],\n",
    "    cache: DescCache,\n",
    "    audit: AuditLogger,\n",
    "    temperature: float,\n",
    "    max_tokens: int,\n",
    "    rate_limit_sleep_sec: float,\n",
    "    max_retries: int,\n",
    "    repair_max_rounds: int,\n",
    "    judge_max_rounds: int,\n",
    ") -> Tuple[str, str, List[str], str]:\n",
    "    if mode not in MODES:\n",
    "        raise ValueError(f\"Unknown mode: {mode}\")\n",
    "\n",
    "    tool_name, orig_desc, _, param_specs, _, all_names, _ = extract_tool_core(tool_json_obj)\n",
    "    top_level_param_names = all_names\n",
    "    param_context = build_param_context_for_prompt(param_specs)\n",
    "\n",
    "    # Mode: empty_desc stays literal.\n",
    "    if mode == \"empty_desc\":\n",
    "        return \"\", \"ok\", [], stable_sha256(\"empty_desc\")\n",
    "\n",
    "    # POLICY: empty original in robustness -> deterministic output (no LLM without anchoring).\n",
    "    if not normalize_single_line(orig_desc) and mode in ROBUSTNESS_MODES:\n",
    "        out = deterministic_description_for_empty_original(mode)\n",
    "        ok, errs = validate_description(\n",
    "            mode,\n",
    "            normalize_single_line(out),\n",
    "            raw_desc=out,\n",
    "            top_level_param_names=top_level_param_names,\n",
    "            original_description=orig_desc,\n",
    "        )\n",
    "        status = \"deterministic_empty_original\" if ok else \"deterministic_empty_original_invalid\"\n",
    "        return normalize_single_line(out), status, errs, stable_sha256(f\"deterministic::{mode}::empty_original\")\n",
    "\n",
    "    prompt = build_generation_prompt(\n",
    "        mode=mode,\n",
    "        tool_name=tool_name,\n",
    "        original_description=orig_desc,\n",
    "        param_context=param_context,\n",
    "        top_level_param_names=top_level_param_names,\n",
    "    )\n",
    "    prompt_hash = stable_sha256(prompt)\n",
    "\n",
    "    tool_sig = tool_signature_for_cache(tool_json_obj)\n",
    "\n",
    "    cache_key = stable_sha256(\n",
    "        \"||\".join(\n",
    "            [\n",
    "                PIPELINE_VERSION,\n",
    "                generation_model,\n",
    "                judge_model,\n",
    "                str(bool(enable_judge)),\n",
    "                \"semantic_gate_v3_minimal_edit_strict\",\n",
    "                mode,\n",
    "                tool_sig,\n",
    "                prompt_hash,\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    cached = cache.get(cache_key)\n",
    "    if cached is not None:\n",
    "        audit.inc(\"llm_cache_hits\", 1)\n",
    "        return cached[\"final_output\"], \"cached\", cached[\"validation_errors\"], prompt_hash\n",
    "\n",
    "    system_text = \"System role: Generate single-line tool documentation strings for function-calling APIs.\"\n",
    "\n",
    "    _BULLET_RE = re.compile(r\"(^|\\n|\\r)\\s*(?:[-*•]|\\d+\\.)\\s+\")\n",
    "\n",
    "    def _validate_raw_then_normalized(raw_text: str) -> Tuple[bool, str, List[str]]:\n",
    "        raw_text = raw_text if isinstance(raw_text, str) else str(raw_text or \"\")\n",
    "        errors: List[str] = []\n",
    "\n",
    "        if \"\\n\" in raw_text or \"\\r\" in raw_text:\n",
    "            errors.append(\"contains_newline_raw\")\n",
    "        if \"`\" in raw_text:\n",
    "            errors.append(\"contains_backtick_raw\")\n",
    "        if _BULLET_RE.search(raw_text):\n",
    "            errors.append(\"contains_bullet_raw\")\n",
    "\n",
    "        normalized = normalize_single_line(raw_text)\n",
    "\n",
    "        ok_norm, norm_errs = validate_description(\n",
    "            mode,\n",
    "            normalized,\n",
    "            raw_desc=raw_text,\n",
    "            top_level_param_names=top_level_param_names,\n",
    "            original_description=orig_desc,\n",
    "        )\n",
    "        errors.extend(norm_errs)\n",
    "        ok = (len(errors) == 0) and ok_norm\n",
    "        return ok, normalized, errors\n",
    "\n",
    "    def _sentence_fixup_if_needed(text: str) -> str:\n",
    "        t = normalize_single_line(text or \"\")\n",
    "        if not t:\n",
    "            return t\n",
    "        if mode != \"style_verbose\":\n",
    "            return t\n",
    "\n",
    "        odesc = normalize_single_line(orig_desc or \"\")\n",
    "        budget = compute_length_budget(mode=mode, original_description=odesc)\n",
    "        if budget.min_sentences >= 2 and _count_sentences_rough(t) == 1:\n",
    "            return _split_one_sentence_minimally_deterministic(t)\n",
    "        return t\n",
    "\n",
    "    # Phase 0: initial generation\n",
    "    raw_initial = llm_call_chat_completions(\n",
    "        client=client,\n",
    "        model=generation_model,\n",
    "        system_text=system_text,\n",
    "        user_text=prompt,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        rate_limit_sleep_sec=rate_limit_sleep_sec,\n",
    "        max_retries=max_retries,\n",
    "        audit=audit,\n",
    "        call_tag=f\"generate::{mode}::{tool_name}\",\n",
    "    )\n",
    "\n",
    "    ok, final, all_errs = _validate_raw_then_normalized(raw_initial)\n",
    "    status = \"ok\"\n",
    "\n",
    "    repaired_rounds = 0\n",
    "    repair_tokens = min(512, max_tokens * 2)\n",
    "\n",
    "    # Phase 1: hard validation repair loop\n",
    "    while not ok and repaired_rounds < repair_max_rounds:\n",
    "        repaired_rounds += 1\n",
    "\n",
    "        repair_prompt = build_repair_prompt(\n",
    "            mode=mode,\n",
    "            tool_name=tool_name,\n",
    "            params_context=param_context,\n",
    "            candidate_output=final,\n",
    "            validation_errors=all_errs,\n",
    "            top_level_param_names=top_level_param_names,\n",
    "            original_description=orig_desc,\n",
    "        )\n",
    "\n",
    "        repair_raw = llm_call_chat_completions(\n",
    "            client=client,\n",
    "            model=generation_model,\n",
    "            system_text=system_text,\n",
    "            user_text=repair_prompt,\n",
    "            temperature=0.0,\n",
    "            max_tokens=repair_tokens,\n",
    "            rate_limit_sleep_sec=rate_limit_sleep_sec,\n",
    "            max_retries=max_retries,\n",
    "            audit=audit,\n",
    "            call_tag=f\"repair::{mode}::{tool_name}::round{repaired_rounds}\",\n",
    "        )\n",
    "\n",
    "        ok, final, all_errs = _validate_raw_then_normalized(repair_raw)\n",
    "\n",
    "    if ok and repaired_rounds > 0:\n",
    "        status = \"repaired\"\n",
    "        audit.inc(\"llm_repaired\", 1)\n",
    "\n",
    "    # Phase 2: optional judge to fix hard validation (only)\n",
    "    judge_tokens = min(512, max_tokens * 2)\n",
    "    if (not ok) and enable_judge and judge_max_rounds > 0:\n",
    "        try:\n",
    "            for jr in range(1, judge_max_rounds + 1):\n",
    "                audit.inc(\"llm_judge_calls\", 1)\n",
    "\n",
    "                judge_prompt = build_judge_prompt(\n",
    "                    mode=mode,\n",
    "                    tool_name=tool_name,\n",
    "                    original_description=orig_desc,\n",
    "                    last_candidate=final,\n",
    "                    validation_errors=all_errs,\n",
    "                    params_context=param_context,\n",
    "                    top_level_param_names=top_level_param_names,\n",
    "                )\n",
    "\n",
    "                judge_raw_out = llm_call_chat_completions(\n",
    "                    client=client,\n",
    "                    model=judge_model,\n",
    "                    system_text=\"System role: Strict compliance editor for tool documentation strings.\",\n",
    "                    user_text=judge_prompt,\n",
    "                    temperature=0.0,\n",
    "                    max_tokens=judge_tokens,\n",
    "                    rate_limit_sleep_sec=rate_limit_sleep_sec,\n",
    "                    max_retries=max_retries,\n",
    "                    audit=audit,\n",
    "                    call_tag=f\"judge::{mode}::{tool_name}::round{jr}\",\n",
    "                )\n",
    "\n",
    "                ok2, judged_norm, errs2 = _validate_raw_then_normalized(judge_raw_out)\n",
    "                if ok2:\n",
    "                    final = judged_norm\n",
    "                    status = \"judged\"\n",
    "                    all_errs = []\n",
    "                    audit.inc(\"llm_judge_fixed\", 1)\n",
    "                    ok = True\n",
    "                    break\n",
    "                else:\n",
    "                    final = judged_norm\n",
    "                    all_errs = errs2\n",
    "\n",
    "            if not ok:\n",
    "                audit.inc(\"llm_judge_failed\", 1)\n",
    "                audit.log_fallback(\n",
    "                    {\n",
    "                        \"ts\": now_unix(),\n",
    "                        \"event\": \"judge_failed_no_immediate_fallback\",\n",
    "                        \"mode\": mode,\n",
    "                        \"tool_name\": tool_name,\n",
    "                        \"generation_model\": generation_model,\n",
    "                        \"judge_model\": judge_model,\n",
    "                        \"last_validation_errors\": all_errs[:50],\n",
    "                    }\n",
    "                )\n",
    "        except Exception as e:\n",
    "            audit.inc(\"llm_judge_failed\", 1)\n",
    "            audit.log_fallback(\n",
    "                {\n",
    "                    \"ts\": now_unix(),\n",
    "                    \"event\": \"judge_exception_no_immediate_fallback\",\n",
    "                    \"mode\": mode,\n",
    "                    \"tool_name\": tool_name,\n",
    "                    \"generation_model\": generation_model,\n",
    "                    \"judge_model\": judge_model,\n",
    "                    \"error_type\": type(e).__name__,\n",
    "                    \"error_str\": str(e)[:2000],\n",
    "                    \"last_validation_errors\": all_errs[:50],\n",
    "                }\n",
    "            )\n",
    "            ok = False\n",
    "\n",
    "    # Phase 2.5: pre-semantic guardrail rewrite\n",
    "    if ok and normalize_single_line(orig_desc):\n",
    "        if should_trigger_pre_semantic_guardrail(\n",
    "            original_description=orig_desc,\n",
    "            candidate_description=final,\n",
    "            top_level_param_names=top_level_param_names,\n",
    "            mode=mode,\n",
    "        ):\n",
    "            guardrail_prompt = build_guardrail_rewrite_prompt(\n",
    "                mode=mode,\n",
    "                tool_name=tool_name,\n",
    "                original_description=orig_desc,\n",
    "                candidate_description=final,\n",
    "                params_context=param_context,\n",
    "            )\n",
    "            gr_raw = llm_call_chat_completions(\n",
    "                client=client,\n",
    "                model=generation_model,\n",
    "                system_text=system_text,\n",
    "                user_text=guardrail_prompt,\n",
    "                temperature=0.0,\n",
    "                max_tokens=repair_tokens,\n",
    "                rate_limit_sleep_sec=rate_limit_sleep_sec,\n",
    "                max_retries=max_retries,\n",
    "                audit=audit,\n",
    "                call_tag=f\"guardrail_rewrite::{mode}::{tool_name}\",\n",
    "            )\n",
    "\n",
    "            ok_gr, gr_norm, errs_gr = _validate_raw_then_normalized(gr_raw)\n",
    "            if not ok_gr:\n",
    "                gr_fixed = _sentence_fixup_if_needed(gr_norm)\n",
    "                ok_gr2, gr_fixed_norm, errs_gr2 = _validate_raw_then_normalized(gr_fixed)\n",
    "                if ok_gr2:\n",
    "                    final = gr_fixed_norm\n",
    "                    status = \"guardrail_rewrite\"\n",
    "                    all_errs = []\n",
    "                    ok = True\n",
    "                else:\n",
    "                    all_errs = errs_gr2\n",
    "                    ok = False\n",
    "            else:\n",
    "                final = gr_norm\n",
    "                status = \"guardrail_rewrite\"\n",
    "                all_errs = []\n",
    "                ok = True\n",
    "\n",
    "    # Phase 3: semantic gate (FIRST)\n",
    "    semantic_ok = True\n",
    "    semantic_judge_line = \"PASS\"\n",
    "\n",
    "    if ok and normalize_single_line(orig_desc):\n",
    "        prompt_sem = build_semantic_judge_prompt(\n",
    "            tool_name=tool_name,\n",
    "            original_description=orig_desc,\n",
    "            candidate_description=final,\n",
    "            params_context=param_context,\n",
    "            mode=mode,\n",
    "        )\n",
    "\n",
    "        raw = llm_call_chat_completions(\n",
    "            client=client,\n",
    "            model=judge_model,\n",
    "            system_text=\"System role: Semantic consistency judge for tool descriptions.\",\n",
    "            user_text=prompt_sem,\n",
    "            temperature=0.0,\n",
    "            max_tokens=256,\n",
    "            rate_limit_sleep_sec=rate_limit_sleep_sec,\n",
    "            max_retries=max_retries,\n",
    "            audit=audit,\n",
    "            call_tag=f\"semantic_judge_first::{tool_name}\",\n",
    "        )\n",
    "\n",
    "        line = normalize_single_line(raw)\n",
    "        semantic_ok = (line.upper() == \"PASS\")\n",
    "        semantic_judge_line = line if line else \"FAIL: empty_judge_output\"\n",
    "\n",
    "        audit.inc(\"semantic_gate_first_pass_total\", 1)\n",
    "        if not semantic_ok:\n",
    "            audit.inc(\"semantic_gate_first_pass_fail\", 1)\n",
    "\n",
    "        audit.log_event(\n",
    "            {\n",
    "                \"ts\": now_unix(),\n",
    "                \"event\": \"semantic_gate_result\",\n",
    "                \"mode\": mode,\n",
    "                \"tool_name\": tool_name,\n",
    "                \"result\": \"PASS\" if semantic_ok else \"FAIL\",\n",
    "                \"judge_line\": semantic_judge_line[:300],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Phase 3.5: semantic repair + semantic re-judge\n",
    "    if ok and (not semantic_ok):\n",
    "        sem_repair_prompt = build_semantic_repair_prompt(\n",
    "            tool_name=tool_name,\n",
    "            mode=mode,\n",
    "            original_description=orig_desc,\n",
    "            candidate_description=final,\n",
    "            semantic_judge_feedback=semantic_judge_line,\n",
    "        )\n",
    "\n",
    "        sem_raw = llm_call_chat_completions(\n",
    "            client=client,\n",
    "            model=generation_model,\n",
    "            system_text=system_text,\n",
    "            user_text=sem_repair_prompt,\n",
    "            temperature=0.0,\n",
    "            max_tokens=repair_tokens,\n",
    "            rate_limit_sleep_sec=rate_limit_sleep_sec,\n",
    "            max_retries=max_retries,\n",
    "            audit=audit,\n",
    "            call_tag=f\"semantic_repair::{mode}::{tool_name}\",\n",
    "        )\n",
    "\n",
    "        ok3, sem_norm, errs3 = _validate_raw_then_normalized(sem_raw)\n",
    "        if not ok3:\n",
    "            audit.log_event(\n",
    "                {\n",
    "                    \"ts\": now_unix(),\n",
    "                    \"event\": \"semantic_repair_validation_failed\",\n",
    "                    \"mode\": mode,\n",
    "                    \"tool_name\": tool_name,\n",
    "                    \"validation_errors\": errs3[:50],\n",
    "                }\n",
    "            )\n",
    "            semantic_ok = False\n",
    "            all_errs = errs3\n",
    "        else:\n",
    "            prompt_sem2 = build_semantic_judge_prompt(\n",
    "                tool_name=tool_name,\n",
    "                original_description=orig_desc,\n",
    "                candidate_description=sem_norm,\n",
    "                params_context=param_context,\n",
    "                mode=mode,\n",
    "            )\n",
    "            raw2 = llm_call_chat_completions(\n",
    "                client=client,\n",
    "                model=judge_model,\n",
    "                system_text=\"System role: Semantic consistency judge for tool descriptions.\",\n",
    "                user_text=prompt_sem2,\n",
    "                temperature=0.0,\n",
    "                max_tokens=256,\n",
    "                rate_limit_sleep_sec=rate_limit_sleep_sec,\n",
    "                max_retries=max_retries,\n",
    "                audit=audit,\n",
    "                call_tag=f\"semantic_judge_after_repair::{tool_name}\",\n",
    "            )\n",
    "            line2 = normalize_single_line(raw2)\n",
    "            semantic_ok2 = (line2.upper() == \"PASS\")\n",
    "\n",
    "            audit.log_event(\n",
    "                {\n",
    "                    \"ts\": now_unix(),\n",
    "                    \"event\": \"semantic_gate_result_after_repair\",\n",
    "                    \"mode\": mode,\n",
    "                    \"tool_name\": tool_name,\n",
    "                    \"result\": \"PASS\" if semantic_ok2 else \"FAIL\",\n",
    "                    \"judge_line\": line2[:300],\n",
    "                }\n",
    "            )\n",
    "\n",
    "            if semantic_ok2:\n",
    "                final = sem_norm\n",
    "                status = \"semantic_repaired\"\n",
    "                semantic_ok = True\n",
    "                all_errs = []\n",
    "            else:\n",
    "                semantic_ok = False\n",
    "                semantic_judge_line = line2\n",
    "                all_errs = [\"semantic_gate_failed_after_repair\"]\n",
    "\n",
    "    # Phase 4: similarity gate + targeted recovery (NO immediate fallback)\n",
    "    if ok and semantic_ok and normalize_single_line(orig_desc):\n",
    "        audit.inc(\"similarity_gate_total\", 1)\n",
    "\n",
    "        sim_ok, sim_metrics, sim_reason = similarity_gate_pass(mode, orig_desc, final)\n",
    "        audit.log_event(\n",
    "            {\n",
    "                \"ts\": now_unix(),\n",
    "                \"event\": \"similarity_gate_checked\",\n",
    "                \"mode\": mode,\n",
    "                \"tool_name\": tool_name,\n",
    "                \"result\": \"PASS\" if sim_ok else \"FAIL\",\n",
    "                \"reason\": sim_reason,\n",
    "                \"metrics\": sim_metrics,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if sim_ok:\n",
    "            audit.inc(\"similarity_gate_pass_total\", 1)\n",
    "        else:\n",
    "            audit.inc(\"similarity_gate_fail_total\", 1)\n",
    "            recovered = False\n",
    "\n",
    "            if (\"too_similar\" in sim_reason) or (\"identical\" in sim_reason):\n",
    "                micro = deterministic_micro_edit_on_candidate(\n",
    "                    mode=mode,\n",
    "                    original_description=orig_desc,\n",
    "                    candidate_description=final,\n",
    "                )\n",
    "                ok_m, micro_norm, micro_errs = _validate_raw_then_normalized(micro)\n",
    "                if ok_m:\n",
    "                    prompt_sem_m = build_semantic_judge_prompt(\n",
    "                        tool_name=tool_name,\n",
    "                        original_description=orig_desc,\n",
    "                        candidate_description=micro_norm,\n",
    "                        params_context=param_context,\n",
    "                        mode=mode,\n",
    "                    )\n",
    "                    raw_m = llm_call_chat_completions(\n",
    "                        client=client,\n",
    "                        model=judge_model,\n",
    "                        system_text=\"System role: Semantic consistency judge for tool descriptions.\",\n",
    "                        user_text=prompt_sem_m,\n",
    "                        temperature=0.0,\n",
    "                        max_tokens=256,\n",
    "                        rate_limit_sleep_sec=rate_limit_sleep_sec,\n",
    "                        max_retries=max_retries,\n",
    "                        audit=audit,\n",
    "                        call_tag=f\"semantic_judge_micro_edit::{tool_name}\",\n",
    "                    )\n",
    "                    line_m = normalize_single_line(raw_m)\n",
    "                    if line_m.upper() == \"PASS\":\n",
    "                        sim_ok2, sim_m2, sim_r2 = similarity_gate_pass(mode, orig_desc, micro_norm)\n",
    "                        if sim_ok2:\n",
    "                            final = micro_norm\n",
    "                            status = \"similarity_recovered_micro_edit\"\n",
    "                            all_errs = []\n",
    "                            recovered = True\n",
    "                            audit.inc(\"similarity_gate_recovered_rule_based\", 1)\n",
    "                            audit.log_event(\n",
    "                                {\n",
    "                                    \"ts\": now_unix(),\n",
    "                                    \"event\": \"similarity_gate_recovered\",\n",
    "                                    \"mode\": mode,\n",
    "                                    \"tool_name\": tool_name,\n",
    "                                    \"recovery\": \"micro_edit\",\n",
    "                                    \"metrics\": sim_m2,\n",
    "                                    \"reason\": sim_r2,\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "            if (not recovered) and (\"too_different\" in sim_reason):\n",
    "                pull_prompt = build_similarity_pullback_prompt(\n",
    "                    mode=mode,\n",
    "                    tool_name=tool_name,\n",
    "                    original_description=orig_desc,\n",
    "                    candidate_description=final,\n",
    "                    params_context=param_context,\n",
    "                )\n",
    "                pull_raw = llm_call_chat_completions(\n",
    "                    client=client,\n",
    "                    model=generation_model,\n",
    "                    system_text=system_text,\n",
    "                    user_text=pull_prompt,\n",
    "                    temperature=0.0,\n",
    "                    max_tokens=repair_tokens,\n",
    "                    rate_limit_sleep_sec=rate_limit_sleep_sec,\n",
    "                    max_retries=max_retries,\n",
    "                    audit=audit,\n",
    "                    call_tag=f\"similarity_pullback::{mode}::{tool_name}\",\n",
    "                )\n",
    "                ok_p, pull_norm, pull_errs = _validate_raw_then_normalized(pull_raw)\n",
    "                if ok_p:\n",
    "                    prompt_sem_p = build_semantic_judge_prompt(\n",
    "                        tool_name=tool_name,\n",
    "                        original_description=orig_desc,\n",
    "                        candidate_description=pull_norm,\n",
    "                        params_context=param_context,\n",
    "                        mode=mode,\n",
    "                    )\n",
    "                    raw_p = llm_call_chat_completions(\n",
    "                        client=client,\n",
    "                        model=judge_model,\n",
    "                        system_text=\"System role: Semantic consistency judge for tool descriptions.\",\n",
    "                        user_text=prompt_sem_p,\n",
    "                        temperature=0.0,\n",
    "                        max_tokens=256,\n",
    "                        rate_limit_sleep_sec=rate_limit_sleep_sec,\n",
    "                        max_retries=max_retries,\n",
    "                        audit=audit,\n",
    "                        call_tag=f\"semantic_judge_pullback::{tool_name}\",\n",
    "                    )\n",
    "                    line_p = normalize_single_line(raw_p)\n",
    "                    if line_p.upper() == \"PASS\":\n",
    "                        sim_ok3, sim_m3, sim_r3 = similarity_gate_pass(mode, orig_desc, pull_norm)\n",
    "                        if sim_ok3:\n",
    "                            final = pull_norm\n",
    "                            status = \"similarity_recovered_pullback\"\n",
    "                            all_errs = []\n",
    "                            recovered = True\n",
    "                            audit.inc(\"similarity_gate_recovered_rule_based\", 1)\n",
    "                            audit.log_event(\n",
    "                                {\n",
    "                                    \"ts\": now_unix(),\n",
    "                                    \"event\": \"similarity_gate_recovered\",\n",
    "                                    \"mode\": mode,\n",
    "                                    \"tool_name\": tool_name,\n",
    "                                    \"recovery\": \"pullback\",\n",
    "                                    \"metrics\": sim_m3,\n",
    "                                    \"reason\": sim_r3,\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "            if not recovered and ENABLE_RULE_BASED_RECOVERY:\n",
    "                rb = rule_based_paraphrase_operator(\n",
    "                    mode=mode,\n",
    "                    original_description=orig_desc,\n",
    "                    top_level_param_names=top_level_param_names,\n",
    "                )\n",
    "                ok_rb, rb_norm, rb_errs = _validate_raw_then_normalized(rb)\n",
    "                if ok_rb:\n",
    "                    prompt_sem_rb = build_semantic_judge_prompt(\n",
    "                        tool_name=tool_name,\n",
    "                        original_description=orig_desc,\n",
    "                        candidate_description=rb_norm,\n",
    "                        params_context=param_context,\n",
    "                        mode=mode,\n",
    "                    )\n",
    "                    raw_rb = llm_call_chat_completions(\n",
    "                        client=client,\n",
    "                        model=judge_model,\n",
    "                        system_text=\"System role: Semantic consistency judge for tool descriptions.\",\n",
    "                        user_text=prompt_sem_rb,\n",
    "                        temperature=0.0,\n",
    "                        max_tokens=256,\n",
    "                        rate_limit_sleep_sec=rate_limit_sleep_sec,\n",
    "                        max_retries=max_retries,\n",
    "                        audit=audit,\n",
    "                        call_tag=f\"semantic_judge_rule_based::{tool_name}\",\n",
    "                    )\n",
    "                    line_rb = normalize_single_line(raw_rb)\n",
    "                    if line_rb.upper() == \"PASS\":\n",
    "                        sim_ok4, sim_m4, sim_r4 = similarity_gate_pass(mode, orig_desc, rb_norm)\n",
    "                        if sim_ok4:\n",
    "                            final = rb_norm\n",
    "                            status = \"similarity_recovered_rule_based\"\n",
    "                            all_errs = []\n",
    "                            recovered = True\n",
    "                            audit.inc(\"similarity_gate_recovered_rule_based\", 1)\n",
    "                            audit.log_event(\n",
    "                                {\n",
    "                                    \"ts\": now_unix(),\n",
    "                                    \"event\": \"similarity_gate_recovered\",\n",
    "                                    \"mode\": mode,\n",
    "                                    \"tool_name\": tool_name,\n",
    "                                    \"recovery\": \"rule_based\",\n",
    "                                    \"metrics\": sim_m4,\n",
    "                                    \"reason\": sim_r4,\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "            if not recovered:\n",
    "                final = make_validator_safe_fallback(\n",
    "                    mode=mode,\n",
    "                    original_description=orig_desc,\n",
    "                    top_level_param_names=top_level_param_names,\n",
    "                )\n",
    "                status = \"similarity_failed_fallback_original\"\n",
    "                all_errs = [\"similarity_gate_failed\"]\n",
    "                audit.inc(\"similarity_gate_fallback_original\", 1)\n",
    "\n",
    "    # FINAL FALLBACK (hard fail or semantic fail)\n",
    "    if (not ok) or (not semantic_ok):\n",
    "        audit.inc(\"llm_rejected\", 1)\n",
    "\n",
    "        fallback = make_validator_safe_fallback(\n",
    "            mode=mode,\n",
    "            original_description=orig_desc,\n",
    "            top_level_param_names=top_level_param_names,\n",
    "        )\n",
    "        final = fallback\n",
    "\n",
    "        ok_fb, fb_errs = validate_description(\n",
    "            mode,\n",
    "            final,\n",
    "            top_level_param_names=top_level_param_names,\n",
    "            original_description=orig_desc,\n",
    "        )\n",
    "        if not ok_fb:\n",
    "            all_errs = (all_errs or []) + [f\"fallback_still_invalid:{e}\" for e in fb_errs[:10]]\n",
    "\n",
    "        status = \"semantic_failed_fallback_original\" if ok and (not semantic_ok) else (\n",
    "            \"judged_failed_fallback_original\" if enable_judge else \"rejected_fallback_original\"\n",
    "        )\n",
    "\n",
    "    cache.put(\n",
    "        key_hash=cache_key,\n",
    "        pipeline_version=PIPELINE_VERSION,\n",
    "        generation_model=generation_model,\n",
    "        judge_model=judge_model,\n",
    "        mode=mode,\n",
    "        tool_name=tool_name,\n",
    "        tool_signature=tool_sig,\n",
    "        prompt_hash=prompt_hash,\n",
    "        prompt_text=prompt,\n",
    "        raw_output=raw_initial if raw_initial is not None else \"\",\n",
    "        final_output=final,\n",
    "        status=status,\n",
    "        validation_errors=all_errs,\n",
    "    )\n",
    "\n",
    "    return final, status, all_errs, prompt_hash\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ================== TOOL STRING PATCHING (INNER TOOL JSON STRING) ==================\n",
    "\n",
    "\n",
    "def infer_tool_name_path(tool_obj: Dict[str, Any]) -> Sequence[str]:\n",
    "    if \"function\" in tool_obj and isinstance(tool_obj[\"function\"], dict):\n",
    "        return (\"function\", \"name\")\n",
    "    return (\"name\",)\n",
    "\n",
    "\n",
    "def patch_tool_name_in_tool_object(\n",
    "    *,\n",
    "    tool_obj: Dict[str, Any],\n",
    "    new_name: str,\n",
    ") -> Tuple[Dict[str, Any], bool, str]:\n",
    "    try:\n",
    "        name_path = infer_tool_name_path(tool_obj)\n",
    "        if len(name_path) == 2:\n",
    "            fn = tool_obj.get(\"function\")\n",
    "            if isinstance(fn, dict):\n",
    "                fn[\"name\"] = new_name\n",
    "                return tool_obj, True, \"patched_obj:function.name\"\n",
    "            return tool_obj, False, \"missing_function_dict\"\n",
    "        else:\n",
    "            tool_obj[\"name\"] = new_name\n",
    "            return tool_obj, True, \"patched_obj:name\"\n",
    "    except Exception as e:\n",
    "        return tool_obj, False, f\"patch_name_obj_exception:{type(e).__name__}\"\n",
    "\n",
    "\n",
    "def patch_tool_name_in_tool_json_string(\n",
    "    *,\n",
    "    tool_json_str: str,\n",
    "    tool_obj: Dict[str, Any],\n",
    "    new_name: str,\n",
    ") -> Tuple[str, bool, str]:\n",
    "    \"\"\"\n",
    "    Minimal-edit name patch: modifica solo lo span della stringa name dentro il JSON tool.\n",
    "    \"\"\"\n",
    "    name_path = infer_tool_name_path(tool_obj)\n",
    "    return patch_json_string_field_in_place(tool_json_str, name_path, new_name)\n",
    "\n",
    "\n",
    "def patch_tool_description_in_tool_object(\n",
    "    *,\n",
    "    tool_obj: Dict[str, Any],\n",
    "    new_desc: str,\n",
    "    desc_path: Sequence[str],\n",
    ") -> Tuple[Dict[str, Any], bool, str]:\n",
    "    \"\"\"\n",
    "    Patch the tool description directly on a tool object (dict), supporting both:\n",
    "      - {\"function\": {\"description\": \"...\"}}\n",
    "      - {\"description\": \"...\"}\n",
    "    Returns (patched_obj, did_patch, reason).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if len(desc_path) == 2 and desc_path[0] == \"function\" and desc_path[1] == \"description\":\n",
    "            fn = tool_obj.get(\"function\")\n",
    "            if isinstance(fn, dict):\n",
    "                old = fn.get(\"description\", None)\n",
    "                fn[\"description\"] = new_desc\n",
    "                return tool_obj, True, \"patched_obj:function.description\"\n",
    "            return tool_obj, False, \"missing_function_dict\"\n",
    "        elif len(desc_path) == 1 and desc_path[0] == \"description\":\n",
    "            old = tool_obj.get(\"description\", None)\n",
    "            tool_obj[\"description\"] = new_desc\n",
    "            return tool_obj, True, \"patched_obj:description\"\n",
    "        else:\n",
    "            return tool_obj, False, \"unsupported_desc_path\"\n",
    "    except Exception as e:\n",
    "        return tool_obj, False, f\"patch_obj_exception:{type(e).__name__}\"\n",
    "\n",
    "\n",
    "def parse_tool_json_string(tool_json_str: str) -> Optional[Dict[str, Any]]:\n",
    "    try:\n",
    "        obj = json.loads(tool_json_str)\n",
    "    except Exception:\n",
    "        return None\n",
    "    return obj if isinstance(obj, dict) else None\n",
    "\n",
    "\n",
    "def patch_tool_description_in_object_node_text_preserving_format(\n",
    "    *,\n",
    "    outer_line: str,\n",
    "    tool_node: \"JsonNode\",\n",
    "    new_desc: str,\n",
    "    desc_path: Sequence[str],\n",
    ") -> Tuple[str, bool, str]:\n",
    "    \"\"\"\n",
    "    In-place patch for tools entry of kind OBJECT, preserving formatting (no json.dumps fallback).\n",
    "\n",
    "    Extended behavior:\n",
    "    - If description exists but is non-string (null/number/etc): replace its span with a JSON string literal.\n",
    "    - If description is missing: insert `\"description\":\"...\"` into the target object span:\n",
    "        - function object for (\"function\",\"description\") if available and is an object\n",
    "        - otherwise root tool object\n",
    "    \"\"\"\n",
    "\n",
    "    def _replace_span(obj_text: str, rel_start: int, rel_end: int, replacement: str) -> Tuple[str, bool, str]:\n",
    "        if rel_start < 0 or rel_end < 0 or rel_start > len(obj_text) or rel_end > len(obj_text) or rel_start >= rel_end:\n",
    "            return \"\", False, \"span_out_of_bounds\"\n",
    "        return obj_text[:rel_start] + replacement + obj_text[rel_end:], True, \"replaced_span\"\n",
    "\n",
    "    def _insert_field_into_object_text(obj_text: str, obj_rel_start: int, obj_rel_end: int, key: str, value: str) -> Tuple[str, bool, str]:\n",
    "        if obj_rel_start < 0 or obj_rel_end > len(obj_text) or obj_rel_end <= obj_rel_start:\n",
    "            return \"\", False, \"object_span_out_of_bounds\"\n",
    "        if obj_text[obj_rel_start] != \"{\" or obj_text[obj_rel_end - 1] != \"}\":\n",
    "            return \"\", False, \"target_not_object_text\"\n",
    "\n",
    "        close_brace = obj_rel_end - 1\n",
    "        j = close_brace - 1\n",
    "        while j > obj_rel_start and obj_text[j] in \" \\t\\r\\n\":\n",
    "            j -= 1\n",
    "\n",
    "        pair = '\"' + json_escape_string(key) + '\":\"' + json_escape_string(value) + '\"'\n",
    "        if obj_text[j] == \"{\":\n",
    "            insert_text = pair\n",
    "        else:\n",
    "            insert_text = \",\" + pair\n",
    "\n",
    "        patched = obj_text[:close_brace] + insert_text + obj_text[close_brace:]\n",
    "        return patched, True, \"inserted_field\"\n",
    "\n",
    "    try:\n",
    "        if tool_node.kind != \"object\":\n",
    "            return \"\", False, \"tool_node_not_object\"\n",
    "        if not tool_node.obj:\n",
    "            return \"\", False, \"tool_object_no_children\"\n",
    "\n",
    "        obj_text = outer_line[tool_node.start : tool_node.end]\n",
    "        replacement_value = '\"' + json_escape_string(new_desc) + '\"'\n",
    "\n",
    "        # Case A: function.description\n",
    "        if len(desc_path) == 2 and desc_path[0] == \"function\" and desc_path[1] == \"description\":\n",
    "            fn_node = tool_node.obj.get(\"function\")\n",
    "            if fn_node is not None and fn_node.kind == \"object\":\n",
    "                # If description exists under function: replace span regardless of kind\n",
    "                if fn_node.obj and \"description\" in fn_node.obj:\n",
    "                    target = fn_node.obj[\"description\"]\n",
    "                    rel_start = target.start - tool_node.start\n",
    "                    rel_end = target.end - tool_node.start\n",
    "                    patched_obj_text, ok, reason = _replace_span(obj_text, rel_start, rel_end, replacement_value)\n",
    "                    if ok:\n",
    "                        return patched_obj_text, True, \"patched_function_description_any_kind\"\n",
    "                    return \"\", False, reason\n",
    "\n",
    "                # Insert description into function object span\n",
    "                fn_rel_start = fn_node.start - tool_node.start\n",
    "                fn_rel_end = fn_node.end - tool_node.start\n",
    "                patched_obj_text, ok, reason = _insert_field_into_object_text(obj_text, fn_rel_start, fn_rel_end, \"description\", new_desc)\n",
    "                if ok:\n",
    "                    return patched_obj_text, True, \"inserted_function_description_missing\"\n",
    "                # If insertion fails, fall through to root insertion\n",
    "            else:\n",
    "                # function missing or not object -> we cannot insert under function reliably; fall back to root insertion\n",
    "                pass\n",
    "\n",
    "            # Root insertion fallback (still in-place)\n",
    "            root_rel_start = 0\n",
    "            root_rel_end = len(obj_text)\n",
    "            patched_obj_text, ok, reason = _insert_field_into_object_text(obj_text, root_rel_start, root_rel_end, \"description\", new_desc)\n",
    "            if ok:\n",
    "                return patched_obj_text, True, \"inserted_root_description_fallback_from_function_path\"\n",
    "            return \"\", False, f\"function_path_insert_failed:{reason}\"\n",
    "\n",
    "        # Case B: root description\n",
    "        if len(desc_path) == 1 and desc_path[0] == \"description\":\n",
    "            target = find_node_by_key_path(tool_node, desc_path)\n",
    "            if target is not None:\n",
    "                # Replace span regardless of kind (string/null/number/etc)\n",
    "                rel_start = target.start - tool_node.start\n",
    "                rel_end = target.end - tool_node.start\n",
    "                patched_obj_text, ok, reason = _replace_span(obj_text, rel_start, rel_end, replacement_value)\n",
    "                if ok:\n",
    "                    return patched_obj_text, True, \"patched_root_description_any_kind\"\n",
    "                return \"\", False, reason\n",
    "\n",
    "            # Missing -> insert into root object span\n",
    "            patched_obj_text, ok, reason = _insert_field_into_object_text(obj_text, 0, len(obj_text), \"description\", new_desc)\n",
    "            if ok:\n",
    "                return patched_obj_text, True, \"inserted_root_description_missing\"\n",
    "            return \"\", False, reason\n",
    "\n",
    "        return \"\", False, \"unsupported_desc_path\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return \"\", False, f\"patch_object_text_exception:{type(e).__name__}\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def deterministic_tool_serialize(tool_obj: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Fallback serializer: keep it compact but DO NOT reorder keys.\n",
    "    Reordering (sort_keys=True) explodes diffs even when semantics are unchanged.\n",
    "    \"\"\"\n",
    "    return json.dumps(tool_obj, ensure_ascii=False, sort_keys=False, separators=(\",\", \":\"))\n",
    "\n",
    "\n",
    "def patch_tool_description_in_tool_json_string(\n",
    "    *,\n",
    "    tool_json_str: str,\n",
    "    new_desc: str,\n",
    "    desc_path: Sequence[str],\n",
    ") -> Tuple[str, bool, str]:\n",
    "    return patch_json_string_field_in_place(tool_json_str, desc_path, new_desc)\n",
    "\n",
    "\n",
    "def patch_outer_jsonl_line_tools(\n",
    "    *,\n",
    "    line: str,\n",
    "    client: OpenAI,\n",
    "    generation_model: str,\n",
    "    judge_model: str,\n",
    "    enable_judge: bool,\n",
    "    mode: str,\n",
    "    cache: DescCache,\n",
    "    audit: AuditLogger,\n",
    "    temperature: float,\n",
    "    max_tokens: int,\n",
    "    rate_limit_sleep_sec: float,\n",
    "    max_retries: int,\n",
    "    repair_max_rounds: int,\n",
    "    judge_max_rounds: int,\n",
    ") -> Tuple[str, Dict[str, Any]]:\n",
    "    stats: Dict[str, Any] = {\n",
    "        \"tools_in_line\": 0,\n",
    "        \"tools_patched\": 0,\n",
    "        \"tools_unchanged\": 0,\n",
    "        \"tools_fallback_reserialized\": 0,\n",
    "        \"tools_parse_failed\": 0,\n",
    "        \"tools_object_in_line\": 0,\n",
    "        \"outer_parse_failed\": False,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        root = JsonSpanParser(line).parse()\n",
    "    except Exception as e:\n",
    "        stats[\"outer_parse_failed\"] = True\n",
    "        audit.log_event(\n",
    "            {\n",
    "                \"ts\": now_unix(),\n",
    "                \"event\": \"outer_json_parse_failed\",\n",
    "                \"mode\": mode,\n",
    "                \"error_type\": type(e).__name__,\n",
    "                \"error_str\": str(e)[:300],\n",
    "            }\n",
    "        )\n",
    "        return line, stats\n",
    "\n",
    "    if root.kind != \"object\" or not root.obj or \"tools\" not in root.obj:\n",
    "        return line, stats\n",
    "\n",
    "    tools_node = root.obj[\"tools\"]\n",
    "    if tools_node.kind != \"array\" or not tools_node.arr:\n",
    "        return line, stats\n",
    "\n",
    "    patches: List[Tuple[int, int, str]] = []\n",
    "\n",
    "    for idx, el in enumerate(tools_node.arr):\n",
    "        stats[\"tools_in_line\"] += 1\n",
    "        audit.inc(\"tools_seen\", 1)\n",
    "\n",
    "        # -------------------------\n",
    "        # Case 1: tools entry is a JSON string containing tool JSON\n",
    "        # -------------------------\n",
    "        if el.kind == \"string\":\n",
    "            audit.inc(\"tools_entry_kind_string\", 1)\n",
    "\n",
    "            tool_json_str = el.value\n",
    "            tool_obj = parse_tool_json_string(tool_json_str)\n",
    "            if tool_obj is None:\n",
    "                stats[\"tools_parse_failed\"] += 1\n",
    "                audit.inc(\"tools_parse_failed\", 1)\n",
    "                audit.log_event(\n",
    "                    {\n",
    "                        \"ts\": now_unix(),\n",
    "                        \"event\": \"tool_string_parse_failed\",\n",
    "                        \"mode\": mode,\n",
    "                        \"tool_index_in_line\": idx,\n",
    "                    }\n",
    "                )\n",
    "                stats[\"tools_unchanged\"] += 1\n",
    "                audit.inc(\"tools_unchanged\", 1)\n",
    "                continue\n",
    "\n",
    "            tool_name, orig_desc, _, _, _, all_names, desc_path = extract_tool_core(tool_obj)\n",
    "            top_level_param_names = all_names\n",
    "\n",
    "            new_desc, status, val_errs, prompt_hash = generate_description_for_tool(\n",
    "                client=client,\n",
    "                generation_model=generation_model,\n",
    "                judge_model=judge_model,\n",
    "                enable_judge=enable_judge,\n",
    "                mode=mode,\n",
    "                tool_json_obj=tool_obj,\n",
    "                cache=cache,\n",
    "                audit=audit,\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens,\n",
    "                rate_limit_sleep_sec=rate_limit_sleep_sec,\n",
    "                max_retries=max_retries,\n",
    "                repair_max_rounds=repair_max_rounds,\n",
    "                judge_max_rounds=judge_max_rounds,\n",
    "            )\n",
    "\n",
    "            audit.log_manipulation_row(\n",
    "                _build_manip_row(\n",
    "                    mode=mode,\n",
    "                    tool_name=tool_name,\n",
    "                    orig_desc=orig_desc,\n",
    "                    new_desc=new_desc,\n",
    "                    status=status,\n",
    "                    validation_errors=val_errs,\n",
    "                    top_level_param_names=top_level_param_names,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            patched_inner, did_patch, reason = patch_tool_description_in_tool_json_string(\n",
    "                tool_json_str=tool_json_str,\n",
    "                new_desc=new_desc,\n",
    "                desc_path=desc_path,\n",
    "            )\n",
    "\n",
    "            if not did_patch:\n",
    "                patched_inner2, did_patch2, reason2 = patch_or_insert_tool_description_in_inner_json_text(\n",
    "                    tool_json_str=tool_json_str,\n",
    "                    new_desc=new_desc,\n",
    "                    desc_path=desc_path,\n",
    "                )\n",
    "\n",
    "                if did_patch2:\n",
    "                    patched_inner = patched_inner2\n",
    "                    audit.log_fallback(\n",
    "                        {\n",
    "                            \"ts\": now_unix(),\n",
    "                            \"event\": \"inplace_patch_failed_fallback_inner_text_patch\",\n",
    "                            \"mode\": mode,\n",
    "                            \"tool_name\": tool_name,\n",
    "                            \"reason\": f\"{reason} -> {reason2}\",\n",
    "                            \"generation_status\": status,\n",
    "                            \"validation_errors\": val_errs[:50],\n",
    "                            \"prompt_hash\": prompt_hash,\n",
    "                        }\n",
    "                    )\n",
    "                else:\n",
    "                    stats[\"tools_fallback_reserialized\"] += 1\n",
    "                    audit.inc(\"tools_fallback_reserialized\", 1)\n",
    "\n",
    "                    if len(desc_path) == 2 and desc_path[0] == \"function\":\n",
    "                        if isinstance(tool_obj.get(\"function\"), dict):\n",
    "                            tool_obj[\"function\"][\"description\"] = new_desc\n",
    "                    else:\n",
    "                        tool_obj[\"description\"] = new_desc\n",
    "\n",
    "                    patched_inner = deterministic_tool_serialize(tool_obj)\n",
    "\n",
    "                    audit.log_fallback(\n",
    "                        {\n",
    "                            \"ts\": now_unix(),\n",
    "                            \"event\": \"inplace_patch_failed_fallback_reserialize\",\n",
    "                            \"mode\": mode,\n",
    "                            \"tool_name\": tool_name,\n",
    "                            \"reason\": f\"{reason} -> inner_text_patch_failed:{reason2}\",\n",
    "                            \"generation_status\": status,\n",
    "                            \"validation_errors\": val_errs[:50],\n",
    "                            \"prompt_hash\": prompt_hash,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "            if normalize_single_line(orig_desc) == normalize_single_line(new_desc) and did_patch:\n",
    "                stats[\"tools_unchanged\"] += 1\n",
    "                audit.inc(\"tools_unchanged\", 1)\n",
    "            else:\n",
    "                stats[\"tools_patched\"] += 1\n",
    "                audit.inc(\"tools_patched\", 1)\n",
    "\n",
    "            replacement_outer = canonical_outer_string_literal_from_decoded(patched_inner)\n",
    "            audit.inc(\"outer_tools_string_literals_reescaped_canonically\", 1)\n",
    "            patches.append((el.start, el.end, replacement_outer))\n",
    "\n",
    "            audit.log_event(\n",
    "                {\n",
    "                    \"ts\": now_unix(),\n",
    "                    \"event\": \"tool_processed\",\n",
    "                    \"mode\": mode,\n",
    "                    \"tool_index_in_line\": idx,\n",
    "                    \"tool_name\": tool_name,\n",
    "                    \"tool_entry_kind\": \"string\",\n",
    "                    \"generation_model\": generation_model,\n",
    "                    \"judge_model\": judge_model,\n",
    "                    \"enable_judge\": bool(enable_judge),\n",
    "                    \"generation_status\": status,\n",
    "                    \"inplace_patch\": did_patch,\n",
    "                    \"inplace_patch_reason\": reason,\n",
    "                    \"outer_tools_replacement_kind\": \"string_literal\",\n",
    "                    \"original_desc_preview\": normalize_single_line(orig_desc)[:300],\n",
    "                    \"new_desc_preview\": normalize_single_line(new_desc)[:300],\n",
    "                    \"validation_errors\": val_errs[:50],\n",
    "                }\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # -------------------------\n",
    "        # Case 2: tools entry is an object (dict-style tool schema)\n",
    "        # -------------------------\n",
    "        if el.kind == \"object\":\n",
    "            stats[\"tools_object_in_line\"] += 1\n",
    "            audit.inc(\"tools_entry_kind_object\", 1)\n",
    "\n",
    "            tool_obj = node_to_python(el)\n",
    "            if not isinstance(tool_obj, dict):\n",
    "                stats[\"tools_unchanged\"] += 1\n",
    "                audit.inc(\"tools_unchanged\", 1)\n",
    "                audit.log_event(\n",
    "                    {\n",
    "                        \"ts\": now_unix(),\n",
    "                        \"event\": \"tool_object_not_dict_skipped\",\n",
    "                        \"mode\": mode,\n",
    "                        \"tool_index_in_line\": idx,\n",
    "                    }\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            tool_name, orig_desc, _, _, _, all_names, desc_path = extract_tool_core(tool_obj)\n",
    "            top_level_param_names = all_names\n",
    "\n",
    "            new_desc, status, val_errs, prompt_hash = generate_description_for_tool(\n",
    "                client=client,\n",
    "                generation_model=generation_model,\n",
    "                judge_model=judge_model,\n",
    "                enable_judge=enable_judge,\n",
    "                mode=mode,\n",
    "                tool_json_obj=tool_obj,\n",
    "                cache=cache,\n",
    "                audit=audit,\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens,\n",
    "                rate_limit_sleep_sec=rate_limit_sleep_sec,\n",
    "                max_retries=max_retries,\n",
    "                repair_max_rounds=repair_max_rounds,\n",
    "                judge_max_rounds=judge_max_rounds,\n",
    "            )\n",
    "\n",
    "            audit.log_manipulation_row(\n",
    "                _build_manip_row(\n",
    "                    mode=mode,\n",
    "                    tool_name=tool_name,\n",
    "                    orig_desc=orig_desc,\n",
    "                    new_desc=new_desc,\n",
    "                    status=status,\n",
    "                    validation_errors=val_errs,\n",
    "                    top_level_param_names=top_level_param_names,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            patched_obj_text, did_text_patch, text_patch_reason = patch_tool_description_in_object_node_text_preserving_format(\n",
    "                outer_line=line,\n",
    "                tool_node=el,\n",
    "                new_desc=new_desc,\n",
    "                desc_path=desc_path,\n",
    "            )\n",
    "\n",
    "            if did_text_patch:\n",
    "                # IMPORTANT: replacement is JSON object text, not a JSON string literal.\n",
    "                inner = patched_obj_text\n",
    "            else:\n",
    "                stats[\"tools_fallback_reserialized\"] += 1\n",
    "                audit.inc(\"tools_fallback_reserialized\", 1)\n",
    "\n",
    "                patched_obj, did_patch, reason = patch_tool_description_in_tool_object(\n",
    "                    tool_obj=tool_obj,\n",
    "                    new_desc=new_desc,\n",
    "                    desc_path=desc_path,\n",
    "                )\n",
    "\n",
    "                inner = json.dumps(patched_obj, ensure_ascii=False, sort_keys=False, separators=(\",\", \":\"))\n",
    "\n",
    "                audit.log_fallback(\n",
    "                    {\n",
    "                        \"ts\": now_unix(),\n",
    "                        \"event\": \"object_text_inplace_patch_failed_fallback_reserialize\",\n",
    "                        \"mode\": mode,\n",
    "                        \"tool_name\": tool_name,\n",
    "                        \"reason\": text_patch_reason,\n",
    "                        \"generation_status\": status,\n",
    "                        \"validation_errors\": val_errs[:50],\n",
    "                        \"prompt_hash\": prompt_hash,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            if normalize_single_line(orig_desc) == normalize_single_line(new_desc):\n",
    "                stats[\"tools_unchanged\"] += 1\n",
    "                audit.inc(\"tools_unchanged\", 1)\n",
    "            else:\n",
    "                stats[\"tools_patched\"] += 1\n",
    "                audit.inc(\"tools_patched\", 1)\n",
    "\n",
    "            # IMPORTANT: Keep object as object in outer JSON (no string conversion).\n",
    "            replacement_outer = inner\n",
    "            patches.append((el.start, el.end, replacement_outer))\n",
    "\n",
    "            audit.log_event(\n",
    "                {\n",
    "                    \"ts\": now_unix(),\n",
    "                    \"event\": \"tool_processed\",\n",
    "                    \"mode\": mode,\n",
    "                    \"tool_index_in_line\": idx,\n",
    "                    \"tool_name\": tool_name,\n",
    "                    \"tool_entry_kind\": \"object\",\n",
    "                    \"generation_model\": generation_model,\n",
    "                    \"judge_model\": judge_model,\n",
    "                    \"enable_judge\": bool(enable_judge),\n",
    "                    \"generation_status\": status,\n",
    "                    \"inplace_patch\": bool(did_text_patch),\n",
    "                    \"inplace_patch_reason\": text_patch_reason,\n",
    "                    \"outer_tools_replacement_kind\": \"object\",\n",
    "                    \"original_desc_preview\": normalize_single_line(orig_desc)[:300],\n",
    "                    \"new_desc_preview\": normalize_single_line(new_desc)[:300],\n",
    "                    \"validation_errors\": val_errs[:50],\n",
    "                }\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # -------------------------\n",
    "        # Case 3: unsupported tools entry kind\n",
    "        # -------------------------\n",
    "        stats[\"tools_unchanged\"] += 1\n",
    "        audit.inc(\"tools_unchanged\", 1)\n",
    "        audit.log_event(\n",
    "            {\n",
    "                \"ts\": now_unix(),\n",
    "                \"event\": \"tool_entry_kind_unsupported_skipped\",\n",
    "                \"mode\": mode,\n",
    "                \"tool_index_in_line\": idx,\n",
    "                \"kind\": el.kind,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if not patches:\n",
    "        return line, stats\n",
    "\n",
    "    patches.sort(key=lambda x: x[0], reverse=True)\n",
    "    out = line\n",
    "    for start, end, repl in patches:\n",
    "        out = out[:start] + repl + out[end:]\n",
    "\n",
    "    return out, stats\n",
    "\n",
    "\n",
    "# ================== JSONL VARIANT GENERATION ==================\n",
    "\n",
    "def build_variant_jsonl_with_llm(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    generation_model: str,\n",
    "    judge_model: str,\n",
    "    enable_judge: bool,\n",
    "    input_path: str,\n",
    "    output_path: str,\n",
    "    mode: str,\n",
    "    output_dir: str,\n",
    "    temperature: float,\n",
    "    max_tokens: int,\n",
    "    rate_limit_sleep_sec: float,\n",
    "    max_retries: int,\n",
    "    repair_max_rounds: int,\n",
    "    judge_max_rounds: int,\n",
    "    seed: int,\n",
    "    overwrite: bool,\n",
    ") -> None:\n",
    "    if mode not in MODES:\n",
    "        raise ValueError(f\"Unknown mode in build_variant_jsonl_with_llm: {mode}\")\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    ensure_dir(output_dir)\n",
    "    audit_dir = os.path.join(\n",
    "        output_dir,\n",
    "        AUDIT_DIR_NAME,\n",
    "        f\"{sanitize_model_name_for_path(generation_model)}__{sanitize_model_name_for_path(judge_model)}__judge-{int(bool(enable_judge))}__{mode}\",\n",
    "    )\n",
    "    ensure_dir(audit_dir)\n",
    "\n",
    "    cache_db = os.path.join(output_dir, CACHE_DB_NAME)\n",
    "    cache = DescCache(cache_db)\n",
    "    audit = AuditLogger(audit_dir)\n",
    "\n",
    "    if os.path.exists(output_path) and not overwrite:\n",
    "        raise FileExistsError(\"Output exists and overwrite=False.\")\n",
    "\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as fin, open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "        for line in fin:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            audit.inc(\"lines_seen\", 1)\n",
    "\n",
    "            line_clean = line.rstrip(\"\\r\\n\")\n",
    "            patched_line, stats = patch_outer_jsonl_line_tools(\n",
    "                line=line_clean,\n",
    "                client=client,\n",
    "                generation_model=generation_model,\n",
    "                judge_model=judge_model,\n",
    "                enable_judge=enable_judge,\n",
    "                mode=mode,\n",
    "                cache=cache,\n",
    "                audit=audit,\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens,\n",
    "                rate_limit_sleep_sec=rate_limit_sleep_sec,\n",
    "                max_retries=max_retries,\n",
    "                repair_max_rounds=repair_max_rounds,\n",
    "                judge_max_rounds=judge_max_rounds,\n",
    "            )\n",
    "\n",
    "\n",
    "            fout.write(patched_line + \"\\n\")\n",
    "            audit.inc(\"lines_written\", 1)\n",
    "\n",
    "            audit.log_event(\n",
    "                {\n",
    "                    \"ts\": now_unix(),\n",
    "                    \"event\": \"line_processed\",\n",
    "                    \"mode\": mode,\n",
    "                    \"outer_parse_failed\": bool(stats.get(\"outer_parse_failed\", False)),\n",
    "                    \"tools_in_line\": stats.get(\"tools_in_line\", 0),\n",
    "                    \"tools_patched_in_line\": stats.get(\"tools_patched\", 0),\n",
    "                    \"tools_fallback_reserialized_in_line\": stats.get(\"tools_fallback_reserialized\", 0),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    audit.flush_summary(\n",
    "        extra={\n",
    "            \"mode\": mode,\n",
    "            \"generation_model\": generation_model,\n",
    "            \"judge_model\": judge_model,\n",
    "            \"enable_judge\": bool(enable_judge),\n",
    "            \"temperature\": temperature,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"rate_limit_sleep_sec\": rate_limit_sleep_sec,\n",
    "            \"max_retries\": max_retries,\n",
    "            \"repair_max_rounds\": repair_max_rounds,\n",
    "            \"judge_max_rounds\": judge_max_rounds,\n",
    "            \"seed\": seed,\n",
    "        }\n",
    "    )\n",
    "    audit.flush_manipulation_summaries()\n",
    "\n",
    "    cache.close()\n",
    "    print(f\"[{mode}] wrote output JSONL\")\n",
    "    print(f\"[{mode}] audit dir: {audit_dir}\")\n",
    "\n",
    "\n",
    "# ================== MULTI-VARIANT ENTRYPOINT ==================\n",
    "\n",
    "def run_when2call_variants(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    generation_model: str,\n",
    "    judge_model: Optional[str] = None,\n",
    "    enable_judge: bool = False,\n",
    "    input_jsonl: str,\n",
    "    output_dir: str,\n",
    "    modes: Optional[List[str]] = None,\n",
    "    overwrite: bool = False,\n",
    "    temperature: float = DEFAULT_TEMPERATURE,\n",
    "    max_tokens: int = DEFAULT_MAX_TOKENS,\n",
    "    rate_limit_sleep_sec: float = DEFAULT_RATE_LIMIT_SLEEP_SEC,\n",
    "    max_retries: int = DEFAULT_MAX_RETRIES,\n",
    "    repair_max_rounds: int = DEFAULT_REPAIR_MAX_ROUNDS,\n",
    "    judge_max_rounds: int = DEFAULT_JUDGE_MAX_ROUNDS,\n",
    "    seed: int = DEFAULT_RANDOM_SEED,\n",
    ") -> None:\n",
    "    if not os.path.exists(input_jsonl):\n",
    "        raise FileNotFoundError(\"Input file not found.\")\n",
    "\n",
    "    ensure_dir(output_dir)\n",
    "\n",
    "    active_modes = modes if modes is not None else list(MODES)\n",
    "    unknown = [m for m in active_modes if m not in MODES]\n",
    "    if unknown:\n",
    "        raise ValueError(f\"Unknown modes requested: {unknown}. Allowed: {MODES}\")\n",
    "\n",
    "    jm = judge_model if judge_model is not None else generation_model\n",
    "\n",
    "    print(f\"Pipeline: {PIPELINE_VERSION}\")\n",
    "    print(f\"Generator model: {generation_model}\")\n",
    "    print(f\"Judge model: {jm} | enable_judge={bool(enable_judge)}\")\n",
    "    print(f\"Modes: {active_modes}\")\n",
    "    print(\n",
    "        f\"Temperature: {temperature} | max_tokens: {max_tokens} | retries: {max_retries} | \"\n",
    "        f\"repair_rounds: {repair_max_rounds} | judge_rounds: {judge_max_rounds}\"\n",
    "    )\n",
    "\n",
    "    base_name = os.path.splitext(os.path.basename(input_jsonl))[0]\n",
    "    model_tag = sanitize_model_name_for_path(generation_model)\n",
    "    judge_tag = sanitize_model_name_for_path(jm)\n",
    "\n",
    "    for mode in active_modes:\n",
    "        out_name = f\"{base_name}__gen-{model_tag}__judge-{judge_tag}__judgeon-{int(bool(enable_judge))}__mode-{mode}.jsonl\"\n",
    "        out_path = os.path.join(output_dir, out_name)\n",
    "\n",
    "        if os.path.exists(out_path) and not overwrite:\n",
    "            print(f\"[{mode}] skipped (exists, overwrite=False)\")\n",
    "            continue\n",
    "\n",
    "        build_variant_jsonl_with_llm(\n",
    "            client=client,\n",
    "            generation_model=generation_model,\n",
    "            judge_model=jm,\n",
    "            enable_judge=enable_judge,\n",
    "            input_path=input_jsonl,\n",
    "            output_path=out_path,\n",
    "            mode=mode,\n",
    "            output_dir=output_dir,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "            rate_limit_sleep_sec=rate_limit_sleep_sec,\n",
    "            max_retries=max_retries,\n",
    "            repair_max_rounds=repair_max_rounds,\n",
    "            judge_max_rounds=judge_max_rounds,\n",
    "            seed=seed,\n",
    "            overwrite=overwrite,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7bcf26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] api_token_api.APITokenApi.get_api_tokens\n",
      "    Retrieve a list of API tokens associated with the user's account.\n",
      "\n",
      "[2] api_token_api.APITokenApi.post_api_token\n",
      "    Generate a new API token to authenticate and authorize subsequent API calls.\n",
      "\n",
      "[3] Buses_3_FindBus\n",
      "    Search for a bus itinerary between two cities on a specific date.\n",
      "\n",
      "[4] Buses_3_BuyBusTicket\n",
      "    Purchase bus tickets for a specified route, date, and time. Options for the number of passengers and additional luggage are available.\n",
      "\n",
      "[5] Events_3_BuyEventTickets\n",
      "    Facilitates the purchase of tickets for a cultural event on a specific date in a designated city.\n",
      "\n",
      "[6] detail_adriel_project\n",
      "    Retrieve the detailed information of the project that Adriel was working on, including the project's current status and expected completion date.\n",
      "\n",
      "[7] adriel_detail_experience_and_education\n",
      "    Retrieve the detailed information regarding Adriel's professional experiences and educational background.\n",
      "\n",
      "[8] adriel_experiences_and_education\n",
      "    Retrieve a comprehensive list detailing Adriel's professional experiences and educational background.\n",
      "\n",
      "[9] adriel_contact\n",
      "    Retrieve the contact information for Adriel, including name, email, and phone number. If no contact_id is provided, the function returns the default contact information.\n",
      "\n",
      "[10] adriel_tech_stack\n",
      "    Retrieves the list of technologies that Adriel is currently working with, including programming languages, frameworks, and tools.\n",
      "\n",
      "[11] help\n",
      "    Provides a list of available commands and their descriptions for a given context within the application.\n",
      "\n",
      "[12] stock_price.get\n",
      "    Retrieve the current stock price for a specified ticker symbol from the stock market.\n",
      "\n",
      "[13] Alarm_1_AddAlarm\n",
      "    Sets a new alarm with specified time and an optional custom name.\n",
      "\n",
      "[14] Messaging_1_ShareLocation\n",
      "    Shares the current geographical location with a specified contact.\n",
      "\n",
      "[15] RentalCars_3_GetCarsAvailable\n",
      "    Discover cars available for rent in a certain location and period. The function returns a list of available cars based on the specified city, rental period, and car type preferences.\n",
      "\n",
      "[16] RentalCars_3_ReserveCar\n",
      "    Make a rental car reservation by specifying the pickup location, dates, type of car, and insurance option.\n",
      "\n",
      "[17] Restaurants_2_ReserveRestaurant\n",
      "    This function makes a table reservation at a specified restaurant by providing the restaurant's name, location, desired reservation time, number of seats, and date.\n",
      "\n",
      "[18] Restaurants_2_FindRestaurants\n",
      "    Find restaurants by location and by category. The function returns a list of restaurants that match the specified criteria.\n",
      "\n",
      "[19] Flights_4_SearchOnewayFlight\n",
      "    Search for one-way flights from an origin to a destination on a specific date, with options for seating class and preferred airlines.\n",
      "\n",
      "[20] Flights_4_SearchRoundtripFlights\n",
      "    Search for roundtrip flights based on origin, destination, dates, seating class, and other preferences.\n",
      "\n",
      "[21] Hotels_2_BookHouse\n",
      "    Book the selected house for given dates and the specified number of adults.\n",
      "\n",
      "[22] Hotels_2_SearchHouse\n",
      "    Search for available houses at a specified location, optionally filtering by amenities such as laundry service and by the number of adults. Results can be sorted by rating.\n",
      "\n",
      "[23] Movies_1_BuyMovieTickets\n",
      "    Purchase tickets for a specific movie showtime at a designated theater location.\n",
      "\n",
      "[24] Movies_1_FindMovies\n",
      "    Search for movies by specified criteria such as location, genre, and show type.\n",
      "\n",
      "[25] Movies_1_GetTimesForMovie\n",
      "    Retrieve a list of showtimes for a specific movie at a particular theater location on a specified date.\n",
      "\n",
      "[26] Services_1_BookAppointment\n",
      "    Books an appointment with a specified hair stylist or salon on a given date and time.\n",
      "\n",
      "[27] Hotels_4_ReserveHotel\n",
      "    Reserve rooms at a selected hotel for given dates.\n",
      "\n",
      "[28] Hotels_4_SearchHotel\n",
      "    Search for accommodations in a specific city, filtering results based on star rating, smoking policy, and the number of rooms required.\n",
      "\n",
      "[29] Payment_1_RequestPayment\n",
      "    Initiates a payment request to a specified contact or account.\n",
      "\n",
      "[30] Payment_1_MakePayment\n",
      "    Executes a transaction to transfer funds from the user to another account.\n",
      "\n",
      "[31] Services_4_BookAppointment\n",
      "    Books a therapy appointment with a specified therapist at a given date and time.\n",
      "\n",
      "[32] multiply\n",
      "    Multiplies two given integers and returns the product.\n",
      "\n",
      "[33] add\n",
      "    Calculate the sum of two integers.\n",
      "\n",
      "[34] fahrenheit_to_celsius\n",
      "    Converts a temperature from Fahrenheit to Celsius.\n",
      "\n",
      "[35] celsius_to_fahrenheit\n",
      "    Converts a temperature given in Celsius to Fahrenheit.\n",
      "\n",
      "[36] duck_duck_go.search\n",
      "    Performs a search using the Duck Duck Go Search API. It is useful for retrieving answers to questions about current events. The input is a search query string, and the output is a JSON array containing the search results.\n",
      "\n",
      "[37] set_alarm\n",
      "    Set an alarm to trigger at a specified time, optionally with a designated purpose.\n",
      "\n",
      "[38] CustomDashboardsApi.add_custom_dashboard\n",
      "    This function adds a new custom dashboard to the system. It allows users to create a personalized view with widgets and data relevant to their needs.\n",
      "\n",
      "[39] CustomDashboardsApi.delete_custom_dashboard\n",
      "    Deletes a specific custom dashboard identified by its unique ID.\n",
      "\n",
      "[40] Services_4_FindProvider\n",
      "    Discover a therapist according to the user's requirements in a specific location.\n",
      "\n",
      "[41] product_search\n",
      "    Search for products by applying filters such as category, color, and size. Returns a list of products that match the criteria.\n",
      "\n",
      "[42] order_status_check\n",
      "    Check the current status of an order by providing the order ID and the name of the product ordered.\n",
      "\n",
      "[43] get_product_details\n",
      "    Retrieve detailed information about a specific product, including color and size availability.\n",
      "\n",
      "[44] uber.eat.order\n",
      "    Order food on Uber Eats by specifying the restaurant and the items with their respective quantities.\n",
      "\n",
      "[45] Music_3_PlayMedia\n",
      "    Initiates playback of a specified music track on a designated device.\n",
      "\n",
      "[46] Music_3_LookupMusic\n",
      "    Retrieve a list of songs that align with the user's musical preferences based on artist, album, genre, and release year.\n",
      "\n",
      "[47] apdex_settings_api.ApdexSettingsApi.create_apdex_configuration\n",
      "    Creates a new Apdex configuration by setting the threshold values for satisfactory, tolerable, and frustrated user experience levels.\n",
      "\n",
      "[48] apdex_settings_api.ApdexSettingsApi.get_all_apdex_configurations\n",
      "    Retrieve a list of all Apdex threshold configurations used for applications performance monitoring.\n",
      "\n",
      "[49] todo.list_action\n",
      "    A function to manage a todo list, including adding new items, deleting existing items, or marking items as completed.\n",
      "\n",
      "[50] Alarm_1_GetAlarms\n",
      "    Retrieve a list of alarms that the user has set in the system.\n",
      "\n",
      "[51] view_service_provider_profile\n",
      "    Retrieve the detailed profile information of a specified service provider.\n",
      "\n",
      "[52] Weather_1_GetWeather\n",
      "    Retrieve the weather forecast for a specified city on a particular date.\n",
      "\n",
      "[53] uber.ride\n",
      "    Find a suitable Uber ride for customers based on their starting location, preferred type of ride, and maximum wait time.\n",
      "\n",
      "[54] SyntheticSettingsApi.get_synthetic_location\n",
      "    Retrieve the configuration details of a specific synthetic location by its unique identifier.\n",
      "\n",
      "[55] SyntheticSettingsApi.get_synthetic_tests\n",
      "    Retrieves a list of all synthetic tests associated with a specified application and location.\n",
      "\n",
      "[56] get_current_weather\n",
      "    Retrieves the current weather conditions for a specified location.\n",
      "\n",
      "[57] dartfx_help\n",
      "    Provides users with help, assistance, and guidance on how to navigate and use the DartFX application features effectively.\n",
      "\n",
      "[58] get_all_apdex_configurations\n",
      "    Retrieve a list of all Apdex score configurations from the system, providing an overview of application performance thresholds.\n",
      "\n",
      "[59] Media_3_FindMovies\n",
      "    Explore and discover movies online based on user-defined preferences such as genre and starring actors.\n",
      "\n",
      "[60] Media_3_PlayMovie\n",
      "    Stream the selected movie online with the option to choose subtitles in various languages.\n",
      "\n",
      "[61] health_api.HealthApi.get_version\n",
      "    Retrieve the current version information of the API, including the major, minor, and patch numbers.\n",
      "\n",
      "[62] create_website_alert_config\n",
      "    Creates a configuration for website alerts that define conditions under which an alert is triggered and optionally an incident is created.\n",
      "\n",
      "[63] events_api.EventsApi.get_events\n",
      "    This endpoint retrieves all available events for the requested timeframe, including options to filter by event type and to exclude or include specific event updates.\n",
      "\n",
      "[64] Events_3_FindEvents\n",
      "    Finds cultural events, such as concerts and plays, happening in a specified city on a given date.\n",
      "\n",
      "[65] RideSharing_2_GetRide\n",
      "    Books a cab for a specified destination, accommodating the requested number of seats and the selected ride type.\n",
      "\n",
      "[66] Travel_1_FindAttractions\n",
      "    Browse attractions in a specified city, filtering by entry fee, category, and suitability for children.\n",
      "\n",
      "[67] Homes_2_ScheduleVisit\n",
      "    Schedules a property visit for a potential buyer or tenant on a specific date.\n",
      "\n",
      "[68] project_api.ProjectApi.get_project_by_name_and_version\n",
      "    Retrieve the details of a specific project using its unique name and version identifier.\n",
      "\n",
      "[69] project_api.ProjectApi.update_project\n",
      "    Updates the existing project details with the provided information.\n",
      "\n",
      "[70] ProjectApi.update_project\n",
      "    Updates the specified project with new information such as its name, status, and description.\n",
      "\n",
      "[71] badge_api.BadgeApi.get_project_vulnerabilities_badge\n",
      "    Retrieves the current security metrics, such as the number of vulnerabilities, for a specified project and its version.\n",
      "\n",
      "[72] badge_api.BadgeApi.get_project_policy_violations_badge1\n",
      "    This function retrieves a badge image that indicates whether a specific project version complies with defined policy rules.\n",
      "\n",
      "[73] Trains_1_FindTrains\n",
      "    Finds available trains to a specified destination city on a particular date, allowing for reservation in different fare classes.\n",
      "\n",
      "[74] set_volume\n",
      "    Set the global volume for all audio playback. The volume level can be set within a range from 0 (mute) to 100 (maximum volume).\n",
      "\n",
      "[75] set_countdown\n",
      "    Sets a countdown timer for a specified duration. The duration can be specified in a string format, such as '1h 30m' for 1 hour and 30 minutes, '45m' for 45 minutes, or '2h' for 2 hours.\n",
      "\n",
      "[76] start_oncall\n",
      "    Initiate an on-call support session when a user explicitly requests assistance. The user's question, which should be clear and devoid of irrelevant details, can be referenced from the preceding chat interaction.\n",
      "\n",
      "[77] generate_password\n",
      "    Generate a secure, random password based on specified criteria including length, numerical, and special character inclusion.\n",
      "\n",
      "[78] Homes_2_FindHomeByArea\n",
      "    Search for a property to rent or buy in a specified city, filtering by number of bedrooms, bathrooms, garage availability, and in-unit laundry facilities.\n",
      "\n",
      "[79] EventSettingsApi.create_website_alert_config\n",
      "    This API endpoint creates a configuration for website alerts, allowing users to define the conditions under which an alert is triggered and optionally create an associated incident.\n",
      "\n",
      "[80] events_api.EventsApi.agent_monitoring_events\n",
      "    Retrieves all agent monitoring events within a specified timeframe. It allows for querying historical events and can filter events based on their state updates. Users can define the timeframe using 'to', 'from', and 'windowSize' parameters.\n",
      "\n",
      "[81] OpenWeatherMap.get_current_weather\n",
      "    Fetches the current weather information for a specified location using the OpenWeatherMap API.\n",
      "\n",
      "[82] ControlAppliance.execute\n",
      "    This function is designed for controlling a home appliance, checking its current status and settings, as well as monitoring indoor air properties like air quality and temperature. For control commands, the input must clearly specify 'power on' or 'start'. To check the status, the input must include the keyword '확인'. Note that this tool is not intended for describing, creating, deleting, or removing modes or routines.\n",
      "\n",
      "[83] HNA_WQA.search\n",
      "    Retrieve up-to-date information by searching the web using keywords. This is particularly useful for queries regarding topics that change frequently, such as the current president, recent movies, or popular songs.\n",
      "\n",
      "[84] cookbook.search_recipe\n",
      "    Searches for cooking recipes based on a provided keyword. Returns a list of recipes that contain the keyword in their title or ingredients list.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterator, Optional, Set, Tuple\n",
    "\n",
    "INPUT_JSONL = \"When2Call/data/test/when2call_test_llm_judge.jsonl\"\n",
    "\n",
    "\n",
    "def iter_tools_from_when2call(\n",
    "    jsonl_path: str,\n",
    "    *,\n",
    "    unique_by_name: bool = True,\n",
    ") -> Iterator[Tuple[str, str, Dict]]:\n",
    "    \"\"\"\n",
    "    Itera sui tool presenti nel campo 'orig_tools' di un file JSONL When2Call.\n",
    "\n",
    "    Yields:\n",
    "        (name, description, tool_dict)\n",
    "\n",
    "    Note:\n",
    "        - 'orig_tools' nel dataset è tipicamente una lista di stringhe JSON.\n",
    "        - Se unique_by_name=True, deduplica per 'name' (stampa ogni tool una sola volta).\n",
    "    \"\"\"\n",
    "    seen: Set[str] = set()\n",
    "    path = Path(jsonl_path)\n",
    "\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line_no, line in enumerate(f, start=1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                record = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                # Riga corrotta/non JSON: la saltiamo\n",
    "                continue\n",
    "\n",
    "            orig_tools = record.get(\"tools\") or []\n",
    "            if not isinstance(orig_tools, list):\n",
    "                continue\n",
    "\n",
    "            for tool_entry in orig_tools:\n",
    "                if isinstance(tool_entry, str):\n",
    "                    try:\n",
    "                        tool = json.loads(tool_entry)\n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "                elif isinstance(tool_entry, dict):\n",
    "                    tool = tool_entry\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                name = (tool.get(\"name\") or \"\").strip()\n",
    "                desc = (tool.get(\"description\") or \"\").strip()\n",
    "\n",
    "                if not name:\n",
    "                    continue\n",
    "\n",
    "                if unique_by_name:\n",
    "                    if name in seen:\n",
    "                        continue\n",
    "                    seen.add(name)\n",
    "\n",
    "                yield name, desc, tool\n",
    "\n",
    "\n",
    "def interactive_pager(it: Iterator[Tuple[str, str, Dict]]) -> None:\n",
    "    \"\"\"\n",
    "    Consuma l'iteratore in modo interattivo: Invio = prossimo, 'q' = stop.\n",
    "    \"\"\"\n",
    "    for idx, (name, desc, _tool) in enumerate(it, start=1):\n",
    "        print(f\"\\n[{idx}] {name}\\n    {desc}\")\n",
    "        cmd = input(\"Invio=prossimo, q=esci > \").strip().lower()\n",
    "        if cmd == \"q\":\n",
    "            break\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tools_iter = iter_tools_from_when2call(INPUT_JSONL, unique_by_name=True)\n",
    "\n",
    "    # Modalità 1 (consigliata): paginazione interattiva (ti fermi con 'q')\n",
    "    interactive_pager(tools_iter)\n",
    "\n",
    "    # ----\n",
    "    # Modalità 2: uso “manuale” dell’iteratore con next() e stop quando vuoi\n",
    "    #\n",
    "    # tools_iter = iter_tools_from_when2call(INPUT_JSONL, unique_by_name=True)\n",
    "    # while True:\n",
    "    #     try:\n",
    "    #         name, desc, tool = next(tools_iter)\n",
    "    #     except StopIteration:\n",
    "    #         print(\"Fine tools.\")\n",
    "    #         break\n",
    "    #     print(f\"{name}: {desc}\")\n",
    "    #     # qui puoi decidere tu quando fermarti\n",
    "    #     if some_condition:\n",
    "    #         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca04250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working copy: When2Call/data/test/when2call_test_llm_judge.WORKING_COPY.jsonl\n",
      "Target: When2Call/data/test/when2call_test_llm_judge.WORKING_COPY.jsonl\n",
      "Audit file (RESUMABLE): audit/e21d3604eba2/when2call_test_llm_judge.WORKING_COPY.e21d3604eba2.style_verbose.gemini-2.5-flash.audit.jsonl\n",
      "Tool occurrences total: 978\n",
      "Resume position: [4/978] (previously reviewed: 3)\n",
      "LLM: gemini-2.5-flash @ https://generativelanguage.googleapis.com/v1beta/openai/\n",
      "Max tokens: 512; retry_on_length=True; retry_max_tokens=1024\n",
      "Commands: ENTER/ok=accept, r=regenerate, e=edit, m=manual, s=skip, q=quit\n",
      "\n",
      "================================================================================\n",
      "[4/978] Buses_3_BuyBusTicket\n",
      "instance_key: rec:64cbc7e8819e45258b49e186164c9fad:t1:9a77a4750b12a8be645d3b59a745bc6f (record_id=64cbc7e8819e45258b49e186164c9fad, tool_index=1)\n",
      "Current description RAW (escaped):\n",
      "\"Purchase bus tickets for a specified route, date, and time. Options for the number of passengers and additional luggage are available.\"\n",
      "\n",
      "Current description DECODED:\n",
      "Purchase bus tickets for a specified route, date, and time. Options for the number of passengers and additional luggage are available.\n",
      "\n",
      "LLM proposal:\n",
      "This tool facilitates the purchase of bus tickets, requiring specification of the desired route, date, and time, with available options to include the number of passengers and any additional luggage.\n",
      "\n",
      "proposal_origin=retry\n",
      "meta: finish_reason=length, max_param_used=max_completion_tokens, usage=CompletionUsage(completion_tokens=18, prompt_tokens=205, total_tokens=713, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "meta(retry): finish_reason=stop, max_param_used=max_completion_tokens, usage=CompletionUsage(completion_tokens=35, prompt_tokens=205, total_tokens=832, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "\n",
      "Changes applied.\n",
      "Descriptions updated (this session): 0\n",
      "Reviewed total (from audit): 3 / 978\n",
      "Completed: False (quit_requested=True)\n",
      "Resume next time from: [4/978]\n",
      "Updated file: When2Call/data/test/when2call_test_llm_judge.WORKING_COPY.jsonl\n",
      "Audit file (same on resume): audit/e21d3604eba2/when2call_test_llm_judge.WORKING_COPY.e21d3604eba2.style_verbose.gemini-2.5-flash.audit.jsonl\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3  28 dicembre\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional, Tuple, List\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# ========= Config =========\n",
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "LLM_MODEL = \"gemini-2.5-flash\"\n",
    "MODE_KEY = \"style_verbose\"\n",
    "\n",
    "HASH_HEX_LEN = 32\n",
    "\n",
    "DEFAULT_MAX_TOKENS = 512\n",
    "RETRY_ON_LENGTH = True\n",
    "RETRY_MAX_TOKENS = 1024\n",
    "\n",
    "DEFAULT_ALLOW_RESERIALIZE_FALLBACK = False\n",
    "\n",
    "REGEN_DIVERSITY_INSTRUCTION = (\n",
    "    \"Return a meaning-equivalent rewrite that is lexically different from your previous rewrite; \"\n",
    "    \"avoid repeating the same sentence structure.\"\n",
    ")\n",
    "\n",
    "# How much of the rejected previous rewrite to store in audit (for resume) and to feed back into prompt.\n",
    "MAX_PREV_REWRITE_CHARS = 800\n",
    "\n",
    "\n",
    "# ========= Client =========\n",
    "def make_gemini_client() -> OpenAI:\n",
    "    token = os.environ.get(\"TOKEN_GEMINI\")\n",
    "    if not token:\n",
    "        raise RuntimeError(\"TOKEN_GEMINI environment variable is not set.\")\n",
    "    return OpenAI(api_key=token, base_url=GEMINI_BASE_URL)\n",
    "\n",
    "\n",
    "# ========= Small utils =========\n",
    "def _json_safe(obj: Any) -> Any:\n",
    "    if obj is None or isinstance(obj, (str, int, float, bool)):\n",
    "        return obj\n",
    "    if isinstance(obj, dict):\n",
    "        return {str(k): _json_safe(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return [_json_safe(x) for x in obj]\n",
    "    if hasattr(obj, \"model_dump\") and callable(getattr(obj, \"model_dump\")):\n",
    "        try:\n",
    "            return _json_safe(obj.model_dump())\n",
    "        except Exception:\n",
    "            pass\n",
    "    if hasattr(obj, \"dict\") and callable(getattr(obj, \"dict\")):\n",
    "        try:\n",
    "            return _json_safe(obj.dict())\n",
    "        except Exception:\n",
    "            pass\n",
    "    if hasattr(obj, \"__dict__\"):\n",
    "        try:\n",
    "            return _json_safe(vars(obj))\n",
    "        except Exception:\n",
    "            pass\n",
    "    try:\n",
    "        return str(obj)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def _sha256_text(s: str) -> str:\n",
    "    return hashlib.sha256((s or \"\").encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "def _canonical_json(obj: Any) -> str:\n",
    "    return json.dumps(obj, ensure_ascii=False, sort_keys=True, separators=(\",\", \":\"))\n",
    "\n",
    "\n",
    "def _sha256_file(path: Path) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with path.open(\"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(1024 * 1024), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "\n",
    "# ========= Raw JSON-string patcher (for tools stored as JSON strings) =========\n",
    "def _extract_json_string_value(raw_json: str, key: str) -> Optional[str]:\n",
    "    token = f'\"{key}\"'\n",
    "    i = raw_json.find(token)\n",
    "    if i < 0:\n",
    "        return None\n",
    "    i = raw_json.find(\":\", i + len(token))\n",
    "    if i < 0:\n",
    "        return None\n",
    "    i += 1\n",
    "    n = len(raw_json)\n",
    "    while i < n and raw_json[i] in \" \\t\\r\\n\":\n",
    "        i += 1\n",
    "    if i >= n or raw_json[i] != '\"':\n",
    "        return None\n",
    "    start = i\n",
    "    i += 1\n",
    "    esc = False\n",
    "    while i < n:\n",
    "        c = raw_json[i]\n",
    "        if esc:\n",
    "            esc = False\n",
    "        else:\n",
    "            if c == \"\\\\\":\n",
    "                esc = True\n",
    "            elif c == '\"':\n",
    "                return raw_json[start : i + 1]\n",
    "        i += 1\n",
    "    return None\n",
    "\n",
    "\n",
    "def _decode_raw_json_string(raw_json_string_with_quotes: str) -> str:\n",
    "    try:\n",
    "        obj = json.loads('{\"description\":' + raw_json_string_with_quotes + \"}\")\n",
    "        return obj.get(\"description\") or \"\"\n",
    "    except json.JSONDecodeError:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def _get_description_for_print(entry: Any) -> Tuple[str, str]:\n",
    "    if isinstance(entry, str):\n",
    "        raw = _extract_json_string_value(entry, \"description\")\n",
    "        if raw is not None:\n",
    "            return raw, \"raw_json\"\n",
    "        try:\n",
    "            obj = json.loads(entry)\n",
    "            return obj.get(\"description\") or \"\", \"rendered\"\n",
    "        except json.JSONDecodeError:\n",
    "            return \"\", \"rendered\"\n",
    "    if isinstance(entry, dict):\n",
    "        return entry.get(\"description\") or \"\", \"rendered\"\n",
    "    return \"\", \"rendered\"\n",
    "\n",
    "\n",
    "def _load_tool(entry: Any) -> Tuple[Optional[Dict[str, Any]], str]:\n",
    "    if isinstance(entry, str):\n",
    "        try:\n",
    "            return json.loads(entry), \"json_str\"\n",
    "        except json.JSONDecodeError:\n",
    "            return None, \"other\"\n",
    "    if isinstance(entry, dict):\n",
    "        return entry, \"dict\"\n",
    "    return None, \"other\"\n",
    "\n",
    "\n",
    "def _skip_ws(s: str, i: int) -> int:\n",
    "    n = len(s)\n",
    "    while i < n and s[i] in \" \\t\\r\\n\":\n",
    "        i += 1\n",
    "    return i\n",
    "\n",
    "\n",
    "def _scan_string_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    n = len(s)\n",
    "    if i >= n or s[i] != '\"':\n",
    "        return None\n",
    "    j = i + 1\n",
    "    esc = False\n",
    "    while j < n:\n",
    "        c = s[j]\n",
    "        if esc:\n",
    "            esc = False\n",
    "        else:\n",
    "            if c == \"\\\\\":\n",
    "                esc = True\n",
    "            elif c == '\"':\n",
    "                return (i, j + 1)\n",
    "        j += 1\n",
    "    return None\n",
    "\n",
    "\n",
    "def _scan_number_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    n = len(s)\n",
    "    j = i\n",
    "    if j < n and s[j] == \"-\":\n",
    "        j += 1\n",
    "    if j >= n:\n",
    "        return None\n",
    "    if s[j] == \"0\":\n",
    "        j += 1\n",
    "    elif s[j].isdigit():\n",
    "        while j < n and s[j].isdigit():\n",
    "            j += 1\n",
    "    else:\n",
    "        return None\n",
    "    if j < n and s[j] == \".\":\n",
    "        j += 1\n",
    "        if j >= n or not s[j].isdigit():\n",
    "            return None\n",
    "        while j < n and s[j].isdigit():\n",
    "            j += 1\n",
    "    if j < n and s[j] in \"eE\":\n",
    "        j += 1\n",
    "        if j < n and s[j] in \"+-\":\n",
    "            j += 1\n",
    "        if j >= n or not s[j].isdigit():\n",
    "            return None\n",
    "        while j < n and s[j].isdigit():\n",
    "            j += 1\n",
    "    return (i, j)\n",
    "\n",
    "\n",
    "def _scan_literal_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    for lit in (\"true\", \"false\", \"null\"):\n",
    "        if s.startswith(lit, i):\n",
    "            return (i, i + len(lit))\n",
    "    return None\n",
    "\n",
    "\n",
    "def _scan_container_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    n = len(s)\n",
    "    if i >= n:\n",
    "        return None\n",
    "\n",
    "    opener = s[i]\n",
    "    if opener not in \"{[\":\n",
    "        return None\n",
    "\n",
    "    stack: List[str] = [\"}\" if opener == \"{\" else \"]\"]\n",
    "    j = i + 1\n",
    "    in_str = False\n",
    "    esc = False\n",
    "\n",
    "    while j < n:\n",
    "        c = s[j]\n",
    "\n",
    "        if in_str:\n",
    "            if esc:\n",
    "                esc = False\n",
    "            else:\n",
    "                if c == \"\\\\\":\n",
    "                    esc = True\n",
    "                elif c == '\"':\n",
    "                    in_str = False\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        if c == '\"':\n",
    "            in_str = True\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        if c == \"{\":\n",
    "            stack.append(\"}\")\n",
    "            j += 1\n",
    "            continue\n",
    "        if c == \"[\":\n",
    "            stack.append(\"]\")\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        if c in \"}]\":\n",
    "            if not stack:\n",
    "                return None\n",
    "            expected = stack[-1]\n",
    "            if c != expected:\n",
    "                return None\n",
    "            stack.pop()\n",
    "            j += 1\n",
    "            if not stack:\n",
    "                return (i, j)\n",
    "            continue\n",
    "\n",
    "        j += 1\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def _is_value_delim(c: str) -> bool:\n",
    "    return c in \",}]\"\n",
    "\n",
    "\n",
    "def _scan_value_span(s: str, i: int) -> Optional[Tuple[int, int]]:\n",
    "    n = len(s)\n",
    "    i = _skip_ws(s, i)\n",
    "    if i >= n:\n",
    "        return None\n",
    "\n",
    "    c = s[i]\n",
    "    if c == '\"':\n",
    "        return _scan_string_span(s, i)\n",
    "    if c in \"{[\":\n",
    "        return _scan_container_span(s, i)\n",
    "\n",
    "    span: Optional[Tuple[int, int]]\n",
    "    if c == \"-\" or c.isdigit():\n",
    "        span = _scan_number_span(s, i)\n",
    "    else:\n",
    "        span = _scan_literal_span(s, i)\n",
    "\n",
    "    if not span:\n",
    "        return None\n",
    "\n",
    "    _, end = span\n",
    "    k = _skip_ws(s, end)\n",
    "    if k >= n:\n",
    "        return span\n",
    "    if _is_value_delim(s[k]):\n",
    "        return span\n",
    "    return None\n",
    "\n",
    "\n",
    "def _replace_top_level_string_field_in_raw_object(raw_json_obj: str, key: str, new_value: str) -> Tuple[str, bool, str]:\n",
    "    s = raw_json_obj\n",
    "    n = len(s)\n",
    "\n",
    "    i = _skip_ws(s, 0)\n",
    "    if i >= n or s[i] != \"{\":\n",
    "        return raw_json_obj, False, \"not_object\"\n",
    "\n",
    "    i += 1\n",
    "    found_any_key = False\n",
    "    expect_key = True\n",
    "\n",
    "    while True:\n",
    "        i = _skip_ws(s, i)\n",
    "        if i >= n:\n",
    "            return raw_json_obj, False, \"cannot_scan_value\"\n",
    "\n",
    "        if expect_key:\n",
    "            if s[i] == \"}\":\n",
    "                return raw_json_obj, False, \"key_not_found\"\n",
    "            if s[i] != '\"':\n",
    "                return raw_json_obj, False, \"invalid_key_string\"\n",
    "\n",
    "            key_span = _scan_string_span(s, i)\n",
    "            if not key_span:\n",
    "                return raw_json_obj, False, \"invalid_key_string\"\n",
    "\n",
    "            found_any_key = True\n",
    "            k_start, k_end = key_span\n",
    "            try:\n",
    "                key_decoded = json.loads(s[k_start:k_end])\n",
    "            except Exception:\n",
    "                return raw_json_obj, False, \"invalid_key_string\"\n",
    "\n",
    "            i = _skip_ws(s, k_end)\n",
    "            if i >= n or s[i] != \":\":\n",
    "                return raw_json_obj, False, \"missing_colon\"\n",
    "\n",
    "            v_span = _scan_value_span(s, i + 1)\n",
    "            if not v_span:\n",
    "                return raw_json_obj, False, \"cannot_scan_value\"\n",
    "\n",
    "            v_start, v_end = v_span\n",
    "\n",
    "            if key_decoded == key:\n",
    "                if v_start >= n or s[v_start] != '\"':\n",
    "                    return raw_json_obj, False, \"value_not_string\"\n",
    "\n",
    "                replacement_literal = json.dumps(new_value, ensure_ascii=False)\n",
    "                patched = s[:v_start] + replacement_literal + s[v_end:]\n",
    "\n",
    "                try:\n",
    "                    obj = json.loads(patched)\n",
    "                except Exception:\n",
    "                    return raw_json_obj, False, \"json_load_failed_after_patch\"\n",
    "\n",
    "                if isinstance(obj, dict) and obj.get(key) == new_value:\n",
    "                    return patched, True, \"ok\"\n",
    "                return raw_json_obj, False, \"validation_failed_after_patch\"\n",
    "\n",
    "            i = v_end\n",
    "            expect_key = False\n",
    "            continue\n",
    "\n",
    "        i = _skip_ws(s, i)\n",
    "        if i >= n:\n",
    "            return raw_json_obj, False, \"cannot_scan_value\"\n",
    "\n",
    "        if s[i] == \",\":\n",
    "            i += 1\n",
    "            expect_key = True\n",
    "            continue\n",
    "        if s[i] == \"}\":\n",
    "            return raw_json_obj, False, (\"key_not_found\" if found_any_key else \"key_not_found\")\n",
    "        return raw_json_obj, False, \"cannot_scan_value\"\n",
    "\n",
    "\n",
    "# ========= IDs =========\n",
    "def _tool_fingerprint_excluding_description(tool_obj: Dict[str, Any]) -> str:\n",
    "    filtered = {k: v for k, v in tool_obj.items() if k != \"description\"}\n",
    "    payload = _canonical_json(filtered)\n",
    "    return hashlib.sha256(payload.encode(\"utf-8\")).hexdigest()[:HASH_HEX_LEN]\n",
    "\n",
    "\n",
    "def _record_id(record_obj: Dict[str, Any], tool_field: str) -> str:\n",
    "    rec = dict(record_obj)\n",
    "    tools = rec.get(tool_field)\n",
    "    if isinstance(tools, list):\n",
    "        canon_tools: List[Any] = []\n",
    "        for entry in tools:\n",
    "            tool_obj, kind = _load_tool(entry)\n",
    "            if tool_obj is None:\n",
    "                canon_tools.append({\"_unparsed\": entry, \"_kind\": kind})\n",
    "            else:\n",
    "                canon_tools.append({k: v for k, v in tool_obj.items() if k != \"description\"})\n",
    "        rec[tool_field] = canon_tools\n",
    "    payload = _canonical_json(rec)\n",
    "    return hashlib.sha256(payload.encode(\"utf-8\")).hexdigest()[:HASH_HEX_LEN]\n",
    "\n",
    "\n",
    "def _tool_instance_key(record_id: str, tool_index: int, tool_obj: Dict[str, Any]) -> str:\n",
    "    fp = _tool_fingerprint_excluding_description(tool_obj)\n",
    "    return f\"rec:{record_id}:t{tool_index}:{fp}\"\n",
    "\n",
    "\n",
    "# ========= Audit (single file, resumable) =========\n",
    "def _audit_identity(dataset_path: Path, *, mode_key: str, model: str, tool_field: str) -> str:\n",
    "    stable = f\"{dataset_path.resolve()}|{mode_key}|{model}|{tool_field}\"\n",
    "    return hashlib.sha256(stable.encode(\"utf-8\")).hexdigest()[:12]\n",
    "\n",
    "\n",
    "def _audit_file_path(\n",
    "    dataset_path: Path,\n",
    "    *,\n",
    "    audit_dir: Path,\n",
    "    mode_key: str,\n",
    "    model: str,\n",
    "    tool_field: str,\n",
    ") -> Path:\n",
    "    audit_key = _audit_identity(dataset_path, mode_key=mode_key, model=model, tool_field=tool_field)\n",
    "    safe_model = \"\".join(ch if ch.isalnum() or ch in (\"-\", \"_\", \".\") else \"_\" for ch in model)\n",
    "    out_dir = audit_dir / audit_key\n",
    "    filename = f\"{dataset_path.stem}.{audit_key}.{mode_key}.{safe_model}.audit.jsonl\"\n",
    "    return out_dir / filename\n",
    "\n",
    "\n",
    "def _append_audit_event(audit_file: Path, event: Dict[str, Any]) -> None:\n",
    "    audit_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    safe_event = _json_safe(event)\n",
    "    with audit_file.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(safe_event, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "def _load_resume_state(\n",
    "    audit_file: Path,\n",
    ") -> Tuple[\n",
    "    Dict[str, Tuple[str, Optional[str], Optional[Dict[str, Any]]]],\n",
    "    Dict[str, int],\n",
    "    Dict[str, Optional[str]],\n",
    "    Optional[Dict[str, Any]],\n",
    "]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - decisions_by_instance: instance_key -> (status, final_description, llm_bundle)\n",
    "      - regen_counts: instance_key -> max regen_index observed\n",
    "      - last_rejected_text: instance_key -> last rejected proposal text (from regenerate events)\n",
    "      - prior_run_start: first run_start event (if any)\n",
    "    \"\"\"\n",
    "    decisions: Dict[str, Tuple[str, Optional[str], Optional[Dict[str, Any]]]] = {}\n",
    "    regen_counts: Dict[str, int] = {}\n",
    "    last_rejected_text: Dict[str, Optional[str]] = {}\n",
    "    prior_run_start: Optional[Dict[str, Any]] = None\n",
    "\n",
    "    if not audit_file.exists():\n",
    "        return decisions, regen_counts, last_rejected_text, None\n",
    "\n",
    "    # Track per-instance best regen index so we keep the latest text\n",
    "    best_ri: Dict[str, int] = {}\n",
    "\n",
    "    with audit_file.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                ev = json.loads(line)\n",
    "            except Exception:\n",
    "                continue\n",
    "            if not isinstance(ev, dict):\n",
    "                continue\n",
    "\n",
    "            et = ev.get(\"event_type\")\n",
    "            if et == \"run_start\" and prior_run_start is None:\n",
    "                prior_run_start = ev\n",
    "\n",
    "            if et == \"regenerate\":\n",
    "                ik = ev.get(\"instance_key\")\n",
    "                ri = ev.get(\"regen_index\")\n",
    "                txt = ev.get(\"last_proposal_text\")\n",
    "                if isinstance(ik, str) and isinstance(ri, int) and ri >= 0:\n",
    "                    prev = regen_counts.get(ik, 0)\n",
    "                    if ri > prev:\n",
    "                        regen_counts[ik] = ri\n",
    "                    prev_best = best_ri.get(ik, -1)\n",
    "                    if ri >= prev_best:\n",
    "                        best_ri[ik] = ri\n",
    "                        last_rejected_text[ik] = txt if isinstance(txt, str) else None\n",
    "\n",
    "            if et == \"decision\":\n",
    "                ik = ev.get(\"instance_key\")\n",
    "                status = ev.get(\"status\")\n",
    "                final_desc = ev.get(\"final_description\")\n",
    "                llm_bundle = ev.get(\"llm_bundle\")\n",
    "                if isinstance(ik, str) and isinstance(status, str):\n",
    "                    decisions[ik] = (\n",
    "                        status,\n",
    "                        final_desc if isinstance(final_desc, str) else None,\n",
    "                        llm_bundle if isinstance(llm_bundle, dict) else None,\n",
    "                    )\n",
    "\n",
    "    return decisions, regen_counts, last_rejected_text, prior_run_start\n",
    "\n",
    "\n",
    "# ========= LLM helpers =========\n",
    "def _ends_like_complete_sentence(text: str) -> bool:\n",
    "    t = (text or \"\").strip()\n",
    "    return bool(t) and t.endswith((\".\", \"!\", \"?\", \"”\", '\"', \"’\", \"'\"))\n",
    "\n",
    "\n",
    "def _sanitize_llm_output(text: str) -> str:\n",
    "    t = (text or \"\").strip()\n",
    "    if t.startswith(\"{\") and \"description\" in t:\n",
    "        try:\n",
    "            obj = json.loads(t)\n",
    "            if isinstance(obj, dict) and isinstance(obj.get(\"description\"), str):\n",
    "                t = obj[\"description\"].strip()\n",
    "        except Exception:\n",
    "            pass\n",
    "    if (t.startswith('\"') and t.endswith('\"')) or (t.startswith(\"'\") and t.endswith(\"'\")):\n",
    "        t = t[1:-1].strip()\n",
    "    return t\n",
    "\n",
    "\n",
    "def _llm_chat_completion(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    model: str,\n",
    "    messages: List[Dict[str, str]],\n",
    "    temperature: float,\n",
    "    max_tokens: int,\n",
    "    seed: Optional[int],\n",
    ") -> Tuple[str, Dict[str, Any]]:\n",
    "    meta: Dict[str, Any] = {\n",
    "        \"seed_requested\": seed,\n",
    "        \"seed_applied\": False,\n",
    "        \"seed_error\": None,\n",
    "        \"finish_reason\": None,\n",
    "        \"usage\": None,\n",
    "        \"max_tokens_requested\": int(max_tokens),\n",
    "        \"max_param_used\": None,\n",
    "    }\n",
    "\n",
    "    base_kwargs: Dict[str, Any] = dict(model=model, messages=messages, temperature=temperature)\n",
    "\n",
    "    def attempt(max_param_used: str, include_seed: bool) -> Tuple[str, Dict[str, Any]]:\n",
    "        req = dict(base_kwargs)\n",
    "        if max_param_used == \"max_completion_tokens\":\n",
    "            req[\"max_completion_tokens\"] = int(max_tokens)\n",
    "        else:\n",
    "            req[\"max_tokens\"] = int(max_tokens)\n",
    "        if include_seed and seed is not None:\n",
    "            req[\"seed\"] = int(seed)\n",
    "\n",
    "        resp = client.chat.completions.create(**req)\n",
    "        text = (resp.choices[0].message.content or \"\").strip()\n",
    "\n",
    "        meta_local = dict(meta)\n",
    "        meta_local[\"max_param_used\"] = max_param_used\n",
    "        meta_local[\"finish_reason\"] = getattr(resp.choices[0], \"finish_reason\", None)\n",
    "        meta_local[\"usage\"] = getattr(resp, \"usage\", None)\n",
    "        meta_local[\"seed_applied\"] = bool(include_seed and seed is not None)\n",
    "        return text, meta_local\n",
    "\n",
    "    def is_seed_error(e: Exception) -> bool:\n",
    "        s = str(e).lower()\n",
    "        return (\"seed\" in s) and (\"unknown\" in s or \"unsupported\" in s or \"invalid\" in s)\n",
    "\n",
    "    try:\n",
    "        return attempt(\"max_completion_tokens\", include_seed=True)\n",
    "    except Exception as e1:\n",
    "        if seed is not None and is_seed_error(e1):\n",
    "            meta[\"seed_error\"] = str(e1)\n",
    "            try:\n",
    "                return attempt(\"max_completion_tokens\", include_seed=False)\n",
    "            except Exception:\n",
    "                pass\n",
    "        try:\n",
    "            return attempt(\"max_tokens\", include_seed=True)\n",
    "        except Exception as e2:\n",
    "            if seed is not None and is_seed_error(e2):\n",
    "                meta[\"seed_error\"] = str(e2)\n",
    "                return attempt(\"max_tokens\", include_seed=False)\n",
    "            raise\n",
    "\n",
    "\n",
    "def generate_verbose_description_via_llm(\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    tool_name: str,\n",
    "    base_description: str,\n",
    "    model: str,\n",
    "    seed: Optional[int],\n",
    "    max_tokens: int,\n",
    "    retry_on_length: bool,\n",
    "    retry_max_tokens: int,\n",
    "    regen_index: int = 0,\n",
    "    previous_rewrite: Optional[str] = None,\n",
    ") -> Tuple[str, Dict[str, Any]]:\n",
    "    system = (\n",
    "        \"Rewrite tool descriptions.\\n\"\n",
    "        \"Hard constraints:\\n\"\n",
    "        \"- Preserve meaning exactly; do not add new capabilities, steps, motivations, benefits, or context.\\n\"\n",
    "        \"- Do not delete information present in the original description.\\n\"\n",
    "        \"- Do not introduce new parameter names, IDs, field names, flags, or implementation details.\\n\"\n",
    "        \"- If parameter/field names/IDs/flags already appear in the original description, keep them (do not remove them).\\n\"\n",
    "        \"- Do not add examples, normative language, or assumptions.\\n\"\n",
    "        \"- Keep the same subject (the tool) and the same scope.\\n\"\n",
    "        \"- Output only the rewritten description text, nothing else.\\n\"\n",
    "        \"- Style: verbose but controlled; keep it concise and complete (1–2 sentences), clear and direct.\\n\"\n",
    "    )\n",
    "\n",
    "    user_parts: List[str] = []\n",
    "    user_parts.append(f\"Tool name: {tool_name}\")\n",
    "    user_parts.append(\"Base description:\")\n",
    "    user_parts.append(base_description.strip() or \"(empty)\")\n",
    "    user_parts.append(\"\")\n",
    "    user_parts.append(\"Rewrite in 'style_verbose' under the constraints.\")\n",
    "\n",
    "    if regen_index > 0:\n",
    "        user_parts.append(\"\")\n",
    "        user_parts.append(f\"Regeneration request: {regen_index}\")\n",
    "        user_parts.append(REGEN_DIVERSITY_INSTRUCTION)\n",
    "        if previous_rewrite and previous_rewrite.strip():\n",
    "            prev = previous_rewrite.strip()\n",
    "            if len(prev) > MAX_PREV_REWRITE_CHARS:\n",
    "                prev = prev[:MAX_PREV_REWRITE_CHARS].rstrip()\n",
    "            user_parts.append(\"\")\n",
    "            user_parts.append(\"Previous rewrite (do not reuse wording):\")\n",
    "            user_parts.append(prev)\n",
    "\n",
    "    user = \"\\n\".join(user_parts)\n",
    "\n",
    "    raw1, meta1 = _llm_chat_completion(\n",
    "        client=client,\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": user}],\n",
    "        temperature=0.0,\n",
    "        max_tokens=max_tokens,\n",
    "        seed=seed,\n",
    "    )\n",
    "    san1 = _sanitize_llm_output(raw1)\n",
    "    finish1 = (meta1.get(\"finish_reason\") or \"\").lower()\n",
    "    looks_truncated_1 = (finish1 == \"length\") or (san1 and not _ends_like_complete_sentence(san1))\n",
    "\n",
    "    if not looks_truncated_1:\n",
    "        return san1, {\n",
    "            \"proposal_origin\": \"primary\",\n",
    "            \"proposal_sanitized_final\": san1,\n",
    "            \"llm_text_raw_primary\": raw1,\n",
    "            \"llm_text_raw_retry\": None,\n",
    "            \"primary\": meta1,\n",
    "            \"retry\": None,\n",
    "        }\n",
    "\n",
    "    raw2 = None\n",
    "    meta2 = None\n",
    "    san2 = None\n",
    "    best_san = san1\n",
    "    origin = \"primary\"\n",
    "\n",
    "    if retry_on_length and retry_max_tokens > max_tokens:\n",
    "        raw2, meta2 = _llm_chat_completion(\n",
    "            client=client,\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": user}],\n",
    "            temperature=0.0,\n",
    "            max_tokens=int(retry_max_tokens),\n",
    "            seed=seed,\n",
    "        )\n",
    "        san2 = _sanitize_llm_output(raw2)\n",
    "        finish2 = (meta2.get(\"finish_reason\") or \"\").lower()\n",
    "        looks_truncated_2 = (finish2 == \"length\") or (san2 and not _ends_like_complete_sentence(san2))\n",
    "\n",
    "        if san2 and len(san2) >= len(best_san):\n",
    "            best_san = san2\n",
    "            origin = \"retry\"\n",
    "\n",
    "        if not looks_truncated_2 and san2:\n",
    "            return san2, {\n",
    "                \"proposal_origin\": \"retry\",\n",
    "                \"proposal_sanitized_final\": san2,\n",
    "                \"llm_text_raw_primary\": raw1,\n",
    "                \"llm_text_raw_retry\": raw2,\n",
    "                \"primary\": meta1,\n",
    "                \"retry\": meta2,\n",
    "            }\n",
    "\n",
    "    return best_san, {\n",
    "        \"proposal_origin\": origin,\n",
    "        \"proposal_sanitized_final\": best_san,\n",
    "        \"llm_text_raw_primary\": raw1,\n",
    "        \"llm_text_raw_retry\": raw2,\n",
    "        \"primary\": meta1,\n",
    "        \"retry\": meta2,\n",
    "    }\n",
    "\n",
    "\n",
    "# ========= IO =========\n",
    "def make_working_copy(input_jsonl: str, output_jsonl: str, *, overwrite: bool = False) -> str:\n",
    "    src = Path(input_jsonl)\n",
    "    dst = Path(output_jsonl)\n",
    "\n",
    "    if not src.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {src}\")\n",
    "\n",
    "    if dst.exists() and not overwrite:\n",
    "        return str(dst)\n",
    "\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(src, dst)\n",
    "    return str(dst)\n",
    "\n",
    "\n",
    "def _normalize_cmd(raw: str) -> str:\n",
    "    c = (raw or \"\").strip().lower()\n",
    "    if c in (\"\", \"y\", \"yes\", \"ok\", \"okay\", \"si\", \"sì\"):\n",
    "        return \"y\"\n",
    "    if c in (\"r\", \"retry\", \"again\", \"prova\", \"prova ancora\", \"rigenera\"):\n",
    "        return \"r\"\n",
    "    if c in (\"e\", \"edit\", \"modifica\"):\n",
    "        return \"e\"\n",
    "    if c in (\"m\", \"manual\", \"mine\", \"mio\", \"mia\", \"custom\"):\n",
    "        return \"m\"\n",
    "    if c in (\"s\", \"skip\", \"salta\", \"pass\"):\n",
    "        return \"s\"\n",
    "    if c in (\"q\", \"quit\", \"exit\", \"esci\"):\n",
    "        return \"q\"\n",
    "    return c\n",
    "\n",
    "\n",
    "# ========= Main interactive =========\n",
    "def interactive_llm_verbose_tools_in_jsonl(\n",
    "    jsonl_path: str,\n",
    "    *,\n",
    "    tool_field: str,\n",
    "    create_backup_of_target: bool,\n",
    "    llm_model: str,\n",
    "    seed: Optional[int],\n",
    "    max_tokens: int,\n",
    "    retry_on_length: bool,\n",
    "    retry_max_tokens: int,\n",
    "    allow_reserialize_fallback: bool,\n",
    "    min_sleep_sec_between_calls: float,\n",
    "    audit_dir: str,\n",
    ") -> None:\n",
    "    path = Path(jsonl_path)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {jsonl_path}\")\n",
    "\n",
    "    client = make_gemini_client()\n",
    "    audit_file = _audit_file_path(\n",
    "        path,\n",
    "        audit_dir=Path(audit_dir),\n",
    "        mode_key=MODE_KEY,\n",
    "        model=llm_model,\n",
    "        tool_field=tool_field,\n",
    "    )\n",
    "\n",
    "    decisions_by_instance, regen_counts, last_rejected_text_by_instance, prior_run_start = _load_resume_state(audit_file)\n",
    "\n",
    "    tool_order: List[Dict[str, Any]] = []\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for raw_line in f:\n",
    "            line = raw_line.rstrip(\"\\n\")\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            try:\n",
    "                record = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "            if not isinstance(record, dict):\n",
    "                continue\n",
    "\n",
    "            rid = _record_id(record, tool_field=tool_field)\n",
    "            tools = record.get(tool_field)\n",
    "            if not isinstance(tools, list):\n",
    "                continue\n",
    "\n",
    "            for tool_index, entry in enumerate(tools):\n",
    "                tool_obj, kind = _load_tool(entry)\n",
    "                if not tool_obj:\n",
    "                    continue\n",
    "                name = (tool_obj.get(\"name\") or \"\").strip()\n",
    "                if not name:\n",
    "                    continue\n",
    "\n",
    "                desc_print, desc_mode = _get_description_for_print(entry)\n",
    "                instance_key = _tool_instance_key(rid, tool_index, tool_obj)\n",
    "\n",
    "                tool_order.append(\n",
    "                    {\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_index,\n",
    "                        \"tool_name\": name,\n",
    "                        \"desc_print\": desc_print,\n",
    "                        \"desc_mode\": desc_mode,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"entry_kind\": kind,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    n_total = len(tool_order)\n",
    "    n_prev_reviewed = len(decisions_by_instance)\n",
    "\n",
    "    start_pos = 0\n",
    "    while start_pos < n_total and tool_order[start_pos][\"instance_key\"] in decisions_by_instance:\n",
    "        start_pos += 1\n",
    "\n",
    "    session_id = hashlib.sha256(f\"{time.time_ns()}\".encode(\"utf-8\")).hexdigest()[:12]\n",
    "    before_sha = _sha256_file(path)\n",
    "\n",
    "    if prior_run_start is None:\n",
    "        _append_audit_event(\n",
    "            audit_file,\n",
    "            {\n",
    "                \"event_type\": \"run_start\",\n",
    "                \"ts\": int(time.time()),\n",
    "                \"session_id\": session_id,\n",
    "                \"mode\": MODE_KEY,\n",
    "                \"model\": llm_model,\n",
    "                \"seed\": seed,\n",
    "                \"dataset_path\": str(path),\n",
    "                \"dataset_sha256_at_session_start\": before_sha,\n",
    "                \"tool_field\": tool_field,\n",
    "                \"n_total_occurrences\": n_total,\n",
    "                \"max_tokens_requested\": int(max_tokens),\n",
    "                \"retry_on_length\": bool(retry_on_length),\n",
    "                \"retry_max_tokens\": int(retry_max_tokens),\n",
    "                \"allow_reserialize_fallback\": bool(allow_reserialize_fallback),\n",
    "            },\n",
    "        )\n",
    "    else:\n",
    "        _append_audit_event(\n",
    "            audit_file,\n",
    "            {\n",
    "                \"event_type\": \"run_resume\",\n",
    "                \"ts\": int(time.time()),\n",
    "                \"session_id\": session_id,\n",
    "                \"mode\": MODE_KEY,\n",
    "                \"model\": llm_model,\n",
    "                \"seed\": seed,\n",
    "                \"dataset_path\": str(path),\n",
    "                \"dataset_sha256_at_session_start\": before_sha,\n",
    "                \"tool_field\": tool_field,\n",
    "                \"n_total_occurrences\": n_total,\n",
    "                \"n_previously_reviewed\": n_prev_reviewed,\n",
    "                \"resume_from_index_1based\": (start_pos + 1) if start_pos < n_total else (n_total + 1),\n",
    "            },\n",
    "        )\n",
    "\n",
    "    print(f\"Target: {path}\")\n",
    "    print(f\"Audit file (RESUMABLE): {audit_file}\")\n",
    "    print(f\"Tool occurrences total: {n_total}\")\n",
    "    if start_pos < n_total:\n",
    "        print(f\"Resume position: [{start_pos + 1}/{n_total}] (previously reviewed: {n_prev_reviewed})\")\n",
    "    else:\n",
    "        print(f\"Resume position: completed (previously reviewed: {n_prev_reviewed})\")\n",
    "    print(f\"LLM: {llm_model} @ {GEMINI_BASE_URL}\")\n",
    "    print(f\"Max tokens: {int(max_tokens)}; retry_on_length={bool(retry_on_length)}; retry_max_tokens={int(retry_max_tokens)}\")\n",
    "    print(\"Commands: ENTER/ok=accept, r=regenerate, e=edit, m=manual, s=skip, q=quit\\n\")\n",
    "\n",
    "    quit_requested = False\n",
    "    resume_next_index_1based: Optional[int] = None\n",
    "\n",
    "    for pos in range(start_pos, n_total):\n",
    "        item = tool_order[pos]\n",
    "        idx = pos + 1\n",
    "\n",
    "        name = item[\"tool_name\"]\n",
    "        desc_mode = item[\"desc_mode\"]\n",
    "        old_desc_print = item[\"desc_print\"]\n",
    "        instance_key = item[\"instance_key\"]\n",
    "        rid = item[\"record_id\"]\n",
    "        tool_i = item[\"tool_index\"]\n",
    "\n",
    "        # Per-instance regen state (resumable for regen_index; previous rejected text is best-effort).\n",
    "        regen_index_local = int(regen_counts.get(instance_key, 0))\n",
    "        previous_rewrite_local: Optional[str] = last_rejected_text_by_instance.get(instance_key)\n",
    "\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"[{idx}/{n_total}] {name}\")\n",
    "        print(f\"instance_key: {instance_key} (record_id={rid}, tool_index={tool_i})\")\n",
    "\n",
    "        if desc_mode == \"raw_json\":\n",
    "            print(\"Current description RAW (escaped):\")\n",
    "            print(old_desc_print if old_desc_print else \"(empty)\")\n",
    "            base_desc = _decode_raw_json_string(old_desc_print) if old_desc_print else \"\"\n",
    "            print(\"\\nCurrent description DECODED:\")\n",
    "            print(base_desc if base_desc else \"(empty)\")\n",
    "        else:\n",
    "            base_desc = old_desc_print or \"\"\n",
    "            print(\"Current description:\")\n",
    "            print(base_desc if base_desc else \"(empty)\")\n",
    "\n",
    "        proposal = \"\"\n",
    "        llm_bundle: Optional[Dict[str, Any]] = None\n",
    "\n",
    "        while True:\n",
    "            if not proposal:\n",
    "                try:\n",
    "                    proposal, llm_bundle = generate_verbose_description_via_llm(\n",
    "                        client=client,\n",
    "                        tool_name=name,\n",
    "                        base_description=base_desc,\n",
    "                        model=llm_model,\n",
    "                        seed=seed,\n",
    "                        max_tokens=max_tokens,\n",
    "                        retry_on_length=retry_on_length,\n",
    "                        retry_max_tokens=retry_max_tokens,\n",
    "                        regen_index=regen_index_local,\n",
    "                        previous_rewrite=previous_rewrite_local,\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nLLM ERROR: {e}\")\n",
    "                    cmd = _normalize_cmd(input(\"Choice [m=manual, e=edit, s=skip, q=quit] > \"))\n",
    "                    now = int(time.time())\n",
    "\n",
    "                    if cmd == \"q\":\n",
    "                        quit_requested = True\n",
    "                        resume_next_index_1based = idx\n",
    "                        break\n",
    "\n",
    "                    if cmd == \"s\":\n",
    "                        decisions_by_instance[instance_key] = (\"skipped\", None, None)\n",
    "                        _append_audit_event(\n",
    "                            audit_file,\n",
    "                            {\n",
    "                                \"event_type\": \"decision\",\n",
    "                                \"ts\": now,\n",
    "                                \"session_id\": session_id,\n",
    "                                \"status\": \"skipped\",\n",
    "                                \"tool_name\": name,\n",
    "                                \"instance_key\": instance_key,\n",
    "                                \"record_id\": rid,\n",
    "                                \"tool_index\": tool_i,\n",
    "                                \"model\": llm_model,\n",
    "                                \"seed\": seed,\n",
    "                                \"base_description\": base_desc,\n",
    "                                \"final_description\": None,\n",
    "                                \"source\": \"user\",\n",
    "                                \"note\": \"skip_after_llm_error\",\n",
    "                            },\n",
    "                        )\n",
    "                        break\n",
    "\n",
    "                    if cmd in (\"m\", \"e\"):\n",
    "                        manual_final = input(\"Manual final description (empty cancels) > \").rstrip(\"\\n\").strip()\n",
    "                        status = \"manual\" if (cmd == \"m\" and manual_final) else (\"edited\" if (cmd == \"e\" and manual_final) else \"skipped\")\n",
    "                        decisions_by_instance[instance_key] = (status, manual_final or None, None)\n",
    "                        _append_audit_event(\n",
    "                            audit_file,\n",
    "                            {\n",
    "                                \"event_type\": \"decision\",\n",
    "                                \"ts\": now,\n",
    "                                \"session_id\": session_id,\n",
    "                                \"status\": status,\n",
    "                                \"tool_name\": name,\n",
    "                                \"instance_key\": instance_key,\n",
    "                                \"record_id\": rid,\n",
    "                                \"tool_index\": tool_i,\n",
    "                                \"model\": llm_model,\n",
    "                                \"seed\": seed,\n",
    "                                \"base_description\": base_desc,\n",
    "                                \"final_description\": manual_final or None,\n",
    "                                \"source\": \"user\",\n",
    "                                \"note\": \"manual_or_edit_after_llm_error\",\n",
    "                            },\n",
    "                        )\n",
    "                        break\n",
    "\n",
    "                    proposal = \"\"\n",
    "                    continue\n",
    "\n",
    "                proposal = (proposal or \"\").strip()\n",
    "\n",
    "            print(\"\\nLLM proposal:\")\n",
    "            print(proposal if proposal else \"(empty)\")\n",
    "\n",
    "            if llm_bundle:\n",
    "                try:\n",
    "                    origin = llm_bundle.get(\"proposal_origin\")\n",
    "                    p = llm_bundle.get(\"primary\")\n",
    "                    r = llm_bundle.get(\"retry\")\n",
    "                    print(f\"\\nproposal_origin={origin}\")\n",
    "                    if p:\n",
    "                        print(f\"meta: finish_reason={p.get('finish_reason')}, max_param_used={p.get('max_param_used')}, usage={p.get('usage')}\")\n",
    "                    if r:\n",
    "                        print(f\"meta(retry): finish_reason={r.get('finish_reason')}, max_param_used={r.get('max_param_used')}, usage={r.get('usage')}\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            cmd = _normalize_cmd(input(\"\\nChoice [ENTER=accept, r=regen, e=edit, m=manual, s=skip, q=quit] > \"))\n",
    "            now = int(time.time())\n",
    "\n",
    "            if cmd == \"y\":\n",
    "                if proposal.strip():\n",
    "                    decisions_by_instance[instance_key] = (\"accepted\", proposal.strip(), llm_bundle)\n",
    "                    _append_audit_event(\n",
    "                        audit_file,\n",
    "                        {\n",
    "                            \"event_type\": \"decision\",\n",
    "                            \"ts\": now,\n",
    "                            \"session_id\": session_id,\n",
    "                            \"status\": \"accepted\",\n",
    "                            \"tool_name\": name,\n",
    "                            \"instance_key\": instance_key,\n",
    "                            \"record_id\": rid,\n",
    "                            \"tool_index\": tool_i,\n",
    "                            \"model\": llm_model,\n",
    "                            \"seed\": seed,\n",
    "                            \"base_description\": base_desc,\n",
    "                            \"final_description\": proposal.strip(),\n",
    "                            \"source\": \"llm\",\n",
    "                            \"llm_bundle\": llm_bundle,\n",
    "                        },\n",
    "                    )\n",
    "                else:\n",
    "                    decisions_by_instance[instance_key] = (\"skipped\", None, llm_bundle)\n",
    "                    _append_audit_event(\n",
    "                        audit_file,\n",
    "                        {\n",
    "                            \"event_type\": \"decision\",\n",
    "                            \"ts\": now,\n",
    "                            \"session_id\": session_id,\n",
    "                            \"status\": \"skipped\",\n",
    "                            \"tool_name\": name,\n",
    "                            \"instance_key\": instance_key,\n",
    "                            \"record_id\": rid,\n",
    "                            \"tool_index\": tool_i,\n",
    "                            \"model\": llm_model,\n",
    "                            \"seed\": seed,\n",
    "                            \"base_description\": base_desc,\n",
    "                            \"final_description\": None,\n",
    "                            \"source\": \"llm\",\n",
    "                            \"note\": \"empty_proposal\",\n",
    "                            \"llm_bundle\": llm_bundle,\n",
    "                        },\n",
    "                    )\n",
    "                break\n",
    "\n",
    "            if cmd == \"r\":\n",
    "                # Store the rejected output and feed it back as \"previous rewrite\" for the next generation.\n",
    "                previous_rewrite_local = proposal.strip() if proposal else None\n",
    "                if previous_rewrite_local and len(previous_rewrite_local) > MAX_PREV_REWRITE_CHARS:\n",
    "                    previous_rewrite_local = previous_rewrite_local[:MAX_PREV_REWRITE_CHARS].rstrip()\n",
    "\n",
    "                regen_counts[instance_key] = regen_counts.get(instance_key, 0) + 1\n",
    "                regen_index_local = int(regen_counts[instance_key])\n",
    "\n",
    "                # Persist the rejected text for resume.\n",
    "                last_rejected_text_by_instance[instance_key] = previous_rewrite_local\n",
    "\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"regenerate\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"regen_index\": regen_index_local,\n",
    "                        \"last_proposal_sha256\": _sha256_text(proposal),\n",
    "                        \"last_proposal_text\": previous_rewrite_local,\n",
    "                        \"last_proposal_origin\": (llm_bundle or {}).get(\"proposal_origin\") if llm_bundle else None,\n",
    "                    },\n",
    "                )\n",
    "\n",
    "                proposal = \"\"\n",
    "                llm_bundle = None\n",
    "                if min_sleep_sec_between_calls > 0:\n",
    "                    time.sleep(min_sleep_sec_between_calls)\n",
    "                continue\n",
    "\n",
    "            if cmd == \"e\":\n",
    "                edited = input(\"Edit proposal (empty cancels) > \").rstrip(\"\\n\").strip()\n",
    "                status = \"edited\" if edited else \"skipped\"\n",
    "                decisions_by_instance[instance_key] = (status, edited or None, llm_bundle)\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"decision\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"status\": status,\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"model\": llm_model,\n",
    "                        \"seed\": seed,\n",
    "                        \"base_description\": base_desc,\n",
    "                        \"final_description\": edited or None,\n",
    "                        \"source\": \"user\",\n",
    "                        \"note\": \"edit_proposal\",\n",
    "                        \"llm_bundle\": llm_bundle,\n",
    "                    },\n",
    "                )\n",
    "                break\n",
    "\n",
    "            if cmd == \"m\":\n",
    "                manual_final = input(\"Manual final description (empty cancels) > \").rstrip(\"\\n\").strip()\n",
    "                status = \"manual\" if manual_final else \"skipped\"\n",
    "                decisions_by_instance[instance_key] = (status, manual_final or None, llm_bundle)\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"decision\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"status\": status,\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"model\": llm_model,\n",
    "                        \"seed\": seed,\n",
    "                        \"base_description\": base_desc,\n",
    "                        \"final_description\": manual_final or None,\n",
    "                        \"source\": \"user\",\n",
    "                        \"note\": \"manual_replace\",\n",
    "                        \"llm_bundle\": llm_bundle,\n",
    "                    },\n",
    "                )\n",
    "                break\n",
    "\n",
    "            if cmd == \"s\":\n",
    "                decisions_by_instance[instance_key] = (\"skipped\", None, llm_bundle)\n",
    "                _append_audit_event(\n",
    "                    audit_file,\n",
    "                    {\n",
    "                        \"event_type\": \"decision\",\n",
    "                        \"ts\": now,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"status\": \"skipped\",\n",
    "                        \"tool_name\": name,\n",
    "                        \"instance_key\": instance_key,\n",
    "                        \"record_id\": rid,\n",
    "                        \"tool_index\": tool_i,\n",
    "                        \"model\": llm_model,\n",
    "                        \"seed\": seed,\n",
    "                        \"base_description\": base_desc,\n",
    "                        \"final_description\": None,\n",
    "                        \"source\": \"user\",\n",
    "                        \"note\": \"skip\",\n",
    "                        \"llm_bundle\": llm_bundle,\n",
    "                    },\n",
    "                )\n",
    "                break\n",
    "\n",
    "            if cmd == \"q\":\n",
    "                quit_requested = True\n",
    "                resume_next_index_1based = idx\n",
    "                break\n",
    "\n",
    "            print(\"Invalid command.\")\n",
    "\n",
    "        if quit_requested:\n",
    "            break\n",
    "\n",
    "    # ========= Apply decisions to file =========\n",
    "    tmp_path = path.with_suffix(path.suffix + \".tmp\")\n",
    "    updated_count = 0\n",
    "    patch_failures = 0\n",
    "\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as fin, tmp_path.open(\"w\", encoding=\"utf-8\") as fout:\n",
    "        for raw_line in fin:\n",
    "            line = raw_line.rstrip(\"\\n\")\n",
    "            if not line.strip():\n",
    "                fout.write(line + \"\\n\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                record = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                fout.write(line + \"\\n\")\n",
    "                continue\n",
    "\n",
    "            if not isinstance(record, dict):\n",
    "                fout.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "                continue\n",
    "\n",
    "            rid = _record_id(record, tool_field=tool_field)\n",
    "            tools = record.get(tool_field)\n",
    "\n",
    "            if isinstance(tools, list):\n",
    "                new_tools: List[Any] = []\n",
    "                for tool_index, entry in enumerate(tools):\n",
    "                    tool_obj, kind = _load_tool(entry)\n",
    "                    if not tool_obj:\n",
    "                        new_tools.append(entry)\n",
    "                        continue\n",
    "\n",
    "                    instance_key = _tool_instance_key(rid, tool_index, tool_obj)\n",
    "                    decision = decisions_by_instance.get(instance_key)\n",
    "\n",
    "                    if decision is None:\n",
    "                        new_tools.append(entry)\n",
    "                        continue\n",
    "\n",
    "                    status, new_desc, llm_bundle = decision\n",
    "                    if status in (\"accepted\", \"edited\", \"manual\") and new_desc:\n",
    "                        if kind == \"json_str\" and isinstance(entry, str):\n",
    "                            # Skip patch if already correct\n",
    "                            already_ok = False\n",
    "                            try:\n",
    "                                obj0 = json.loads(entry)\n",
    "                                if isinstance(obj0, dict) and obj0.get(\"description\") == new_desc:\n",
    "                                    already_ok = True\n",
    "                            except Exception:\n",
    "                                already_ok = False\n",
    "\n",
    "                            if already_ok:\n",
    "                                new_tools.append(entry)\n",
    "                                continue\n",
    "\n",
    "                            patched, ok, reason = _replace_top_level_string_field_in_raw_object(entry, \"description\", new_desc)\n",
    "                            if ok:\n",
    "                                new_tools.append(patched)\n",
    "                                updated_count += 1\n",
    "                            else:\n",
    "                                fallback_ok = False\n",
    "                                fallback_patched = entry\n",
    "                                if allow_reserialize_fallback:\n",
    "                                    try:\n",
    "                                        obj = json.loads(entry)\n",
    "                                        if isinstance(obj, dict):\n",
    "                                            obj[\"description\"] = new_desc\n",
    "                                            fallback_patched = json.dumps(obj, ensure_ascii=False)\n",
    "                                            fallback_ok = True\n",
    "                                    except Exception:\n",
    "                                        fallback_ok = False\n",
    "\n",
    "                                if fallback_ok:\n",
    "                                    new_tools.append(fallback_patched)\n",
    "                                    updated_count += 1\n",
    "                                    _append_audit_event(\n",
    "                                        audit_file,\n",
    "                                        {\n",
    "                                            \"event_type\": \"patch_fallback_reserialize\",\n",
    "                                            \"ts\": int(time.time()),\n",
    "                                            \"session_id\": session_id,\n",
    "                                            \"instance_key\": instance_key,\n",
    "                                            \"record_id\": rid,\n",
    "                                            \"tool_index\": tool_index,\n",
    "                                            \"tool_name\": tool_obj.get(\"name\"),\n",
    "                                            \"entry_sha256_before\": _sha256_text(entry),\n",
    "                                            \"entry_sha256_after\": _sha256_text(fallback_patched),\n",
    "                                            \"patch_reason\": reason,\n",
    "                                        },\n",
    "                                    )\n",
    "                                else:\n",
    "                                    new_tools.append(entry)\n",
    "                                    patch_failures += 1\n",
    "                                    _append_audit_event(\n",
    "                                        audit_file,\n",
    "                                        {\n",
    "                                            \"event_type\": \"patch_failure\",\n",
    "                                            \"ts\": int(time.time()),\n",
    "                                            \"session_id\": session_id,\n",
    "                                            \"instance_key\": instance_key,\n",
    "                                            \"record_id\": rid,\n",
    "                                            \"tool_index\": tool_index,\n",
    "                                            \"tool_name\": tool_obj.get(\"name\"),\n",
    "                                            \"status\": status,\n",
    "                                            \"patch_reason\": reason,\n",
    "                                            \"final_description_sha256\": _sha256_text(new_desc),\n",
    "                                            \"entry_sha256\": _sha256_text(entry),\n",
    "                                            \"entry_excerpt\": entry[:240],\n",
    "                                            \"llm_text_raw_primary_sha256\": _sha256_text((llm_bundle or {}).get(\"llm_text_raw_primary\") or \"\"),\n",
    "                                            \"llm_text_raw_retry_sha256\": _sha256_text((llm_bundle or {}).get(\"llm_text_raw_retry\") or \"\"),\n",
    "                                            \"proposal_origin\": (llm_bundle or {}).get(\"proposal_origin\"),\n",
    "                                        },\n",
    "                                    )\n",
    "                        else:\n",
    "                            if tool_obj.get(\"description\") == new_desc:\n",
    "                                new_tools.append(tool_obj)\n",
    "                                continue\n",
    "                            tool_obj[\"description\"] = new_desc\n",
    "                            new_tools.append(tool_obj)\n",
    "                            updated_count += 1\n",
    "                    else:\n",
    "                        new_tools.append(entry)\n",
    "\n",
    "                record[tool_field] = new_tools\n",
    "\n",
    "            fout.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    if create_backup_of_target:\n",
    "        bak_path = path.with_suffix(path.suffix + \".bak\")\n",
    "        if not bak_path.exists():\n",
    "            shutil.copy2(path, bak_path)\n",
    "\n",
    "    tmp_path.replace(path)\n",
    "    after_sha = _sha256_file(path)\n",
    "\n",
    "    n_reviewed = len(decisions_by_instance)\n",
    "    n_skipped = sum(1 for st, _, _ in decisions_by_instance.values() if st == \"skipped\")\n",
    "    completed = (n_reviewed >= n_total) and (not quit_requested)\n",
    "\n",
    "    _append_audit_event(\n",
    "        audit_file,\n",
    "        {\n",
    "            \"event_type\": \"run_end\",\n",
    "            \"ts\": int(time.time()),\n",
    "            \"session_id\": session_id,\n",
    "            \"mode\": MODE_KEY,\n",
    "            \"model\": llm_model,\n",
    "            \"seed\": seed,\n",
    "            \"dataset_path\": str(path),\n",
    "            \"dataset_sha256_at_session_start\": before_sha,\n",
    "            \"dataset_sha256_at_session_end\": after_sha,\n",
    "            \"n_total_occurrences\": n_total,\n",
    "            \"n_reviewed_total\": n_reviewed,\n",
    "            \"n_updated_this_session\": updated_count,\n",
    "            \"n_skipped_total\": n_skipped,\n",
    "            \"completed\": bool(completed),\n",
    "            \"quit_requested\": bool(quit_requested),\n",
    "            \"raw_patch_failures_this_session\": patch_failures,\n",
    "            \"resume_next_index_1based\": resume_next_index_1based if quit_requested else (n_total + 1 if completed else None),\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(\"\\nChanges applied.\")\n",
    "    print(f\"Descriptions updated (this session): {updated_count}\")\n",
    "    if patch_failures:\n",
    "        print(f\"Raw JSON-string patch failures (left unchanged): {patch_failures}\")\n",
    "    print(f\"Reviewed total (from audit): {n_reviewed} / {n_total}\")\n",
    "    print(f\"Completed: {completed} (quit_requested={quit_requested})\")\n",
    "    if quit_requested and resume_next_index_1based is not None:\n",
    "        print(f\"Resume next time from: [{resume_next_index_1based}/{n_total}]\")\n",
    "    print(f\"Updated file: {path}\")\n",
    "    print(f\"Audit file (same on resume): {audit_file}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT_JSONL = \"When2Call/data/test/when2call_test_llm_judge.jsonl\"\n",
    "    OUTPUT_JSONL = \"When2Call/data/test/when2call_test_llm_judge.WORKING_COPY.jsonl\"\n",
    "\n",
    "    working = make_working_copy(INPUT_JSONL, OUTPUT_JSONL, overwrite=False)\n",
    "    print(f\"Working copy: {working}\")\n",
    "\n",
    "    seed_env = os.environ.get(\"GEMINI_SEED\")\n",
    "    seed_val: Optional[int] = int(seed_env.strip()) if (seed_env and seed_env.strip()) else None\n",
    "\n",
    "    max_tokens_env = os.environ.get(\"GEMINI_MAX_TOKENS\")\n",
    "    max_tokens_val = int(max_tokens_env.strip()) if (max_tokens_env and max_tokens_env.strip()) else DEFAULT_MAX_TOKENS\n",
    "\n",
    "    retry_max_tokens_env = os.environ.get(\"GEMINI_RETRY_MAX_TOKENS\")\n",
    "    retry_max_tokens_val = int(retry_max_tokens_env.strip()) if (retry_max_tokens_env and retry_max_tokens_env.strip()) else RETRY_MAX_TOKENS\n",
    "\n",
    "    allow_reserialize_env = os.environ.get(\"ALLOW_RESERIALIZE_FALLBACK\")\n",
    "    allow_reserialize_val = (\n",
    "        bool(int(allow_reserialize_env.strip()))\n",
    "        if (allow_reserialize_env and allow_reserialize_env.strip())\n",
    "        else DEFAULT_ALLOW_RESERIALIZE_FALLBACK\n",
    "    )\n",
    "\n",
    "    interactive_llm_verbose_tools_in_jsonl(\n",
    "        working,\n",
    "        tool_field=\"tools\",\n",
    "        create_backup_of_target=False,\n",
    "        llm_model=LLM_MODEL,\n",
    "        seed=seed_val,\n",
    "        max_tokens=max_tokens_val,\n",
    "        retry_on_length=RETRY_ON_LENGTH,\n",
    "        retry_max_tokens=retry_max_tokens_val,\n",
    "        allow_reserialize_fallback=allow_reserialize_val,\n",
    "        min_sleep_sec_between_calls=0.0,\n",
    "        audit_dir=\"audit\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7272157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
